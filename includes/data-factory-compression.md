### <a name="compression-support"></a>Поддержка сжатия
Обработка больших наборов данных может привести к возникновению узких мест ввода-вывода и сети. Поэтому использование сжатых данных в хранилищах может не только ускорить передачу данных по сети и освободить место на диске, но также обеспечить и значительное повышение производительности при обработке больших данных. Сейчас сжатие поддерживается для файловых хранилищ данных, таких как хранилище BLOB-объектов Azure или локальная файловая система.  

> [!NOTE]
> Параметры сжатия для данных в форматах **AvroFormat**, **OrcFormat** или **ParquetFormat** не поддерживаются. 
> 
> 

Чтобы указать сжатие для набора данных, используйте свойство **compression** в наборе данных JSON, как показано в следующем примере.   

```json
{  
    "name": "AzureBlobDataSet",  
      "properties": {  
        "availability": {  
            "frequency": "Day",  
              "interval": 1  
        },  
        "type": "AzureBlob",  
        "linkedServiceName": "StorageLinkedService",  
        "typeProperties": {  
            "fileName": "pagecounts.csv.gz",  
              "folderPath": "compression/file/",  
              "compression": {  
                "type": "GZip",  
                "level": "Optimal"  
              }  
        }  
      }  
}  
```

Раздел **compression** содержит два свойства:  

* **Type** — кодек сжатия; возможные значения: **GZIP**, **Deflate** и **BZIP2**.  
* **Level** — коэффициент сжатия; возможные значения: **Optimal** и **Fastest**. 
  
  * **Fastest:** операция сжатия должна выполняться как можно быстрее, даже если итоговый файл сжимается не оптимально. 
  * **Optimal**: операция сжатия должна выполняться оптимально, даже если для ее завершения требуется больше времени. 
    
    Дополнительные сведения см. в статье [Уровень сжатия](https://msdn.microsoft.com/library/system.io.compression.compressionlevel.aspx). 

Предположим, что приведенный выше пример набора данных используется в качестве результата операции копирования. Эта операция сжимает выходные данные с использованием кодека GZIP и оптимального коэффициента сжатия, а затем записывает сжатые данные в файл с именем pagecounts.csv.gz в хранилище BLOB-объектов Azure.   

При задании свойства "compression" во входном наборе входных данных JSON конвейер может считывать сжатые данные из источника, а при задании этого свойства в результирующем наборе данных JSON операция копирования может записывать сжатые данные в место назначения. Ниже приведено несколько примеров сценариев: 

* Считайте сжатые с помощью кодека GZIP данные из BLOB-объекта Azure, распакуйте их и запишите результирующие данные в Базу данных SQL Azure. В этом случае вы определяете входной набор данных BLOB-объекта Azure с помощью  свойства "compression" JSON. 
* Считайте данные из обычного текстового файла в локальной файловой системе, сожмите их в формате GZip и запишите сжатые данные в BLOB-объект Azure. В этом случае вы определяете выходной набор данных BLOB-объекта Azure с помощью  свойства "compression" JSON.  
* Считайте сжатые с помощью кодека GZIP данные из BLOB-объекта Azure, распакуйте их и сожмите с помощью BZIP2, а затем запишите результирующие данные в BLOB-объект Azure. В этом случае вы определяете входной набор данных BLOB-объекта Azure, установив для типа сжатия значение GZIP, и результирующий набор данных, установив для типа сжатия значение BZIP2.   



<!--HONumber=Nov16_HO3-->


