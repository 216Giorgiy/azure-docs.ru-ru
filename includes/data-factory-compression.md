### Поддержка сжатия  
Обработка больших наборов данных может привести к возникновению узких мест ввода-вывода и сети. Поэтому использование сжатых данных в хранилищах может не только ускорить передачу данных по сети и освободить место на диске, но также обеспечить и значительное повышение производительности при обработке больших данных. В настоящее время сжатие поддерживается для файловых хранилищ данных, таких как хранилище больших двоичных объектов Azure или локальная файловая система.

> [AZURE.NOTE] В данный момент параметры сжатия для данных в формате **AvroFormat** не поддерживаются.

Чтобы указать сжатие для набора данных, используйте свойство **compression** в наборе данных JSON, как показано в следующем примере.

	{  
		"name": "AzureBlobDataSet",  
	  	"properties": {  
	    	"availability": {  
	    		"frequency": "Day",  
	    	  	"interval": 1  
	    	},  
	    	"type": "AzureBlob",  
	    	"linkedServiceName": "StorageLinkedService",  
	    	"typeProperties": {  
	    		"fileName": "pagecounts.csv.gz",  
	    	  	"folderPath": "compression/file/",  
	    	  	"compression": {  
	    	    	"type": "GZip",  
	    	    	"level": "Optimal"  
	    	  	}  
    		}  
	  	}  
	}  
 
Обратите внимание, что раздел **compression** содержит два свойства:
  
- **Type:** кодек сжатия, который может иметь значение **GZIP**, **Deflate** или **BZIP2**.  
- **Level:** коэффициент сжатия, который может иметь значение **Optimal** или **Fastest**. 
	- **Fastest:** операция сжатия должна выполняться как можно быстрее, даже если итоговый файл сжимается не оптимально. 
	- **Optimal**: операция сжатия должна выполняться оптимально, даже если для ее завершения требуется больше времени. 
	
	Дополнительные сведения см. в разделе [Уровень сжатия](https://msdn.microsoft.com/library/system.io.compression.compressionlevel.aspx).

Предположим, что приведенный выше пример набора данных используется в качестве результата операции копирования; эта операция сжимает выходные данные с использованием кодека GZIP и оптимального коэффициента сжатия, а затем записывает сжатые данные в файл с именем pagecounts.csv.gz в хранилище больших двоичных объектов Azure.

При задании свойства "compression" во входном наборе входных данных JSON конвейер может считывать сжатые данные из источника, а при задании этого свойства в результирующем наборе данных JSON операция копирования может записывать сжатые данные в место назначения. Ниже приведено несколько примеров сценариев:

- Считайте сжатые с помощью кодека GZIP данные из BLOB-объекта Azure, распакуйте их и запишите результирующие данные в Базу данных SQL Azure. В этом случае вы определяете входной набор данных BLOB-объекта Azure с помощью свойства "compression" JSON. 
- Считайте данные из обычного текстового файла в локальной файловой системе, сожмите их в формате GZip и запишите сжатые данные в BLOB-объект Azure. В этом случае вы определяете выходной набор данных BLOB-объекта Azure с помощью свойства "compression" JSON.  
- Считайте сжатые с помощью кодека GZIP данные из BLOB-объекта Azure, распакуйте их и сожмите с помощью BZIP2, а затем запишите результирующие данные в BLOB-объект Azure. В этом случае вы определяете входной набор данных BLOB-объекта Azure, установив для типа сжатия значение GZIP, и результирующий набор данных, установив для типа сжатия значение BZIP2.   

<!---HONumber=AcomDC_0224_2016-->