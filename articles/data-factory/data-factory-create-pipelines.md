<properties 
	pageTitle="Конвейеры и действия в фабрике данных Azure | Microsoft Azure" 
	description="Узнайте, что такое конвейеры фабрики данных Azure и как с их помощью перемещать данные и преобразовывать их в готовые к использованию полезные сведения." 
	services="data-factory" 
	documentationCenter="" 
	authors="spelluru" 
	manager="jhubbard" 
	editor="monicar"/>

<tags 
	ms.service="data-factory" 
	ms.workload="data-services" 
	ms.tgt_pltfrm="na" 
	ms.devlang="na" 
	ms.topic="article" y
	ms.date="12/08/2015" 
	ms.author="spelluru"/>

# Конвейеры и действия в фабрике данных Azure
Эта статья поможет вам понять сущность конвейеров и действий в фабрике данных Azure, а также научиться с их помощью создавать комплексные рабочие процессы, управляемые данными, для конкретных бизнес-сценариев. В статье предполагается, что вы уже изучили материалы в разделах [Обзор](data-factory-introduction.md) и [Создание наборов данных](data-factory-create-datasets.md).

## Что такое конвейер
**Конвейеры — это логические группы действий**. С помощью конвейеров действия объединяются в блоки для выполнения определенных задач. Чтобы лучше понять сущность конвейеров, необходимо сначала разобраться с понятием «действия».

### Что такое действие
Действия определяют то, что нужно выполнить с вашими данными. Каждое действие принимает некоторое количество [наборов данных](data-factory-create-datasets.md) на входе и создает один или несколько наборов данных на выходе. **Действие — это единица управления в фабрике данных Azure.**

Действие копирования, например, может использоваться для управления копированием данных из одного набора данных в другой. Аналогичным образом можно использовать действие Hive, которое выполнит запрос Hive к кластеру Azure HDInsight для преобразования или анализа данных. Фабрика данных Azure предоставляет широкий выбор [действий для преобразования, анализа](data-factory-data-transformation-activities.md) и [перемещения данных](data-factory-data-movement-activities.md). Кроме того, вы можете создать действие .NET для выполнения собственного кода.

Рассмотрим два набора данных.

**Набор данных Azure SQL**

Таблица MyTable содержит столбец timestampcolumn, который помогает определить дату и время вставки данных в базу данных.

	{
	  "name": "AzureSqlInput",
	  "properties": {
	    "type": "AzureSqlTable",
	    "linkedServiceName": "AzureSqlLinkedService",
	    "typeProperties": {
	      "tableName": "MyTable"
	    },
	    "external": true,
	    "availability": {
	      "frequency": "Hour",
	      "interval": 1
	    },
	    "policy": {
	      "externalData": {
	        "retryInterval": "00:01:00",
	        "retryTimeout": "00:10:00",
	        "maximumRetry": 3
	      }
	    }
	  }
	}

**Набор данных BLOB-объекта Azure**

Данные копируются в новый BLOB-объект каждый час, и путь, указываемый для объекта, отображает дату и время по часам.

	{
	  "name": "AzureBlobOutput",
	  "properties": {
	    "type": "AzureBlob",
	    "linkedServiceName": "StorageLinkedService",
	    "typeProperties": {
	      "folderPath": "mycontainer/myfolder/yearno={Year}/monthno={Month}/dayno={Day}/hourno={Hour}",
	      "partitionedBy": [
	        {
	          "name": "Year",
	          "value": {
	            "type": "DateTime",
	            "date": "SliceStart",
	            "format": "yyyy"
	          }
	        },
	        {
	          "name": "Month",
	          "value": {
	            "type": "DateTime",
	            "date": "SliceStart",
	            "format": "%M"
	          }
	        },
	        {
	          "name": "Day",
	          "value": {
	            "type": "DateTime",
	            "date": "SliceStart",
	            "format": "%d"
	          }
	        },
	        {
	          "name": "Hour",
	          "value": {
	            "type": "DateTime",
	            "date": "SliceStart",
	            "format": "%H"
	          }
	        }
	      ],
	      "format": {
	        "type": "TextFormat",
	        "columnDelimiter": "\t",
	        "rowDelimiter": "\n"
	      }
	    },
	    "availability": {
	      "frequency": "Hour",
	      "interval": 1
	    }
	  }
	}


Действие копирования в приведенном ниже примере конвейера копирует данные из Azure SQL в хранилище BLOB-объектов Azure. Каждый час оно принимает таблицу Azure SQL в качестве входного набора данных и записывает в хранилище BLOB-объектов Azure данные в виде набора данных AzureBlobOutput. Выходной набор данных тоже создается каждый час. Сведения о том, как копирование данных распределено во времени, см. в разделе «Планирование и выполнение». Для этого конвейера задан 3-часовой период активности: с 2015-01-01T08:00:00 до 2015-01-01T11:00:00.

**Конвейер:**
	
	{  
	    "name":"SamplePipeline",
	    "properties":{  
	    "start":"2015-01-01T08:00:00",
	    "end":"2015-01-01T11:00:00",
	    "description":"pipeline for copy activity",
	    "activities":[  
	      {
	        "name": "AzureSQLtoBlob",
	        "description": "copy activity",
	        "type": "Copy",
	        "inputs": [
	          {
	            "name": "AzureSQLInput"
	          }
	        ],
	        "outputs": [
	          {
	            "name": "AzureBlobOutput"
	          }
	        ],
	        "typeProperties": {
	          "source": {
	            "type": "SqlSource",
	            "SqlReaderQuery": "$$Text.Format('select * from MyTable where timestampcolumn >= \\'{0:yyyy-MM-dd HH:mm}\\' AND timestampcolumn < \\'{1:yyyy-MM-dd HH:mm}\\'', WindowStart, WindowEnd)"
	          },
	          "sink": {
	            "type": "BlobSink"
	          }
	        },
	       "scheduler": {
	          "frequency": "Hour",
	          "interval": 1
	        },
	        "policy": {
	          "concurrency": 1,
	          "executionPriorityOrder": "OldestFirst",
	          "retry": 0,
	          "timeout": "01:00:00"
	        }
	      }
	     ]
	   }
	}

Теперь у вас есть общее представление о том, что такое действие, и можно вернуться к рассмотрению конвейеров.
 
Конвейеры — это логические группы действий. С помощью конвейеров действия объединяются в блоки для выполнения определенных задач. **Конвейер является также единицей развертывания действий и управления ими.** Например, логически связанные действия можно объединить в один конвейер, чтобы одновременно управлять их состоянием.

Выходной набор данных одного действия в конвейере может являться входным для другого действия в том же или другом конвейере в зависимости от того, какие отношения определены между действиями. Подробную информацию см. в разделе [Планирование и выполнение](#scheduling-and-execution).

Создание конвейера в фабрике данных Azure, как правило, состоит из следующих этапов:

1.	Создание фабрики данных (если не создана).
2.	Создание связанной службы для каждого хранилища данных или службы вычислений.
3.	Создание входных и выходных наборов данных.
4.	Создание конвейера с действиями, которые обрабатывают определенные на предыдущем этапе наборы данных.

![Сущности фабрики данных](./media/data-factory-create-pipelines/entities.png)

Рассмотрим определение конвейера подробнее.

## Анатомия конвейера  

В общем виде структуру конвейера можно представить приведенным ниже образом.

	{
	    "name": "PipelineName",
	    "properties": 
	    {
	        "description" : "pipeline description",
	        "activities":
	        [
	
	        ],
			"start": "<start date-time>",
			"end": "<end date-time>"
	    }
	}

В разделе **activities** можно определить одно или несколько действий. Каждое действие имеет приведенную ниже структуру верхнего уровня.

	{
	    "name": "ActivityName",
	    "description": "description", 
	    "type": "<ActivityType>",
	    "inputs":  "[]",
	    "outputs":  "[]",
	    "linkedServiceName": "MyLinkedService",
	    "typeProperties":
	    {
	
	    },
	    "policy":
	    {
	    }
	    "scheduler":
	    {
	    }
	}

В приведенной ниже таблице описаны свойства, используемые в определениях JSON действия и конвейера.

Тег | Описание | Обязательно
--- | ----------- | --------
name | Имя действия или конвейера. Содержит имя операции, которую должно выполнять действие или конвейер.<br/><ul><li>Максимальное количество символов — 260.</li><li>Имя должно начинаться с цифры, буквы или знака подчеркивания (\_).</li><li>Не разрешается использовать следующие символы: ".", "+", "?", "/", "<", ">", "*", "%", "&", ":", "\" </li></ul>| Да description | Текст, описывающий операцию, для выполнения которой используется действие или конвейер. | Да type | Задает тип действия. Описание различных типов действий см. в статьях [Действия перемещения данных](data-factory-data-movement-activities.md) и [Действия преобразования данных](data-factory-data-transformation-activities.md). | Да inputs | Входные таблицы, используемые действием.<p>// одна входная таблица<br/>"inputs": [ { "name": "inputtable1" } ]</p><p>// две входные таблицы<br/>"inputs": [ { "name": "inputtable1" }, { "name": "inputtable2" } ]</p>| Да outputs| Выходные таблицы, используемые действием.<p>одна выходная таблица<br/>"outputs": [ { "name": “outputtable1” } ]</p><p>//две выходные таблицы<br/>"outputs": [ { "name": “outputtable1” }, { "name": “outputtable2” } ]</p>| Да linkedServiceName | Имя связанной службы, используемой действием. <p>В ряде случаев для действий требуется указать связанную службу, через которую осуществляется подключение к вычислительной среде.</p>| Да — для действия HDInsight и действия пакетной оценки показателей машинного обучения Azure<p>Нет — для всех остальных действий</p>typeProperties | Свойства в разделе typeProperties зависят от типа действия. Дополнительные сведения см. в статьях, посвященных конкретным действиям. | Нет policy | Политики, которые влияют на поведение во время выполнения действия. Если для этого свойства не задано значение, используются стандартные политики. Дополнительные сведения см. ниже. | Нет start | Дата и время запуска конвейера. Задается в [формате ISO](http://en.wikipedia.org/wiki/ISO_8601). Например, 2014-10-14T16:32:41Z. <p>Свойства start и end определяют период активности конвейера. Выходные фрагменты создаются только в этот активный период.</p> | Нет<p>Если задано значение для свойства end, необходимо задать значение и для свойства start.</p><p>Для создания конвейера время начала и окончания можно оставить пустым, однако, если требуется задать активный период работы конвейера, следует задать оба значения. Если не указать время начала и окончания при создании конвейера, можно установить их позже с помощью командлета Set-AzureRmDataFactoryPipelineActivePeriod.</p> end | Конечная дата и время для конвейера. Не является обязательным и задается в формате ISO. Например: 2014-10-14T17:32:41Z <p>Для бесконечной работы конвейера задайте значение свойства end равным 9999-09-09.</p>| Нет <p>Если задать значение для свойства start, необходимо задать значение и для свойства end.</p><p>См. примечания для свойства **start**. </p> isPaused | Если задано значение true, конвейер выполняться не будет. Значение по умолчанию — false. Это свойство можно использовать для включения и отключения конвейера. | Нет scheduler| Свойство scheduler используется, чтобы задавать расписание выполнения действия. Для него предусмотрен тот же набор подсвойств, что и для [свойства availability в наборе данных](data-factory-create-datasets.md#Availability). | Нет | 

### Типы действий
Фабрика данных Azure позволяет выполнять широкий спектр действий для [перемещения](data-factory-data-movement-activities.md) и [преобразования данных](data-factory-data-transformation-activities.md).

### Политики
Политики влияют на поведение во время выполнения действия, особенно при обработке среза таблицы. В следующей таблице приведено несколько примеров.

Свойство | Допустимые значения | Значение по умолчанию | Описание
-------- | ----------- | -------------- | ---------------
concurrency | Целое число<p>Максимальное значение — 10</p> | 1 | Количество одновременных запусков действия.<p>Определяет количество параллельных запусков одного действия для обработки разных срезов. Высокое значение этого свойства ускорит обработку большого набора доступных данных.</p> 
executionPriorityOrder | NewestFirst<p>OldestFirst</p> | OldestFirst | Определяет порядок обработки срезов данных.<p>Предположим, есть два ожидающих обработки среза (от 16:00 и от 17:00). Если для свойства executionPriorityOrder задано значение NewestFirst, то срез от 17:00 будет обработан первым. Аналогично, если для executionPriorityORder задано значение OldestFIrst, то первым будет обработан срез от 16:00.</p> 
retry | Целое число<p>Максимальное значение — 10</p> | 3 | Число повторных попыток обработки данных до того, как срез перейдет в состояние Failure (сбой). Выполнение действия со срезом данных повторяется указанное количество раз. Повторная попытка выполняется сразу после неудачной.
timeout | TimeSpan | 00:00:00 | Время ожидания для действия. Пример: 00:10:00 (время ожидания — 10 минут).<p>Если значение не указано или равно 0, время ожидания бесконечно.</p><p>Если время обработки среза превышает время ожидания, система отменяет текущую обработку и начинает новую. Количество повторов зависит от значения свойства retry. Когда время ожидания истекает, состояние среза меняется на TimedOut.</p>
delay | TimeSpan | 00:00:00 | Определяет задержку перед обработкой среза данных.<p>Выполнение действия для среза данных начинается после того, как истекает время задержки.</p><p>Пример: 00:10:00 (10-минутная задержка).</p>
longRetry | Целое число<p>Максимальное значение — 10</p> | 1 | Количество интервальных повторных попыток, после которых срез переходит в состояние Failed (сбой).<p>Попытки longRetry выполняются с интервалом, определяемым свойством longRetryInterval. Используйте свойство longRetry, если повторные попытки необходимо выполнять с паузами. Если заданы значения и для retry, и для longRetry, каждая попытка longRetry будет состоять из попыток retry (то есть общее количество попыток составит произведение количества попыток retry и longRetry).</p><p>Например, для действия настроена такая политика:<br/>retry — 3;<br/>longRetry — 2;<br/>longRetryInterval — 01:00:00.<br/></p><p>Предположим, что требуется обработать только один срез (состояние — Waiting) и при каждом выполнении действия происходит сбой. Первые три попытки будут выполнены подряд. После каждой повторной попытки срез будет находиться в состоянии Retry. После трех попыток состояние среза изменится на LongRetry.</p><p>Через час (значение свойства longRetryInteval) будут выполнены еще три попытки подряд. После этого состояние среза изменится на Failed и дальнейшие попытки предприниматься не будут. Таким образом, всего было предпринято шесть попыток.</p><p>Примечание. Если какая-либо из попыток завершается успешно, срез переходит в состояние Ready и дальнейшие попытки не выполняются.</p><p>Свойство longRetry можно использовать в ситуациях, когда зависимые данные поступают в неопределенное время или если среда обработки данных нестабильна. В таких случаях последовательные попытки могут оказаться бесполезными, а интервальные, напротив, могут привести к желаемому результату.</p><p>Предупреждение. Не задавайте высокие значения для свойств longRetry и longRetryInterval, так как высокие значения могут быть признаками более глубоких системных проблем, которые игнорируются.</p> 
longRetryInterval | TimeSpan | 00:00:00 | Период времени между длительными повторными попытками. 

## Создание конвейера и управление им
Фабрика данных Azure позволяет создавать и развертывать конвейеры (содержащие одно или несколько действий) различными способами.

### Использование портала Azure

1. Перейдите на [портал Azure](https://portal.azure.com/).
2. Выберите экземпляр фабрики данных Azure, в котором хотите создать конвейер.
3. Щелкните элемент **Создание и развертывание** в группе связанных элементов **Сводка**. 
 
	![Плитка «Создание и развертывание»](./media/data-factory-create-pipelines/author-deploy-tile.png)

4. Нажмите кнопку **Создать конвейер** на панели команд.

	![Кнопка «Создать конвейер»](./media/data-factory-create-pipelines/new-pipeline-button.png)

5. В окне редактора отобразится шаблон JSON конвейера.

	![Редактор конвейера](./media/data-factory-create-pipelines/pipeline-in-editor.png)

6. По окончании создания конвейера нажмите кнопку **Развернуть** на панели команд, чтобы развернуть конвейер.

	**Примечание.** Во время развертывания служба фабрики данных Azure выполнит ряд проверок, помогающих избежать распространенных проблем. В случае ошибки появится соответствующее сообщение. Устраните ошибку, а затем повторно разверните созданный конвейер. Для обновления и удаления конвейера можно использовать редактор.

### Использование подключаемого модуля Visual Studio
Для создания и развертывания конвейеров в фабрике данных Azure можно использовать Visual Studio. Дополнительные сведения см. в учебнике [Копирование данных из хранилища Azure в Azure SQL (Visual Studio)](data-factory-get-started-using-vs.md).

### Использование Azure PowerShell
Для создания конвейеров в фабрике данных Azure можно использовать Azure PowerShell. Предположим, вы определили JSON конвейера в файле, который находится в папке c:\\DPWikisample.json. В следующем примере показано, как можно загрузить его в экземпляр фабрики данных Azure.

	New-AzureRmDataFactoryPipeline -ResourceGroupName ADF -Name DPWikisample -DataFactoryName wikiADF -File c:\DPWikisample.json

Дополнительные сведения об этом командлете см. в разделе [Командлет New-AzureRmDataFactoryPipeline](https://msdn.microsoft.com/library/mt619358.aspx).

### Использование интерфейса REST API
Вы можете создавать и развертывать конвейеры также с помощью интерфейса REST API. Это способ является программным. Дополнительные сведения см. в разделе [Создание и обновление конвейеров](https://msdn.microsoft.com/library/azure/dn906741.aspx).

### Использование пакета .NET SDK
Вы можете создавать и развертывать конвейеры, используя пакет .NET SDK. Это способ является программным. Дополнительные сведения см. в разделе [Создание, отслеживание фабрик данных Azure и управление ими программным способом](data-factory-create-data-factories-programmatically.md).


## Планирование и выполнение
Выше мы рассмотрели, что представляют собой конвейеры и действия, как они определяются и для чего используются в фабрике данных Azure. Теперь рассмотрим, как они выполняются.

Конвейер работает только в период активности, то есть между временем начала и окончания. Он не работает до времени начала и после времени окончания. Если конвейер приостановлен, он не будет работать независимо от значений времени начала и окончания. Запустить конвейер можно только в том случае, если он не находится в приостановленном состоянии.

Строго говоря, выполняется не сам конвейер, а действия в нем. Однако это происходит в общем контексте конвейера. Сведения о планировании и выполнении в фабрике данных Azure см. в разделе [Планирование и выполнение](data-factory-scheduling-and-execution.md).

## Управление и мониторинг  
После развертывания конвейера можно управлять им, срезами и циклами выполнения и наблюдать за их состояниями. Дополнительные сведения см. в разделе [Мониторинг конвейеров и управление ими](data-factory-monitor-manage-pipelines.md).

## Дальнейшие действия

- Изучите [планирование и выполнение в фабрике данных Azure](data-factory-scheduling-and-execution.md).  
- Ознакомьтесь с информацией о функциях [перемещения](data-factory-data-movement-activities.md) и [преобразования данных](data-factory-data-transformation-activities.md) в фабрике данных Azure.
- Ознакомьтесь со сведениями об [управлении и мониторинге в фабрике данных Azure](data-factory-monitor-manage-pipelines.md).
- [Создайте и разверните свой первый конвейер](data-factory-build-your-first-pipeline.md). 


 

   













 
 


 

 

<!---HONumber=AcomDC_0218_2016-->