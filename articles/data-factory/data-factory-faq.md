<properties 
	pageTitle="Фабрика данных Azure — часто задаваемые вопросы" 
	description="Часто задаваемые вопросы о фабрике данных Azure." 
	services="data-factory" 
	documentationCenter="" 
	authors="spelluru" 
	manager="jhubbard" 
	editor="monicar"/>

<tags 
	ms.service="data-factory" 
	ms.workload="data-services" 
	ms.tgt_pltfrm="na" 
	ms.devlang="na" 
	ms.topic="article" 
	ms.date="12/01/2015" 
	ms.author="spelluru"/>

# Фабрика данных Azure — часто задаваемые вопросы

## Общие вопросы

### Что такое фабрика данных Azure?

Фабрика данных представляет собой облачную службу интеграции информации, которая организует и автоматизирует перемещение и преобразование данных. Как на производственной фабрике сырье преобразуется в готовую продукцию с помощью оборудования, так и в фабриках данных необработанные данные собираются и преобразуются в готовые к использованию сведения с помощью специальных служб.

Для приема, подготовки, преобразования, анализа и публикации данных фабрики данных используют как локальные, так и облачные источники. Благодаря таким службам, как [Azure HDInsight (Hadoop)](http://azure.microsoft.com/documentation/services/hdinsight/) и [пакетная служба Azure](https://azure.microsoft.com/documentation/services/batch/), фабрики данных позволяют построить управляемый конвейер обработки и преобразования больших объемов данных в соответствии с конкретными потребностями, а [машинное обучение Azure](https://azure.microsoft.com/documentation/services/machine-learning/) позволяет применять их в решениях аналитики. Больше не нужно ограничиваться мониторингом табличных данных: фабрики данных предоставляют широкие возможности визуализации для быстрого анализа тенденций и зависимостей между конвейерами данных. Вы можете использовать унифицированное представление всех конвейеров данных для оперативного выявления проблем и настройки оповещений.

См. раздел [Обзор и основные понятия](data-factory-introduction.md) для получения дополнительных сведений.
 
### Какие проблемы клиента устраняет фабрика данных?

Фабрика данных Azure позволяет сбалансированно применять 2 подхода: с одной стороны — гибкость использования различных систем хранения данных, обработки и перемещения служб между традиционными реляционными хранилищами параллельно с неструктурированными данными, а с другой — возможности контроля и мониторинга полностью управляемой службы.

### Кто является целевой аудиторией для фабрики данных?


- Разработчики данных: те, кто отвечает за создание служб Integration Services между Hadoop и другими системами:
	- Необходимо поддерживать и интегрироваться с постоянно меняющимся и растущим ландшафтом данных
	- Необходимо писать пользовательский код для производства информации, а это — ресурсоемкая задача, которую трудно поддерживать и которая не является высокодоступной или отказоустойчивой

- ИТ-специалисты: те, кто стремится наладить в своей ИТ-инфраструктуре обработку более сложных данных:
	- Необходимо выполнять поиск по всем данным организации для лучшего понимания сути дела
	- Необходимо управлять ресурсами вычислений и хранения для сбалансированности затрат и масштаба как локально, так и в облаке
	- Необходимо быстро добавлять различные источники и процессы для выполнения новых бизнес-задач, сохраняя видимость всех ресурсов вычислений и хранения

### Где можно найти подробную информацию о ценах на фабрику данных Azure?

Подробные сведения о ценах на фабрику данных Azure см. на [странице сведений о ценах на фабрику данных][adf-pricing-details].

### Вопрос. Как приступить к работе с фабрикой данных Azure?

- Общие сведения о фабрике данных Azure см. в разделе [Введение в фабрику данных Azure][adf-introduction].
- Краткое руководство см. в разделе [Приступая к работе с фабрикой данных Azure][adfgetstarted].
- Полная документация содержится в разделе [Документация по фабрике данных Azure][adf-documentation-landingpage].

  
### Как пользователи получают доступ к фабрике данных?

Клиенты могут получать доступ к фабрике данных через [портал Azure][azure-portal].

### Какова региональная доступность фабрики данных?

Фабрика данных доступна в западной части США и в Северной Европе. Службы вычислений и хранения, используемые фабриками данных, могут быть и в других регионах.
 
### Каковы ограничения на число фабрик данных/конвейеров/действий/наборов данных?
 
См. раздел **Ограничения фабрики данных Azure** в статье [Подписка Azure, границы, квоты и ограничения службы](../azure-subscription-service-limits.md#data-factory-limits).


### В чем заключается взаимодействие разработчика со службой фабрики данных Azure?

Вы можете проектировать и создавать фабрики данных с помощью одного из следующих средств.

- **Портал Azure** Колонки фабрики данных на портале Azure предоставляют пользовательский интерфейс для создания связанных служб и фабрик данных. **Редактор фабрики данных**, который также является частью портала, позволяет легко создавать связанные службы, таблицы, наборы данных и конвейеры, просто указывая определения JSON для таких артефактов. В разделе [Начало работы с фабрикой данных][datafactory-getstarted] приведен пример использования портала и редактора для создания и развертывания фабрики данных.   
- **Azure PowerShell**. Если вы знакомы с системой PowerShell и предпочитаете использовать ее вместо пользовательского интерфейса портала, можете воспользоваться командлетами фабрики данных Azure, которые входят в состав Azure PowerShell, для создания и развертывания фабрик данных. В разделе [Создание и мониторинг фабрики данных Azure с помощью Azure PowerShell][create-data-factory-using-powershell] содержится простой пример, а в разделе [Учебник: перемещение и обработка файлов журналов с помощью фабрики данных][adf-tutorial] приводится расширенный пример использования командлетов PowerShell для создания и развертывания фабрики данных. Полная документация по командлетам фабрики данных содержится в [справочнике по командлетам фабрики данных][adf-powershell-reference], который можно найти в библиотеке MSDN.  
- **Visual Studio** Вы можете также использовать Visual Studio для программного создания, мониторинга и управления фабриками данных. Подробную информацию см. в статье [Создание, отслеживание фабрик данных Azure и управление ими с помощью пакета .NET SDK фабрики данных](data-factory-create-data-factories-programmatically.md)  
- **Библиотека классов .NET**. Фабрики данных можно создавать программными средствами с помощью пакета .NET SDK для фабрик данных. Пошаговое руководство по созданию фабрики данных с помощью пакета SDK для .NET см. в разделе [Создание, мониторинг фабрик данных и управление ими с помощью пакета SDK для .NET][create-factory-using-dotnet-sdk]. Полную документация по пакету SDK для .NET фабрик данных см. в [справочнике по библиотеке классов фабрики данных][msdn-class-library-reference].  
- **REST API**. API REST, предоставляемый службой фабрики данных Azure, можно использовать для создания и развертывания фабрик данных. Полную документацию по REST API для фабрик данных см. в [справочнике по REST API фабрики данных][msdn-rest-api-reference]. 

### Можно ли переименовать фабрику данных?
Нет. Как и для других ресурсов Azure, имя фабрики данных Azure изменить нельзя.

## Действия — вопросы и ответы
### Какие источники данных и действия поддерживаются?

Поддерживаемые источники данных и действия описаны в статьях [Действия перемещения данных](data-factory-data-movement-activities.md)и[Действия преобразования данных](data-factory-data-transformation-activities.md).

### Когда запускается действие?
Параметр конфигурации **availability** в таблице выходных данных определяет, когда выполняется действие. Прежде чем действие начнет выполняться, оно проверяет, все ли зависимости входных данных удовлетворяются (т. е. состояние **готовности**).

## Действие копирования — вопросы и ответы
### Что лучше: конвейер с несколькими действиями или отдельный конвейер для каждого действия? 
Предполагается, что конвейеры объединяют связанные действия. Логически действия можно хранить в одном конвейере, если содержащие их таблицы не используются каким-либо действием за пределами конвейера. Таким образом, вам не придется объединять активные периоды конвейера в цепочку, чтобы они были согласованы друг с другом. Кроме того, целостность данных в таблицах конвейера лучше сохраняется при обновлении конвейера. В сущности, обновление конвейера останавливает все действия в конвейере, удаляет их и создает их снова. С точки зрения разработки также будет легче просматривать поток данных в связанных действиях в одном JSON-файле для конвейера.

## Действие HDInsight — вопросы и ответы

### В каких регионах поддерживается HDInsight?

См. раздел «Географическая доступность» в следующей статье или [сведения о ценах на HDInsight][hdinsight-supported-regions].

### Какой регион используется кластером HDInsight по запросу?

Кластер HDInsight по запросу создается в том же регионе, где существует хранилище, которое вы указали для использования с кластером.

### Как связать дополнительные учетные записи хранения с кластером HDInsight?

Если вы используете собственный кластер HDInsight (BYOC), см. следующие разделы:

- [Использование кластера HDInsight с дополнительными учетными записями хранения и метахранилищами][hdinsight-alternate-storage]
- [Использование дополнительных учетных записей хранения с Hive HDInsight][hdinsight-alternate-storage-2]

При использовании кластера по запросу, созданного службой фабрики данных, необходимо указать дополнительные учетные записи хранения для связанной службы HDInsight, чтобы служба фабрики данных могла зарегистрировать их от вашего имени. В определении JSON для связанной службы по запросу используйте свойство **additionalLinkedServiceNames**, чтобы указать дополнительные хранилища учетных записей, как показано в следующем фрагменте кода JSON:
 
	{
	    "name": "MyHDInsightOnDemandLinkedService",
	    "properties":
	    {
	        "type": "HDInsightOnDemandLinkedService",
	        "clusterSize": 1,
	        "timeToLive": "00:01:00",
	        "linkedServiceName": "LinkedService-SampleData",
	        "additionalLinkedServiceNames": [ "otherLinkedServiceName1", "otherLinkedServiceName2" ] 
	    }
	} 

В приведенном выше примере otherLinkedServiceName1 и otherLinkedServiceName2 представляют связанные службы, определения которых содержат учетные данные, необходимые кластеру HDInsight для доступа к дополнительным учетным записям хранения.

## Срезы — вопросы и ответы

### Как повторно выполнять срез?
Вы можете повторно выполнить срез одним из следующих способов:

- Щелкните **Выполнить** в командной строке в колонке **СРЕЗ ДАННЫХ** для среза на портале. 
- Выполните командлет **Set-AzureRmDataFactorySliceStatus** с состоянием, имеющим значение **Waiting** для этого среза.   
	
		Set-AzureRmDataFactorySliceStatus -Status Waiting -ResourceGroupName $ResourceGroup -DataFactoryName $df -TableName $table -StartDateTime "02/26/2015 19:00:00" -EndDateTime "02/26/2015 20:00:00" 

Дополнительные сведения об этом командлете см. в разделе [Set-AzureRmDataFactorySliceStatus][set-azure-datafactory-slice-status].

### Сколько времени занимает обработка среза?
1. Щелкните плитку **Наборы данных** в колонке **ФАБРИКА ДАННЫХ** для своей фабрики данных.
2. Щелкните конкретный набор данных в колонке **Наборы данных**.
3. Выберите интересующий вас срез в списке **последних срезов** в колонке **Таблица**.
4. Щелкните выполняемое действие в списке **выполняемых действий** в колонке **СРЕЗ ДАННЫХ**. 
5. Щелкните плитку **Свойства** в колонке **СВЕДЕНИЯ О ВЫПОЛНЯЕМОМ ДЕЙСТВИИ**. 
6. Вы увидите поле **ДЛИТЕЛЬНОСТЬ** со значением. Это время, затраченное на обработку среза.   

### Как остановить выполнение среза?
Если необходимо остановить выполнение конвейера, можно использовать командлет [Suspend-AzureRmDataFactoryPipeline](https://msdn.microsoft.com/library/mt603721.aspx). В настоящее время приостановка конвейера не останавливает выполняющиеся срезы. После завершения текущих выполняемых задач никакие дополнительные срезы выбираются.

Если вы действительно хотите немедленно прекратить все выполняемые задачи, единственным способом является удаление конвейера и создание его заново. Если вы решили удалить конвейер, НЕ обязательно удалять таблицы и связанные службы, используемые конвейером.



[adfgetstarted]: data-factory-get-started.md
[adf-introduction]: data-factory-introduction.md
[adf-troubleshoot]: data-factory-troubleshoot.md
[datafactory-getstarted]: data-factory-get-started.md
[create-data-factory-using-powershell]: data-factory-monitor-manage-using-powershell.md
[adf-tutorial]: data-factory-tutorial.md
[create-factory-using-dotnet-sdk]: data-factory-create-data-factories-programmatically.md
[msdn-class-library-reference]: https://msdn.microsoft.com/library/dn883654.aspx
[msdn-rest-api-reference]: https://msdn.microsoft.com/library/dn906738.aspx

[adf-powershell-reference]: https://msdn.microsoft.com/library/dn820234.aspx
[adf-documentation-landingpage]: http://go.microsoft.com/fwlink/?LinkId=516909
[azure-portal]: http://portal.azure.com
[set-azure-datafactory-slice-status]: https://msdn.microsoft.com/library/mt603522.aspx

[adf-pricing-details]: http://go.microsoft.com/fwlink/?LinkId=517777
[hdinsight-supported-regions]: http://azure.microsoft.com/pricing/details/hdinsight/
[hdinsight-alternate-storage]: http://social.technet.microsoft.com/wiki/contents/articles/23256.using-an-hdinsight-cluster-with-alternate-storage-accounts-and-metastores.aspx
[hdinsight-alternate-storage-2]: http://blogs.msdn.com/b/cindygross/archive/2014/05/05/use-additional-storage-accounts-with-hdinsight-hive.aspx
 

<!---HONumber=AcomDC_0218_2016-->