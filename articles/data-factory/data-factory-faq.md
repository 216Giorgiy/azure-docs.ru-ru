<properties 
	pageTitle="Фабрика данных Azure — часто задаваемые вопросы" 
	description="Часто задаваемые вопросы о фабрике данных Azure." 
	services="data-factory" 
	documentationCenter="" 
	authors="spelluru" 
	manager="jhubbard" 
	editor="monicar"/>

<tags 
	ms.service="data-factory" 
	ms.workload="data-services" 
	ms.tgt_pltfrm="na" 
	ms.devlang="na" 
	ms.topic="article" 
	ms.date="06/16/2015" 
	ms.author="spelluru"/>

# Фабрика данных Azure — часто задаваемые вопросы

## Общие вопросы

### Вопрос. Что такое фабрика данных Azure?

Фабрика данных является полностью управляемой службой для разработчиков, предназначенной для создания хранилища данных, перемещения и обработки процессов в высоко доступные и отказоустойчивые конвейеры данных. Фабрика данных работает как с локальными, так и с облачными хранилищами данных. Конвейер — это набор входных данных, операций обработки и выходных данных, который определяется с помощью простого сценария JSON и активируется с помощью команд PowerShell. После активации фабрика данных управляет и планирует конвейеры для запуска в HDInsight (Hadoop) с параметрами для автоматического управления кластером от имени пользователя. Фабрика данных также представляет возможности визуального управления и контроля на портале предварительной версии Azure; вы сможете отслеживать все конвейеры, получая разнообразные оперативные данные и информацию о работоспособности службы на единой панели мониторинга.
 
### Вопрос. Какие проблемы клиента решает фабрика данных?

Фабрика данных Azure позволяет сбалансированно применять 2 подхода: с одной стороны — гибкость использования различных систем хранения данных, обработки и перемещения служб между традиционными реляционными хранилищами параллельно с неструктурированными данными, а с другой — возможности контроля и мониторинга полностью управляемой службы.

### Вопрос. Кто является целевой аудиторией для фабрики данных?


- Разработчики данных: те, кто отвечает за создание служб Integration Services между Hadoop и другими системами:
	- Необходимо поддерживать и интегрироваться с постоянно меняющимся и растущим ландшафтом данных
	- Необходимо писать пользовательский код для производства информации, а это — ресурсоемкая задача, которую трудно поддерживать и которая не является высокодоступной или отказоустойчивой

- ИТ-специалисты: те, кто стремится наладить в своей ИТ-инфраструктуре обработку более сложных данных:
	- Необходимо выполнять поиск по всем данным организации для лучшего понимания сути дела
	- Необходимо управлять ресурсами вычислений и хранения для сбалансированности затрат и масштаба как локально, так и в облаке
	- Необходимо быстро добавлять различные источники и процессы для выполнения новых бизнес-задач, сохраняя видимость всех ресурсов вычислений и хранения

###  Вопрос. Где можно найти подробную информацию о ценах на фабрику данных Azure?

Подробные сведения о ценах на фабрику данных Azure см. на [странице сведений о ценах на фабрику данных][adf-pricing-details].

### В. Вопрос. Как приступить к работе с фабрикой данных Azure?

- Общие сведения о фабрике данных Azure см. в разделе [Введение в фабрику данных Azure][adf-introduction].
- Краткое руководство см. в разделе [Приступая к работе с фабрикой данных Azure][adfgetstarted].
- Полная документация содержится в разделе [Документация по фабрике данных Azure][adf-documentation-landingpage].

  
### Вопрос. Как клиенты получают доступ к фабрике данных?

Клиенты могут получать доступ к фабрике данных через [портал предварительной версии Azure][azure-preview-portal].

### Вопрос. Какова региональная доступность фабрики данных?

Общедоступная предварительная версии фабрики данных будет доступна только в Западной части США. Службы вычислений и хранения, используемые фабриками данных, могут быть и в других регионах.
 
### Вопрос. Каковы ограничения на число фабрик данных, конвейеров, действий, наборов данных? 


- Число фабрик данных в пределах подписки: 50.
- Число конвейеров в фабрике данных: 100.
- Число действий в конвейере: 10.
- Число наборов данных в фабрике данных: 100.

### Вопрос. В чем заключается взаимодействие разработчика со службой фабрики данных Azure?

Вы можете проектировать и создавать фабрики данных с помощью одного из следующих средств.

- **Портал предварительной версии Azure** Выноски фабрики данных на портале предварительной версии Azure предоставляют обширные возможности для создания связанных служб и фабрик данных. **Редактор фабрики данных**, который также является частью портала, позволяет легко создавать связанные службы, таблицы, наборы данных и конвейеры, просто указывая определения JSON для таких артефактов. В разделе [Редактор фабрик данных][data-factory-editor] приведены общие сведения о редакторе, а в разделе [Приступая к работе с фабрикой данных][datafactory-getstarted] содержится пример использования портала и редактора для создания и развертывания фабрики данных.   
- **Azure PowerShell**. Если вы знакомы с системой PowerShell и предпочитаете использовать ее вместо пользовательского интерфейса портала, можете воспользоваться командлетами фабрики данных Azure, которые входят в состав Azure PowerShell, для создания и развертывания фабрик данных. В разделе [Создание и мониторинг фабрики данных Azure с помощью Azure PowerShell][create-data-factory-using-powershell] содержится простой пример, а в разделе [Учебник: перемещение и обработка файлов журналов с помощью фабрики данных][adf-tutorial] приводится расширенный пример использования командлетов PowerShell для создания и развертывания фабрики данных. Полная документация по командлетам фабрики данных содержится в [справочнике по командлетам фабрики данных][adf-powershell-reference], который можно найти в библиотеке MSDN.  
- **Библиотека классов .NET**. Фабрики данных можно создавать программными средствами с помощью пакета .NET SDK для фабрик данных. Пошаговое руководство по созданию фабрики данных с помощью пакета SDK для .NET см. в разделе [Создание, мониторинг фабрик данных и управление ими с помощью пакета SDK для .NET][create-factory-using-dotnet-sdk]. Полную документация по пакету SDK для .NET фабрик данных см. в [справочнике по библиотеке классов фабрики данных][msdn-class-library-reference].  
- **REST API**. API REST, предоставляемый службой фабрики данных Azure, можно использовать для создания и развертывания фабрик данных. Полную документацию по REST API для фабрик данных см. в [справочнике по REST API фабрики данных][msdn-rest-api-reference]. 

### Вопрос. Можно ли переименовать фабрику данных?
Нет. Как и для других ресурсов Azure, имя фабрики данных Azure изменить нельзя.

## Действия — вопросы и ответы
### Вопрос. Какие источники данных и действия поддерживаются?

- **Поддерживаемые источники данных.** 
	- Хранилище Azure (большие двоичные объекты и таблицы).
	- Azure SQL.
	- Azure DocumentDB.
	- Локальный сервер SQL Server
	- Локальная база данных Oracle. 
	- Локальная файловая система.
	- Локальная база данных MySQL.
	- Локальная база данных DB2.
	- Локальная база данных Teradata.
	- Локальная база данных Sybase.
	- Локальная база данных PostgreSQL.  
- **Поддерживаемые действия**. 
	- Действие Copy (из локальной среды в облако и из облака в локальную среду).
	- Действие HDInsight (Pig, Hive, MapReduce, потоковые преобразования Hadoop).
	- Действие пакетной оценки показателей машинного обучения Azure.
	- Действие хранимой процедуры SQL Azure.
	- Настраиваемые действия .NET.

### Когда запускается действие?
Параметр конфигурации **availability** в таблице выходных данных определяет, когда выполняется действие. Прежде чем действие начнет выполняться, оно проверяет, все ли зависимости входных данных удовлетворяются (т. е. состояние **готовности**).

## Действие копирования — вопросы и ответы
### Вопрос. В каких регионах поддерживается действие копирования?

Действие копирования поддерживает копирование данных в следующих регионах: восточный регион США, восточный регион США 2, западный регион США, центральный регион США, северо-центральный регион США, юго-центральный регион США, Северная Европа, Западная Европа и Юго-Восточная Азия.

Копирование данных в других регионах также поддерживается при использовании одного из пяти вышеперечисленных регионов для маршрутизации данных. Операция копирования измеряется на основе региона, через который маршрутизуются данные.

Регион назначения копирования | Регион, используемый для маршрутизации
-------------------------- | -----------------------
Восточная Азия | Юго-Восточная Азия
Восточная часть Японии | Запад США
Западная часть Японии | Запад США
Южная часть Бразилии | Восток США 2

### Как копировать в несколько таблиц выходных данных?
У вас может быть несколько выходных таблиц в конвейере, как показано в следующем примере:

	"outputs":  [ 
		{ "name": “outputtable1” }, 
		{ "name": “outputtable2” }  
	],
 
### Что лучше: конвейер с несколькими действиями или отдельный конвейер для каждого действия? 
Предполагается, что конвейеры объединяют связанные действия. Логически действия можно хранить в одном конвейере, если содержащие их таблицы не используются каким-либо действием за пределами конвейера. Таким образом, вам не придется объединять активные периоды конвейера в цепочку, чтобы они были согласованы друг с другом. Кроме того, целостность данных в таблицах конвейера лучше сохраняется при обновлении конвейера. В сущности, обновление конвейера останавливает все действия в конвейере, удаляет их и создает их снова. С точки зрения разработки также будет легче просматривать поток данных в связанных действиях в одном JSON-файле для конвейера.

## Действие HDInsight — вопросы и ответы

### Вопрос. В каких регионах поддерживается HDInsight?

См. раздел «Географическая доступность» в следующей статье или [сведения о ценах на HDInsight][hdinsight-supported-regions].

### Вопрос. Какой регион используется кластером HDInsight по запросу?

Кластер HDInsight по запросу создается в том же регионе, где существует хранилище, которое вы указали для использования с кластером.

### Вопрос. Как связать дополнительные учетные записи хранения с кластером HDInsight?

Если вы используете собственный кластер HDInsight (BYOC), см. следующие разделы:

- [Использование кластера HDInsight с дополнительными учетными записями хранения и метахранилищами][hdinsight-alternate-storage]
- [Использование дополнительных учетных записей хранения с Hive HDInsight][hdinsight-alternate-storage-2]

При использовании кластера по запросу, созданного службой фабрики данных, необходимо указать дополнительные учетные записи хранения для связанной службы HDInsight, чтобы служба фабрики данных могла зарегистрировать их от вашего имени. В определении JSON для связанной службы по запросу используйте свойство **additionalLinkedServiceNames**, чтобы указать дополнительные хранилища учетных записей, как показано в следующем фрагменте кода JSON:
 
	{
	    "name": "MyHDInsightOnDemandLinkedService",
	    "properties":
	    {
	        "type": "HDInsightOnDemandLinkedService",
	        "clusterSize": 1,
	        "timeToLive": "00:01:00",
	        "linkedServiceName": "LinkedService-SampleData",
	        "additionalLinkedServiceNames": [ "otherLinkedServiceName1", "otherLinkedServiceName2" ] 
	    }
	} 

В приведенном выше примере otherLinkedServiceName1 и otherLinkedServiceName2 представляют связанные службы, определения которых содержат учетные данные, необходимые кластеру HDInsight для доступа к дополнительным учетным записям хранения.

## Действие хранимой процедуры — вопросы и ответы
### Какие источники данных поддерживает действие хранимой процедуры?
Действие хранимой процедуры в настоящее время поддерживает только базу данных SQL Azure.

## Срезы — вопросы и ответы

### Как повторно выполнять срез?
Вы можете повторно выполнить срез одним из следующих способов:

- Щелкните **Выполнить** в командной строке в колонке **СРЕЗ ДАННЫХ** для среза на портале. 
- Выполните командлет **AzureDataFactorySliceStatus** с состоянием, имеющим значение **PendingExecution** для этого среза.   
	
		Set-AzureDataFactorySliceStatus -Status PendingExecution -ResourceGroupName $ResourceGroup -DataFactoryName $df -TableName $table -StartDateTime "02/26/2015 19:00:00" -EndDateTime "02/26/2015 20:00:00" 

Дополнительные сведения об этом командлете см. в разделе [Set-AzureDataFactorySliceStatus][set-azure-datafactory-slice-status].

### Сколько времени занимает обработка среза?
1. Щелкните плитку **Наборы данных** в колонке **ФАБРИКА ДАННЫХ** для своей фабрики данных.
2. Щелкните конкретный набор данных в колонке **Наборы данных**.
3. Выберите интересующий вас срез в списке **последних срезов** в колонке **Таблица**.
4. Щелкните выполняемое действие в списке **выполняемых действий** в колонке **СРЕЗ ДАННЫХ**. 
5. Щелкните плитку **Свойства** в колонке **СВЕДЕНИЯ О ВЫПОЛНЯЕМОМ ДЕЙСТВИИ**. 
6. Вы увидите поле **ДЛИТЕЛЬНОСТЬ** со значением. Это время, затраченное на обработку среза.   

### Как остановить выполнение среза?
Если необходимо остановить выполнение конвейера, можно использовать командлет [Suspend-AzureDataFactoryPipeline](https://msdn.microsoft.com/library/dn834939.aspx). В настоящее время приостановка конвейера не останавливает выполняющиеся срезы. После завершения текущих выполняемых задач никакие дополнительные срезы выбираются.

Если вы действительно хотите немедленно прекратить все выполняемые задачи, единственным способом является удаление конвейера и создание его заново. Если вы решили удалить конвейер, НЕ обязательно удалять таблицы и связанные службы, используемые конвейером.



[image-rerun-slice]: ./media/data-factory-faq/rerun-slice.png

[adfgetstarted]: data-factory-get-started.md
[adf-introduction]: data-factory-introduction.md
[adf-troubleshoot]: data-factory-troubleshoot.md
[data-factory-editor]: data-factory-editor.md
[datafactory-getstarted]: data-factory-get-started.md
[create-data-factory-using-powershell]: data-factory-monitor-manage-using-powershell.md
[adf-tutorial]: data-factory-tutorial.md
[create-factory-using-dotnet-sdk]: data-factory-create-data-factories-programmatically.md
[msdn-class-library-reference]: https://msdn.microsoft.com/library/dn883654.aspx
[msdn-rest-api-reference]: https://msdn.microsoft.com/library/dn906738.aspx

[adf-powershell-reference]: https://msdn.microsoft.com/library/dn820234.aspx
[adf-documentation-landingpage]: http://go.microsoft.com/fwlink/?LinkId=516909
[azure-preview-portal]: http://portal.azure.com
[set-azure-datafactory-slice-status]: https://msdn.microsoft.com/library/azure/dn835095.aspx

[adf-pricing-details]: http://go.microsoft.com/fwlink/?LinkId=517777
[hdinsight-supported-regions]: http://azure.microsoft.com/pricing/details/hdinsight/
[hdinsight-alternate-storage]: http://social.technet.microsoft.com/wiki/contents/articles/23256.using-an-hdinsight-cluster-with-alternate-storage-accounts-and-metastores.aspx
[hdinsight-alternate-storage-2]: http://blogs.msdn.com/b/cindygross/archive/2014/05/05/use-additional-storage-accounts-with-hdinsight-hive.aspx
 

<!---HONumber=58_postMigration-->