<properties 
	pageTitle="Фабрика данных Azure — часто задаваемые вопросы" 
	description="Часто задаваемые вопросы о фабрике данных Azure." 
	services="data-factory" 
	documentationCenter="" 
	authors="spelluru" 
	manager="jhubbard" 
	editor="monicar"/>

<tags 
	ms.service="data-factory" 
	ms.workload="data-services" 
	ms.tgt_pltfrm="na" 
	ms.devlang="na" 
	ms.topic="article" 
	ms.date="04/18/2016" 
	ms.author="spelluru"/>

# Фабрика данных Azure — часто задаваемые вопросы

## Общие вопросы

### Что такое фабрика данных Azure?

Фабрика данных представляет собой облачную службу интеграции информации, которая **автоматизирует перемещение и преобразование данных**. Как на производственной фабрике сырье преобразуется в готовую продукцию с помощью оборудования, так и в фабриках данных необработанные данные собираются и преобразуются в готовые к использованию сведения с помощью специальных служб.
 
Служба фабрики данных позволяет создавать управляемые данными рабочие процессы для перемещения данных между локальными и облачными хранилищами данных, а также обрабатывать или преобразовывать данные с помощью служб вычислений, таких как Azure HDInsight и аналитика озера данных Azure. Для созданного конвейера, который выполняет необходимое действие, можно запланировать периодический запуск (ежечасно, ежедневно, еженедельно и т. д.).

См. раздел [Обзор и основные понятия](data-factory-introduction.md) для получения дополнительных сведений.

### Где можно найти подробную информацию о ценах на фабрику данных Azure?

Подробные сведения о ценах на фабрику данных Azure см. на [странице сведений о ценах на фабрику данных][adf-pricing-details].

### Вопрос. Как приступить к работе с фабрикой данных Azure?

- Общие сведения о фабрике данных Azure см. в разделе [Введение в фабрику данных Azure](data-factory-introduction.md).
- Краткое руководство см. в разделе [Приступая к работе с фабрикой данных Azure](data-factory-get-started.md).
- Полная документация содержится в разделе [Документация по фабрике данных Azure](https://azure.microsoft.com/documentation/services/data-factory/).
  
### Какова региональная доступность фабрики данных?
Фабрика данных доступна в **западной части США** и в **Северной Европе**. Службы вычислений и хранения, используемые фабриками данных, могут быть и в других регионах. См. раздел [Поддерживаемые регионы](data-factory-introduction.md#supported-regions).
 
### Каковы ограничения на число фабрик данных/конвейеров/действий/наборов данных?
 
См. раздел **Ограничения фабрики данных Azure** в статье [Подписка Azure, границы, квоты и ограничения службы](../azure-subscription-service-limits.md#data-factory-limits).


### В чем заключается взаимодействие разработчика со службой фабрики данных Azure?

Вы можете проектировать и создавать фабрики данных с помощью одного из следующих средств.

- **Портал Azure** Колонки фабрики данных на портале Azure предоставляют пользовательский интерфейс для создания связанных служб и фабрик данных. **Редактор фабрики данных**, который также является частью портала, позволяет легко создавать связанные службы, таблицы, наборы данных и конвейеры, просто указывая определения JSON для таких артефактов. В разделе [Начало работы с фабрикой данных](data-factory-get-started.md) приведен пример использования портала и редактора для создания и развертывания фабрики данных.   

- **Azure PowerShell** Если вы знакомы с системой PowerShell и предпочитаете использовать ее вместо пользовательского интерфейса портала, можете воспользоваться командлетами фабрики данных Azure, которые входят в состав Azure PowerShell, для создания и развертывания фабрик данных. В разделе [Создание и мониторинг фабрики данных Azure с помощью Azure PowerShell](data-factory-monitor-manage-using-powershell.md) содержится простой пример, а в разделе [Учебник: перемещение и обработка файлов журналов с помощью фабрики данных][adf-tutorial] приводится расширенный пример использования командлетов PowerShell для создания и развертывания фабрики данных. Полная документация по командлетам фабрики данных содержится в [справочнике по командлетам фабрики данных][adf-powershell-reference], который можно найти в библиотеке MSDN.
  
- **Visual Studio** Вы можете также использовать Visual Studio для программного создания, мониторинга и управления фабриками данных. Подробную информацию см. в статье [Создание, отслеживание фабрик данных Azure и управление ими с помощью пакета .NET SDK фабрики данных](data-factory-create-data-factories-programmatically.md)
  
- **Библиотека классов .NET** Фабрики данных можно создавать программными средствами с помощью пакета SDK .NET для фабрик данных. Пошаговое руководство по созданию фабрики данных с помощью пакета SDK для .NET см. в разделе [Создание, мониторинг фабрик данных и управление ими с помощью пакета SDK для .NET][create-factory-using-dotnet-sdk]. Полную документация по пакету SDK для .NET фабрик данных см. в [справочнике по библиотеке классов фабрики данных][msdn-class-library-reference].

- **REST API** REST API, предоставляемый службой фабрики данных Azure, можно использовать для создания и развертывания фабрик данных. Полную документацию по REST API для фабрик данных см. в [справочнике по REST API фабрики данных][msdn-rest-api-reference].
 
- **Шаблон Azure Resource Manager** Сведения см. в статье [Руководство. Создание фабрики данных Azure с помощью шаблона Azure Resource Manager](data-factory-build-your-first-pipeline-using-arm.md).

### Можно ли переименовать фабрику данных?
Нет. Как и для других ресурсов Azure, имя фабрики данных Azure изменить нельзя.

## Действия — вопросы и ответы
### Какие типы действий использовать в конвейере фабрики данных Azure? 

- [Действия перемещения данных](data-factory-data-movement-activities.md) для перемещения данных.
- [Действия преобразования данных](data-factory-data-transformation-activities.md) для обработки или преобразования данных. 

### Когда запускается действие?
Параметр конфигурации **availability** в таблице выходных данных определяет, когда выполняется действие. Прежде чем действие начнет выполняться, оно проверяет, все ли зависимости входных данных удовлетворяются (т. е. состояние **Ready**) (если указаны входные наборы данных).

## Действие копирования — вопросы и ответы
### Что лучше: конвейер с несколькими действиями или отдельный конвейер для каждого действия? 
Предполагается, что конвейеры объединяют связанные действия. Логически действия можно хранить в одном конвейере, если содержащие их таблицы не используются каким-либо действием за пределами конвейера. Таким образом, вам не придется объединять активные периоды конвейера в цепочку, чтобы они были согласованы друг с другом. Кроме того, целостность данных в таблицах конвейера лучше сохраняется при обновлении конвейера. В сущности, обновление конвейера останавливает все действия в конвейере, удаляет их и создает их снова. С точки зрения разработки также будет легче просматривать поток данных в связанных действиях в одном JSON-файле для конвейера.

## Действие HDInsight — вопросы и ответы

### В каких регионах поддерживается HDInsight?

См. раздел «Географическая доступность» в следующей статье или [сведения о ценах на HDInsight][hdinsight-supported-regions].

### Какой регион используется кластером HDInsight по запросу?

Кластер HDInsight по запросу создается в том же регионе, где существует хранилище, которое вы указали для использования с кластером.

### Как связать дополнительные учетные записи хранения с кластером HDInsight?

Если вы используете собственный кластер HDInsight (BYOC), см. следующие разделы:

- [Использование кластера HDInsight с дополнительными учетными записями хранения и метахранилищами][hdinsight-alternate-storage]
- [Использование дополнительных учетных записей хранения с Hive HDInsight][hdinsight-alternate-storage-2]

При использовании кластера по запросу, созданного службой фабрики данных, необходимо указать дополнительные учетные записи хранения для связанной службы HDInsight, чтобы служба фабрики данных могла зарегистрировать их от вашего имени. В определении JSON для связанной службы по запросу используйте свойство **additionalLinkedServiceNames**, чтобы указать дополнительные хранилища учетных записей, как показано в следующем фрагменте кода JSON:
 
	{
	    "name": "MyHDInsightOnDemandLinkedService",
	    "properties":
	    {
	        "type": "HDInsightOnDemandLinkedService",
	        "clusterSize": 1,
	        "timeToLive": "00:01:00",
	        "linkedServiceName": "LinkedService-SampleData",
	        "additionalLinkedServiceNames": [ "otherLinkedServiceName1", "otherLinkedServiceName2" ] 
	    }
	} 

В приведенном выше примере otherLinkedServiceName1 и otherLinkedServiceName2 представляют связанные службы, определения которых содержат учетные данные, необходимые кластеру HDInsight для доступа к дополнительным учетным записям хранения.

## Срезы — вопросы и ответы

### Как повторно выполнять срез?
Вы можете повторно выполнить срез одним из следующих способов:

- Щелкните **Выполнить** в командной строке в колонке **СРЕЗ ДАННЫХ** для среза на портале. 
- Выполните командлет **Set-AzureRmDataFactorySliceStatus** с состоянием, имеющим значение **Waiting** для этого среза.   
	
		Set-AzureRmDataFactorySliceStatus -Status Waiting -ResourceGroupName $ResourceGroup -DataFactoryName $df -TableName $table -StartDateTime "02/26/2015 19:00:00" -EndDateTime "02/26/2015 20:00:00" 

Дополнительные сведения об этом командлете см. в разделе [Set-AzureRmDataFactorySliceStatus][set-azure-datafactory-slice-status].

### Сколько времени занимает обработка среза?
1. Щелкните плитку **Наборы данных** в колонке **ФАБРИКА ДАННЫХ** для своей фабрики данных.
2. Щелкните конкретный набор данных в колонке **Наборы данных**.
3. Выберите интересующий вас срез в списке **последних срезов** в колонке **Таблица**.
4. Щелкните выполняемое действие в списке **выполняемых действий** в колонке **СРЕЗ ДАННЫХ**. 
5. Щелкните плитку **Свойства** в колонке **СВЕДЕНИЯ О ВЫПОЛНЯЕМОМ ДЕЙСТВИИ**. 
6. Вы увидите поле **ДЛИТЕЛЬНОСТЬ** со значением. Это время, затраченное на обработку среза.   

### Как остановить выполнение среза?
Если необходимо остановить выполнение конвейера, можно использовать командлет [Suspend-AzureRmDataFactoryPipeline](https://msdn.microsoft.com/library/mt603721.aspx). В настоящее время приостановка конвейера не останавливает выполняющиеся срезы. После завершения текущих выполняемых задач никакие дополнительные срезы выбираются.

Если вы действительно хотите немедленно прекратить все выполняемые задачи, единственным способом является удаление конвейера и создание его заново. Если вы решили удалить конвейер, НЕ обязательно удалять таблицы и связанные службы, используемые конвейером.


[adf-tutorial]: data-factory-tutorial.md
[create-factory-using-dotnet-sdk]: data-factory-create-data-factories-programmatically.md
[msdn-class-library-reference]: https://msdn.microsoft.com/library/dn883654.aspx
[msdn-rest-api-reference]: https://msdn.microsoft.com/library/dn906738.aspx

[adf-powershell-reference]: https://msdn.microsoft.com/library/dn820234.aspx
[azure-portal]: http://portal.azure.com
[set-azure-datafactory-slice-status]: https://msdn.microsoft.com/library/mt603522.aspx

[adf-pricing-details]: http://go.microsoft.com/fwlink/?LinkId=517777
[hdinsight-supported-regions]: http://azure.microsoft.com/pricing/details/hdinsight/
[hdinsight-alternate-storage]: http://social.technet.microsoft.com/wiki/contents/articles/23256.using-an-hdinsight-cluster-with-alternate-storage-accounts-and-metastores.aspx
[hdinsight-alternate-storage-2]: http://blogs.msdn.com/b/cindygross/archive/2014/05/05/use-additional-storage-accounts-with-hdinsight-hive.aspx
 

<!---HONumber=AcomDC_0420_2016-->