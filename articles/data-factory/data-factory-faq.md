<properties 
	pageTitle="Фабрика данных Azure — часто задаваемые вопросы" 
	description="Часто задаваемые вопросы о фабрике данных Azure." 
	services="data-factory" 
	documentationCenter="" 
	authors="spelluru" 
	manager="jhubbard" 
	editor="monicar"/>

<tags 
	ms.service="data-factory" 
	ms.workload="data-services" 
	ms.tgt_pltfrm="na" 
	ms.devlang="na" 
	ms.topic="article" 
	ms.date="04/23/2015" 
	ms.author="spelluru"/>

# Фабрика данных Azure — часто задаваемые вопросы

## Общие вопросы

### В. что такое фабрика данных Azure?

Фабрика данных является полностью управляемой службой для разработчиков, предназначенной для создания хранилища данных, перемещения и обработки процессов в высоко доступные и отказоустойчивые конвейеры данных. Фабрика данных работает как с локальными, так и с облачными хранилищами данных. Конвейер — это набор входных данных, операций обработки и выходных данных, который определяется с помощью простого сценария JSON и активируется с помощью команд PowerShell. После активации фабрика данных управляет и планирует конвейеры для запуска в HDInsight (Hadoop) с параметрами для автоматического управления кластером от имени пользователя. Фабрика данных также представляет возможности визуального управления и контроля на портале предварительной версии Azure; вы сможете отслеживать все конвейеры, получая разнообразные оперативные данные и информацию о работоспособности службы на единой панели мониторинга.
 
### Вопрос. какие запрос клиента фабрика данных решения?

Фабрика данных Azure позволяет сбалансированно применять 2 подхода: с одной стороны — гибкость использования различных систем хранения данных, обработки и перемещения служб между традиционными реляционными хранилищами параллельно с неструктурированными данными, а с другой — возможности контроля и мониторинга полностью управляемой службы.

### Вопрос, являющиеся целевых аудиторий для фабрики данных?


- Разработчики данных: те, кто отвечает за создание служб Integration Services между Hadoop и другими системами:
	- Необходимо поддерживать и интегрироваться с постоянно меняющимся и растущим ландшафтом данных
	- Необходимо писать пользовательский код для производства информации, а это — ресурсоемкая задача, которую трудно поддерживать и которая не является высокодоступной или отказоустойчивой

- ИТ-специалисты: те, кто стремится наладить в своей ИТ-инфраструктуре обработку более сложных данных:
	- Необходимо выполнять поиск по всем данным организации для лучшего понимания сути дела
	- Необходимо управлять ресурсами вычислений и хранения для сбалансированности затрат и масштаба как локально, так и в облаке
	- Необходимо быстро добавлять различные источники и процессы для выполнения новых бизнес-задач, сохраняя видимость всех ресурсов вычислений и хранения

###  Дополнительные сведения об вопрос, где можно найти цен для фабрики данных Azure?

В разделе [сведения о ценах фабрики данных страницы][adf-pricing-details] для сведений о ценах для фабрики данных Azure.

### В. Как начать работу с фабрикой данных Azure?

- Общие сведения о данных фабрика Azure см. [Введение в Azure данные фабрики][adf-introduction].
- Краткий учебник, в разделе [Приступая к работе с фабрикой данных Azure][adfgetstarted].
- Полная документация. в разделе [фабрика данных Azure документации][adf-documentation-landingpage].

  
### Вопрос. как клиентам доступ к данным фабрики

Клиенты могут получить доступ к фабрика данных через [предварительной версии портала Azure][azure-preview-portal].

### В. что такое фабрика данных области доступности?

Общедоступная предварительная версии фабрики данных будет доступна только в Западной части США. Службы вычислений и хранения, используемые фабриками данных, могут быть и в других регионах.
 
### В. Каковы ограничения на число фабрики и конвейеры и действий и наборы данных? 


- Количество данных фабрики в подписке: 50
- Количество конвейеры в фабрику данных: 100
- Число действий в конвейере: 10
- Количество наборов данных с в фабрике данных: 100

### Вопрос. есть опыт разработки разработчик со службой данных фабрика Azure?

Вы можете проектировать и создавать фабрики данных с помощью одного из следующих средств.

- **Предварительную версию портала azure**. Выноски фабрики данных на портале предварительной версии Azure предоставляют обширные возможности для создания связанных служб и фабрик данных.  **Данных фабрики редактора**, который также является частью портала позволяет легко создавать связанные службы, таблицы, наборы данных и конвейеры, указав определения JSON для артефактов. В разделе [фабрики редактора данных][data-factory-editor] Общие сведения о редакторе и [Приступая к работе с фабрикой данных][datafactory-getstarted] пример использования портала и редактор для создания и развертывания фабрика данных.   
- **Azure PowerShell**. Если вы знакомы с системой PowerShell и предпочитаете использовать ее вместо пользовательского интерфейса портала, можете воспользоваться командлетами фабрики данных Azure, которые входят в состав Azure PowerShell, для создания и развертывания фабрик данных. См. [монитор фабрика данных Azure с помощью Azure PowerShell и создать][create-data-factory-using-powershell] простой пример и [учебника: перемещение и обрабатывать файлы журнала, с помощью фабрики данных][adf-tutorial] пример расширенного использования PowerShell cmdles Создание ad развертывание фабрики данных. В разделе [Справочник по командлетам фабрики данных][adf-powershell-reference] содержимого в библиотеке MSDN для Полная документация командлетов фабрика данных.  
- **Библиотеки классов .NET**. Фабрики данных можно создавать программными средствами с помощью пакета .NET SDK для фабрик данных. В разделе [создания, контроля и управления фабрики данных с помощью пакета SDK для .NET][create-factory-using-dotnet-sdk] Пошаговое руководство для создания фабрики данных с помощью пакета SDK для .NET. См. [Справочник по библиотеке классов данных фабрики][msdn-class-library-reference] для подробную документацию пакета SDK .NET фабрики данных.  
- **REST API**. API REST, предоставляемый службой фабрики данных Azure, можно использовать для создания и развертывания фабрик данных. В разделе [Справочник по API REST фабрики данных][msdn-rest-api-reference] полный документацию по API REST фабрики данных. 

## Мероприятия - часто задаваемые вопросы
### В. что такое поддерживаемых источников данных и действия

- **Поддерживаемых источников данных:** хранилища Azure (больших двоичных объектов и таблиц), SQL Server, базы данных SQL Azure, файловая система, база данных Oracle.
- **Поддерживается действий:**: копирование действия (локальной для облака и облака в локальную среду), действия HDInsight (Pig, Hive, MapReduce, преобразований для потоковой передачи Hadoop), Azure машины обучения пакета оценки действия, действия хранимой процедуры и пользовательские действия C#.

### При запуске действия?
 **Доступности** определяет параметр конфигурации в таблице выходных данных при выполнении действия. Действие проверяет, удовлетворяет ли все зависимости входных данных (т. е. **готов** состояние) перед началом выполнения.

## Скопируйте действие - часто задаваемые вопросы
### Вопрос. какие области поддерживаются с помощью операции копирования?

Поддерживает действие копирования, копирование данных в следующих областях: Восток США, восток США 2, Запад США, центральной части США, North Central US, США, Северная Европа, Западной Европе и Юго-Восточная Азия.

Копирование данных в других регионах также поддерживается, с помощью одного из регионов выше для маршрутизации данных. Операция копирования измеряется на основе региона, через который маршрутизуются данные.

Регион назначения копирования | Области используются для маршрутизации
-------------------------- | -----------------------
Восточная Азия | Юго-Восточная Азия
Восточная часть Японии | Запад США
Западная часть Японии | Запад США
Южная часть Бразилии | Восток США 2

### Как копировать с несколькими таблицами вывода
Может иметь несколько выходных таблиц в конвейере, как показано в следующем примере:

	"outputs":  [ 
		{ "name": “outputtable1” }, 
		{ "name": “outputtable2” }  
	],
 
### Что лучше: конвейера с несколькими действиями или отдельный конвейера для каждого действия? 
Предполагается, что конвейеры объединить связанные действия. Логически действия можно хранить в один конвейер Если таблицы, которые их соединяют не подвергался любое действие за пределами конвейера. Таким образом, не потребовалось бы цепочки конвейера активного периода, чтобы они были выровнены друг с другом. Кроме того целостность данных в таблицах в конвейер внутренней лучше сохранятся при обновлении конвейера. По существу конвейера обновления останавливает все действия в конвейере, удаляет их и создает их снова. От создания перспективы, также может легко определить поток данных в связанных действиях в одном файле JSON для конвейера.

## Действие HDInsight - часто задаваемые вопросы

### Вопрос. Какие регионы поддерживаются HDInsight?

В разделе географической доступности в следующей статье: или [сведения о ценах на HDInsight][hdinsight-supported-regions].

### Вопрос. какие области используется кластер HDInsight по запросу?

Кластер HDInsight по запросу создается в том же регионе, где существует хранилище, которое вы указали для использования с кластером.

### Вопрос как связать дополнительные учетные записи хранения для кластера HDInsight?

Если вы используете собственные кластера HDInsight (BYOC - перевести собственные кластера), в следующих разделах:

- [Использование кластера HDInsight с альтернативной хранилища учетных записей и Метахранилищам][hdinsight-alternate-storage]
- [Используйте дополнительные учетные записи хранения с помощью Hive в HDInsight][hdinsight-alternate-storage-2]

При использовании кластера по требованию, созданных службой данных фабрики, необходимо указать дополнительные учетные записи хранения для HDInsight связанные службы, чтобы служба данных фабрики можно зарегистрировать их от вашего имени. В определении JSON для связанной службы по запросу, используйте **additionalLinkedServiceNames** свойство, чтобы указать альтернативные хранилища учетных записей, как показано в следующем фрагменте JSON:
 
	{
	    "name": "MyHDInsightOnDemandLinkedService",
	    "properties":
	    {
	        "type": "HDInsightOnDemandLinkedService",
	        "clusterSize": 1,
	        "timeToLive": "00:01:00",
	        "linkedServiceName": "LinkedService-SampleData",
	        "additionalLinkedServiceNames": [ "otherLinkedServiceName1", "otherLinkedServiceName2" ] 
	    }
	} 

В приведенном выше примере otherLinkedServiceName1 и otherLinkedServiceName2 представляют связанные службы, определения которых содержат учетные данные, необходимые для доступа к учетным записям альтернативное хранилище кластера HDInsight.

## Хранимая процедура действие - часто задаваемые вопросы
### Какие источники данных поддерживают хранимые процедуры действия?
Действие хранимые процедуры в настоящее время поддерживает только базы данных SQL Azure.

## Фрагменты - часто задаваемые вопросы

### Как повторно фрагмента
Можно повторно выполнить срез одним из следующих способов:

- Щелкните **запуска** в командной строке на **СРЕЗ данных** выноску фрагмента на портале. 
- Запустите **AzureDataFactorySliceStatus набора** равным командлет с состоянием **PendingExecution** для диаграммы.   
	
		Set-AzureDataFactorySliceStatus -Status PendingExecution -ResourceGroupName $ResourceGroup -DataFactoryName $df -TableName $table -StartDateTime "02/26/2015 19:00:00" -EndDateTime "02/26/2015 20:00:00" 

В разделе [набора AzureDataFactorySliceStatus][set-azure-datafactory-slice-status] подробные сведения о командлете.

### Сколько времени заняло обработки фрагмента?
1. Щелкните **наборы данных** на плитке **ФАБРИКА данных** выноску поставщика данных.
2. Щелкните конкретного набора данных на **наборы данных** выноски.
3. Выберите срез, который вы заинтересованы в из **последние фрагменты** списке **таблицы** выноски.
4. Щелкните действие, запустите из **действие выполняется** списке **СРЕЗ данных** выноски. 
5. Щелкните **Свойства** на плитке **сведения о выполнении действия** выноски. 
6. Вы увидите **ДЛИТЕЛЬНОСТЬ** со значением поля. Это время, затраченное на обработку фрагмента.   

### Как остановить выполнение среза?
Если необходимо остановить выполнение конвейера, можно использовать [приостановки AzureDataFactoryPipeline](https://msdn.microsoft.com/library/dn834939.aspx) командлета. В настоящее время Приостановка конвейера не останавливает выполнение среза, выполняющихся. После завершения выполняющихся выполнений, без дополнительных фрагмент выбирается.

Если Вы действительно хотите немедленно прекратить выполнение, единственным способом будет удалить конвейера и создайте его заново. Если вы решили удалить конвейера, удалить таблицы и связанные службы, используемые конвейером необязательно.



[image-rerun-slice]: ./media/data-factory-faq/rerun-slice.png

[adfgetstarted]: data-factory-get-started.md
[adf-introduction]: data-factory-introduction.md
[adf-troubleshoot]: data-factory-troubleshoot.md
[data-factory-editor]: data-factory-editor.md
[datafactory-getstarted]: data-factory-get-started.md
[create-data-factory-using-powershell]: data-factory-monitor-manage-using-powershell.md
[adf-tutorial]: data-factory-tutorial.md
[create-factory-using-dotnet-sdk]: data-factory-create-data-factories-programmatically.md
[msdn-class-library-reference]: https://msdn.microsoft.com/library/dn883654.aspx
[msdn-rest-api-reference]: https://msdn.microsoft.com/library/dn906738.aspx

[adf-powershell-reference]: https://msdn.microsoft.com/library/dn820234.aspx
[adf-documentation-landingpage]: http://go.microsoft.com/fwlink/?LinkId=516909
[azure-preview-portal]: http://portal.azure.com
[set-azure-datafactory-slice-status]: https://msdn.microsoft.com/library/azure/dn835095.aspx

[adf-pricing-details]: http://go.microsoft.com/fwlink/?LinkId=517777
[hdinsight-supported-regions]: http://azure.microsoft.com/pricing/details/hdinsight/
[hdinsight-alternate-storage]: http://social.technet.microsoft.com/wiki/contents/articles/23256.using-an-hdinsight-cluster-with-alternate-storage-accounts-and-metastores.aspx
[hdinsight-alternate-storage-2]: http://blogs.msdn.com/b/cindygross/archive/2014/05/05/use-additional-storage-accounts-with-hdinsight-hive.aspx

<!---HONumber=GIT-SubDir--> 