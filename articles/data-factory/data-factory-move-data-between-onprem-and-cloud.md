<properties 
	pageTitle="Перемещение данных между локальным и облачным хранилищами с помощью фабрики данных Azure" 
	description="Узнайте, как перемещать данные между локальным и облачным хранилищами с помощью шлюза управления данными и фабрики данных Azure." 
	services="data-factory" 
	documentationCenter="" 
	authors="spelluru" 
	manager="jhubbard" 
	editor="monicar"/>

<tags 
	ms.service="data-factory" 
	ms.workload="data-services" 
	ms.tgt_pltfrm="na" 
	ms.devlang="na" 
	ms.topic="article" 
	ms.date="01/21/2016" 
	ms.author="spelluru"/>

# Перемещение данных между локальными источниками и облаком при помощи шлюза управления данными
Одной из проблем интеграции данных является незаметное для пользователя перемещение данных между локальной средой и облаком. Для решения этой проблемы в фабрике данных используется шлюз управления данными. Шлюз управления данными — это локально устанавливаемый агент, который позволяет использовать гибридные конвейеры.

Эта статья содержит общие сведения об интеграции локальных хранилищ данных с облачными хранилищами, а также об обработке данных в облаке с использованием фабрики данных. Базовая информация изложена в статье [Действия перемещения данных](data-factory-data-movement-activities.md), а также в других статьях, посвященных основным понятиям фабрики данных. В данной статье предполагается, что вы уже знакомы с основными понятиями фабрики данных, в частности с конвейерами, действиями, наборами данных и действием копирования.

Шлюз данных предоставляет следующие возможности:

1.	Моделирование источников локальных и облачных данных в пределах одной фабрики данных, а также перемещение данных.
2.	Использование единого средства отслеживания и управления с возможностью контроля состояния шлюза при помощи облачной панели мониторинга фабрики данных.
3.	Безопасное управление доступом к локальным источникам данных.
	1. Изменять настройки корпоративного брандмауэра не требуется. Шлюз только пропускает исходящие HTTP-соединения во внешнюю сеть.
	2. Учетные данные для ваших локальных хранилищ данных можно шифровать с помощью личного сертификата.
4.	Эффективное перемещение данных: данные передаются параллельно, благодаря логике автоматического повторения перемещение не зависит от временных сетевых проблем.

## Особенности использования шлюза управления данными
1.	Для нескольких локальных источников данных можно использовать один экземпляр шлюза управления данными, но учтите, что **каждый экземпляр шлюза связан только с одной фабрикой данных Azure** и его невозможно одновременно использовать с другой фабрикой данных.
2.	На компьютере может быть установлен **только один экземпляр шлюза управления данными**. Предположим, у вас есть две фабрики данных, которым необходимо получить доступ к локальным источникам данных. В этом случае вам необходимо установить шлюзы на двух локальных компьютерах, чтобы каждый шлюз был связан с отдельной фабрикой данных.
3.	**Шлюз не должен находиться в той же машине, что и источник данных**, но, если он расположен вблизи источника данных, это сокращает количество времени, требуемого для подключения шлюза к этому источнику. Мы рекомендуем установить шлюз на компьютере, отличном от того, на котором размещен локальный источник данных, чтобы шлюз не конкурировал за использование ресурсов с источником данных.
4.	У вас может быть **несколько шлюзов на разных компьютерах, подключенных к одному и тому же локальному источнику данных**. Например, имеется два шлюза, обслуживающие две фабрики данных, однако один и тот же локальный источник данных зарегистрирован в обеих фабриках данных.
5.	Если вы уже установили шлюз на компьютер, который обслуживает сценарий **Power BI**, установите **отдельный шлюз для фабрики данных Azure** в другой машине.
6.	**Шлюз необходимо использовать, даже если используется ExpressRoute**. 
7.	Источник данных следует считать локальным (то есть защищенным брандмауэром), даже если используется **ExpressRoute**, а для связи между службой и источником данных **используется шлюз**. 

## Установка шлюза управления данными

### Предварительные требования к установке шлюза
1.	Поддерживаемые **операционные системы**: Windows 7, Windows 8/8.1, Windows Server 2008 R2, Windows Server 2012, Windows Server 2012 R2.
2.	Рекомендуемая **конфигурация** для компьютера шлюза: четырехъядерный процессор с тактовой частотой не менее 2 ГГц, не менее 8 ГБ ОЗУ и 80 ГБ дискового пространства.
3.	Когда хост-компьютер переходит в спящий режим, шлюз не может отвечать на запросы данных. Поэтому перед установкой шлюза на компьютере следует настроить соответствующую **схему управления питанием**. Если компьютер настроен на использование режима гибернации, во время установки шлюза отобразится соответствующее сообщение.

Так как циклы копирования выполняются с определенной частотой, ресурсы компьютера (ЦП, память) используются нерегулярно: есть пиковые нагрузки, и есть время простоя. Использование ресурсов также зависит от объема перемещаемых данных. Когда выполняется несколько заданий копирования, в пиковые периоды уровень использования ресурсов системы повышается. Выше приведены минимальные требования к конфигурации. Мы рекомендуем всегда иметь запас ресурсов, поскольку нагрузка зависит от объема перемещаемых данных.

### Установка
Шлюз управления данными можно установить, скачав пакет MSI из [Центра загрузки Майкрософт](https://www.microsoft.com/download/details.aspx?id=39717). Пакет MSI также может использоваться для обновления имеющегося шлюза управления данными до последней версии с сохранением всех параметров. Ссылку на пакет MSI можно найти на портале Azure, следуя приведенным ниже пошаговым инструкциям.


### Рекомендации по установке
1.	Настройте схему управления питанием на хост-компьютере шлюза, отключив спящий режим. Когда хост-компьютер переходит в спящий режим, шлюз не может отвечать на запросы данных.
2.	Создайте резервную копию сертификата, связанного со шлюзом.

## Обновление шлюза управления данными
По умолчанию шлюз управления данными автоматически обновляется, если доступна новая версия. Он не будет обновлен, пока не будут выполнены все запланированные задания. До завершения операции обновления в шлюзе не будут обрабатываться какие-либо дополнительные задачи. Если обновление завершится сбоем, для шлюза будет выполнен откат к предыдущей версии.

Время запланированного обновления отображается на портале в колонке свойств шлюза, на домашней странице диспетчера конфигурации шлюза управления данными и в сообщении уведомления на панели задач. Вы можете установить обновление сразу или дождаться, пока шлюз не будет автоматически обновлен в запланированное время. На следующем снимке экрана показано сообщение уведомления на странице диспетчера конфигурации шлюза управления данными вместе с кнопкой "Обновить", которую можно нажать, чтобы установить обновление немедленно.

![Обновление диспетчера конфигураций DMG](./media/data-factory-move-data-between-onprem-and-cloud/gateway-auto-update-config-manager.png)

Сообщение уведомления на панели задач выглядит следующим образом:

![Сообщение на панели задач](./media/data-factory-move-data-between-onprem-and-cloud/gateway-auto-update-tray-message.png)

На панели задач отображается состояние операции обновления (выполняемой вручную или автоматически). В следующий раз, когда вы откроете диспетчер конфигурации шлюза управления данными, на панели уведомлений отобразится сообщение об обновлении шлюза со ссылкой на [раздел о новых возможностях](data-factory-gateway-release-notes.md).

На вкладке "Обновление" отображается расписание обновления, а также время последнего обновления или установки шлюза. Если функция автоматического обновления отключена, вы увидите соответствующее сообщение, но вы не сможете включить эту функцию на вкладке. Для этого необходимо использовать командлет.
  

## Значки и уведомления на панели задач
На следующем рисунке показаны некоторые значки панели задач.

![значки на панели задач](./media/data-factory-move-data-between-onprem-and-cloud/gateway-tray-icons.png)

Если навести курсор на значок или сообщение уведомления на панели задач, появится всплывающее окно со сведениями о состоянии шлюза или операции обновления.

## Включение или отключение функции автоматического обновления
Чтобы включить или отключить функцию автоматического обновления, сделайте следующее:

1. Запустите Windows PowerShell на компьютере шлюза. 
2. Перейдите в папку C:\\Program Files\\Microsoft Data Management Gateway\\1.0\\PowerShellScript.
3. Выполните следующую команду, чтобы отключить функцию автоматического обновления.   

		.\GatewayAutoUpdateToggle.ps1  -off

4. Чтобы снова включить ее:
	
		.\GatewayAutoUpdateToggle.ps1  -on  

## Рекомендации по портам и безопасности
Описанные здесь рекомендации в первую очередь касаются двух основных брандмауэров: **корпоративного брандмауэра**, работающего на центральном корпоративном маршрутизаторе, и **брандмауэра Windows**, настроенного в качестве основного на локальном компьютере, где установлен шлюз.

![брандмауэры](./media/data-factory-move-data-between-onprem-and-cloud/firewalls.png)

### Подключение шлюза к облачным службам
Чтобы обеспечить подключение шлюза к фабрике данных Azure и другим облачным службам, необходимо убедиться, что настроено правило исходящего трафика для портов **TCP** **80** и **443**. При необходимости можно включить порты **9350**–**9354**. Эти порты использует служебная шина Microsoft Azure для установки подключения между фабрикой данных Azure и шлюзом управления данными. Использование этих портов может повысить эффективность обмена данными между этими компонентами.

На уровне корпоративного брандмауэра необходимо настроить следующие домены и исходящие порты:

| Имена доменов | порты; | Описание |
| ------ | --------- | ------------ |
| **.servicebus.windows.net | 443, 80 | Прослушивание ретранслятора служебной шины через TCP (порт 443 требуется для получения маркера Access Control) | | *.servicebus.windows.net | 9350–9354 | Дополнительное прослушивание ретранслятора служебной шины через TCP | | *.core.windows.net | 443 | HTTPS | | *.clouddatahub.net | 443 | HTTPS | | graph.windows.net | 443 | HTTPS | | login.windows.net | 443 | HTTPS | 

Эти исходящие порты, как правило, включены на уровне брандмауэра Windows. В противном случае домены и порты можно соответствующим образом настроить на компьютере шлюза.

### Настройка учетных данных
Этот входящий порт **8050** будет использовать приложение **Настройка учетных данных** для ретрансляции учетных данных на шлюз в случае настройки локальной связанной службы на портале Azure (подробности ниже в статье). По умолчанию при установке шлюза управления данными программа установки открывается на компьютере шлюза.
 
В случае использования стороннего брандмауэра можно вручную открыть порт 8050. Если во время установки шлюза возникли проблемы с брандмауэром, попробуйте установить шлюз без настройки брандмауэра, используя следующую команду:

	msiexec /q /i DataManagementGateway.msi NOFIREWALL=1

Если порт 8050 не открыт на компьютере шлюза, то для настройки учетных данных хранилища данных в рамках настройки локальной связанной службы необходимо использовать другие способы, помимо приложения **Настройка учетных данных**. Например, можно использовать командлет PowerShell [New-AzureRmDataFactoryEncryptValue](https://msdn.microsoft.com/library/mt603802.aspx). Дополнительные сведения о настройке учетных данных хранилища данных см. в разделе [Настройка учетных данных и безопасность](#setting-credentials-and-security).

**Копирование данных из источника данных в приемник данных**

Необходимо убедиться, что правила брандмауэра в корпоративном брандмауэре, брандмауэре Windows на компьютере шлюза и в самом хранилище данных активированы надлежащим образом. Таким образом шлюз сможет успешно подключиться как к источнику, так и к приемнику. Такие правила необходимо активировать для каждого хранилища данных, задействованного в операции копирования.

Например, для копирования из **локального хранилища данных в базу данных SQL Azure или хранилище данных SQL Azure** необходимо разрешить исходящий обмен данными через **TCP**-порт **1433** как для брандмауэра Windows, так и для корпоративного брандмауэра. Кроме этого, необходимо настроить параметры брандмауэра сервера SQL Azure, чтобы добавить IP-адрес компьютера шлюза в список разрешенных IP-адресов.

### Рекомендации для прокси-сервера
По умолчанию шлюз управления данными использует параметры прокси-сервера Internet Explorer и получает к нему доступ, используя учетные данные по умолчанию. Если вам это не подходит, можно продолжить настройку **параметров прокси-сервера**, как описано ниже, чтобы обеспечить возможность подключения шлюза к фабрике данных Azure.

1.	После установки шлюза управления данными в проводнике создайте резервную копию исходного файла в пути C:\\Program Files\\Microsoft Data Management Gateway\\1.0\\Shared\\diahost.exe.config.
2.	Запустите файл Notepad.exe с правами администратора и откройте текстовый файл с путем C:\\Program Files\\Microsoft Data Management Gateway\\1.0\\Shared\\diahost.exe.config. Там вы найдете тег по умолчанию для system.net:

			<system.net>
				<defaultProxy useDefaultCredentials="true" />
			</system.net>	

	Затем можно добавить подробные сведения о прокси-сервере, например адрес, внутри родительского тега:

			<system.net>
			      <defaultProxy enabled="true">
			            <proxy bypassonlocal="true" proxyaddress="http://proxy.domain.org:8888/" />
			      </defaultProxy>
			</system.net>

	Внутри тега прокси-сервера можно указать дополнительные свойства, чтобы задать требуемые параметры, например scriptLocation. Сведения о синтаксисе см. в разделе [Элемент прокси (параметры сети)](https://msdn.microsoft.com/library/sa91de1e.aspx).

			<proxy autoDetect="true|false|unspecified" bypassonlocal="true|false|unspecified" proxyaddress="uriString" scriptLocation="uriString" usesystemdefault="true|false|unspecified "/>

3. Сохраните файл конфигурации в исходном расположении, а затем перезапустите службу шлюза управления данными для получения изменений. Чтобы сделать это, последовательно выберите **Пуск** > **Services.msc** или откройте **диспетчер конфигурации шлюза управления данными**, нажмите кнопку **Остановить службу**, а затем — **Запустить службу**. Если служба не запускается, вероятно, в измененном файле конфигурации приложения добавлен неправильный синтаксис тегов XML.

Кроме того, необходимо также убедиться, что Microsoft Azure входит в белый список в вашей компании. Список допустимых IP-адресов Microsoft Azure можно скачать в [Центре загрузки Майкрософт](https://www.microsoft.com/download/details.aspx?id=41653).

### Возможные признаки проблем, связанных с брандмауэром и прокси-сервером
Вероятная причина приведенных ниже ошибок — неправильная конфигурация брандмауэра или прокси-сервера, которая блокирует подключение шлюза управления данными к фабрике данных Azure для проверки подлинности. Чтобы настроить брандмауэр и прокси-сервер должным образом, см. раздел выше.

1.	При попытке зарегистрировать шлюз появляется следующая ошибка: "Не удалось зарегистрировать ключ шлюза. Перед повторной попыткой регистрации ключа убедитесь, что шлюз управления данными подключен и на хост-компьютере запущена служба шлюза управления данными".
2.	В диспетчере конфигурации отображается состояние "Отключено" или "Подключение". В средстве просмотра событий Windows в разделе "Журналы приложения и служб" > "Шлюз управления данными" отображается ошибка "Не удается подключиться к удаленному серверу" или "Компонент шлюза управления данными перестал отвечать и будет автоматически перезагружен. Имя компонента: шлюз".

## Устранение неполадок шлюза


- Более подробную информацию можно найти в журналах шлюза в журналах событий Windows. Их можно найти в **средстве просмотра событий** Windows в разделе **Журналы приложения и служб** > **Шлюз управления данными**. Устраняя связанные со шлюзом ошибки, обращайте внимание на события уровня ошибок.
- Если шлюз прекращает работать после **изменения сертификата**, перезапустите (остановите и запустите) **службу шлюза управления данными** с помощью диспетчера конфигурации шлюза управления данными Microsoft или элемента "Службы" на панели управления. Если ошибка сохраняется, может потребоваться предоставить пользователю службы шлюза управления данными явные разрешения для доступа к сертификату в диспетчере сертификатов (certmgr.msc). Учетная запись пользователя для службы по умолчанию: **NT Service\\DIAHostService**. 
- При возникновении ошибок, связанных с подключением к хранилищу данных или с драйвером, запустите **диспетчер конфигурации шлюза управления данными** на компьютере шлюза, перейдите на вкладку **Диагностика**, выберите или введите соответствующие значения для полей в разделе **Проверить подключение к локальному источнику данных с помощью этого шлюза** и нажмите кнопку **Проверить подключение**. Так вы сможете проверить, можно ли подключиться к локальному источнику данных с компьютера шлюза с этими параметрами подключения и учетными данными. Если после установки драйвера тестовое подключение по-прежнему не работает, перезапустите шлюз для того, чтобы получить последние изменения.  

	![Проверить подключение](./media/data-factory-move-data-between-onprem-and-cloud/TestConnection.png)
		
## Пошаговое руководство. Использование шлюза управления данными 
Это руководство поможет вам создать фабрику данных с конвейером, который позволяет перемещать данные из локальной базы данных SQL Server в большой двоичный объект Azure.

### Шаг 1. Создание фабрики данных Azure
На этом шаге вы создадите экземпляр фабрики данных Azure с именем **ADFTutorialOnPremDF** на портале Azure. Фабрику данных также можно создать с помощью командлетов фабрики данных Azure.

1.	После входа на [портал Azure](https://portal.azure.com) щелкните **СОЗДАТЬ** в нижнем левом углу, выберите **Анализ данных** в колонке **Создать**, затем щелкните **Фабрика данных** в колонке **Анализ данных**.

	![Создать -> Фабрика данных](./media/data-factory-move-data-between-onprem-and-cloud/NewDataFactoryMenu.png)
  
6. В колонке **Создать фабрику данных** выполните следующие действия.
	1. Введите **имя** **ADFTutorialOnPremDF**.
	2. Щелкните **ИМЯ ГРУППЫ РЕСУРСОВ** и выберите **ADFTutorialResourceGroup**. Вы можете выбрать существующую группу ресурсов или создать новую группу. Чтобы создать новую группу ресурсов:
		1. Щелкните **Создать новую группу ресурсов**.
		2. В колонке **Создать группу ресурсов** введите **имя** для группы ресурсов и нажмите кнопку **ОК**.

7. Обратите внимание, что в колонке **Новая фабрика данных** установлен флажок **Добавить на начальную панель**.

	![Добавить на начальную панель](./media/data-factory-move-data-between-onprem-and-cloud/OnPremNewDataFactoryAddToStartboard.png)

8. В колонке **Новая фабрика данных** щелкните **Создать**.

	Имя фабрики данных Azure должно быть глобально уникальным. Получив сообщение об ошибке **Имя фабрики данных "ADFTutorialOnPremDF" недоступно**, измените имя фабрики данных (например, на yournameADFTutorialOnPremDF) и попробуйте создать ее еще раз. Выполняя оставшиеся действия, описанные в этом руководстве, вместо ADFTutorialOnPremDF используйте именно это имя.

9. Найдите уведомления, возникшие в процессе создания, нажав кнопку **Уведомления** в строке заголовка, как показано ниже. Чтобы закрыть окно уведомлений, нажмите эту кнопку еще раз.

	![Раздел "УВЕДОМЛЕНИЯ"](./media/data-factory-move-data-between-onprem-and-cloud/OnPremNotificationsHub.png)

11. По завершении создания вы увидите колонку **Фабрика данных**, как показано ниже.

	![Домашняя страница фабрики данных](./media/data-factory-move-data-between-onprem-and-cloud/OnPremDataFactoryHomePage.png)

### Шаг 2. Создание шлюза управления данными
5. В колонке **ФАБРИКА ДАННЫХ** щелкните плитку **Разработка и развертывание**, чтобы запустить **редактор** для фабрики данных.

	![Плитка «Создание и развертывание»](./media/data-factory-move-data-between-onprem-and-cloud/author-deploy-tile.png) 
6.	В редакторе фабрики данных щелкните **... (многоточие)** на панели инструментов, а затем **Новый шлюз данных**. 

	![«Новый шлюз данных» на панели инструментов](./media/data-factory-move-data-between-onprem-and-cloud/NewDataGateway.png)
2. В колонке **Создать** в поле **Имя** введите **adftutorialgateway** и нажмите кнопку **ОК**. 	

	![Колонка "Создать шлюз"](./media/data-factory-move-data-between-onprem-and-cloud/OnPremCreateGatewayBlade.png)

3. В колонке **Настройка** щелкните **Установить непосредственно на этот компьютер**. Это позволит скачать пакет установки для шлюза, а также установить, настроить и зарегистрировать шлюз на компьютере.

	> [AZURE.NOTE] 
	Используйте Internet Explorer или другой браузер, совместимый с Microsoft ClickOnce.
	> 
	> Если вы используете Chrome, перейдите в [интернет-магазин Chrome](https://chrome.google.com/webstore/), введите ClickOnce в строке поиска, выберите одно из расширений ClickOnce и установите его.
	>  
	> То же самое (установку расширения) необходимо сделать и в Firefox. Щелкните **Открыть меню** на панели инструментов (**три горизонтальные линии** в правом верхнем углу), нажмите кнопку **Надстройки**, введите ClickOnce в строку поиска, выберите одно из расширений ClickOnce и установите его.

	![Шлюз — колонка "Настройка"](./media/data-factory-move-data-between-onprem-and-cloud/OnPremGatewayConfigureBlade.png)

	Это самый простой способ (одним щелчком) скачать, установить, настроить и зарегистрировать шлюз в один шаг. Вы увидите, что на компьютере установлено приложение **Microsoft Data Management Gateway Configuration Manager**. Вы также можете найти исполняемый файл **ConfigManager.exe** в папке по следующему пути: **C:\\Program Files\\Microsoft Data Management Gateway\\1.0\\Shared**.

	Шлюз также можно скачать и установить вручную, используя ссылки в этой колонке. Затем вы можете зарегистрировать его с помощью ключа, указанного в текстовом поле **ЗАРЕГИСТРИРОВАТЬ С ПОМОЩЬЮ КЛЮЧА**.
	
	Дополнительная информация о шлюзе, в том числе рекомендации и важные особенности, приведена в первых разделах этой статьи.

	>[AZURE.NOTE] Для успешной установки шлюза управления данными и его настройки вы должны обладать правами администратора на локальном компьютере. В локальную группу Windows "Пользователи шлюза управления данными" можно добавить дополнительных пользователей. Участники этой группы смогут использовать диспетчер конфигурации шлюза управления данными для настройки шлюза.

5. Подождите несколько минут и запустите на компьютере приложение **Диспетчер конфигураций шлюза управления данными**. Для этого введите текст **шлюз управления данными** в окне **Поиск**. Вы также можете найти исполняемый файл **ConfigManager.exe** в папке по следующему пути: **C:\\Program Files\\Microsoft Data Management Gateway\\1.0\\Shared**.

	![Диспетчер конфигурации шлюза](./media/data-factory-move-data-between-onprem-and-cloud/OnPremDMGConfigurationManager.png)

6. Подождите, пока установятся следующие значения:
	1. В поле **Состояние** установлено значение **Работает**.
	2. В поле **Имя шлюза** установлено значение **adftutorialgateway**.
	3. Для **имени экземпляра** установлено значение **adftutorialgateway**.
	4. Для параметра **Регистрация** установлено значение **Зарегистрировано**.
	5. В строке состояния внизу отображается надпись **Установлено подключение к облачной службе шлюза управления данными** и **зеленый флажок**.

8. Перейдите на вкладку **Сертификаты**. Сертификат, указанный на этой вкладке, используется для шифрования и расшифровки учетных данных локального хранилища данных, указанного на портале. Чтобы использовать вместо него собственный сертификат, щелкните **Изменить**. По умолчанию шлюз использует сертификат, который автоматически создан службой фабрики данных.

	![Конфигурация сертификата шлюза](./media/data-factory-move-data-between-onprem-and-cloud/gateway-certificate.png)
9. (Необязательно) Для решения проблем со шлюзом вы можете использовать подробный журнал шлюза. Чтобы включить эту возможность, перейдите на вкладку **Диагностика** и установите флажок **Подробное ведение журнала для устранения неполадок**. Данные журналов можно изучить в **Обозревателе событий**, открыв узел **Журналы приложений и служб** -> **Шлюз управления данными**. 

	![Вкладка «Диагностика»](./media/data-factory-move-data-between-onprem-and-cloud/diagnostics-tab.png)

	Также на этой странице вы можете **проверить соединение** с локальным источником данных через шлюз.
10. На портале Azure нажмите кнопку **ОК** в колонке **Настройка**, а затем в колонке **Новый шлюз данных**.
6. В представлении в виде дерева в левой части окна вы увидите элемент **adftutorialgateway** в узле **Шлюзы данных**. Щелкните его, чтобы увидеть связанные JSON-файлы. 
	

### Шаг 3. Создание связанных служб 
На этом шаге вы создадите две связанные службы: **StorageLinkedService** и **SqlServerLinkedService**. Служба **SqlServerLinkedService** связывает фабрику данных с локальной базой данных SQL Server, а служба **StorageLinkedService** — с хранилищем больших двоичных объектов Azure. Далее это руководство поможет вам создать конвейер, который позволит копировать данные из локальной базы данных SQL Server в службу хранилища больших двоичных объектов Azure.

#### Добавление связанной службы в локальную базу данных SQL Server
1.	В **редакторе фабрики данных** щелкните **Создать хранилище данных** на панели инструментов и выберите **SQL Server**. 

	![Создать связанную службу SQL Server](./media/data-factory-move-data-between-onprem-and-cloud/NewSQLServer.png) 
3.	В **редакторе JSON** выполните следующие действия. 
	1. Для параметра **gatewayName** укажите значение **adftutorialgateway**.	
	2. При использовании проверки подлинности Windows:
		1. Измените строку **connectionString** следующим образом. 
			1. Для параметра **Встроенная система безопасности** установите значение **True**.
			2. Укажите **имя сервера** базы данных и **имя базы данных**. 
			2. Удалите **идентификатор пользователя** и **пароль**. 
		3. Укажите имя пользователя и пароль в свойствах **userName** и **password**.
		
				"typeProperties": {
            		"connectionString": "Data Source=<servername>;Initial Catalog=<databasename>;Integrated Security=True;",
            		"gatewayName": "adftutorialgateway",
            		"userName": "<Specify user name if you are using Windows Authentication>",
            		"password": "<Specify password for the user account>"
        		}

	4. При использовании проверки подлинности SQL:
		1. Укажите **имя сервера** базы данных, **имя базы данных**, **идентификатор пользователя** и **пароль** в строке **connectionString**.       
		2. Удалите из JSON два последних свойства: **userName** и **password**.
		3. Удалите символ **, (запятая)** в конце строки, в которой указано значение свойства **gatewayName**. 

				"typeProperties": {
            		"connectionString": "Data Source=<servername>;Initial Catalog=<databasename>;Integrated Security=False;User ID=<username>;Password=<password>;",
	           		"gatewayName": "<Name of the gateway that the Data Factory service should use to connect to the on-premises SQL Server database>"
    		    }
	   
2.	Нажмите кнопку **Развернуть** на панели команд, чтобы развернуть связанную службу SQL Server.

#### Добавление связанной службы для учетной записи хранения Azure
 
1. В **редакторе фабрики данных** щелкните **Создать хранилище данных** на панели команд и выберите **Хранилище Azure**.
2. В поле **Имя учетной записи** введите имя учетной записи хранения Azure.
3. В поле **Ключ учетной записи** введите ключ учетной записи хранения Azure.
4. Щелкните **Развернуть**, чтобы развернуть службу **StorageLinkedService**.
   
 
### Шаг 4. Создание входных и выходных наборов данных
В этом шаге вы создадите наборы входных и выходных данных, которые представляют собой входные и выходные данные для операции копирования (из локальной базы данных SQL в хранилище больших двоичных объектов Azure). Перед созданием наборов данных или таблиц (прямоугольных наборов данных) необходимо сделать следующее (после списка есть подробные шаги):

- в базе данных SQL Server, которую вы добавили в фабрику данных как связанную службу, создайте таблицу с именем **emp** и вставьте в таблицу пару записей в качестве примера;
- В учетной записи хранения BLOB-объектов Azure, которую вы добавили в качестве связанной службы в фабрику данных, создайте контейнер BLOB-объектов с именем **adftutorial**.

### Подготовка локальной связанной службы SQL Server для учебника

1. В базе данных SQL Server, которую вы указали для локальных связанных служб (**SqlServerLinkedService**), используйте следующий сценарий SQL, чтобы создать в базе данных таблицу **emp**.


        CREATE TABLE dbo.emp
		(
			ID int IDENTITY(1,1) NOT NULL, 
			FirstName varchar(50),
			LastName varchar(50),
    		CONSTRAINT PK_emp PRIMARY KEY (ID)
		)
		GO
 

2. Вставьте несколько образцов в таблицу:


        INSERT INTO emp VALUES ('John', 'Doe')
		INSERT INTO emp VALUES ('Jane', 'Doe')



### Создание входной таблицы

1. В **редакторе фабрики данных** щелкните на панели команд элемент **Создать набор данных** и выберите пункт **Таблица SQL Server**. 
2.	Замените сценарий JSON в области справа на следующий текст:    

		{
		  "name": "EmpOnPremSQLTable",
		  "properties": {
		    "type": "SqlServerTable",
		    "linkedServiceName": "SqlServerLinkedService",
		    "typeProperties": {
		      "tableName": "emp"
		    },
		    "external": true,
		    "availability": {
		      "frequency": "Hour",
		      "interval": 1
		    },
		    "policy": {
		      "externalData": {
		        "retryInterval": "00:01:00",
		        "retryTimeout": "00:10:00",
		        "maximumRetry": 3
		      }
		    }
		  }
		}

	Обратите внимание на следующее:
	
	- **type** имеет значение **SqlServerTable**.
	- **tableName** имеет значение **emp**.
	- Для параметра **linkedServiceName** установлено значение **SqlServerLinkedService** (вы создали эту связанную службу в шаге 2).
	- Если входная таблица не создается другим конвейером фабрики данных Azure, для параметра **external** следует задать значение **true**. Это означает, что входные данные создаются вне службы фабрики данных Azure. При необходимости можно указать любые внешние политики данных с помощью **externalData** в разделе **Policy**.    

	Дополнительную информацию о свойствах JSON-сценариев см. в статье [Справка по использованию JSON-сценариев][json-script-reference].

2. Нажмите кнопку **Развернуть** на панели команд, чтобы развернуть набор данных (таблица представляет собой прямоугольный набор данных). Убедитесь, что в заголовке окна отображается сообщение **ТАБЛИЦА УСПЕШНО РАЗВЕРНУТА**.


### Создание выходной таблицы

1.	В **редакторе фабрики данных** щелкните на панели команд **Создать набор данных** и выберите **Хранилище больших двоичных объектов Azure**.
2.	Замените сценарий JSON в области справа на следующий текст: 

		{
		  "name": "OutputBlobTable",
		  "properties": {
		    "type": "AzureBlob",
		    "linkedServiceName": "StorageLinkedService",
		    "typeProperties": {
		      "folderPath": "adftutorial/outfromonpremdf",
		      "format": {
		        "type": "TextFormat",
		        "columnDelimiter": ","
		      }
		    },
		    "availability": {
		      "frequency": "Hour",
		      "interval": 1
		    }
		  }
		}
  
	Обратите внимание на следующее;
	
	- для параметра **type** задано значение **AzureBlob**;
	- для параметра **linkedServiceName** установлено значение **StorageLinkedService** (вы создали эту связанную службу в шаге 2);
	- для параметра **folderPath** установлено значение **adftutorial/outfromonpremdf**, где outfromonpremdf — это папка в контейнере adftutorial; вам просто нужно создать контейнер **adftutorial**;
	- Параметр **availability** имеет значение **hourly** (параметру **frequency** присваивается значение **hour**, а параметру **interval** — значение **1**). служба фабрики данных будет создавать срез выходных данных каждый час в таблице **emp** в базе данных SQL Azure. 

	Если параметр **fileName** для **входной таблицы** не задан, все файлы и большие двоичные объекты из входной папки (**folderPath**) считаются входными данными. Если указать fileName в JSON, только указанный файл или большой двоичный объект рассматриваются как входные данные. Примеры файлов см. в [учебнике][adf-tutorial].
 
	Если не указать **fileName** для **выходной таблицы**, то созданные в**folderPath** файлы получают имена в следующем формате: Data.<Guid>.txt (например: Data.0a405f8a-93ff-4c6f-b3be-f69616f1df7a.txt.).

	Для динамической установки папки **folderPath** и имени **fileName** на основе времени **SliceStart**, используйте свойство partitionedBy В следующем примере folderPath использует год, месяц и день из SliceStart (время начала обработки среза), а в fileName используется время (часы) из SliceStart. Например, если срез выполняется для временной отметки 2014-10-20T08:00:00, folderName получает значение wikidatagateway/wikisampledataout/2014/10/20, а fileName – 08.csv.

	  	"folderPath": "wikidatagateway/wikisampledataout/{Year}/{Month}/{Day}",
        "fileName": "{Hour}.csv",
        "partitionedBy": 
        [
        	{ "name": "Year", "value": { "type": "DateTime", "date": "SliceStart", "format": "yyyy" } },
            { "name": "Month", "value": { "type": "DateTime", "date": "SliceStart", "format": "MM" } }, 
            { "name": "Day", "value": { "type": "DateTime", "date": "SliceStart", "format": "dd" } }, 
            { "name": "Hour", "value": { "type": "DateTime", "date": "SliceStart", "format": "hh" } } 
        ],

 

	Дополнительную информацию о свойствах JSON-сценариев см. в статье [Справка по использованию JSON-сценариев][json-script-reference].

2.	Нажмите кнопку **Развернуть** на панели команд, чтобы развернуть набор данных (таблица представляет собой прямоугольный набор данных). Убедитесь, что в заголовке окна отображается сообщение **ТАБЛИЦА УСПЕШНО РАЗВЕРНУТА**.
  

### Шаг 5. Создание и запуск конвейера
На этом шаге вы создадите **конвейер** одним **действием копирования**, для выполнения которого **EmpOnPremSQLTable** будет использоваться как входные данные, а **OutputBlobTable** — как выходные данные.

1.	В колонке **ФАБРИКА ДАННЫХ** щелкните плитку **Разработка и развертывание**, чтобы запустить **редактор** для фабрики данных.

	![Плитка «Создание и развертывание»](./media/data-factory-move-data-between-onprem-and-cloud/author-deploy-tile.png) 
2.	Нажмите кнопку **Создать конвейер** на панели команд. Если вы не видите эту кнопку, нажмите **... (многоточие)**, чтобы отобразить ее.
2.	Замените сценарий JSON в области справа на следующий текст:   


		{
		  "name": "ADFTutorialPipelineOnPrem",
		  "properties": {
		    "description": "This pipeline has one Copy activity that copies data from an on-prem SQL to Azure blob",
		    "activities": [
		      {
		        "name": "CopyFromSQLtoBlob",
		        "description": "Copy data from on-prem SQL server to blob",
		        "type": "Copy",
		        "inputs": [
		          {
		            "name": "EmpOnPremSQLTable"
		          }
		        ],
		        "outputs": [
		          {
		            "name": "OutputBlobTable"
		          }
		        ],
		        "typeProperties": {
		          "source": {
		            "type": "SqlSource",
		            "sqlReaderQuery": "select * from emp"
		          },
		          "sink": {
		            "type": "BlobSink"
		          }
		        },
		        "Policy": {
		          "concurrency": 1,
		          "executionPriorityOrder": "NewestFirst",
		          "style": "StartOfInterval",
		          "retry": 0,
		          "timeout": "01:00:00"
		        }
		      }
		    ],
		    "start": "2015-02-13T00:00:00Z",
		    "end": "2015-02-14T00:00:00Z",
		    "isPaused": false
		  }
		}

	Обратите внимание на следующее.
 
	- В разделе действий есть только действие, для параметра **type** которого задано значение **Copy**.
	- для параметра действия **input** установлено значение **EmpOnPremSQLTable**, а для **output** — **OutputBlobTable**;
	- В разделе **transformation** в качестве **типа источника** задано значение **SqlSource**, а в качестве **типа приемника** — **BlobSink**.
- для свойства **sqlReaderQuery** типа **SqlSource** задан вид SQL-запроса **select * from emp**.

	Замените значение свойства **start** текущей датой, а значение свойства **end** — датой следующего дня. Даты начала и окончания должны быть в [формате ISO](http://en.wikipedia.org/wiki/ISO_8601). Например, 2014-10-14T16:32:41Z. Время **окончания** указывать не обязательно, однако в этом примере мы будем его использовать.
	
	Если не указать значение свойства **end**, оно вычисляется по формуле "**время начала + 48 часов**". Чтобы запустить конвейер в течение неопределенного срока, укажите значение **9/9/9999** для свойства **end**.
	
	Вы определяете интервал времени, в который будут выполняться срезы данных на основе свойств **доступности**, определенных для каждой таблицы фабрики данных Azure.
	
	В приведенном выше примере будет 24 среза данных, так как срезы данных производятся каждый час.
	
2. Нажмите кнопку **Развернуть** на панели команд, чтобы развернуть набор данных (таблица представляет собой прямоугольный набор данных). Убедитесь, что в заголовке окна отображается сообщение **КОНВЕЙЕР УСПЕШНО РАЗВЕРНУТ**.
5. Теперь закройте колонку **Редактор**, щелкнув **X**. Щелкните **X** снова, чтобы закрыть колонку ADFTutorialDataFactory с представлением панели инструментов и дерева. При отображении сообщения **Несохраненные редакторы будут отклонены** щелкните **ОК**.
6. После этого следует вернуться к колонке **ФАБРИКА ДАННЫХ** для фабрики **ADFTutorialOnPremDF**.

**Поздравляем!** Вы успешно создали фабрику данных Azure, связанные службы, таблицы и конвейер, а также выполнили планирование конвейера.

#### Просмотр фабрики данных в представлении схемы 
1. На **классическом портале Azure** щелкните элемент **Схемы** на домашней странице фабрики данных **ADFTutorialOnPremDF**.

	![Ссылка на схему](./media/data-factory-move-data-between-onprem-and-cloud/OnPremDiagramLink.png)

2. Вы должны увидеть схему, аналогичную приведенной ниже:

	![Представление схемы](./media/data-factory-move-data-between-onprem-and-cloud/OnPremDiagramView.png)

	Можно увеличивать и уменьшать масштаб, выбирать 100%-й масштаб или масштаб по размеру, автоматически размещать конвейеры и таблицы, а также отображать сведения из журнала обращений и преобразований (выделение восходящих и нисходящих элементов для выбранных элементов). Дважды щелкните объект (входную или выходную таблицу или конвейер), чтобы просмотреть его свойства.

### Шаг 6. Мониторинг наборов данных и конвейеров
В этом шаге вы будете использовать портал Azure для мониторинга фабрики данных Azure. Вы также можете использовать командлеты PowerShell для мониторинга наборов данных и конвейеров. Дополнительные сведения о мониторинге см. в статье [Мониторинг конвейеров и управление ими](data-factory-monitor-manage-pipelines.md).

1. Перейдите на **классический портал Azure** (если вы закрыли страницу портала).
2. Если колонка для **ADFTutorialOnPremDF** закрыта, откройте ее, щелкнув **ADFTutorialOnPremDF** на **начальной панели**.
3. Вы увидите **количество** и **имена** таблиц, а также конвейер, который вы создали в этой колонке.

	![Домашняя страница фабрики данных](./media/data-factory-move-data-between-onprem-and-cloud/OnPremDiagramView.png)
4. Теперь щелкните плитку **Наборы данных**.
5. В колонке **Наборы данных** щелкните **EmpOnPremSQLTable**.

	![Срезы EmpOnPremSQLTable](./media/data-factory-move-data-between-onprem-and-cloud/OnPremSQLTableSlicesBlade.png)

6. Обратите внимание, что срезы данных до текущего момента времени уже выполнены и все они находятся в состоянии **Готов**. Это результат того, что вы вставили данные в базу данных SQL Server, и они находились там все время. Убедитесь, что в разделе **Проблемные срезы** в нижней части окна не показаны срезы.


	Оба списка, **Недавно обновленные срезы** и **Срезы, в которых недавно произошел сбой**, сортируются по **ПОСЛЕДНЕМУ ВРЕМЕНИ ОБНОВЛЕНИЯ**. Время обновления среза изменяется в таких ситуациях:
    

	-  Вы обновляете состояние среза вручную, например используя командлет **Set-AzureRmDataFactorySliceStatus** или щелкнув **ВЫПОЛНИТЬ** в колонке **СРЕЗ** для этого среза.
	-  В ходе выполнения состояние среза меняется (например, выполнение началось, выполнение завершилось со сбоем, выполнение завершилось успешно и т. п.).
 
	Щелкните заголовок списков или **... (многоточие)**, чтобы просмотреть расширенный список срезов. Чтобы отфильтровать срезы, выберите пункт **Фильтр** на панели инструментов.
	
	Чтобы вместо этого просмотреть срезы данных, отсортированные по времени начала и окончания среза, щелкните плитку **Срезы данных (по времени среза)**.

7. Затем в колонке **Наборы данных** щелкните **OutputBlobTable**.

	![OputputBlobTable slices][image-data-factory-output-blobtable-slices]
8. Убедитесь, что выполнены срезы вплоть до текущего времени и состояние каждого из них — **Готово**. Подождите, пока значение состояния срезов до текущего времени **Готово**.
9. Щелкните любой срез данных в списке для отображения колонки **СРЕЗ ДАННЫХ**.

	![Колонка среза данных](./media/data-factory-move-data-between-onprem-and-cloud/DataSlice.png)

	Если срез не находится в состоянии **Готов**, вы можете увидеть восходящие срезы, которые не находятся в состоянии готовности и блокируют выполнение текущего среза в списке **Неготовые восходящие срезы**.

10. Щелкните **выполненное действие** в нижней части списка, чтобы просмотреть **дополнительную информацию о выполненном действии**.

	![Activity Run Details blade][image-data-factory-activity-run-details]

11. Закройте все колонки, щелкая значок **X**, пока
12. не вернетесь к начальной колонке **ADFTutorialOnPremDF**.
14. (Необязательно) Щелкните **Конвейеры**, а затем — **ADFTutorialOnPremDF** и просмотрите параметры входных таблиц (**Использовано**) или выходных таблиц (**Выполнено**).
15. Используйте инструменты, такие как **обозреватель хранилищ Azure** для проверки выходных данных.

	![Обозреватель хранилищ Azure](./media/data-factory-move-data-between-onprem-and-cloud/OnPremAzureStorageExplorer.png)

## Перемещение шлюза с одного компьютера на другой
Этот раздел содержит процедуру перемещения клиента шлюза с одного компьютера на другой.

2. На портале перейдите на **главную страницу фабрики данных**, а затем щелкните плитку **Связанные службы**. 

	![Ссылка на шлюзы данных](./media/data-factory-move-data-between-onprem-and-cloud/DataGatewaysLink.png) 
3. Выберите нужный шлюз в разделе **ШЛЮЗЫ ДАННЫХ** в колонке **Связанные службы**.
	
	![Колонка «Связанные службы» с выбранным шлюзом](./media/data-factory-move-data-between-onprem-and-cloud/LinkedServiceBladeWithGateway.png)
4. В колонке **Шлюз данных** щелкните **Загрузить и установить шлюз данных**.
	
	![Ссылка на шлюз загрузки](./media/data-factory-move-data-between-onprem-and-cloud/DownloadGatewayLink.png) 
5. В колонке **Настройка** щелкните **Загрузить и установить шлюз данных**, а затем следуйте инструкциям по установке шлюза данных на компьютере. 

	![Колонка «Настройка»](./media/data-factory-move-data-between-onprem-and-cloud/ConfigureBlade.png)
6. Не закрывайте **диспетчер конфигурации шлюза управления данными**. 
 
	![Менеджер конфигураций](./media/data-factory-move-data-between-onprem-and-cloud/ConfigurationManager.png)	
7. В колонке **Настройка** на портале щелкните **Повторно создать ключ** на панели команд и нажмите кнопку **Да** в окне с предупреждением. Скопируйте ключ в буфер обмена с помощью **кнопки копирования** рядом с текстом ключа. Обратите внимание, что шлюз на старом компьютере прекращает работу сразу же при повторном создании ключа.  
	
	![Повторное создание ключа](./media/data-factory-move-data-between-onprem-and-cloud/RecreateKey.png)
	 
8. Вставьте **ключ** в текстовое поле на странице **Регистрация шлюза** в **диспетчере конфигурации шлюза управления данными** на новом компьютере. (Необязательно) Чтобы увидеть текст ключа, установите флажок **Показать ключ шлюза**.
 
	![Копирование и регистрация ключа](./media/data-factory-move-data-between-onprem-and-cloud/CopyKeyAndRegister.png)
9. Щелкните **Зарегистрировать**, чтобы зарегистрировать шлюз в облачной службе.
10. На странице **Выбор сертификата** нажмите кнопку **Обзор** и выберите сертификат, который использовался на старом шлюзе, а затем введите **пароль** и щелкните **Готово**. 
 
	![Выбор сертификата](./media/data-factory-move-data-between-onprem-and-cloud/SpecifyCertificate.png)

	Вы можете экспортировать сертификат из старого шлюза следующим образом. Запустите диспетчер конфигурации шлюза управления данными на старом компьютере, перейдите на вкладку **Сертификат**, нажмите кнопку **Экспорт** и следуйте инструкциям на экране. 
10. После успешной регистрации шлюза вы увидите, что на главной странице диспетчера конфигурации шлюза значение параметра **Регистрация** изменилось на **Зарегистрировано**, а параметр **Состояние** получил значение **Запущено**. 

## Настройка учетных данных и безопасность

Вы также можете создать связанную службу SQL Server, используя вместо редактора фабрики данных колонку «Связанные службы».
 
3.	На главной странице фабрики данных щелкните плитку **Связанные службы**. 
4.	В колонке **Связанные службы** на панели команд щелкните **Создать хранилище данных**. 
4.	В поле **Имя** введите **SqlServerLinkedService**. 
2.	Щелкните стрелку рядом с элементом **Тип** и выберите **SQL Server**.

	![Создание хранилища данных](./media/data-factory-move-data-between-onprem-and-cloud/new-data-store.png)
3.	Под параметром **Тип** должны появиться дополнительные параметры.
4.	Для параметра **Шлюз данных** укажите только что созданный шлюз. 

	![Параметры SQL Server](./media/data-factory-move-data-between-onprem-and-cloud/sql-server-settings.png)
4.	В поле **Сервер** введите имя сервера базы данных.
5.	В поле **База данных** введите имя базы данных.
6.	Щелкните стрелку рядом с элементом **Учетные данные**.

	![Колонка учетных данных](./media/data-factory-move-data-between-onprem-and-cloud/credentials-dialog.png)
7.	В колонке **Учетные данные** выберите ссылку **Щелкните здесь, чтобы задать учетные данные**.
8.	В диалоговом окне **Настройка учетных данных** выполните следующие действия.

	![Диалоговое окно "Настройка учетных данных"](./media/data-factory-move-data-between-onprem-and-cloud/setting-credentials-dialog.png) 
	1. Выберите тип **проверки подлинности**, который служба фабрики данных будет использовать для подключения к базе данных. 
	2. В поле **ИМЯ ПОЛЬЗОВАТЕЛЯ** укажите имя пользователя с доступом к базе данных.
	3. В поле **ПАРОЛЬ** укажите пароль этого пользователя. 
	4. Щелкните **ОК**, чтобы закрыть диалоговое окно. 
4. Щелкните **ОК**, чтобы закрыть колонку **Учетные данные**. 
5. Щелкните **ОК** в колонке **Новое хранилище данных**. 	
6. Убедитесь, что в колонке «Связанные службы» состояние службы **SqlServerLinkedService** изменилось на «В сети». 
	![Состояние связанной службы SQL Server](./media/data-factory-move-data-between-onprem-and-cloud/sql-server-linked-service-status.png)

Если для доступа к порталу используется компьютер, отличный от компьютера шлюза, необходимо убедиться в том, что диспетчер учетных данных может подключиться к компьютеру шлюза. Если приложению не удается подключиться к компьютеру шлюза, вы не сможете задать учетные данные для источника данных и проверить подключение к нему.

При использовании приложения "Настройка учетных данных" (открывается на портале Azure для настройки доступа к локальному источнику данных) учетные данные шифруются с помощью сертификата, который указан на вкладке "Сертификат" в диспетчере конфигурации шлюза управления данными на компьютере со шлюзом.

Если вам нужен способ шифрования учетных данных на основе API, используйте командлет PowerShell [New-AzureRmDataFactoryEncryptValue](https://msdn.microsoft.com/library/mt603802.aspx). Командлет шифрует учетные данные с помощью сертификата, который настроен в шлюзе. Учетные данные, зашифрованные этим командлетом, можно добавить в JSON-файл в элемент EncryptedCredential строки подключения для использования с командлетом [New-AzureRmDataFactoryLinkedService](https://msdn.microsoft.com/library/mt603647.aspx) или с фрагментом кода JSON в редакторе фабрики данных на портале.

	"connectionString": "Data Source=<servername>;Initial Catalog=<databasename>;Integrated Security=True;EncryptedCredential=<encrypted credential>",

**Примечание.** Если используется приложение «Настройка учетных данных», зашифрованные учетные данные автоматически добавляются в связанные службы, как показано выше.

Для настройки учетных данных при помощи редактора фабрики данных существует еще один способ. Если при помощи редактора создать связанную службу SQL Server и ввести учетные данные в виде обычного текста, эти учетные данные будут шифроваться с помощью сертификата, который принадлежит службе фабрики данных, а НЕ сертификата, который используется шлюзом. Хотя этот способ работает быстрее в некоторых случаях, он менее безопасен. Поэтому мы рекомендуем использовать его только для целей разработки и тестирования.


## Создание и регистрация шлюза управления данными с помощью Azure PowerShell 
В этом разделе описывается, как создать и зарегистрировать шлюз с использованием командлетов Azure PowerShell.

1. Запустите модуль **Azure PowerShell** в режиме администратора. 
2. Командлеты фабрики данных Azure доступны в режиме **AzureResourceManager**. Выполните следующую команду, чтобы перейти в режим **AzureResourceManager**:     

        switch-azuremode AzureResourceManager


2. Используйте командлет **New-AzureRmDataFactoryGateway** для создания логического шлюза следующим образом:

		New-AzureRmDataFactoryGateway -Name <gatewayName> -DataFactoryName <dataFactoryName> -ResourceGroupName ADF –Description <desc>

	**Пример команды и выходных данных**:


		PS C:\> New-AzureRmDataFactoryGateway -Name MyGateway -DataFactoryName $df -ResourceGroupName ADF –Description “gateway for walkthrough”

		Name              : MyGateway
		Description       : gateway for walkthrough
		Version           :
		Status            : NeedRegistration
		VersionStatus     : None
		CreateTime        : 9/28/2014 10:58:22
		RegisterTime      :
		LastConnectTime   :
		ExpiryTime        :
		ProvisioningState : Succeeded


3. Используйте командлет **New-AzureRmDataFactoryGatewayKey**, чтобы создать регистрационный ключ для вновь созданного шлюза, и сохраните этот ключ в локальной переменной **$Key**:

		New-AzureRmDataFactoryGatewayKey -GatewayName <gatewayname> -ResourceGroupName ADF -DataFactoryName <dataFactoryName>

	
	**Пример результата выполнения команды:**


		PS C:\> $Key = New-AzureRmDataFactoryGatewayKey -GatewayName MyGateway -ResourceGroupName ADF -DataFactoryName $df 

	
4. В Azure PowerShell перейдите к папке **C:\\Program Files\\Microsoft Data Management Gateway\\1.0\\PowerShellScript** и выполните сценарий **RegisterGateway.ps1** с локальной переменной **$Key**, как показано в примере ниже. Эта команда зарегистрирует агент клиента, который установлен на вашем компьютере, в ранее созданном логическом шлюзе.

		PS C:\> .\RegisterGateway.ps1 $Key.GatewayKey
		
		Agent registration is successful!

5. Вы можете использовать командлет **Get-AzureRmDataFactoryGateway**, чтобы получить список шлюзов своей фабрики данных. Если в поле **Состояние** указано значение **Подключено**, шлюз готов к эксплуатации.

		Get-AzureRmDataFactoryGateway -DataFactoryName <dataFactoryName> -ResourceGroupName ADF

Вы можете удалить шлюз, используя командлет **Remove-AzureRmDataFactoryGateway**, или обновить описание шлюза, используя командлет **Set-AzureRmDataFactoryGateway**. Дополнительную информацию о синтаксисе и другую информацию об этих командлетах см. в "Справочных материалах по командлетам фабрики данных".


## Потоки данных при копировании с помощью шлюза управления данными
Если в конвейере для передачи локальных данных в облако (с целью дальнейшей обработки) либо для экспорта готовых данных из облака обратно в локальное хранилище используется действие копирования, в таких операциях участвует шлюз данных.

Ниже показана обобщенная диаграмма потока данных и этапы копирования через шлюз:
	![Поток данных при использовании шлюза](./media/data-factory-move-data-between-onprem-and-cloud/data-flow-using-gateway.png)

1.	Разработчик создает новый шлюз для фабрики данных Azure, используя [портал Azure](https://portal.azure.com) или [командлет PowerShell](https://msdn.microsoft.com/library/dn820234.aspx). 
2.	На панели "Связанные службы" разработчик определяет новую связанную службу для локального хранилища данных со шлюзом. В ходе настройки связанной службы разработчик указывает типы проверки подлинности и учетные данные в приложении "Настройка учетных данных" (см. пошаговые инструкции выше). Приложение "Настройка учетных данных" проверяет подключение к хранилищу данных и шлюзу и сохраняет учетные данные.
3.	Перед сохранением учетных данных в облаке шлюз шифрует их при помощи связанного с ним сертификата (указывается разработчиком).
4.	Служба перемещения (фабрика данных) взаимодействует со шлюзом, планируя задания и управляя ими через канал управления. Этот канал использует общую очередь служебной шины Azure. Когда нужно начать задание копирования, фабрика данных добавляет в очередь запрос с указанием учетных данных. После опроса очереди шлюз начинает задание.
5.	Шлюз расшифровывает учетные данные с помощью того же сертификата, после чего подключается к локальному хранилищу данных, используя соответствующий вариант проверки подлинности.
6.	Шлюз копирует данные из локального хранилища в облачное или из облачного хранилища в локальное в зависимости от настроек действия копирования в конвейере данных. Примечание: на этом этапе шлюз напрямую взаимодействует с облачной службой хранилища (например, с хранилищем BLOB-объектов Azure, SQL Azure и т. д) через защищенный канал (HTTPS).

<!---HONumber=AcomDC_0204_2016-->