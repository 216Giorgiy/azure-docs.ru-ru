<properties 
	pageTitle="Перемещение данных между локальным и облачным хранилищами с помощью фабрики данных Azure" 
	description="Узнайте, как перемещать данные между локальным и облачным хранилищами с помощью шлюза управления данными и фабрики данных Azure." 
	services="data-factory" 
	documentationCenter="" 
	authors="spelluru" 
	manager="jhubbard" 
	editor="monicar"/>

<tags 
	ms.service="data-factory" 
	ms.workload="data-services" 
	ms.tgt_pltfrm="na" 
	ms.devlang="na" 
	ms.topic="article" 
	ms.date="10/23/2015" 
	ms.author="spelluru"/>

# Перемещение данных между локальными источниками и облаком при помощи шлюза управления данными
Одной из проблем интеграции данных является незаметное для пользователя перемещение данных между локальной средой и облаком. Для решения этой проблемы в фабрике данных используется шлюз управления данными. Шлюз управления данными — это локально устанавливаемый агент, который позволяет использовать гибридные конвейеры.

Эта статья содержит общие сведения об интеграции локальных хранилищ данных с облачными хранилищами, а также об обработке данных в облаке с использованием фабрики данных. Базовая информация изложена в статье [Действия перемещения данных](data-factory-data-movement-activities.md), а также в других статьях, посвященных основным понятиям фабрики данных. В данной статье предполагается, что вы уже знакомы с основными понятиями фабрики данных, в частности с конвейерами, действиями, наборами данных и действием копирования.

Шлюз данных предоставляет следующие возможности:

1.	Моделирование источников локальных и облачных данных в пределах одной фабрики данных, а также перемещение данных.
2.	Использование единого средства отслеживания и управления с возможностью контроля состояния шлюза при помощи облачной панели мониторинга фабрики данных.
3.	Безопасное управление доступом к локальным источникам данных.
	1. Изменять настройки корпоративного брандмауэра не требуется. Шлюз только пропускает исходящие HTTP-соединения во внешнюю сеть.
	2. Учетные данные для ваших локальных хранилищ данных можно шифровать с помощью личного сертификата.
4.	Эффективное перемещение данных: данные передаются параллельно, благодаря логике автоматического повторения перемещение не зависит от временных сетевых проблем.

## Особенности использования шлюза управления данными
1.	Для нескольких локальных источников данных можно использовать один экземпляр шлюза управления данными, но учтите, что **каждый экземпляр шлюза связан только с одной фабрикой данных Azure** и его невозможно одновременно использовать с другой фабрикой данных.
2.	На компьютере может быть установлен **только один экземпляр шлюза управления данными**. Предположим, у вас есть две фабрики данных, которым необходимо получить доступ к локальным источникам данных. В этом случае вам необходимо установить шлюзы на двух локальных компьютерах, чтобы каждый шлюз был связан с отдельной фабрикой данных.
3.	**Шлюз не должен находиться в той же машине, что и источник данных**, но, если он расположен вблизи источника данных, это сокращает количество времени, требуемого для подключения шлюза к этому источнику. Мы рекомендуем установить шлюз на компьютере, отличном от того, на котором размещен локальный источник данных, чтобы шлюз не конкурировал за использование ресурсов с источником данных.
4.	У вас может быть **несколько шлюзов на разных компьютерах, подключенных к одному и тому же локальному источнику данных**. Например, имеется два шлюза, обслуживающие две фабрики данных, однако один и тот же локальный источник данных зарегистрирован в обеих фабриках данных.
5.	Если вы уже установили шлюз на компьютер, который обслуживает сценарий **Power BI**, установите **отдельный шлюз для фабрики данных Azure** в другой машине.
6.	**Шлюз необходимо использовать, даже если используется ExpressRoute**. 
7.	Источник данных следует считать локальным (то есть защищенным брандмауэром), даже если используется **ExpressRoute**, а для связи между службой и источником данных **используется шлюз**. 

## Предварительные требования к установке шлюза
1.	Поддерживаемые **операционные системы**: Windows 7, Windows 8/8.1, Windows Server 2008 R2, Windows Server 2012.
2.	Рекомендуемая **конфигурация** для компьютера шлюза: четырехъядерный процессор с тактовой частотой не менее 2 ГГц, не менее 8 ГБ ОЗУ и 80 ГБ дискового пространства.
3.	Когда хост-компьютер переходит в спящий режим, шлюз не может отвечать на запросы данных. Поэтому перед установкой шлюза на компьютере следует настроить соответствующую **схему управления питанием**. Если компьютер настроен на использование режима гибернации, во время установки шлюза отобразится соответствующее сообщение.

Так как циклы копирования выполняются с определенной частотой, ресурсы компьютера (ЦП, память) используются нерегулярно: есть пиковые нагрузки, и есть время простоя. Использование ресурсов также зависит от объема перемещаемых данных. Когда выполняется несколько заданий копирования, в пиковые периоды уровень использования ресурсов системы повышается. Выше приведены минимальные требования к конфигурации. Мы рекомендуем всегда иметь запас ресурсов, поскольку нагрузка зависит от объема перемещаемых данных.

## Установка
Шлюз управления данными можно установить, загрузив пакет MSI из центра загрузки Майкрософт. Пакет MSI также может использоваться для обновления имеющегося шлюза управления данными до последней версии с сохранением всех параметров. Ссылку на пакет MSI можно найти на портале Azure, следуя приведенным ниже пошаговым инструкциям.

### Рекомендации по установке
1.	Настройте схему управления питанием на хост-компьютере шлюза, отключив спящий режим. Когда хост-компьютер переходит в спящий режим, шлюз не может отвечать на запросы данных.
2.	Создайте резервную копию сертификата, связанного со шлюзом.

### Устранение неполадок
Если ваша компания использует брандмауэр или прокси-сервер, при возникновении проблем подключения к облачным службам Майкрософт могут потребоваться дополнительные действия.

#### Просмотр журналов шлюза с помощью средства просмотра событий

Диспетчер конфигурации шлюза показывает состояние шлюза, например "Отключено" или "Подключение".

Более подробные сведения можно найти в журналах шлюза в журналах событий Windows. Их можно найти в **средстве просмотра событий** Windows в разделе **Журналы приложения и служб** > **Шлюз управления данными**. Устраняя связанные со шлюзом ошибки, обращайте внимание на события уровня ошибок.


#### Возможные симптомы проблем, связанных с брандмауэром

1. При попытке зарегистрировать шлюз появляется следующая ошибка: "Не удалось зарегистрировать ключ шлюза. Перед повторной попыткой регистрации ключа убедитесь, что шлюз управления данными подключен и на хост-компьютере запущена служба шлюза управления данными".
2. В диспетчере конфигурации отображается состояние "Отключено" или "Подключение". В средстве просмотра событий Windows в разделе "Журналы приложения и служб" > "Шлюз управления данными" отображается ошибка "Не удается подключиться к удаленному серверу" или "Компонент шлюза управления данными перестал отвечать и будет автоматически перезагружен. Имя компонента: шлюз".

К таким ошибкам приводит неправильная конфигурация брандмауэра или прокси-сервера: попытки шлюза управления данными подключиться к облачным службам блокируются с целью проверки подлинности.

Потенциально эта проблема может возникать с двумя брандмауэрами: корпоративным брандмауэром, работающем на центральном корпоративном маршрутизаторе, и брандмауэром Windows, настроенным в качестве основного на локальном компьютере, на котором установлен шлюз. Ниже приведены некоторые рекомендации.

- Не следует менять политику входящих соединений в корпоративном брандмауэре.
- В корпоративном брандмауэре и брандмауэре Windows следует включить правило исходящих подключений для портов TCP: 80, 440 и 9305–9354. Эти порты используются служебной шиной Microsoft Azure для установления соединения между облачными службами и шлюзом управления данными.

На компьютере со шлюзом пакет MSI автоматически настроит правила брандмауэра Windows для портов входящих соединений (см. рекомендации по портам и безопасности ниже).

Тем не менее, в процессе установки предполагается, что на локальном компьютере и в корпоративном брандмауэре указанные порты исходящих соединений открыты по умолчанию. Если это не так, указанные порты исходящих соединений необходимо открыть. Если вы используете брандмауэр, отличный от стандартного брандмауэра Windows, эти порты, возможно, нужно будет открыть вручную.

Если ваша компания использует прокси-сервер, необходимо добавить Microsoft Azure в белый список. Список действующих IP-адресов Microsoft Azure можно скачать в [центре загрузки Майкрософт](http://msdn.microsoft.com/library/windowsazure/dn175718.aspx).

## Пошаговые инструкции по работе со шлюзом данных
Это руководство поможет вам создать фабрику данных с конвейером, который позволяет перемещать данные из локальной базы данных SQL Server в большой двоичный объект Azure.

### Шаг 1. Создание фабрики данных Azure
На этом шаге вы создадите экземпляр фабрики данных Azure с именем **ADFTutorialOnPremDF**, используя портал управления Azure. Фабрику данных также можно создать с помощью командлетов фабрики данных Azure.

1.	После входа на [портал предварительной версии Azure](https://portal.azure.com) щелкните **СОЗДАТЬ** в нижнем левом углу, выберите **Анализ данных** в колонке **Создать**, затем щелкните **Фабрика данных** в колонке **Анализ данных**.

	![Создать -> Фабрика данных](./media/data-factory-move-data-between-onprem-and-cloud/NewDataFactoryMenu.png)
  
6. В колонке **Создать фабрику данных** выполните следующие действия.
	1. Введите **имя** **ADFTutorialOnPremDF**.
	2. Щелкните **ИМЯ ГРУППЫ РЕСУРСОВ** и выберите **ADFTutorialResourceGroup**. Вы можете выбрать существующую группу ресурсов или создать новую группу. Чтобы создать новую группу ресурсов:
		1. Щелкните **Создать новую группу ресурсов**.
		2. В колонке **Создать группу ресурсов** введите **имя** для группы ресурсов и нажмите кнопку **ОК**.

7. Обратите внимание, что в колонке **Новая фабрика данных** установлен флажок **Добавить на начальную панель**.

	![Добавить на начальную панель](./media/data-factory-move-data-between-onprem-and-cloud/OnPremNewDataFactoryAddToStartboard.png)

8. В колонке **Новая фабрика данных** щелкните **Создать**.

	Имя фабрики данных Azure должно быть глобально уникальным. Получив сообщение об ошибке **Имя фабрики данных "ADFTutorialOnPremDF" недоступно**, измените имя фабрики данных (например, на yournameADFTutorialOnPremDF) и попробуйте создать ее еще раз. Выполняя оставшиеся действия, описанные в этом руководстве, вместо ADFTutorialOnPremDF используйте именно это имя.

9. Найдите уведомления, возникшие в процессе создания, нажав кнопку **Уведомления** в строке заголовка, как показано ниже. Чтобы закрыть окно уведомлений, нажмите эту кнопку еще раз.

	![Раздел "УВЕДОМЛЕНИЯ"](./media/data-factory-move-data-between-onprem-and-cloud/OnPremNotificationsHub.png)

11. По завершении создания вы увидите колонку **Фабрика данных**, как показано ниже.

	![Домашняя страница фабрики данных](./media/data-factory-move-data-between-onprem-and-cloud/OnPremDataFactoryHomePage.png)

### Шаг 2. Создание шлюза управления данными
5. В колонке **ФАБРИКА ДАННЫХ** щелкните плитку **Разработка и развертывание**, чтобы запустить **редактор** для фабрики данных.

	![Плитка «Создание и развертывание»](./media/data-factory-move-data-between-onprem-and-cloud/author-deploy-tile.png) 
6.	В редакторе фабрики данных щелкните **... (многоточие)** на панели инструментов, а затем **Новый шлюз данных**. 

	![«Новый шлюз данных» на панели инструментов](./media/data-factory-move-data-between-onprem-and-cloud/NewDataGateway.png)
2. В колонке **Создать** в поле **Имя** введите **adftutorialgateway** и нажмите кнопку **ОК**. 	

	![Колонка "Создать шлюз"](./media/data-factory-move-data-between-onprem-and-cloud/OnPremCreateGatewayBlade.png)

3. В колонке **Настройка** щелкните **Установить непосредственно на этот компьютер**. Это позволит скачать пакет установки для шлюза, а также установить, настроить и зарегистрировать шлюз на компьютере.

	> [AZURE.NOTE]Используйте Internet Explorer или другой браузер, совместимый с Microsoft ClickOnce.

	![Шлюз — колонка "Настройка"](./media/data-factory-move-data-between-onprem-and-cloud/OnPremGatewayConfigureBlade.png)

	Это самый простой способ (одним щелчком) скачать, установить, настроить и зарегистрировать шлюз в один шаг. Вы увидите, что на компьютере установлено приложение **Microsoft Data Management Gateway Configuration Manager**. Вы также можете найти исполняемый файл **ConfigManager.exe** в папке по следующему пути: **C:\\Program Files\\Microsoft Data Management Gateway\\1.0\\Shared**.

	Шлюз также можно скачать и установить вручную, используя ссылки в этой колонке. Затем вы можете зарегистрировать его с помощью ключа, указанного в текстовом поле **ЗАРЕГИСТРИРОВАТЬ С ПОМОЩЬЮ КЛЮЧА**.
	
	Дополнительная информация о шлюзе, в том числе рекомендации и важные особенности, приведена в первых разделах этой статьи.

	>[AZURE.NOTE]Для успешной установки шлюза управления данными и его настройки вы должны обладать правами администратора на локальном компьютере. В локальную группу Windows "Пользователи шлюза управления данными" можно добавить дополнительных пользователей. Участники этой группы смогут использовать диспетчер конфигурации шлюза управления данными для настройки шлюза.

5. Подождите несколько минут и запустите на компьютере приложение **Диспетчер конфигураций шлюза управления данными**. Для этого введите текст **шлюз управления данными** в окне **Поиск**. Вы также можете запустить исполняемый файл **ConfigManager.exe**, который расположен в папке **C:\\Program Files\\Microsoft Data Management Gateway\\1.0\\Shared**.

	![Диспетчер конфигурации шлюза](./media/data-factory-move-data-between-onprem-and-cloud/OnPremDMGConfigurationManager.png)

6. Подождите, пока установятся следующие значения:
	1. В поле **Состояние** установлено значение **Работает**.
	2. В поле **Имя шлюза** установлено значение **adftutorialgateway**.
	3. Для **имени экземпляра** установлено значение **adftutorialgateway**.
	4. В поле**Регистрация** установлено значение **Зарегистрировано**.
	5. В строке состояния внизу отображается надпись **Установлено подключение к облачной службе шлюза управления данными** и **зеленый флажок**.

8. Перейдите на вкладку **Сертификаты**. Сертификат, указанный на этой вкладке, используется для шифрования и расшифровки учетных данных локального хранилища данных, указанного на портале. Чтобы использовать вместо него собственный сертификат, щелкните **Изменить**. По умолчанию шлюз использует сертификат, который автоматически создан службой фабрики данных.

	![Конфигурация сертификата шлюза](./media/data-factory-move-data-between-onprem-and-cloud/gateway-certificate.png)
9. На портале Azure нажмите кнопку **ОК** в колонке **Настройка**, а затем в колонке **Новый шлюз данных**.
6. В представлении в виде дерева в левой части окна вы увидите элемент **adftutorialgateway** в узле **Шлюзы данных**. Щелкните его, чтобы увидеть связанные JSON-файлы. 
	

### Шаг 3. Создание связанных служб 
На этом шаге вы создадите две связанные службы: **StorageLinkedService** и **SqlServerLinkedService**. Служба **SqlServerLinkedService** связывается с локальной базой данных SQL Server, а связанная служба **StorageLinkedService** связывает хранилище больших двоичных объектов Azure с фабрикой данных. Далее это руководство поможет вам создать конвейер, который позволит копировать данные из локальной базы данных SQL Server в службу хранилища больших двоичных объектов Azure.

#### Добавление связанной службы в локальную базу данных SQL Server
1.	В **редакторе фабрики данных** щелкните **Создать хранилище данных** на панели инструментов и выберите **SQL Server**. 

	![Создать связанную службу SQL Server](./media/data-factory-move-data-between-onprem-and-cloud/NewSQLServer.png) 
3.	В **редакторе JSON** выполните следующие действия. 
	1. Для параметра **gatewayName** укажите значение **adftutorialgateway**.	
	2. При использовании проверки подлинности Windows:
		1. Измените строку **connectionString** следующим образом. 
			1. Для параметра **Встроенная система безопасности** установите значение **True**.
			2. Укажите **имя сервера** базы данных и **имя базы данных**. 
			2. Удалите **идентификатор пользователя** и **пароль**. 
		3. Укажите имя пользователя и пароль в свойствах **userName** и **password**.
		
				"typeProperties": {
            		"connectionString": "Data Source=<servername>;Initial Catalog=<databasename>;Integrated Security=True;",
            		"gatewayName": "adftutorialgateway",
            		"userName": "<Specify user name if you are using Windows Authentication>",
            		"password": "<Specify password for the user account>"
        		}

	4. При использовании проверки подлинности SQL:
		1. Укажите **имя сервера** базы данных, **имя базы данных**, **идентификатор пользователя** и **пароль** в строке **connectionString**.       
		2. Удалите из JSON два последних свойства: **userName** и **password**.
		3. Удалите символ **, (запятая)** в конце строки, в которой указано значение свойства **gatewayName**. 

				"typeProperties": {
            		"connectionString": "Data Source=<servername>;Initial Catalog=<databasename>;Integrated Security=False;User ID=<username>;Password=<password>;",
	           		"gatewayName": "<Name of the gateway that the Data Factory service should use to connect to the on-premises SQL Server database>"
    		    }
	   
2.	Нажмите кнопку **Развернуть** на панели команд, чтобы развернуть связанную службу SQL Server.

#### Добавление связанной службы для учетной записи хранения Azure
 
1. В **редакторе фабрики данных** щелкните **Создать хранилище данных** на панели команд и выберите **Хранилище Azure**.
2. В поле **Имя учетной записи** введите имя учетной записи хранения Azure.
3. В поле **Ключ учетной записи** введите ключ учетной записи хранения Azure.
4. Щелкните **Развернуть**, чтобы развернуть службу **StorageLinkedService**.
   
 
### Шаг 4. Создание входных и выходных наборов данных
В этом шаге вы создадите наборы входных и выходных данных, которые представляют собой входные и выходные данные для операции копирования (из локальной базы данных SQL в хранилище больших двоичных объектов Azure). Перед созданием наборов данных или таблиц (прямоугольных наборов данных) необходимо сделать следующее (после списка есть подробные шаги):

- в базе данных SQL Server, которую вы добавили в фабрику данных как связанную службу, создайте таблицу с именем **emp** и вставьте в таблицу пару записей в качестве примера;
- в учетной записи хранилища больших двоичных объектов Azure, которую вы добавили в качестве связанной службы в фабрику данных, создайте контейнер больших двоичных объектов с именем **adftutorial**.

### Подготовка локальной связанной службы SQL Server для учебника

1. В базе данных SQL Server, которую вы указали в качестве локальной связанной службы (**SqlServerLinkedService**), запустите следующий сценарий SQL, который создаст в базе данных таблицу **emp**.


        CREATE TABLE dbo.emp
		(
			ID int IDENTITY(1,1) NOT NULL, 
			FirstName varchar(50),
			LastName varchar(50),
    		CONSTRAINT PK_emp PRIMARY KEY (ID)
		)
		GO
 

2. Вставьте несколько образцов в таблицу:


        INSERT INTO emp VALUES ('John', 'Doe')
		INSERT INTO emp VALUES ('Jane', 'Doe')



### Создание входной таблицы

1. В **редакторе фабрики данных** щелкните на панели команд элемент **Создать набор данных** и выберите пункт **Таблица SQL Server**. 
2.	Замените сценарий JSON в области справа на следующий текст:    

		{
		  "name": "EmpOnPremSQLTable",
		  "properties": {
		    "type": "SqlServerTable",
		    "linkedServiceName": "SqlServerLinkedService",
		    "typeProperties": {
		      "tableName": "emp"
		    },
		    "external": true,
		    "availability": {
		      "frequency": "Hour",
		      "interval": 1
		    },
		    "policy": {
		      "externalData": {
		        "retryInterval": "00:01:00",
		        "retryTimeout": "00:10:00",
		        "maximumRetry": 3
		      }
		    }
		  }
		}

	Обратите внимание на следующее:
	
	- **type** имеет значение **SqlServerTable**.
	- **tableName** имеет значение **emp**.
	- Для параметра **linkedServiceName** установлено значение **SqlServerLinkedService** (вы создали эту связанную службу в шаге 2).
	- Если входная таблица не создается другим конвейером фабрики данных Azure, для параметра **external** следует задать значение **true**. Это означает, что входные данные создаются вне службы фабрики данных Azure. При необходимости можно указать любые внешние политики данных с помощью **externalData** в разделе **Policy**.    

	Дополнительную информацию о свойствах JSON-сценариев см. в статье [Справка по использованию JSON-сценариев][json-script-reference].

2. Нажмите кнопку **Развернуть** на панели команд, чтобы развернуть набор данных (таблица представляет собой прямоугольный набор данных). Убедитесь, что в заголовке окна отображается сообщение **ТАБЛИЦА УСПЕШНО РАЗВЕРНУТА**.


### Создание выходной таблицы

1.	В **редакторе фабрики данных** щелкните на панели команд **Создать набор данных** и выберите **Хранилище больших двоичных объектов Azure**.
2.	Замените сценарий JSON в области справа на следующий текст: 

		{
		  "name": "OutputBlobTable",
		  "properties": {
		    "type": "AzureBlob",
		    "linkedServiceName": "StorageLinkedService",
		    "typeProperties": {
		      "folderPath": "adftutorial/outfromonpremdf",
		      "format": {
		        "type": "TextFormat",
		        "columnDelimiter": ","
		      }
		    },
		    "availability": {
		      "frequency": "Hour",
		      "interval": 1
		    }
		  }
		}
  
	Обратите внимание на следующее;
	
	- **type** имеет значение **AzureBlob**.
	- для параметра **linkedServiceName** установлено значение **StorageLinkedService** (вы создали эту связанную службу в шаге 2);
	- для параметра **folderPath** установлено значение **adftutorial/outfromonpremdf**, где outfromonpremdf — это папка в контейнере adftutorial; вам просто нужно создать контейнер **adftutorial**;
	- Параметр **availability** имеет значение **hourly**, при этом **frequency** получает значение **hour**, а **interval** — значение **1**. служба фабрики данных будет создавать срез выходных данных каждый час в таблице **emp** в базе данных SQL Azure. 

	Если не указан параметр **fileName** для **входной таблицы**, входными данными считаются все файлы и большие двоичные объекты из входной папки (**folderPath**). Если указать fileName в JSON, только указанный файл или большой двоичный объект рассматриваются как входные данные. Примеры файлов см. в [учебнике][adf-tutorial].
 
	Если не указать **fileName** для **выходной таблицы**, то созданные в**folderPath** файлы получают имена в следующем формате: Data.<Guid>.txt (например: Data.0a405f8a-93ff-4c6f-b3be-f69616f1df7a.txt.).

	Для динамической установки папки **folderPath** и имени **fileName** на основе времени **SliceStart**, используйте свойство partitionedBy В следующем примере folderPath использует год, месяц и день из SliceStart (время начала обработки среза), а в fileName используется время (часы) из SliceStart. Например, если срез выполняется для временной отметки 2014-10-20T08:00:00, folderName получает значение wikidatagateway/wikisampledataout/2014/10/20, а fileName – 08.csv.

	  	"folderPath": "wikidatagateway/wikisampledataout/{Year}/{Month}/{Day}",
        "fileName": "{Hour}.csv",
        "partitionedBy": 
        [
        	{ "name": "Year", "value": { "type": "DateTime", "date": "SliceStart", "format": "yyyy" } },
            { "name": "Month", "value": { "type": "DateTime", "date": "SliceStart", "format": "MM" } }, 
            { "name": "Day", "value": { "type": "DateTime", "date": "SliceStart", "format": "dd" } }, 
            { "name": "Hour", "value": { "type": "DateTime", "date": "SliceStart", "format": "hh" } } 
        ],

 

	Дополнительную информацию о свойствах JSON-сценариев см. в статье [Справка по использованию JSON-сценариев][json-script-reference].

2.	Нажмите кнопку **Развернуть** на панели команд, чтобы развернуть набор данных (таблица представляет собой прямоугольный набор данных). Убедитесь, что в заголовке окна отображается сообщение **ТАБЛИЦА УСПЕШНО РАЗВЕРНУТА**.
  

### Шаг 5. Создание и запуск конвейера
На этом шаге вы создадите **конвейер** одним **действием копирования**, для выполнения которого **EmpOnPremSQLTable** будет использоваться как входные данные, а **OutputBlobTable** — как выходные данные.

1.	В колонке **ФАБРИКА ДАННЫХ** щелкните плитку **Разработка и развертывание**, чтобы запустить **редактор** для фабрики данных.

	![Плитка «Создание и развертывание»](./media/data-factory-move-data-between-onprem-and-cloud/author-deploy-tile.png) 
2.	Нажмите кнопку **Создать конвейер** на панели команд. Если вы не видите эту кнопку, нажмите **... (многоточие)**, чтобы отобразить ее.
2.	Замените сценарий JSON в области справа на следующий текст:   


		{
		  "name": "ADFTutorialPipelineOnPrem",
		  "properties": {
		    "description": "This pipeline has one Copy activity that copies data from an on-prem SQL to Azure blob",
		    "activities": [
		      {
		        "name": "CopyFromSQLtoBlob",
		        "description": "Copy data from on-prem SQL server to blob",
		        "type": "Copy",
		        "inputs": [
		          {
		            "name": "EmpOnPremSQLTable"
		          }
		        ],
		        "outputs": [
		          {
		            "name": "OutputBlobTable"
		          }
		        ],
		        "typeProperties": {
		          "source": {
		            "type": "SqlSource",
		            "sqlReaderQuery": "select * from emp"
		          },
		          "sink": {
		            "type": "BlobSink"
		          }
		        },
		        "Policy": {
		          "concurrency": 1,
		          "executionPriorityOrder": "NewestFirst",
		          "style": "StartOfInterval",
		          "retry": 0,
		          "timeout": "01:00:00"
		        }
		      }
		    ],
		    "start": "2015-02-13T00:00:00Z",
		    "end": "2015-02-14T00:00:00Z",
		    "isPaused": false
		  }
		}

	Обратите внимание на следующее.
 
	- В разделе действий есть только действие, для параметра **type** которого задано значение **Copy**.
	- для параметра действия **input** установлено значение **EmpOnPremSQLTable**, а для **output** — **OutputBlobTable**;
	- В разделе **transformation** в качестве **типа источника** установлено **SqlSource**, а в качестве **типа приемника** — **BlobSink**.
- для свойства **sqlReaderQuery** типа **SqlSource** задан вид SQL-запроса **select * from emp**.

	Замените значение свойства **start** текущей датой, а значение свойства **end** — датой следующего дня. Даты начала и окончания должны быть в [формате ISO](http://en.wikipedia.org/wiki/ISO_8601). Например, 2014-10-14T16:32:41Z. Время **окончания** указывать не обязательно, однако в этом примере мы будем его использовать.
	
	Если вы не укажете значение свойства **end** (время завершения), оно будет вычислено по формуле **время начала + 48 часов**. Чтобы запустить конвейер в течение неопределенного срока, укажите значение **9/9/9999** для свойства **end**.
	
	Вы определяете интервал времени, в который будут выполняться срезы данных на основе свойств **доступности**, определенных для каждой таблицы фабрики данных Azure.
	
	В приведенном выше примере будет 24 среза данных, так как срезы данных производятся каждый час.
	
2. Нажмите кнопку **Развернуть** на панели команд, чтобы развернуть набор данных (таблица представляет собой прямоугольный набор данных). Убедитесь, что в заголовке окна отображается сообщение **КОНВЕЙЕР УСПЕШНО РАЗВЕРНУТ**.
5. Теперь закройте колонку **Редактор**, щелкнув **X**. Щелкните **X** снова, чтобы закрыть колонку ADFTutorialDataFactory с представлением панели инструментов и дерева. При отображении сообщения **Несохраненные редакторы будут отклонены** щелкните **ОК**.
6. После этого следует вернуться к колонке **ФАБРИКА ДАННЫХ** для фабрики **ADFTutorialOnPremDF**.

**Поздравляем!** Вы успешно создали фабрику данных Azure, связанные службы, таблицы и конвейер, а также выполнили планирование конвейера.

#### Просмотр фабрики данных в представлении схемы 
1. На портале **предварительной версии Azure** щелкните плитку **Схемы** на домашней странице фабрики данных **ADFTutorialOnPremDF**.

	![Ссылка на схему](./media/data-factory-move-data-between-onprem-and-cloud/OnPremDiagramLink.png)

2. Вы должны увидеть схему, аналогичную приведенной ниже:

	![Представление схемы](./media/data-factory-move-data-between-onprem-and-cloud/OnPremDiagramView.png)

	Можно увеличивать и уменьшать масштаб, выбирать 100%-й масштаб или масштаб по размеру, автоматически размещать конвейеры и таблицы, а также отображать сведения из журнала обращений и преобразований (выделение восходящих и нисходящих элементов для выбранных элементов). Дважды щелкните объект (входную или выходную таблицу или конвейер), чтобы просмотреть его свойства.

### Шаг 6. Мониторинг наборов данных и конвейеров
В этом шаге вы будете использовать портал Azure для мониторинга фабрики данных Azure. Вы также можете использовать командлеты PowerShell для мониторинга наборов данных и конвейеров. Дополнительные сведения о мониторинге см. в статье [Мониторинг конвейеров и управление ими](monitor-manage-pipelines.md).

1. Перейдите на **портал предварительной версии Azure** (если вы закрыли страницу портала).
2. Если колонка для **ADFTutorialOnPremDF** закрыта, откройте ее, щелкнув **ADFTutorialOnPremDF** на **начальной панели**.
3. Вы увидите **количество** и **имена** таблиц, а также конвейер, который вы создали в этой колонке.

	![Домашняя страница фабрики данных](./media/data-factory-move-data-between-onprem-and-cloud/OnPremDiagramView.png)
4. Теперь щелкните плитку **Наборы данных**.
5. В колонке **Наборы данных** щелкните **EmpOnPremSQLTable**.

	![Срезы EmpOnPremSQLTable](./media/data-factory-move-data-between-onprem-and-cloud/OnPremSQLTableSlicesBlade.png)

6. Обратите внимание, что срезы данных до текущего момента времени уже выполнены и все они находятся в состоянии **Готов**. Это результат того, что вы вставили данные в базу данных SQL Server, и они находились там все время. Убедитесь, что в разделе **Проблемные срезы** в нижней части окна не показаны срезы.


	Оба списка, **Недавно обновленные срезы** и **Срезы, в которых недавно произошел сбой**, сортируются по **ПОСЛЕДНЕМУ ВРЕМЕНИ ОБНОВЛЕНИЯ**. Время обновления среза изменяется в таких ситуациях:
    

	-  Вы обновляете состояние среза вручную, например используя командлет **Set-AzureDataFactorySliceStatus** или щелкнув **ВЫПОЛНИТЬ** в колонке **СРЕЗ** для этого среза.
	-  В ходе выполнения состояние среза меняется (например, выполнение началось, выполнение завершилось со сбоем, выполнение завершилось успешно и т. п.).
 
	Щелкните заголовок списков или **... (многоточие)**, чтобы просмотреть расширенный список срезов. Чтобы отфильтровать срезы, выберите пункт **Фильтр** на панели инструментов.
	
	Чтобы вместо этого просмотреть срезы данных, отсортированные по времени начала и окончания среза, щелкните плитку **Срезы данных (по времени среза)**.

7. Затем в колонке **Наборы данных** щелкните **OutputBlobTable**.

	![OputputBlobTable slices][image-data-factory-output-blobtable-slices]
8. Убедитесь, что выполнены срезы вплоть до текущего времени и состояние каждого из них — **Готово**. Подождите, пока значение состояния срезов до текущего времени **Готово**.
9. Щелкните любой срез данных в списке для отображения колонки **СРЕЗ ДАННЫХ**.

	![Колонка среза данных](./media/data-factory-move-data-between-onprem-and-cloud/DataSlice.png)

	Если срез не находится в состоянии **Готов**, вы можете увидеть восходящие срезы, которые не находятся в состоянии готовности и блокируют выполнение текущего среза в списке **Неготовые восходящие срезы**.

10. Щелкните **выполненное действие** в нижней части списка, чтобы просмотреть **дополнительную информацию о выполненном действии**.

	![Activity Run Details blade][image-data-factory-activity-run-details]

11. Закройте все колонки, щелкая значок **X**, пока
12. не вернетесь к начальной колонке **ADFTutorialOnPremDF**.
14. Щелкните **Конвейеры**, а затем — **ADFTutorialOnPremDF** и просмотрите параметры входных таблиц (**Использовано**) или выходных таблиц (**Выполнено**). Это необязательное действие.
15. Используйте инструменты, такие как **обозреватель хранилищ Azure** для проверки выходных данных.

	![Обозреватель хранилищ Azure](./media/data-factory-move-data-between-onprem-and-cloud/OnPremAzureStorageExplorer.png)

## Перемещение шлюза с одного компьютера на другой
Этот раздел содержит процедуру перемещения клиента шлюза с одного компьютера на другой.

2. На портале перейдите на **главную страницу фабрики данных**, а затем щелкните плитку **Связанные службы**. 

	![Ссылка на шлюзы данных](./media/data-factory-move-data-between-onprem-and-cloud/DataGatewaysLink.png) 
3. Выберите нужный шлюз в разделе **ШЛЮЗЫ ДАННЫХ** в колонке **Связанные службы**.
	
	![Колонка «Связанные службы» с выбранным шлюзом](./media/data-factory-move-data-between-onprem-and-cloud/LinkedServiceBladeWithGateway.png)
4. В колонке **Шлюз данных** щелкните **Загрузить и установить шлюз данных**.
	
	![Ссылка на шлюз загрузки](./media/data-factory-move-data-between-onprem-and-cloud/DownloadGatewayLink.png) 
5. В колонке **Настройка** щелкните **Загрузить и установить шлюз данных**, а затем следуйте инструкциям по установке шлюза данных на компьютере. 

	![Колонка «Настройка»](./media/data-factory-move-data-between-onprem-and-cloud/ConfigureBlade.png)
6. Не закрывайте **диспетчер конфигурации шлюза управления данными**. 
 
	![Менеджер конфигураций](./media/data-factory-move-data-between-onprem-and-cloud/ConfigurationManager.png)	
7. В колонке **Настройка** на портале щелкните **Повторно создать ключ** на панели команд и щелкните **Да** в окне с предупреждением. Скопируйте ключ в буфер обмена с помощью **кнопки копирования** рядом с текстом ключа. Обратите внимание, что шлюз на старом компьютере прекращает работу сразу же при повторном создании ключа.  
	
	![Повторное создание ключа](./media/data-factory-move-data-between-onprem-and-cloud/RecreateKey.png)
	 
8. Вставьте **ключ** в текстовое поле на странице **Регистрация шлюза** в **диспетчере конфигурации шлюза управления данными** на новом компьютере. Чтобы увидеть текст ключа, установите флажок **Показать ключ шлюза** (необязательное действие).
 
	![Копирование и регистрация ключа](./media/data-factory-move-data-between-onprem-and-cloud/CopyKeyAndRegister.png)
9. Щелкните **Зарегистрировать**, чтобы зарегистрировать шлюз в облачной службе.
10. На странице **Выбор сертификата** нажмите кнопку **Обзор** и выберите тот же сертификат, который использовался на старом шлюзе, затем введите **пароль** и щелкните **Готово**. 
 
	![Выбор сертификата](./media/data-factory-move-data-between-onprem-and-cloud/SpecifyCertificate.png)

	Вы можете экспортировать сертификат из старого шлюза следующим образом: запустите диспетчер конфигурации шлюза управления данными на старом компьютере, перейдите на вкладку **Сертификат**, нажмите кнопку **Экспорт** и следуйте инструкциям на экране. 
10. После успешной регистрации шлюза вы увидите, что на главной странице диспетчера конфигурации шлюза значение параметра **Регистрация** изменилось на **Зарегистрировано**, а параметр **Состояние** получил значение **Работает**. 

## Настройка учетных данных и безопасность

Вы также можете создать связанную службу SQL Server, используя вместо редактора фабрики данных колонку «Связанные службы».
 
3.	На главной странице фабрики данных щелкните плитку **Связанные службы**. 
4.	В колонке **Связанные службы** на панели команд щелкните **Создать хранилище данных**. 
4.	В поле **Имя** введите **SqlServerLinkedService**. 
2.	Щелкните стрелку рядом с надписью **Тип** и выберите **SQL Server**.

	![Создание хранилища данных](./media/data-factory-move-data-between-onprem-and-cloud/new-data-store.png)
3.	Под параметром **Тип** должны появиться дополнительные параметры.
4.	В параметре **Шлюз данных** выберите только что созданный шлюз. 

	![Параметры SQL Server](./media/data-factory-move-data-between-onprem-and-cloud/sql-server-settings.png)
4.	В поле **Сервер** введите имя сервера базы данных.
5.	В поле **База данных** введите имя базы данных.
6.	Щелкните стрелку рядом с элементом **Учетные данные**.

	![Колонка учетных данных](./media/data-factory-move-data-between-onprem-and-cloud/credentials-dialog.png)
7.	В колонке **Учетные данные** выберите ссылку **Щелкните здесь, чтобы задать учетные данные**.
8.	В диалоговом окне **Настройка учетных данных** выполните следующие действия.

	![Диалоговое окно "Настройка учетных данных"](./media/data-factory-move-data-between-onprem-and-cloud/setting-credentials-dialog.png) 1. Выберите тип **проверки подлинности**, который служба фабрики данных будет использовать для подключения к базе данных. 2. В поле **ИМЯ ПОЛЬЗОВАТЕЛЯ** укажите имя пользователя, у которого есть доступ к базе данных. 3. В поле **ПАРОЛЬ** укажите пароль этого пользователя. 4. Щелкните **ОК**, чтобы закрыть диалоговое окно. 
4. Щелкните **ОК**, чтобы закрыть колонку **Учетные данные**. 
5. Щелкните **ОК** в колонке **Новое хранилище данных**. 	
6. Убедитесь, что в колонке «Связанные службы» служба **SqlServerLinkedService** получила состояние «В сети». ![Состояние связанной службы SQL Server](./media/data-factory-move-data-between-onprem-and-cloud/sql-server-linked-service-status.png)

Если для доступа к порталу используется компьютер, отличный от компьютера шлюза, необходимо убедиться в том, что диспетчер учетных данных может подключиться к компьютеру шлюза. Если приложению не удается подключиться к компьютеру шлюза, вы не сможете задать учетные данные для источника данных и проверить подключение к нему.

При использовании приложения "Настройка учетных данных" (открывается на портале Azure для настройки доступа к локальному источнику данных) учетные данные шифруются с помощью сертификата, который указан на вкладке "Сертификат" в диспетчере конфигурации шлюза управления данными на компьютере со шлюзом.

Если вам нужен способ шифрования учетных данных на основе API, используйте командлет PowerShell [New-AzureDataFactoryEncryptValue](https://msdn.microsoft.com/library/azure/dn834940.aspx). Командлет шифрует учетные данные с помощью сертификата, который настроен в шлюзе. Зашифрованные учетные данные, возвращенные этим командлетом, можно добавить в JSON-файл в строку подключения (connectionString) в элемент EncryptedCredential. Этот файл нужно использовать с командлетом [New-AzureDataFactoryLinkedService](https://msdn.microsoft.com/library/azure/dn820246.aspx) или в фрагменте кода JSON в редакторе фабрики данных на портале.

	"connectionString": "Data Source=<servername>;Initial Catalog=<databasename>;Integrated Security=True;EncryptedCredential=<encrypted credential>",

**Примечание.** Если используется приложение «Настройка учетных данных», зашифрованные учетные данные автоматически добавляются в связанные службы, как показано выше.

Для настройки учетных данных при помощи редактора фабрики данных существует еще один способ. Если при помощи редактора создать связанную службу SQL Server и ввести учетные данные в виде обычного текста, эти учетные данные будут шифроваться с помощью сертификата, который принадлежит службе фабрики данных, а НЕ сертификата, который используется шлюзом. Хотя этот способ работает быстрее в некоторых случаях, он менее безопасен. Поэтому мы рекомендуем использовать его только для целей разработки и тестирования.


## Создание и регистрация шлюза с использованием Azure PowerShell 
В этом разделе описывается, как создать и зарегистрировать шлюз с использованием командлетов Azure PowerShell.

1. Запустите модуль **Azure PowerShell** в режиме администратора. 
2. Командлеты фабрики данных Azure доступны в режиме **AzureResourceManager**. Выполните следующую команду, чтобы перейти в режим **AzureResourceManager**:     

        switch-azuremode AzureResourceManager


2. Используйте командлет **New-AzureDataFactoryGateway** для создания логического шлюза следующим образом:

		New-AzureDataFactoryGateway -Name <gatewayName> -DataFactoryName <dataFactoryName> -ResourceGroupName ADF –Description <desc>

	**Пример команды и выходных данных**:


		PS C:\> New-AzureDataFactoryGateway -Name MyGateway -DataFactoryName $df -ResourceGroupName ADF –Description “gateway for walkthrough”

		Name              : MyGateway
		Description       : gateway for walkthrough
		Version           :
		Status            : NeedRegistration
		VersionStatus     : None
		CreateTime        : 9/28/2014 10:58:22
		RegisterTime      :
		LastConnectTime   :
		ExpiryTime        :
		ProvisioningState : Succeeded


3. Используйте командлет **New-AzureDataFactoryGatewayKey**, чтобы создать регистрационный ключ для вновь созданного шлюза, и сохраните этот ключ в локальной переменной **$Key**:

		New-AzureDataFactoryGatewayKey -GatewayName <gatewayname> -ResourceGroupName ADF -DataFactoryName <dataFactoryName>

	
	**Пример результата выполнения команды:**


		PS C:\> $Key = New-AzureDataFactoryGatewayKey -GatewayName MyGateway -ResourceGroupName ADF -DataFactoryName $df 

	
4. В Azure PowerShell перейдите к папке **C:\\Program Files\\Microsoft Data Management Gateway\\1.0\\PowerShellScript** и выполните сценарий **RegisterGateway.ps1** с локальной переменной **$Key**, как показано в примере ниже. Эта команда зарегистрирует агент клиента, который установлен на вашем компьютере, на ранее созданном логическом шлюзе.

		PS C:\> .\RegisterGateway.ps1 $Key.GatewayKey
		
		Agent registration is successful!

5. Вы можете использовать командлет **Get-AzureDataFactoryGateway**, чтобы получить список шлюзов своей фабрики данных. Если в поле **Состояние** указано значение **Подключено**, шлюз готов к эксплуатации.

		Get-AzureDataFactoryGateway -DataFactoryName <dataFactoryName> -ResourceGroupName ADF

Вы можете удалить шлюз, используя командлет **Remove-AzureDataFactoryGateway**, или обновить описание шлюза, используя командлет **Set-AzureDataFactoryGateway**. Дополнительную информацию о синтаксисе и другую информацию об этих командлетах см. в "Справочных материалах по командлетам фабрики данных".


## Потоки данных при копировании с помощью шлюза управления данными
Если в конвейере для передачи локальных данных в облако (с целью дальнейшей обработки) либо для экспорта готовых данных из облака обратно в локальное хранилище используется действие копирования, в таких операциях участвует шлюз данных.

Здесь показана обобщенная диаграмма потока данных и этапы копирования через шлюз данных. ![Поток данных при использовании шлюза](./media/data-factory-move-data-between-onprem-and-cloud/data-flow-using-gateway.png)

1.	Разработчик создает новый шлюз для фабрики данных Azure, используя [портал Azure](http://portal.azure.com) или [командлет PowerShell](https://msdn.microsoft.com/library/dn820234.aspx). 
2.	На панели "Связанные службы" разработчик определяет новую связанную службу для локального хранилища данных со шлюзом. В ходе настройки связанной службы разработчик указывает типы проверки подлинности и учетные данные в приложении "Настройка учетных данных" (см. пошаговые инструкции выше). Приложение "Настройка учетных данных" проверяет подключение к хранилищу данных и шлюзу и сохраняет учетные данные.
3.	Перед сохранением учетных данных в облаке шлюз шифрует их при помощи связанного с ним сертификата (указывается разработчиком).
4.	Служба перемещения (фабрика данных) взаимодействует со шлюзом, планируя задания и управляя ими через канал управления. Этот канал использует общую очередь служебной шины Azure. Когда нужно начать задание копирования, фабрика данных добавляет в очередь запрос с указанием учетных данных. После опроса очереди шлюз начинает задание.
5.	Шлюз расшифровывает учетные данные с помощью того же сертификата, после чего подключается к локальному хранилищу данных, используя соответствующий вариант проверки подлинности.
6.	Шлюз копирует данные из локального хранилища в облачное или из облачного хранилища в локальное в зависимости от настроек действия копирования в конвейере данных. Примечание: на этом этапе шлюз напрямую взаимодействует с облачной службой хранилища (например, с хранилищем BLOB-объектов Azure, SQL Azure и т. д) через защищенный канал (HTTPS).

### Рекомендации по портам и безопасности

1. Как сказано в пошаговых инструкциях выше, настроить учетные данные для доступа к локальному хранилищу данных из фабрики данных можно несколькими способами. В зависимости от выбранного способа действуют различные требования к портам.	

	- Использование приложения **Настройка учетных данных**. Программа установки шлюза управления данными по умолчанию открывает порты **8050** и **8051** в локальном брандмауэре Windows на компьютере со шлюзом. Эти порты используются приложением настройки учетных данных для передачи учетных данных на шлюз. Эти порты открываются только на компьютере, на котором установлен брандмауэр Windows. Они недоступны для подключений из Интернета, и их не нужно открывать в корпоративном брандмауэре.
	2.	Использование командлета PowerShell [New-AzureDataFactoryEncryptValue](https://msdn.microsoft.com/library/dn834940.aspx). а. Если вы шифруете учетные данные с помощью команды PowerShell и не хотите, чтобы программа установки шлюза открыла входящие порты в брандмауэре Windows на компьютере со шлюзом, во время установки используйте такую команду:
	
			msiexec /q /i DataManagementGateway.msi NOFIREWALL=1
3.	Приложение **Настройка учетных данных** необходимо запускать на компьютере с подключением к шлюзу управления данными. Только так вы сможете настроить учетные данные для источника данных и протестировать подключение к нему.
4.	При копировании данных в локальную базу данных SQL Server из базы данных Azure SQL (или наоборот) убедитесь в следующем.	
	- 	Брандмауэр на компьютере со шлюзом разрешает исходящие подключения TCP на **TCP**-порту **1433**.
	- 	В [параметрах брандмауэра Azure SQL](https://msdn.microsoft.com/library/azure/jj553530.aspx) добавьте **IP-адрес шлюза** в список **разрешенных IP-адресов**.
5.	При копировании данных из локального сервера SQL Server в любое место назначения, когда используются разные компьютер шлюза и компьютер с сервером SQL Server, выполните следующие действия: [настройте брандмауэр Windows](https://msdn.microsoft.com/library/ms175043.aspx) на компьютере с сервером SQL Server таким образом, чтобы шлюз мог получать доступ к базе данных через порты, которые прослушивает экземпляр SQL Server. Для экземпляра по умолчанию это порт 1433.

## Отправить отзыв
Мы будем очень благодарны за ваш отзыв об этой статье. Вы можете отправить его на наш адрес [электронной почты](mailto:adfdocfeedback@microsoft.com?subject=data-factory-move-data-between-onprem-and-cloud.md). Это займет несколько минут.

<!---HONumber=Nov15_HO1-->