<properties
	pageTitle="Создание первой фабрики данных (Visual Studio) | Microsoft Azure"
	description="В этом учебнике вы создадите образец конвейера фабрики данных Azure с помощью Visual Studio."
	services="data-factory"
	documentationCenter=""
	authors="spelluru"
	manager="jhubbard"
	editor="monicar"/>

<tags
	ms.service="data-factory"
	ms.workload="data-services"
	ms.tgt_pltfrm="na"
	ms.devlang="na"
	ms.topic="hero-article" 
	ms.date="05/16/2016"
	ms.author="spelluru"/>

# Создание первой фабрики данных Azure с помощью Microsoft Visual Studio
> [AZURE.SELECTOR]
- [Обзор учебника](data-factory-build-your-first-pipeline.md)
- [Редактор фабрики данных](data-factory-build-your-first-pipeline-using-editor.md)
- [PowerShell](data-factory-build-your-first-pipeline-using-powershell.md)
- [Visual Studio](data-factory-build-your-first-pipeline-using-vs.md)
- [Шаблон диспетчера ресурсов](data-factory-build-your-first-pipeline-using-arm.md)


Из этой статьи вы узнаете, как создать свою первую фабрику данных Azure с помощью программы Microsoft Visual Studio.

## Предварительные требования

1. Прежде чем продолжать, **обязательно** прочтите [обзорную статью](data-factory-build-your-first-pipeline.md) по этой теме и выполните предварительные условия.
2. Чтобы опубликовать сущности фабрики данных в фабрике данных Azure, необходимо **обладать правами администратора подписки Azure**. Сейчас действует такое ограничение. Мы сообщим вам, как только это требование изменится.
3. На вашем компьютере должны быть установлены следующие компоненты:
	- Visual Studio 2013 или Visual Studio 2015.
	- Загрузите пакет SDK Azure для Visual Studio 2013 или Visual Studio 2015. Перейдите к [Странице загрузки Azure](https://azure.microsoft.com/downloads/) и щелкните **VS 2013** или **VS2015** в разделе **.NET**.
	- Скачайте последнюю версию подключаемого модуля фабрики данных Azure для Visual Studio: [VS 2013](https://visualstudiogallery.msdn.microsoft.com/754d998c-8f92-4aa7-835b-e89c8c954aa5) или [VS 2015](https://visualstudiogallery.msdn.microsoft.com/371a4cf9-0093-40fa-b7dd-be3c74f49005). При использовании Visual Studio 2013 можно обновить подключаемый модуль, выполнив следующие действия: в меню выберите команду **Сервис** -> **Расширения и обновления** -> **В сети** -> **Галерея Visual Studio** -> **Инструменты фабрики данных Microsoft Azure для Visual Studio** -> **Обновить**.
 
В следующих разделах показано, как создавать и развертывать сущности фабрики данных.

## Создание проекта Visual Studio 
1. Запустите **Visual Studio 2013** или **Visual Studio 2015**. Щелкните **Файл**, наведите указатель мыши на пункт **Создать** и щелкните **Проект**. Откроется диалоговое окно **Новый проект**.  
2. В диалоговом окне **Новый проект** выберите шаблон **Фабрика данных** и нажмите **Пустой проект фабрики данных**.   

	![Диалоговое окно "Новый проект"](./media/data-factory-build-your-first-pipeline-using-vs/new-project-dialog.png)

3. Введите **имя** проекта, **расположение** и имя **решения**, а затем нажмите кнопку **ОК**.

	![Обозреватель решений](./media/data-factory-build-your-first-pipeline-using-vs/solution-explorer.png)

## Создание связанных служб
Фабрика данных может иметь один или несколько конвейеров. Конвейер может содержать одно или несколько действий. Это может быть, например, действие копирования, копирующее данные из исходного хранилища данных в конечное, и действие HDInsight Hive для выполнения скрипта Hive, преобразующего входные данные в выходные данные продукта. Имя и параметры для фабрики данных вы укажете позднее, при публикации решения фабрики данных.

На этом этапе вы свяжете учетную запись службы хранилища Azure и используемый по запросу кластер Azure HDInsight с фабрикой данных. В этом примере учетная запись хранения Azure содержит входные и выходные данные для конвейера. Для выполнения скрипта Hive, указанного в действии конвейера, в этом примере используется связанная служба HDInsight. Необходимо определить, какие данные хранилища и службы вычислений используются в сценарии, и связать эти службы с фабрикой данных путем создания связанных служб.

#### Создание связанной службы хранения Azure
На этом этапе вы свяжете учетную запись хранения Azure с фабрикой данных. В целях данного руководства используйте одну и ту же учетную запись хранения Azure для хранения входных и выходных данных и файла скрипта HQL.

4. Щелкните правой кнопкой мыши **Связанные службы** в обозревателе решений, наведите указатель мыши на команду **Добавить** и щелкните **Новый элемент**.      
5. В диалоговом окне **Добавление нового элемента** выберите в списке пункт **Связанные службы хранилища Azure** и нажмите кнопку **Добавить**. 
3. Замените **accountname** и **accountkey** на имя вашей учетной записи хранения Azure и ее ключ. Сведения о получении ключа доступа к хранилищу см. в разделах о [просмотре, копировании и повторном создании ключей доступа к хранилищу](../storage/storage-create-storage-account.md#view-copy-and-regenerate-storage-access-keys).

	![Связанная служба хранилища Azure](./media/data-factory-build-your-first-pipeline-using-vs/azure-storage-linked-service.png)

4. Сохраните файл **AzureStorageLinkedService1.json**.

#### Создание связанной службы Azure HDInsight
На этом этапе вы свяжете используемый по запросу кластер HDInsight с фабрикой данных. Кластер HDInsight автоматически создается в среде выполнения и удаляется после завершения обработки и простоя в течение указанного времени. Вместо используемого по запросу кластера HDInsight можно использовать собственный кластер HDInsight. Дополнительные сведения см. в статье [Связанные службы вычислений](data-factory-compute-linked-services.md).

1. В **обозревателе решений** щелкните правой кнопкой мыши **Связанные службы**, наведите указатель на пункт **Добавить** и выберите **Новый элемент**.
2. Выберите **Связанная служба HDInsight по запросу**, а затем щелкните **Добавить**. 
3. Замените фрагмент **JSON** на приведенный ниже код.

		{
		  "name": "HDInsightOnDemandLinkedService",
		  "properties": {
		    "type": "HDInsightOnDemand",
		    "typeProperties": {
		      "version": "3.2",
		      "clusterSize": 1,
		      "timeToLive": "00:30:00",
		      "linkedServiceName": "AzureStorageLinkedService1"
		    }
		  }
		}
	
	В следующей таблице приведены описания свойств JSON, используемых в этом фрагменте кода.
	
	Свойство | Описание
	-------- | -----------
	Version (версия) | Указывает, что версия создаваемого кластера HDInsight — 3.2. 
	ClusterSize (размер кластера) | Создает кластер HDInsight с одним узлом. 
	TimeToLive (срок жизни) | Указывает, сколько времени может простаивать кластер HDInsight, прежде чем он будет удален.
	linkedServiceName (имя связанной службы) | Указывает имя учетной записи хранения, в которой будут храниться журналы, создаваемые HDInsight.

	Обратите внимание на следующее.
	
	- С помощью вышеупомянутого файла JSON фабрика данных создает кластер HDInsight **под управлением Windows**. Можно также создать кластер HDInsight **под управлением Linux**. Дополнительные сведения см. в разделе [Связанная служба Azure HDInsight по запросу](data-factory-compute-linked-services.md#azure-hdinsight-on-demand-linked-service).
	- Вместо используемого по запросу кластера HDInsight можно использовать **собственный кластер HDInsight**. См. сведения о [связанной службе Azure HDInsight](data-factory-compute-linked-services.md#azure-hdinsight-linked-service).
	- Кластер HDInsight создает **контейнер по умолчанию** в хранилище BLOB-объектов, указанном в коде JSON (**linkedServiceName**). При удалении кластера HDInsight этот контейнер не удаляется. Это сделано специально. Если используется связанная служба HDInsight по запросу, кластер HDInsight создается для обработки каждого среза данных (если не используется динамический кластер **timeToLive**), после чего он удаляется.
	
		По мере обработки новых срезов количество контейнеров в хранилище BLOB-объектов будет увеличиваться. Если эти контейнеры не используются для устранения неполадок с заданиями, удалите их — это позволит сократить расходы на хранение. Подобные контейнеры имеют имена в формате **adfyourdatafactoryname**-**linkedservicename-datetimestamp**. Для удаления контейнеров в хранилище Azure BLOB-объектов используйте такие средства, как [обозреватель хранилищ Microsoft](http://storageexplorer.com/).

	Дополнительные сведения см. в разделе [Связанная служба Azure HDInsight по запросу](data-factory-compute-linked-services.md#azure-hdinsight-on-demand-linked-service). 
4. Сохраните файл **HDInsightOnDemandLinkedService1.json**.

## Создание наборов данных
На этом этапе вы создадите наборы данных, которые представляют входные и выходные данные для обработки Hive. Эти наборы данных ссылаются на службу **AzureStorageLinkedService1**, созданную ранее в ходе работы с этим руководством. Точки связанной службы указывают на учетную запись хранения Azure, а наборы данных указывают контейнер, папку и имя файла в хранилище, в котором содержатся входные и выходные данные.

#### Создание входного набора данных

1. В **обозревателе решений** щелкните правой кнопкой мыши элемент **Таблицы**, наведите указатель на пункт **Добавить** и выберите **Новый элемент**. 
2. Выберите из списка **BLOB-объект Azure**, измените имя файла на **InputDataSet.json** и нажмите кнопку **Добавить**.
3. Замените фрагмент **JSON** в редакторе на приведенный ниже код. 

	В фрагменте JSON создается набор данных с именем **AzureBlobInput**, представляющий входные данные для действия в конвейере. Кроме того, нужно указать, что входные данные размещаются в контейнере BLOB-объектов **adfgetstarted** и в папке **inputdata**.
		
		{
			"name": "AzureBlobInput",
		    "properties": {
		        "type": "AzureBlob",
		        "linkedServiceName": "AzureStorageLinkedService1",
		        "typeProperties": {
		            "fileName": "input.log",
		            "folderPath": "adfgetstarted/inputdata",
		            "format": {
		                "type": "TextFormat",
		                "columnDelimiter": ","
		            }
		        },
		        "availability": {
		            "frequency": "Month",
		            "interval": 1
		        },
		        "external": true,
		        "policy": {}
		    }
		} 

	В следующей таблице приведены описания свойств JSON, используемых в этом фрагменте кода.

	| Свойство | Описание |
	| :------- | :---------- |
	| type | Для свойства типа задано значение AzureBlob, так как данные хранятся в хранилище BLOB-объектов Azure. |  
	| linkedServiceName (имя связанной службы) | Ссылается на созданную ранее службу AzureStorageLinkedService1. |
	| fileName | Это необязательное свойство. Если это свойство не указано, выбираются все файлы из папки folderPath. В этом случае обрабатывается только файл input.log. |
	| type | Файлы журнала представлены в текстовом формате, поэтому мы используем значение TextFormat. | 
	| columnDelimiter | Столбцы в файлах журнала разделяются запятыми (,). |
	| frequency и interval | Для свойства frequency задано значение Month, а для свойства interval — значение 1. Это означает, что срезы входных данных доступны ежемесячно. | 
	| external | Это свойство имеет значение true, если входные данные не создаются службой фабрики данных. | 
	  
	
3. Сохраните файл **InputDataset.json**.

 
#### Создание выходного набора данных
Теперь создайте выходной набор данных, представляющий выходные данные, которые хранятся в хранилище BLOB-объектов Azure.

1. В **обозревателе решений** щелкните правой кнопкой мыши элемент **Таблицы**, наведите указатель на пункт **Добавить** и выберите **Новый элемент**. 
2. Выберите из списка **BLOB-объект Azure**, измените имя файла на **OutputDataset.json** и нажмите кнопку **Добавить**. 
3. Замените фрагмент **JSON** в редакторе на приведенный ниже код. 

	Этот фрагмент кода JSON создает набор данных с именем **AzureBlobOutput** и определяет структуру данных, получаемых с помощью скрипта Hive. Кроме того, нужно указать, что результаты будут храниться в контейнере больших двоичных объектов с именем **adfgetstarted** и в папке с именем **partitioneddata**. В разделе **availability** указывается частота, с которой будет создаваться выходной набор данных (ежемесячно).
	
		{
		  "name": "AzureBlobOutput",
		  "properties": {
		    "type": "AzureBlob",
		    "linkedServiceName": "AzureStorageLinkedService1",
		    "typeProperties": {
		      "folderPath": "adfgetstarted/partitioneddata",
		      "format": {
		        "type": "TextFormat",
		        "columnDelimiter": ","
		      }
		    },
		    "availability": {
		      "frequency": "Month",
		      "interval": 1
		    }
		  }
		}

	Описание этих свойств можно найти в разделе **Создание входного набора данных**. Значение свойства external для выходного набора данных не указывается, так как набор данных создается службой фабрики данных.

4. Сохраните файл **OutputDataset.json**.


### Создание конвейера
На этом этапе вы создадите свой первый конвейер с действием **HDInsightHive**. Обратите внимание, что срез входных данных создается ежемесячно (frequency: Month, interval: 1), срез выходных данных создается ежемесячно, а свойство scheduler для действия тоже имеет значение Month (см. ниже). Параметры выходного набора данных (outputs) и планировщика действия (scheduler) должны совпадать. В настоящее время расписание активируется с помощью выходного набора данных, поэтому его необходимо создать, даже если действие не создает никаких выходных данных. Если действие не принимает никаких входных данных, входной набор данных можно не создавать. Свойства, используемые в следующем фрагменте JSON, описаны в конце этого раздела.

1. В **обозревателе решений** щелкните правой кнопкой мыши **Конвейеры**, наведите указатель на команду **Добавить** и выберите **Новый элемент**. 
2. Выберите в списке пункт **Конвейер преобразования Hive** и нажмите кнопку **Добавить**. 
3. Замените фрагмент **JSON** на приведенный ниже код.

	> [AZURE.IMPORTANT] Замените свойство **storageaccountname** именем вашей учетной записи хранения.

		{
		    "name": "MyFirstPipeline",
		    "properties": {
		        "description": "My first Azure Data Factory pipeline",
		        "activities": [
		            {
		                "type": "HDInsightHive",
		                "typeProperties": {
		                    "scriptPath": "adfgetstarted/script/partitionweblogs.hql",
		                    "scriptLinkedService": "AzureStorageLinkedService1",
		                    "defines": {
		                        "inputtable": "wasb://adfgetstarted@<storageaccountname>.blob.core.windows.net/inputdata",
		                        "partitionedtable": "wasb://adfgetstarted@<storageaccountname>.blob.core.windows.net/partitioneddata"
		                    }
		                },
		                "inputs": [
		                    {
		                        "name": "AzureBlobInput"
		                    }
		                ],
		                "outputs": [
		                    {
		                        "name": "AzureBlobOutput"
		                    }
		                ],
		                "policy": {
		                    "concurrency": 1,
		                    "retry": 3
		                },
		                "scheduler": {
		                    "frequency": "Month",
		                    "interval": 1
		                },
		                "name": "RunSampleHiveActivity",
		                "linkedServiceName": "HDInsightOnDemandLinkedService"
		            }
		        ],
		        "start": "2016-04-01T00:00:00Z",
		        "end": "2016-04-02T00:00:00Z",
		        "isPaused": false
		    }
		}

 	Этот фрагмент создает конвейер из одного действия, использующего Hive для обработки данных в кластере HDInsight.
	
	Этот фрагмент создает конвейер из одного действия, использующего Hive для обработки данных в кластере HDInsight.
	
	Файл **partitionweblogs.hql** скрипта Hive хранится в учетной записи хранения Azure (указывается с помощью свойства scriptLinkedService с именем **AzureStorageLinkedService1**) в папке **script** в контейнере **adfgetstarted**.

	Раздел **defines** используется для настройки параметров среды выполнения, которые будут переданы в скрипт Hive в качестве значений конфигурации Hive (например, ${hiveconf:inputtable}, ${hiveconf:partitionedtable}).

	Активный период конвейера задается с помощью свойств **start** и **end**.

	В JSON действия укажите, что скрипт Hive будет выполняться в среде вычислений, указанной в свойстве **linkedServiceName**, — **HDInsightOnDemandLinkedService**.

	> [AZURE.NOTE] Подробные сведения о свойствах JSON, используемых в приведенном выше примере, см. в статье [Анатомия конвейера](data-factory-create-pipelines.md#anatomy-of-a-pipeline).
3. Сохраните файл **HiveActivity1.json**.

### Добавление файлов partitionweblogs.hql и input.log в качестве зависимости 

1. В **окне обозревателя решений** щелкните правой кнопкой мыши **Зависимости**, наведите указатель на команду **Добавить** и щелкните **Существующий элемент**.  
2. Перейдите в папку **C:\\ADFGettingStarted**, выберите файлы **partitionweblogs.hql** и **input.log**, а затем щелкните **Добавить**. Эти два файла, которые вы создали, являются необходимыми компонентами, описанными в [обзорной статье](data-factory-build-your-first-pipeline.md).

При публикации решения в рамках следующего шага файл **partitionweblogs.hql** отправляется в папку скриптов, расположенную в контейнере больших двоичных объектов **adfgetstarted**.

### Публикация и развертывание сущностей фабрики данных

18. В обозревателе решений щелкните проект правой кнопкой мыши и выберите **Опубликовать**. 
19. Если вы видите диалоговое окно **Войдите в учетную запись Майкрософт**, введите данные учетной записи с подпиской Azure и нажмите кнопку **Войти**.
20. Вы должны увидеть следующее диалоговое окно:

	![Диалоговое окно "Опубликовать"](./media/data-factory-build-your-first-pipeline-using-vs/publish.png)

21. На странице "Настройка фабрики данных" выполните следующие действия.
	1. Выберите элемент **Создать фабрику данных**.
	2. В поле **Имя** введите **FirstDataFactoryUsingVS**. 
	
		> [AZURE.IMPORTANT] Имя фабрики данных Azure должно быть глобально уникальным. Если при публикации появится сообщение об ошибке **Имя фабрики данных FirstDataFactoryUsingVS недоступно**, измените имя (например, yournameFirstDataFactoryUsingVS). Ознакомьтесь с разделом [Фабрика данных — правила именования](data-factory-naming-rules.md), чтобы узнать о правилах именования артефактов фабрики данных.
	3. Выберите соответствующую подписку в поле **Подписка**. 
	4. Выберите **группу ресурсов** для создаваемой фабрики данных. 
	5. Выберите **регион** для фабрики данных. 
	6. Нажмите кнопку **Далее** для перехода на страницу **Публикация элементов**. (Нажмите клавишу **TAB**, чтобы выйти из поля «Имя», если кнопка **Далее** недоступна).
23. На странице **Публикация элементов** убедитесь, что выбраны все сущности данных фабрики, и нажмите кнопку **Далее** для перехода на страницу **Сводка**.     
24. Просмотрите сводку и нажмите кнопку **Далее** для запуска процесса развертывания и просмотра **Состояния развертывания**.
25. На странице **Состояние развертывания** вы увидите состояние процесса развертывания. После завершения развертывания нажмите кнопку "Готово".

Обратите внимание на следующее:

- Если появится сообщение об ошибке **Подписка не зарегистрирована для использования пространства имен Microsoft.DataFactory**, выполните одно из следующих действий и повторите попытку публикации.

	- В Azure PowerShell выполните следующую команду, чтобы зарегистрировать поставщик фабрики данных Azure:
		
			Register-AzureRmResourceProvider -ProviderNamespace Microsoft.DataFactory
	
		Чтобы убедиться, что поставщик фабрики данных зарегистрирован, можно выполнить следующую команду:
	
			Get-AzureRmResourceProvider
	- Войдите на [портал Azure](https://portal.azure.com) с помощью подписки Azure и перейдите к колонке фабрики данных или создайте фабрику данных на портале Azure. Поставщик будет зарегистрирован автоматически.
- 	В будущем имя фабрики данных может быть зарегистрировано в качестве DNS-имени и, следовательно, стать отображаемым.
- 	Чтобы создать экземпляры фабрики данных, вы должны быть администратором или участником подписки Azure.

 
## Отслеживание конвейера

6. Войдите на [портал Azure](https://portal.azure.com/) и выполните следующие действия:
	1. Щелкните **Обзор** и выберите **Фабрики данных**. ![Обзор фабрик данных](./media/data-factory-build-your-first-pipeline-using-vs/browse-datafactories.png)
	2. Выберите **FirstDataFactoryUsingVS** из списка фабрик данных.
7. На домашней странице своей фабрики данных щелкните элемент **Схема**.
  
	![Плитка "Схема"](./media/data-factory-build-your-first-pipeline-using-vs/diagram-tile.png)
7. В представлении диаграммы вы увидите все конвейеры и наборы данных, используемые в этом учебнике.
	
	![Представление схемы](./media/data-factory-build-your-first-pipeline-using-vs/diagram-view-2.png)
8. Чтобы просмотреть все действия в конвейере, щелкните конвейер в схеме правой кнопкой мыши и выберите пункт "Открыть конвейер".

	![Откройте меню конвейера](./media/data-factory-build-your-first-pipeline-using-vs/open-pipeline-menu.png)
9. Убедитесь, что действие HDInsightHive отображается в конвейере.
  
	![Откройте представление конвейера](./media/data-factory-build-your-first-pipeline-using-vs/open-pipeline-view.png)

	Чтобы перейти к предыдущему представлению, щелкните **Фабрики данных** в меню навигации вверху.
10. В **представлении схемы** дважды щелкните набор данных **AzureBlobInput**. Убедитесь, что срез находится в состоянии **Готово**. Для отображения этого состояния может потребоваться несколько минут. Если это не произойдет через некоторое время, убедитесь, что входной файл (input.log) расположен в правильном контейнере (adfgetstarted) и папке (inputdata).

	![Срез входных данных в состоянии "Готово"](./media/data-factory-build-your-first-pipeline-using-vs/input-slice-ready.png)
11. Щелкните **X**, чтобы закрыть колонку **AzureBlobInput**.
12. В **представлении схемы** дважды щелкните набор данных **AzureBlobOutput**. Вы увидите срез, который обрабатывается в данный момент.

	![Выборка](./media/data-factory-build-your-first-pipeline-using-vs/dataset-blade.png)
9. Как только обработка завершится, срез перейдет в состояние **Готово**.
	>[AZURE.IMPORTANT] Создание используемого по требованию кластера HDInsight обычно занимает некоторое время (около 20 минут).  

	![Выборка](./media/data-factory-build-your-first-pipeline-using-vs/dataset-slice-ready.png)
	
10. Когда срез перейдет в состояние **Готово**, проверьте выходные данные в папке **partitioneddata** контейнера **adfgetstarted** в хранилище BLOB-объектов.
 
	![выходные данные](./media/data-factory-build-your-first-pipeline-using-vs/three-ouptut-files.png)

Инструкции по использованию портала Azure для мониторинга конвейера и наборов данных, созданных с помощью этого руководства, см. в разделе [Мониторинг конвейеров фабрики данных Azure и управление ими](data-factory-monitor-manage-pipelines.md).

Кроме того, для мониторинга конвейеров данных можно использовать приложение для мониторинга и управления. Дополнительные сведения об использовании этого приложения см. в статье [Мониторинг конвейеров фабрики данных Azure и управление ими с помощью нового приложения по мониторингу и управлению](data-factory-monitor-manage-app.md).

> [AZURE.IMPORTANT] В случае успешной обработки среза входной файл удаляется. Если вы хотите повторно обработать срез или еще раз выполнить инструкции из руководства, передайте входной файл (input.log) в папку inputdata в контейнере adfgetstarted.
 

## Использование обозревателя серверов для просмотра фабрик данных

1. В **Visual Studio** щелкните **Вид** в меню и нажмите кнопку **Обозреватель серверов**.
2. В окне обозревателя серверов разверните элементы **Azure** и **Фабрика данных**. Когда отобразится окно **Вход в Visual Studio**, введите данные **учетной записи**, связанной с вашей подпиской Azure, и нажмите кнопку **Продолжить**. Введите **пароль** и нажмите кнопку **Войти**. Visual Studio пытается получить сведения обо всех фабриках данных Azure в подписке. В окне **Список задач фабрики данных** будет отображено состояние операции.

	![Обозреватель серверов](./media/data-factory-build-your-first-pipeline-using-vs/server-explorer.png)
3. Щелкните фабрику данных правой кнопкой мыши и выберите пункт **Экспорт фабрики данных в новый проект**, чтобы создать проект Visual Studio на основе существующей фабрики данных.

	![Экспорт фабрики данных](./media/data-factory-build-your-first-pipeline-using-vs/export-data-factory-menu.png)

## Обновление средств фабрик данных для Visual Studio

Чтобы обновить средства фабрики данных Azure для Visual Studio, выполните следующие действия.

1. Щелкните в меню пункт **Сервис** и выберите элемент **Расширения и обновления**.
2. Выберите пункт **Обновления** слева, а затем — **Коллекция Visual Studio**.
3. Выберите **Средства фабрики данных Azure для Visual Studio** и нажмите кнопку **Обновить**. Если эта запись отсутствует, у вас уже установлена последняя версия средства. 

## Использование файлов конфигурации
Файлы конфигурации в Visual Studio можно использовать для индивидуальной настройки свойств связанных служб, таблиц и конвейеров для каждой среды.

Рассмотрим следующее определение JSON для связанной службы хранилища Azure. В нем нужно указать свойство **connectionString** с разными значениями accountname и accountkey. Значения accountname и accountkey зависят от того, в какой среде вы развертываете сущности фабрики данных (в среде разработки, в среде тестирования или в рабочей среде). Это можно сделать с помощью отдельного файла конфигурации для каждой среды.

	{
	    "name": "StorageLinkedService",
	    "properties": {
	        "type": "AzureStorage",
	        "description": "",
	        "typeProperties": {
	            "connectionString": "DefaultEndpointsProtocol=https;AccountName=<accountname>;AccountKey=<accountkey>"
	        }
	    }
	} 

### Добавление файла конфигурации
Добавьте файл конфигурации для каждой среды, выполнив следующие действия.

1. Щелкните правой кнопкой мыши проект фабрики данных в решении Visual Studio и последовательно выберите **Добавить** и **Новый элемент**.
2. В левой части окна в списке установленных шаблонов последовательно выберите пункты **Конфигурация** и **Файл конфигурации**, введите **имя** файла конфигурации и нажмите кнопку **Добавить**.

	![Добавление файла конфигурации](./media/data-factory-build-your-first-pipeline-using-vs/add-config-file.png)
3. Добавьте параметры конфигурации и их значения в формате, показанном ниже.

		{
		    "$schema": "http://datafactories.schema.management.azure.com/vsschemas/V1/Microsoft.DataFactory.Config.json",
		    "AzureStorageLinkedService1": [
		        {
		            "name": "$.properties.typeProperties.connectionString",
		            "value": "DefaultEndpointsProtocol=https;AccountName=<accountname>;AccountKey=<accountkey>"
		        }
		    ],
		    "AzureSqlLinkedService1": [
		        {
		            "name": "$.properties.typeProperties.connectionString",
		            "value":  "Server=tcp:spsqlserver.database.windows.net,1433;Database=spsqldb;User ID=spelluru;Password=Sowmya123;Trusted_Connection=False;Encrypt=True;Connection Timeout=30"
		        }
		    ]
		}

	В этом примере настраивается свойство connectionString связанной службы хранилища Azure и связанной службы Azure SQL. Обратите внимание, что имя указывается с использованием синтаксиса [JsonPath](http://goessner.net/articles/JsonPath/).

	Если JSON-файл содержит свойство, которое имеет массив значений, как показано ниже,

		"structure": [
	  		{
	  			"name": "FirstName",
	    		"type": "String"
	  		},
	  		{
	    		"name": "LastName",
	    	    "type": "String"
			}
		],
	
	вам нужно настроить файл конфигурации следующим образом (используйте в индексации отсчет с нуля):
		
		{
            "name": "$.properties.structure[0].name",
            "value": "FirstName"
        }
        {
            "name": "$.properties.structure[0].type",
            "value": "String"
        }
        {
            "name": "$.properties.structure[1].name",
            "value": "LastName"
        }
        {
            "name": "$.properties.structure[1].type",
            "value": "String"
        }

### Имена свойств c пробелами
Если имя свойства содержит пробелы, используйте квадратные скобки, как показано в следующем примере (имя сервера базы данных):

     {
         "name": "$.properties.activities[1].typeProperties.webServiceParameters.['Database server name']",
         "value": "MyAsqlServer.database.windows.net"
     }


### Развертывание решения с помощью конфигурации
Во время публикации сущностей фабрики данных Azure в Visual Studio можно указать конфигурацию, которая будет использоваться для этой операции публикации.

Чтобы опубликовать сущности в проекте фабрики данных Azure с помощью файла конфигурации, выполните следующие действия.

1. Щелкните правой кнопкой мыши проект фабрики данных и выберите пункт **Опубликовать**. Откроется диалоговое окно **Публикация элементов**. 
2. На странице **Настройка фабрики данных** выберите существующую фабрику данных или укажите значения для создания новой, а затем нажмите кнопку **Далее**.   
3. На странице **Публикация элементов** вы найдете раскрывающийся список **Выбор конфигурации развертывания** с доступными конфигурациями.

	![Выбор файла конфигурации](./media/data-factory-build-your-first-pipeline-using-vs/select-config-file.png)

4. Выберите нужный **файл конфигурации** и нажмите кнопку **Далее**.
5. Убедитесь, что на странице **Сводка** отображается имя нужного JSON-файла, и нажмите кнопку **Далее**. 
6. По завершении развертывания нажмите кнопку **Готово**. 

Во время развертывания значения из файла конфигурации используются, чтобы указать значения свойств в JSON-файлах для сущностей фабрики данных (связанные службы, таблицы и конвейеры), прежде чем сущности будут развернуты в службу фабрики данных Azure.

## Сводка 
Следуя инструкциям из этого руководства, вы создали фабрику данных Azure для обработки данных путем выполнения сценария Hive в кластере Hadoop HDInsight. Вы использовали редактор фабрики данных на портале Azure для выполнения следующих действий.

1.	Создание **фабрики данных Azure**.
2.	Создание двух **связанных служб**:
	1.	**Служба хранилища Azure** — связанная служба для связывания хранилища BLOB-объектов Azure, которое содержит входные и выходные файлы, с фабрикой данных.
	2.	**Azure HDInsight** — связанная служба по запросу для связывания кластера HDInsight Hadoop с фабрикой данных. Фабрика данных Azure своевременно создает кластер HDInsight Hadoop для обработки входных данных и генерирования выходных данных.
3.	Создание двух **наборов данных**, которые описывают входные и выходные данные для действия HDInsight Hive в конвейере.
4.	Создание **конвейера** с действием **HDInsight Hive**.


## Дальнейшие действия
В этой статье вы создали конвейер с действием преобразования (действие HDInsight), которое выполняет сценарий Hive в кластере HDInsight по требованию. Сведения о том, как копировать данные из хранилища BLOB-объектов Azure в SQL Azure с помощью действия копирования, см. в статье [Учебник. Копирование данных из хранилища BLOB-объектов Azure в Azure SQL](data-factory-copy-data-from-azure-blob-storage-to-sql-database.md).
  
## См. также
| Раздел | Описание |
| :---- | :---- |
| [Действия по преобразованию данных](data-factory-data-transformation-activities.md) | В этой статье рассматриваются действия по преобразованию данных (например, преобразование HDInsight Hive, используемое в этом руководстве), поддерживаемые фабрикой данных Azure. | 
| [Планирование и исполнение с использованием фабрики данных](data-factory-scheduling-and-execution.md) | Здесь объясняются аспекты планирования и исполнения в модели приложений фабрики данных. |
| [Конвейеры](data-factory-create-pipelines.md) | Эта статья поможет вам понять сущность конвейеров и действий в фабрике данных Azure, а также научиться с их помощью создавать комплексные рабочие процессы, управляемые данными, для конкретных бизнес-сценариев. |
| [Наборы данных](data-factory-create-datasets.md) | Эта статья поможет вам понять, что такое наборы данных в фабрике данных Azure.
| [Мониторинг конвейеров фабрики данных Azure и управление ими с помощью нового приложения по мониторингу и управлению](data-factory-monitor-manage-app.md) | В этой статье описывается мониторинг и отладка конвейеров, а также управление ими с помощью приложения мониторинга и управления. 

<!---HONumber=AcomDC_0629_2016-->