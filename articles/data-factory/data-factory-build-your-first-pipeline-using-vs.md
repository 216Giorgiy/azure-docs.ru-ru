<properties
	pageTitle="Начало работы с фабрикой данных Azure с помощью Visual Studio"
	description="В этом учебнике вы создадите образец конвейера фабрики данных Azure с помощью Visual Studio."
	services="data-factory"
	documentationCenter=""
	authors="spelluru"
	manager="jhubbard"
	editor="monicar"/>

<tags
	ms.service="data-factory"
	ms.workload="data-services"
	ms.tgt_pltfrm="na"
	ms.devlang="na"
	ms.topic="hero-article" 
	ms.date="12/18/2015"
	ms.author="spelluru"/>

# Создание первого конвейера фабрики данных Azure с помощью Visual Studio
> [AZURE.SELECTOR]
- [Tutorial Overview](data-factory-build-your-first-pipeline.md)
- [Using Data Factory Editor](data-factory-build-your-first-pipeline-using-editor.md)
- [Using PowerShell](data-factory-build-your-first-pipeline-using-powershell.md)
- [Using Visual Studio](data-factory-build-your-first-pipeline-using-vs.md)
- [Using Resource Manager Template](data-factory-build-your-first-pipeline-using-arm.md)


Из этой статьи вы узнаете, как создать свою первую фабрику данных Azure с помощью программы Microsoft Visual Studio.

## Предварительные требования

1. Прежде чем продолжать, **обязательно** прочтите [обзорную статью](data-factory-build-your-first-pipeline.md) по этой теме и выполните предварительные условия.
2. Здесь не приводятся общие сведения о службе фабрики данных Azure. Рекомендуем ознакомиться со статьей [Введение в службу фабрики данных Azure](data-factory-introduction.md), в которой вы найдете подробный обзор этой службы.  

## Пошаговое руководство. Создание и развертывание сущностей фабрики данных с помощью Visual Studio 

### Предварительные требования

На вашем компьютере должны быть установлены следующие компоненты:

- Visual Studio 2013 или Visual Studio 2015.
- Загрузите пакет SDK Azure для Visual Studio 2013 или Visual Studio 2015. Перейдите к [Странице загрузки Azure](https://azure.microsoft.com/downloads/) и щелкните **VS 2013** или **VS2015** в разделе **.NET**.
- Скачайте последнюю версию подключаемого модуля фабрики данных Azure для Visual Studio: [VS 2013](https://visualstudiogallery.msdn.microsoft.com/754d998c-8f92-4aa7-835b-e89c8c954aa5) или [VS 2015](https://visualstudiogallery.msdn.microsoft.com/371a4cf9-0093-40fa-b7dd-be3c74f49005). При использовании Visual Studio 2013 можно обновить подключаемый модуль, выполнив следующие действия: в меню выберите команду **Сервис** -> **Расширения и обновления** -> **В сети** -> **Галерея Visual Studio** -> **Инструменты фабрики данных Microsoft Azure для Visual Studio** -> **Обновить**. 
	
	

### Создание проекта Visual Studio 
1. Запустите **Visual Studio 2013** или **Visual Studio 2015**. Щелкните **Файл**, наведите указатель мыши на пункт **Создать** и щелкните **Проект**. Откроется диалоговое окно **Новый проект**.  
2. В диалоговом окне **Новый проект** выберите шаблон **Фабрика данных** и нажмите **Пустой проект фабрики данных**.   

	![Диалоговое окно "Новый проект"](./media/data-factory-build-your-first-pipeline-using-vs/new-project-dialog.png)

3. Введите **имя** проекта, **расположение** и имя **решения**, а затем нажмите кнопку **ОК**.

	![Обозреватель решений](./media/data-factory-build-your-first-pipeline-using-vs/solution-explorer.png)

### Создание связанных служб
Фабрика данных может иметь один или несколько конвейеров. Конвейер может содержать одно или несколько действий. Это может быть, например, действие копирования, копирующее данные из исходного хранилища данных в конечное, и действие HDInsight Hive для выполнения скрипта Hive, преобразующего входные данные в выходные данные продукта. Имя и параметры для фабрики данных вы укажете позднее, при публикации решения фабрики данных.

На этом этапе вы свяжете учетную запись службы хранилища Azure и используемый по запросу кластер Azure HDInsight с фабрикой данных. В этом примере учетная запись хранения Azure содержит входные и выходные данные для конвейера. Для выполнения скрипта Hive, указанного в действии конвейера, в этом примере используется связанная служба HDInsight. Необходимо определить, какие данные хранилища и службы вычислений используются в сценарии, и связать эти службы с фабрикой данных путем создания связанных служб.

#### Создание связанной службы хранения Azure
На этом этапе вы свяжете учетную запись хранения Azure с фабрикой данных. В целях данного руководства используйте одну и ту же учетную запись хранения Azure для хранения входных и выходных данных и файла скрипта HQL.

4. Щелкните правой кнопкой мыши **Связанные службы** в обозревателе решений, наведите указатель мыши на команду **Добавить** и щелкните **Новый элемент**.      
5. В диалоговом окне **Добавление нового элемента** выберите в списке пункт **Связанные службы хранилища Azure** и нажмите кнопку **Добавить**. 
3. Замените **accountname** и **accountkey** на имя вашей учетной записи хранения Azure и ее ключ. Сведения о получении ключа доступа к хранилищу см. в разделах о [просмотре, копировании и повторном создании ключей доступа к хранилищу](../storage/storage-create-storage-account.md#view-copy-and-regenerate-storage-access-keys).

	![Связанная служба хранилища Azure](./media/data-factory-build-your-first-pipeline-using-vs/azure-storage-linked-service.png)

4. Сохраните файл **AzureStorageLinkedService1.json**.

#### Создание связанной службы Azure HDInsight
На этом этапе вы свяжете используемый по запросу кластер HDInsight с фабрикой данных. Кластер HDInsight автоматически создается в среде выполнения и удаляется после завершения обработки и простоя в течение указанного времени. Вместо используемого по запросу кластера HDInsight можно использовать собственный кластер HDInsight. Дополнительные сведения см. в статье [Связанные службы вычислений](data-factory-compute-linked-services.md).

1. В **обозревателе решений** щелкните правой кнопкой мыши **Связанные службы**, наведите указатель на пункт **Добавить** и выберите **Новый элемент**.
2. Выберите **Связанная служба HDInsight по запросу**, а затем щелкните **Добавить**. 
3. Замените фрагмент **JSON** на приведенный ниже код.

		{
		  "name": "HDInsightOnDemandLinkedService",
		  "properties": {
		    "type": "HDInsightOnDemand",
		    "typeProperties": {
		      "version": "3.2",
		      "clusterSize": 1,
		      "timeToLive": "00:30:00",
		      "linkedServiceName": "AzureStorageLinkedService1"
		    }
		  }
		}
	
	В следующей таблице приведены описания свойств JSON, используемых в этом фрагменте кода.
	
	Свойство | Описание
	-------- | -----------
	Version (версия) | Указывает, что версия создаваемого кластера HDInsight — 3.2. 
	ClusterSize (размер кластера) | Создает кластер HDInsight с одним узлом. 
	TimeToLive (срок жизни) | Указывает, сколько времени может простаивать кластер HDInsight, прежде чем он будет удален.
	linkedServiceName (имя связанной службы) | Указывает имя учетной записи хранения, в которой будут храниться журналы, создаваемые HDInsight.

	Обратите внимание на следующее.
	
	- С помощью вышеупомянутого файла JSON фабрика данных создает кластер HDInsight **под управлением Windows**. Также можно создать кластер HDInsight **под управлением Linux**. Дополнительные сведения см. в разделе [Связанная служба Azure HDInsight по запросу](data-factory-compute-linked-services.md#azure-hdinsight-on-demand-linked-service). 
	- Вместо используемого по запросу кластера HDInsight можно использовать **собственный кластер HDInsight**. Дополнительные сведения см. в разделе [Связанная служба Azure HDInsight](data-factory-compute-linked-services.md#azure-hdinsight-linked-service).
	- Кластер HDInsight создает **контейнер по умолчанию** в хранилище BLOB-объектов, которое указано в коде JSON (**linkedServiceName**). При удалении кластера HDInsight этот контейнер не удаляется. Это сделано специально. Если используется связанная служба HDInsight по запросу, кластер HDInsight создается для обработки каждого среза данных (если не используется динамический кластер **timeToLive**), после чего он удаляется.
	
		По мере обработки новых срезов количество контейнеров в хранилище BLOB-объектов будет увеличиваться. Если эти контейнеры не используются для устранения неполадок с заданиями, удалите их — это позволит сократить расходы на хранение. Такие контейнеры имеют имена в формате "adf**имя\_вашей\_фабрики\_данных**-**имя\_связанной\_службы**-метка\_даты\_и\_времени". Для удаления контейнеров в хранилище Azure BLOB-объектов используйте такие средства, как [обозреватель хранилищ Microsoft](http://storageexplorer.com/).

	Дополнительные сведения см. в разделе [Связанная служба Azure HDInsight по запросу](data-factory-compute-linked-services.md#azure-hdinsight-on-demand-linked-service). 
4. Сохраните файл **HDInsightOnDemandLinkedService1.json**.

### Создание наборов данных
На этом этапе вы создадите наборы данных, которые представляют входные и выходные данные для обработки Hive. Эти наборы данных ссылаются на службу **AzureStorageLinkedService1**, созданную ранее в ходе работы с этим руководством. Точки связанной службы указывают на учетную запись хранения Azure, а наборы данных указывают контейнер, папку и имя файла в хранилище, в котором содержатся входные и выходные данные.

#### Создание входного набора данных

1. В **обозревателе решений** щелкните правой кнопкой мыши элемент **Таблицы**, наведите указатель на пункт **Добавить** и выберите **Новый элемент**. 
2. Выберите из списка **BLOB-объект Azure**, измените имя файла на **OutputDataset.json** и нажмите кнопку **Добавить**.
3. Замените фрагмент **JSON** в редакторе на приведенный ниже код. 

	В фрагменте JSON создается набор данных с именем **AzureBlobInput**, представляющий входные данные для действия в конвейере. Кроме того, нужно указать, что входные данные размещаются в контейнере BLOB-объектов **adfgetstarted** и в папке **inputdata**.
		
		{
			"name": "AzureBlobInput",
		    "properties": {
		        "type": "AzureBlob",
		        "linkedServiceName": "AzureStorageLinkedService1",
		        "typeProperties": {
		            "fileName": "input.log",
		            "folderPath": "adfgetstarted/inputdata",
		            "format": {
		                "type": "TextFormat",
		                "columnDelimiter": ","
		            }
		        },
		        "availability": {
		            "frequency": "Month",
		            "interval": 1
		        },
		        "external": true,
		        "policy": {}
		    }
		} 

	В следующей таблице приведены описания свойств JSON, используемых в этом фрагменте кода.

	| Свойство | Описание |
	| :------- | :---------- |
	| type | Для свойства типа задано значение AzureBlob, так как данные хранятся в хранилище BLOB-объектов Azure. |  
	| linkedServiceName (имя связанной службы) | Ссылается на созданную ранее службу AzureStorageLinkedService1. |
	| fileName | Это необязательное свойство. Если это свойство не указано, выбираются все файлы из папки folderPath. В этом случае обрабатывается только файл input.log. |
	| type | Файлы журнала представлены в текстовом формате, поэтому мы используем значение TextFormat. | 
	| columnDelimiter | Столбцы в файлах журнала разделяются запятыми (,). |
	| frequency и interval | Для свойства frequency задано значение Month, а для свойства interval — значение 1. Это означает, что срезы входных данных доступны ежемесячно. | 
	| external | Это свойство имеет значение true, если входные данные не создаются службой фабрики данных. | 
	  
	
3. Сохраните файл **InputDataset.json**.

 
#### Создадите выходной набор данных.
Теперь создайте выходной набор данных, представляющий выходные данные, которые хранятся в хранилище BLOB-объектов Azure.

1. В **обозревателе решений** щелкните правой кнопкой мыши элемент **Таблицы**, наведите указатель на пункт **Добавить** и выберите **Новый элемент**. 
2. Выберите из списка **BLOB-объект Azure**, измените имя файла на **OutputDataset.json** и нажмите кнопку **Добавить**. 
3. Замените фрагмент **JSON** в редакторе на приведенный ниже код. 

	Этот фрагмент кода JSON создает набор данных с именем **AzureBlobOutput** и определяет структуру данных, получаемых с помощью скрипта Hive. Кроме того, нужно указать, что результаты будут храниться в контейнере больших двоичных объектов с именем **adfgetstarted** и в папке с именем **partitioneddata**. В разделе **availability** указывается частота, с которой будет создаваться выходной набор данных (ежемесячно).
	
		{
		  "name": "AzureBlobOutput",
		  "properties": {
		    "type": "AzureBlob",
		    "linkedServiceName": "AzureStorageLinkedService1",
		    "typeProperties": {
		      "folderPath": "adfgetstarted/partitioneddata",
		      "format": {
		        "type": "TextFormat",
		        "columnDelimiter": ","
		      }
		    },
		    "availability": {
		      "frequency": "Month",
		      "interval": 1
		    }
		  }
		}

	Описание этих свойств можно найти в разделе **Создание входного набора данных**. Значение свойства external для выходного набора данных не указывается, так как набор данных создается службой фабрики данных.

4. Сохраните файл **OutputDataset.json**.


### Создание конвейера
На этом этапе вы создадите свой первый конвейер с действием **HDInsightHive**. Обратите внимание, что срез входных данных создается ежемесячно (frequency: Month, interval: 1), срез выходных данных создается ежемесячно, а свойство scheduler для действия тоже имеет значение Month (см. ниже). Параметры выходного набора данных (outputs) и планировщика действия (scheduler) должны совпадать. В настоящее время расписание активируется с помощью выходного набора данных, поэтому его необходимо создать, даже если действие не создает никаких выходных данных. Если действие не принимает никаких входных данных, входной набор данных можно не создавать. Свойства, используемые в следующем фрагменте JSON, описаны в конце этого раздела.

1. В **обозревателе решений** щелкните правой кнопкой мыши **Конвейеры**, наведите указатель на команду **Добавить** и выберите **Новый элемент**. 
2. Выберите в списке пункт **Конвейер преобразования Hive** и нажмите кнопку **Добавить**. 
3. Замените фрагмент **JSON** на приведенный ниже код.

	> [AZURE.IMPORTANT] Замените свойство **storageaccountname** именем вашей учетной записи хранения.

		{
		    "name": "MyFirstPipeline",
		    "properties": {
		        "description": "My first Azure Data Factory pipeline",
		        "activities": [
		            {
		                "type": "HDInsightHive",
		                "typeProperties": {
		                    "scriptPath": "adfgetstarted/script/partitionweblogs.hql",
		                    "scriptLinkedService": "AzureStorageLinkedService1",
		                    "defines": {
		                        "inputtable": "wasb://adfgetstarted@<storageaccountname>.blob.core.windows.net/inputdata",
		                        "partitionedtable": "wasb://adfgetstarted@<storageaccountname>.blob.core.windows.net/partitioneddata"
		                    }
		                },
		                "inputs": [
		                    {
		                        "name": "AzureBlobInput"
		                    }
		                ],
		                "outputs": [
		                    {
		                        "name": "AzureBlobOutput"
		                    }
		                ],
		                "policy": {
		                    "concurrency": 1,
		                    "retry": 3
		                },
		                "scheduler": {
		                    "frequency": "Month",
		                    "interval": 1
		                },
		                "name": "RunSampleHiveActivity",
		                "linkedServiceName": "HDInsightOnDemandLinkedService"
		            }
		        ],
		        "start": "2014-02-01T00:00:00Z",
		        "end": "2014-02-02T00:00:00Z",
		        "isPaused": false
		    }
		}

 	Этот фрагмент создает конвейер из одного действия, использующего Hive для обработки данных в кластере HDInsight.
	
	Этот фрагмент создает конвейер из одного действия, использующего Hive для обработки данных в кластере HDInsight.
	
	Файл **partitionweblogs.hql** скрипта Hive хранится в учетной записи хранения Azure (указывается с помощью свойства scriptLinkedService с именем **AzureStorageLinkedService1**) в папке **script** в контейнере **adfgetstarted**.

	Раздел **defines** используется для настройки параметров среды выполнения, которые будут переданы в скрипт Hive в качестве значений конфигурации Hive (например, ${hiveconf:inputtable}, ${hiveconf:partitionedtable}).

	Активный период конвейера задается с помощью свойств **start** и **end**.

	В JSON действия укажите, что скрипт Hive будет выполняться в среде вычислений, указанной в свойстве **linkedServiceName**, — **HDInsightOnDemandLinkedService**.

3. Сохраните файл **HiveActivity1.json**.

### Добавление файлов partitionweblogs.hql и input.log в качестве зависимости 

1. В **окне обозревателя решений** щелкните правой кнопкой мыши **Зависимости**, наведите указатель на команду **Добавить** и щелкните **Существующий элемент**.  
2. Перейдите в папку **C:\\ADFGettingStarted**, выберите файлы **partitionweblogs.hql** и **input.log**, а затем щелкните **Добавить**. Эти два файла, которые вы создали, являются необходимыми компонентами, описанными в [обзорной статье](data-factory-build-your-first-pipeline.md).

При публикации решения в рамках следующего шага файл **partitionweblogs.hql** отправляется в папку скриптов, расположенную в контейнере больших двоичных объектов **adfgetstarted**.

### Публикация и развертывание сущностей фабрики данных

18. В обозревателе решений щелкните проект правой кнопкой мыши и выберите **Опубликовать**. 
19. Если вы видите диалоговое окно **Войдите в учетную запись Майкрософт**, введите данные учетной записи с подпиской Azure и нажмите кнопку **Войти**.
20. Вы должны увидеть следующее диалоговое окно:

	![Диалоговое окно "Опубликовать"](./media/data-factory-build-your-first-pipeline-using-vs/publish.png)

21. На странице "Настройка фабрики данных" выполните следующие действия.
	1. Выберите элемент **Создать фабрику данных**.
	2. В поле **Имя** введите **FirstDataFactoryUsingVS**. 
	
		> [AZURE.IMPORTANT] Имя фабрики данных Azure должно быть глобально уникальным. Если при публикации появится сообщение об ошибке **Имя фабрики данных FirstDataFactoryUsingVS недоступно**, измените имя (например, yournameFirstDataFactoryUsingVS). Ознакомьтесь с разделом [Фабрика данных — правила именования](data-factory-naming-rules.md), чтобы узнать о правилах именования артефактов фабрики данных.
		> 
		> В будущем имя фабрики данных может быть зарегистрировано в качестве DNS-имени и, следовательно, стать отображаемым.
	3. Выберите соответствующую подписку в поле **Подписка**. 
	4. Выберите **группу ресурсов** для создаваемой фабрики данных. 
	5. Выберите **регион** для фабрики данных. 
	6. Нажмите кнопку **Далее** для перехода на страницу **Публикация элементов**. (Нажмите клавишу **TAB**, чтобы выйти из поля "Имя", если кнопка **Далее** недоступна). 
23. На странице **Публикация элементов** убедитесь, что выбраны все сущности данных фабрики, и нажмите кнопку **Далее** для перехода на страницу **Сводка**.     
24. Просмотрите сводку и нажмите кнопку **Далее** для запуска процесса развертывания и просмотра **Состояния развертывания**.
25. На странице **Состояние развертывания** вы увидите состояние процесса развертывания. После завершения развертывания нажмите кнопку "Готово". 
 
## Шаг 4. Мониторинг конвейера

6. Войдите на [портал Azure](https://portal.azure.com/) и выполните следующие действия:
	1. Щелкните **Обзор** и выберите **Фабрики данных**. ![Обзор фабрик данных](./media/data-factory-build-your-first-pipeline-using-vs/browse-datafactories.png) 
	2. Выберите **FirstDataFactoryUsingVS** из списка фабрик данных. 
7. На домашней странице своей фабрики данных щелкните элемент **Схема**.
  
	![Плитка "Схема"](./media/data-factory-build-your-first-pipeline-using-vs/diagram-tile.png)
7. В представлении диаграммы вы увидите все конвейеры и наборы данных, используемые в этом учебнике.
	
	![Представление схемы](./media/data-factory-build-your-first-pipeline-using-vs/diagram-view-2.png) 
8. Чтобы просмотреть все действия в конвейере, щелкните конвейер в схеме правой кнопкой мыши и выберите пункт "Открыть конвейер". 

	![Откройте меню конвейера](./media/data-factory-build-your-first-pipeline-using-vs/open-pipeline-menu.png)
9. Убедитесь, что действие HDInsightHive отображается в конвейере. 
  
	![Откройте представление конвейера](./media/data-factory-build-your-first-pipeline-using-vs/open-pipeline-view.png)

	Чтобы перейти к предыдущему представлению, щелкните **Фабрики данных** в меню навигации вверху. 
10. В **представлении схемы** дважды щелкните набор данных **AzureBlobInput**. Убедитесь, что срез находится в состоянии **Готово**. Для отображения этого состояния может потребоваться несколько минут. Если это не произойдет через некоторое время, убедитесь, что входной файл (input.log) расположен в правильном контейнере (adfgetstarted) и папке (inputdata).

	![Срез входных данных в состоянии "Готово"](./media/data-factory-build-your-first-pipeline-using-vs/input-slice-ready.png)
11. Щелкните **X**, чтобы закрыть колонку **AzureBlobInput**. 
12. В **представлении схемы** дважды щелкните набор данных **AzureBlobOutput**. Вы увидите срез, который обрабатывается в данный момент.

	![Выборка](./media/data-factory-build-your-first-pipeline-using-vs/dataset-blade.png)
9. Как только обработка завершится, срез перейдет в состояние **Готово**.
	>[AZURE.IMPORTANT] Создание используемого по требованию кластера HDInsight обычно занимает некоторое время (около 20 минут).  

	![Выборка](./media/data-factory-build-your-first-pipeline-using-vs/dataset-slice-ready.png)
	
10. Когда срез перейдет в состояние **Готово**, проверьте выходные данные в папке **partitioneddata** контейнера **adfgetstarted** в хранилище BLOB-объектов.
 
	![выходные данные](./media/data-factory-build-your-first-pipeline-using-vs/three-ouptut-files.png)

## Использование обозревателя серверов для просмотра сущностей фабрики данных

1. В **Visual Studio** щелкните **Вид** в меню и нажмите кнопку **Обозреватель серверов**.
2. В окне обозревателя серверов разверните элементы **Azure** и **Фабрика данных**. Когда отобразится окно **Вход в Visual Studio**, введите данные **учетной записи**, связанной с вашей подпиской Azure, и нажмите кнопку **Продолжить**. Введите **пароль** и нажмите кнопку **Войти**. Visual Studio пытается получить сведения обо всех фабриках данных Azure в подписке. В окне **Список задач фабрики данных** будет отображено состояние операции.

	![Обозреватель серверов](./media/data-factory-build-your-first-pipeline-using-vs/server-explorer.png)
3. Щелкните фабрику данных правой кнопкой мыши и выберите пункт **Экспорт фабрики данных в новый проект**, чтобы создать проект Visual Studio на основе существующей фабрики данных.

	![Экспорт фабрики данных](./media/data-factory-build-your-first-pipeline-using-vs/export-data-factory-menu.png)

## Обновление средств фабрик данных для Visual Studio

Чтобы обновить средства фабрики данных Azure для Visual Studio, выполните следующие действия.

1. Щелкните в меню пункт **Сервис** и выберите элемент **Расширения и обновления**.
2. Выберите пункт **Обновления** слева, а затем — **Коллекция Visual Studio**.
3. Выберите **Средства фабрики данных Azure для Visual Studio** и нажмите кнопку **Обновить**. Если эта запись отсутствует, у вас уже установлена последняя версия средства. 

Инструкции по использованию портала Azure для мониторинга конвейера и наборов данных, созданных с помощью этого руководства, см. в разделе [Мониторинг конвейеров фабрики данных Azure и управление ими](data-factory-monitor-manage-pipelines.md).
 

## Дальнейшие действия
В этой статье вы создали конвейер с действием преобразования (действие HDInsight), которое выполняет сценарий Hive в кластере HDInsight по требованию. Сведения о том, как копировать данные из хранилища BLOB-объектов Azure в SQL Azure с помощью действия копирования, см. в статье [Учебник. Копирование данных из хранилища BLOB-объектов Azure в Azure SQL](data-factory-get-started.md).
  

<!---HONumber=AcomDC_0128_2016-->