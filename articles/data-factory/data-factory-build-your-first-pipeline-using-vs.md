---
title: "Создание первой фабрики данных (Visual Studio) | Документация Майкрософт"
description: "В этом руководстве вы создадите образец конвейера фабрики данных Azure с помощью Visual Studio."
services: data-factory
documentationcenter: 
author: spelluru
manager: jhubbard
editor: monicar
ms.assetid: 7398c0c9-7a03-4628-94b3-f2aaef4a72c5
ms.service: data-factory
ms.workload: data-services
ms.tgt_pltfrm: na
ms.devlang: na
ms.topic: hero-article
ms.date: 03/06/2017
ms.author: spelluru
translationtype: Human Translation
ms.sourcegitcommit: 094729399070a64abc1aa05a9f585a0782142cbf
ms.openlocfilehash: 23927acae12f0db13fe6dd24a4e1fde8ced25d40
ms.lasthandoff: 03/07/2017


---
# <a name="tutorial-build-your-azure-first-data-factory-using-microsoft-visual-studio"></a>Руководство. Создание первой фабрики данных Azure с помощью Microsoft Visual Studio
> [!div class="op_single_selector"]
> * [Обзор и предварительные требования](data-factory-build-your-first-pipeline.md)
> * [Портал Azure](data-factory-build-your-first-pipeline-using-editor.md)
> * [Visual Studio](data-factory-build-your-first-pipeline-using-vs.md)
> * [PowerShell](data-factory-build-your-first-pipeline-using-powershell.md)
> * [Шаблон Resource Manager](data-factory-build-your-first-pipeline-using-arm.md)
> * [ИНТЕРФЕЙС REST API](data-factory-build-your-first-pipeline-using-rest-api.md)
>
>

Из этой статьи вы узнаете, как создать свою первую фабрику данных Azure с помощью программы Microsoft Visual Studio. Чтобы выполнить приведенные здесь инструкции с помощью других средств или пакетов SDK, выберите в раскрывающемся списке один из доступных вариантов.

> [!NOTE]
> В этом руководстве конвейер данных преобразовывает входные данные в выходные. Он не копирует данные из исходного хранилища данных в целевое. Инструкции по копированию данных из хранилища BLOB-объектов Azure в базу данных SQL с помощью фабрики данных Azure см. в [этой статье](data-factory-copy-data-from-azure-blob-storage-to-sql-database.md).
> 
> Можно объединить в цепочку два действия (выполнить одно действие вслед за другим), настроив выходной набор данных одного действия как входной набор данных другого действия. Подробные сведения см. в статье [Планирование и исполнение с использованием фабрики данных](data-factory-scheduling-and-execution.md). 

## <a name="prerequisites"></a>Предварительные требования
1. Прочтите [обзорную статью](data-factory-build-your-first-pipeline.md) и выполните **предварительные требования** .
2. Чтобы публиковать сущности фабрики данных из Visual Studio в фабрику данных Azure, требуются **права администратора подписки Azure** .
3. На вашем компьютере должны быть установлены следующие компоненты:
   * Visual Studio 2013 или Visual Studio 2015.
   * Загрузите пакет SDK Azure для Visual Studio 2013 или Visual Studio 2015. Перейдите на [cтраницу загрузки Azure](https://azure.microsoft.com/downloads/) и щелкните **VS 2013** или **VS2015** в разделе **.NET**.
   * Скачайте последнюю версию подключаемого модуля фабрики данных Azure для Visual Studio: [VS 2013](https://visualstudiogallery.msdn.microsoft.com/754d998c-8f92-4aa7-835b-e89c8c954aa5) или [VS 2015](https://visualstudiogallery.msdn.microsoft.com/371a4cf9-0093-40fa-b7dd-be3c74f49005). Вы также можете обновить подключаемый модуль, выполнив следующие действия. В меню выберите **Сервис** -> **Расширения и обновления** -> **В сети** -> **Галерея Visual Studio** -> **Microsoft Azure Data Factory Tools for Visual Studio**(Средства фабрики данных Microsoft Azure для Visual Studio) -> **Обновить**.

Теперь давайте создадим фабрику данных Azure с помощью Visual Studio.

## <a name="create-visual-studio-project"></a>Создание проекта Visual Studio
1. Запустите **Visual Studio 2013** или **Visual Studio 2015**. Щелкните **Файл**, наведите указатель мыши на пункт **Создать** и щелкните **Проект**. Откроется диалоговое окно **Новый проект** .  
2. В диалоговом окне **Новый проект** выберите шаблон **DataFactory** и щелкните **Empty Data Factory Project** (Пустой проект фабрики данных).   

    ![Диалоговое окно "Новый проект"](./media/data-factory-build-your-first-pipeline-using-vs/new-project-dialog.png)
3. Введите **имя** проекта, **расположение** и имя **решения**, а затем нажмите кнопку **ОК**.

    ![Обозреватель решений](./media/data-factory-build-your-first-pipeline-using-vs/solution-explorer.png)

## <a name="create-linked-services"></a>Создание связанных служб
Фабрика данных может иметь один или несколько конвейеров. Конвейер может содержать одно или несколько действий. Это может быть, например, действие копирования, копирующее данные из исходного хранилища данных в целевое, или действие HDInsight Hive для выполнения скрипта Hive, преобразующего входные данные. См. список [поддерживаемых хранилищ данных](data-factory-data-movement-activities.md#supported-data-stores-and-formats) для всех источников и приемников, которые поддерживаются действием копирования. См. список [связанных служб вычислений](data-factory-compute-linked-services.md), поддерживаемых фабрикой данных.

На этом шаге вы свяжете учетную запись службы хранилища Azure и используемый по запросу кластер Azure HDInsight с фабрикой данных. В этом примере учетная запись хранения Azure содержит входные и выходные данные для конвейера. Для выполнения скрипта Hive, указанного в действии конвейера, в этом примере используется связанная служба HDInsight. Определите, какие данные хранилища и службы вычислений используются в сценарии, и свяжите эти службы с фабрикой данных, создав связанные службы.  

Имя и параметры для фабрики данных вы укажете позднее, при публикации решения фабрики данных.

#### <a name="create-azure-storage-linked-service"></a>Создание связанной службы хранения Azure
На этом шаге вы свяжете учетную запись хранения Azure с фабрикой данных. В целях данного руководства используйте одну и ту же учетную запись хранения Azure для хранения входных и выходных данных и файла скрипта HQL.

1. Щелкните правой кнопкой мыши **Связанные службы** в обозревателе решений, наведите указатель мыши на команду **Добавить** и выберите **Новый элемент**.      
2. В диалоговом окне **Добавление нового элемента** выберите в списке пункт **Azure Storage Linked Service** (Связанная служба хранилища Azure) и нажмите кнопку **Добавить**.
3. Замените **accountname** и **accountkey** именем учетной записи хранения Azure и ее ключом. Сведения о получении, просмотре, копировании и повторном создании ключей доступа к хранилищу см. в разделе [Управление учетной записью хранения](../storage/storage-create-storage-account.md#manage-your-storage-account).
    ![Связанная служба хранения Azure](./media/data-factory-build-your-first-pipeline-using-vs/azure-storage-linked-service.png)
4. Сохраните файл **AzureStorageLinkedService1.json** .

#### <a name="create-azure-hdinsight-linked-service"></a>Создание связанной службы Azure HDInsight
На этом шаге вы свяжете используемый по запросу кластер HDInsight с фабрикой данных. Кластер HDInsight автоматически создается в среде выполнения и удаляется после завершения обработки и простоя в течение указанного времени. Вместо используемого по запросу кластера HDInsight можно использовать собственный кластер HDInsight. Дополнительные сведения см. в статье [Связанные службы вычислений](data-factory-compute-linked-services.md).

1. В **обозревателе решений** щелкните правой кнопкой мыши **Связанные службы**, наведите указатель на пункт **Добавить** и выберите **Новый элемент**.
2. Выберите **Связанная служба HDInsight по запросу**, а затем щелкните **Добавить**.
3. Замените фрагмент **JSON** на приведенный ниже код JSON.

    ```JSON
    {
      "name": "HDInsightOnDemandLinkedService",
      "properties": {
        "type": "HDInsightOnDemand",
        "typeProperties": {
          "version": "3.2",
          "clusterSize": 1,
          "timeToLive": "00:30:00",
          "linkedServiceName": "AzureStorageLinkedService1"
        }
      }
    }
    ```

    В следующей таблице приведены описания свойств JSON, используемых в этом фрагменте кода.

   | Свойство | Описание |
   | -------- | ----------- |
   | Version (версия) | Указывает, что версия создаваемого кластера HDInsight — 3.2. |
   | ClusterSize (размер кластера) |Указывает размер кластера HDInsight. |
   | TimeToLive (срок жизни) |Указывает, сколько времени может простаивать кластер HDInsight, прежде чем он будет удален. |
   | linkedServiceName (имя связанной службы) |Указывает имя учетной записи хранения, в которой будут храниться журналы, создаваемые HDInsight. |

    Обратите внимание на следующие моменты.

   * С помощью вышеупомянутого JSON-файла фабрика данных создает кластер HDInsight **под управлением Windows**. Можно также создать кластер HDInsight **под управлением Linux**. Дополнительные сведения см. в разделе [Связанная служба Azure HDInsight по запросу](data-factory-compute-linked-services.md#azure-hdinsight-on-demand-linked-service).
   * Вместо кластера HDInsight по запросу можно использовать **собственный кластер HDInsight**. См. сведения о [связанной службе Azure HDInsight](data-factory-compute-linked-services.md#azure-hdinsight-linked-service).
   * Кластер HDInsight создает **контейнер по умолчанию** в хранилище BLOB-объектов, указанном в коде JSON (**linkedServiceName**). При удалении кластера HDInsight этот контейнер не удаляется. В этом весь замысел. Если используется связанная служба HDInsight по запросу, кластер HDInsight создается при каждой обработке среза данных (если не используется динамический кластер**timeToLive**). После завершения обработки кластер автоматически удаляется.

       По мере обработки новых срезов количество контейнеров в хранилище BLOB-объектов будет увеличиваться. Если эти контейнеры не используются для устранения неполадок с заданиями, удалите их — это позволит сократить расходы на хранение. Имена этих контейнеров указаны по шаблону `adf**yourdatafactoryname**-**linkedservicename**-datetimestamp`. Для удаления контейнеров в хранилище BLOB-объектов Azure используйте такие инструменты, как [Microsoft Storage Explorer](http://storageexplorer.com/) .

     Дополнительные сведения см. в разделе [Связанная служба Azure HDInsight по запросу](data-factory-compute-linked-services.md#azure-hdinsight-on-demand-linked-service).
4. Сохраните файл **HDInsightOnDemandLinkedService1.json** .

## <a name="create-datasets"></a>Создание наборов данных
На этом шаге вы создадите наборы данных, которые представляют входные и выходные данные для обработки Hive. Эти наборы данных ссылаются на службу **AzureStorageLinkedService1** , созданную ранее в ходе работы с этим руководством. Точки связанной службы указывают на учетную запись хранения Azure, а наборы данных указывают контейнер, папку и имя файла в хранилище, в котором содержатся входные и выходные данные.   

#### <a name="create-input-dataset"></a>Создание входного набора данных
1. В **обозревателе решений** щелкните правой кнопкой мыши элемент **Таблицы**, наведите указатель на пункт **Добавить** и выберите **Новый элемент**.
2. Выберите в списке **BLOB-объект Azure**, измените имя файла на **InputDataSet.json** и нажмите кнопку **Добавить**.
3. Замените фрагмент **JSON** в редакторе на приведенный ниже фрагмент кода JSON.

    В фрагменте JSON создается набор данных с именем **AzureBlobInput** , представляющий входные данные для действия в конвейере. Кроме того, нужно указать, что входные данные размещаются в контейнере больших двоичных объектов `adfgetstarted` и в папке `inputdata`.

    ```JSON
    {
        "name": "AzureBlobInput",
        "properties": {
            "type": "AzureBlob",
            "linkedServiceName": "AzureStorageLinkedService1",
            "typeProperties": {
                "fileName": "input.log",
                "folderPath": "adfgetstarted/inputdata",
                "format": {
                    "type": "TextFormat",
                    "columnDelimiter": ","
                }
            },
            "availability": {
                "frequency": "Month",
                "interval": 1
            },
            "external": true,
            "policy": {}
        }
    }
    ```
    В следующей таблице приведены описания свойств JSON, используемых в этом фрагменте кода.

   | Свойство | Описание |
   | -------- | ----------- |
   | type |Для свойства типа задано значение AzureBlob, так как данные хранятся в хранилище BLOB-объектов Azure. |
   | linkedServiceName (имя связанной службы) |Ссылается на созданную ранее службу AzureStorageLinkedService1. |
   | fileName |Это необязательное свойство. Если это свойство не указано, выбираются все файлы из папки folderPath. В этом случае обрабатывается только файл input.log. |
   | type |Файлы журнала представлены в текстовом формате, поэтому мы используем значение TextFormat. |
   | columnDelimiter |Столбцы в файлах журнала разделяются запятыми (,). |
   | frequency и interval |Для свойства frequency задано значение Month, а для свойства interval — значение 1. Это означает, что срезы входных данных доступны ежемесячно. |
   | external |Это свойство имеет значение true, если входные данные не создаются службой фабрики данных. |
4. Сохраните файл **InputDataset.json** .

#### <a name="create-output-dataset"></a>Создание выходного набора данных
Теперь создайте выходной набор данных, представляющий выходные данные, которые хранятся в хранилище BLOB-объектов Azure.

1. В **обозревателе решений** щелкните правой кнопкой мыши элемент **Таблицы**, наведите указатель на пункт **Добавить** и выберите **Новый элемент**.
2. Выберите в списке **BLOB-объект Azure**, измените имя файла на **OutputDataset.json** и нажмите кнопку **Добавить**.
3. Замените фрагмент **JSON** в редакторе на приведенный ниже код JSON.

    Этот фрагмент кода JSON создает набор данных с именем **AzureBlobOutput**и определяет структуру данных, получаемых с помощью скрипта Hive. Кроме того, нужно указать, что результаты будут храниться в контейнере больших двоичных объектов `adfgetstarted` и в папке `partitioneddata`. В разделе **availability** указывается частота, с которой будет создаваться выходной набор данных (ежемесячно).

    ```JSON
    {
      "name": "AzureBlobOutput",
      "properties": {
        "type": "AzureBlob",
        "linkedServiceName": "AzureStorageLinkedService1",
        "typeProperties": {
          "folderPath": "adfgetstarted/partitioneddata",
          "format": {
            "type": "TextFormat",
            "columnDelimiter": ","
          }
        },
        "availability": {
          "frequency": "Month",
          "interval": 1
        }
      }
    }
    ```

    Описание этих свойств можно найти в разделе **Создание входного набора данных** . Значение свойства external для выходного набора данных не указывается, так как набор данных создается службой фабрики данных.
4. Сохраните файл **OutputDataset.json** .

### <a name="create-pipeline"></a>Создание конвейера
На этом шаге вы создадите свой первый конвейер с действием **HDInsightHive** . Срез входных данных создается ежемесячно (frequency: Month, interval: 1), срез выходных данных создается ежемесячно, свойство scheduler для действия также указывается ежемесячно. Параметры выходного набора данных (outputs) и планировщика действия (scheduler) должны совпадать. В настоящее время расписание активируется с помощью выходного набора данных, поэтому его необходимо создать, даже если действие не создает никаких выходных данных. Если действие не принимает никаких входных данных, входной набор данных можно не создавать. Свойства, используемые в следующем фрагменте JSON, описаны в конце этого раздела.

1. В **обозревателе решений** щелкните правой кнопкой мыши **Конвейеры**, наведите указатель на команду **Добавить** и выберите **Новый элемент.**
2. Выберите в списке пункт **Конвейер преобразования Hive** и нажмите кнопку **Добавить**.
3. Замените фрагмент **JSON** на приведенный ниже код.

   > [!IMPORTANT]
   > Замените свойство **storageaccountname** именем вашей учетной записи хранения.
   >
   >

    ```JSON
    {
        "name": "MyFirstPipeline",
        "properties": {
            "description": "My first Azure Data Factory pipeline",
            "activities": [
                {
                    "type": "HDInsightHive",
                    "typeProperties": {
                        "scriptPath": "adfgetstarted/script/partitionweblogs.hql",
                        "scriptLinkedService": "AzureStorageLinkedService1",
                        "defines": {
                            "inputtable": "wasb://adfgetstarted@<storageaccountname>.blob.core.windows.net/inputdata",
                            "partitionedtable": "wasb://adfgetstarted@<storageaccountname>.blob.core.windows.net/partitioneddata"
                        }
                    },
                    "inputs": [
                        {
                            "name": "AzureBlobInput"
                        }
                    ],
                    "outputs": [
                        {
                            "name": "AzureBlobOutput"
                        }
                    ],
                    "policy": {
                        "concurrency": 1,
                        "retry": 3
                    },
                    "scheduler": {
                        "frequency": "Month",
                        "interval": 1
                    },
                    "name": "RunSampleHiveActivity",
                    "linkedServiceName": "HDInsightOnDemandLinkedService"
                }
            ],
            "start": "2016-04-01T00:00:00Z",
            "end": "2016-04-02T00:00:00Z",
            "isPaused": false
        }
    }
    ```
     Этот фрагмент создает конвейер из одного действия, использующего Hive для обработки данных в кластере HDInsight.

    Файл сценария Hive **partitionweblogs.hql** хранится в учетной записи хранения Azure (задается с помощью свойства scriptLinkedService с именем **AzureStorageLinkedService1**) и в папке `script` контейнера `adfgetstarted`.

    Раздел **defines** используется для настройки параметров среды выполнения, которые будут переданы в скрипт Hive в качестве значений конфигурации Hive (например, ${hiveconf:inputtable}, ${hiveconf:partitionedtable}).

    Активный период конвейера задается с помощью свойств **start** и **end**.

    В действии JSON укажите, что скрипт Hive будет выполняться в среде вычислений, указанной в свойстве **linkedServiceName**, — **HDInsightOnDemandLinkedService**.

   > [!NOTE]
   > Сведения о свойствах JSON, используемых в этом примере, см. в разделе "Конвейер JSON" статьи [Конвейеры и действия в фабрике данных Azure](data-factory-create-pipelines.md).

4. Сохраните файл **HiveActivity1.json** .

### <a name="add-partitionweblogshql-and-inputlog-as-a-dependency"></a>Добавление файлов partitionweblogs.hql и input.log в качестве зависимости
1. В **окне обозревателя решений** щелкните правой кнопкой мыши **Зависимости**, наведите указатель на команду **Добавить** и щелкните **Существующий элемент**.  
2. Перейдите в папку **C:\ADFGettingStarted**, выберите файлы **partitionweblogs.hql** и **input.log**, а затем щелкните **Добавить**. Эти два файла, которые вы создали, являются необходимыми компонентами, описанными в [обзорной статье](data-factory-build-your-first-pipeline.md).

При публикации решения в рамках следующего шага файл **partitionweblogs.hql** отправляется в папку скриптов, расположенную в контейнере больших двоичных объектов `adfgetstarted`.   

### <a name="publishdeploy-data-factory-entities"></a>Публикация и развертывание сущностей фабрики данных
1. В обозревателе решений щелкните проект правой кнопкой мыши и выберите **Опубликовать**.
2. Когда отобразится диалоговое окно **Вход в учетную запись Майкрософт**, введите данные учетной записи с подпиской Azure и нажмите кнопку **Войти**.
3. Вы должны увидеть следующее диалоговое окно:

   ![Диалоговое окно "Опубликовать"](./media/data-factory-build-your-first-pipeline-using-vs/publish.png)
4. На странице **Configure data factory** (Настройка фабрики данных) выполните следующие действия:

   1. Выберите элемент **Создать фабрику данных** .
   2. Введите уникальное **имя** фабрики данных. Например, **FirstDataFactoryUsingVS09152016**. Оно должно быть глобально уникальным.
   3. Выберите соответствующую подписку в поле **Подписка** . Если подписки не отображаются, проверьте, выполнен ли вход с использованием учетной записи администратора или соадминистратора подписки.
   4. Выберите **группу ресурсов** для создаваемой фабрики данных.
   5. Выберите **регион** для фабрики данных.
   6. Нажмите кнопку **Далее**, чтобы перейти на страницу **Publish Items** (Публикация элементов). (Нажмите клавишу **TAB**, чтобы выйти из поля с именем, если кнопка **Далее** недоступна).

        > [!IMPORTANT]
        > Если при публикации появится сообщение об ошибке **Имя FirstDataFactoryUsingVS фабрики данных недоступно** , измените имя (например, на ваше_имя_FirstDataFactoryUsingVS). Ознакомьтесь с разделом [Фабрика данных — правила именования](data-factory-naming-rules.md) , чтобы узнать о правилах именования артефактов фабрики данных.   
1. На странице **Publish Items** (Публикация элементов) выберите все сущности фабрик данных и нажмите кнопку **Далее**, чтобы перейти на страницу **Сводка**.     
2. Просмотрите сводку и нажмите кнопку **Далее** для запуска процесса развертывания и просмотра **состояния развертывания**.
3. На странице **Состояние развертывания** вы увидите состояние процесса развертывания. После завершения развертывания нажмите кнопку "Готово".

Необходимо учитывать следующие важные замечания.

- Если появится сообщение об ошибке**Подписка не зарегистрирована для использования пространства имен Microsoft.DataFactory**, выполните одно из следующих действий и повторите попытку публикации.
    - В Azure PowerShell выполните следующую команду, чтобы зарегистрировать поставщик фабрики данных Azure:
        ```PowerShell    
        Register-AzureRmResourceProvider -ProviderNamespace Microsoft.DataFactory
        ```
        Чтобы убедиться, что поставщик фабрики данных зарегистрирован, выполните следующую команду:

        ```PowerShell
        Get-AzureRmResourceProvider
        ```
    - Войдите на [портал Azure](https://portal.azure.com) с использованием подписки Azure и откройте колонку фабрики данных или создайте на портале фабрику данных. Поставщик будет зарегистрирован автоматически.
- В будущем имя фабрики данных может быть зарегистрировано в качестве DNS-имени и, следовательно, стать отображаемым.
- Чтобы создать экземпляры фабрики данных, вы должны быть администратором или соадминистратором подписки Azure.

## <a name="monitor-pipeline"></a>Отслеживание конвейера
### <a name="monitor-pipeline-using-diagram-view"></a>Мониторинг конвейера с использованием представления схемы
1. Войдите на [портал Azure](https://portal.azure.com/) и сделайте следующее:
   1. Щелкните **Другие службы** и выберите **Фабрики данных**.
       
        ![Обзор фабрик данных](./media/data-factory-build-your-first-pipeline-using-vs/browse-datafactories.png)
   2. В списке фабрик данных выберите имя своей фабрики данных (например, **FirstDataFactoryUsingVS09152016**).
   
       ![Выбор фабрики данных](./media/data-factory-build-your-first-pipeline-using-vs/select-first-data-factory.png)
2. На домашней странице своей фабрики данных щелкните элемент **Схема**.

    ![Плитка "Схема"](./media/data-factory-build-your-first-pipeline-using-vs/diagram-tile.png)
3. В представлении схемы вы увидите все конвейеры и наборы данных, используемые в этом руководстве.

    ![Представление схемы](./media/data-factory-build-your-first-pipeline-using-vs/diagram-view-2.png)
4. Чтобы просмотреть все действия в конвейере, щелкните конвейер в схеме правой кнопкой мыши и выберите пункт "Открыть конвейер".

    ![Откройте меню конвейера](./media/data-factory-build-your-first-pipeline-using-vs/open-pipeline-menu.png)
5. Убедитесь, что действие HDInsightHive отображается в конвейере.

    ![Откройте представление конвейера](./media/data-factory-build-your-first-pipeline-using-vs/open-pipeline-view.png)

    Чтобы перейти к предыдущему представлению, щелкните **Фабрики данных** в меню навигации вверху.
6. В **представлении схемы** дважды щелкните набор данных **AzureBlobInput**. Убедитесь, что срез находится в состоянии **Готово** . Для отображения этого состояния может потребоваться несколько минут. Если это не произойдет через некоторое время, убедитесь, что входной файл (input.log) расположен в правильном контейнере (`adfgetstarted`) и папке (`inputdata`).

   ![Срез входных данных в состоянии "Готово"](./media/data-factory-build-your-first-pipeline-using-vs/input-slice-ready.png)
7. Щелкните **X**, чтобы закрыть колонку **AzureBlobInput**.
8. В **представлении схемы** дважды щелкните набор данных **AzureBlobOutput**. Вы увидите срез, который сейчас обрабатывается.

   ![Выборка](./media/data-factory-build-your-first-pipeline-using-vs/dataset-blade.png)
9. Как только обработка завершится, срез перейдет в состояние **Готово** .

   > [!IMPORTANT]
   > Создание используемого по требованию кластера HDInsight обычно занимает некоторое время (около 20 минут). Таким образом, конвейер обработает срез **примерно через 30 минут** .  
   >
   >

    ![Выборка](./media/data-factory-build-your-first-pipeline-using-vs/dataset-slice-ready.png)    
10. Когда срез перейдет в состояние **Готово**, проверьте выходные данные в папке `partitioneddata` контейнера `adfgetstarted` в хранилище BLOB-объектов.  

    ![выходные данные](./media/data-factory-build-your-first-pipeline-using-vs/three-ouptut-files.png)
11. Щелкните срез, чтобы просмотреть сведения о нем в колонке **Срез данных** .

    ![Сведения о срезе данных](./media/data-factory-build-your-first-pipeline-using-vs/data-slice-details.png)  
12. Щелкните выполнение действия в списке **Выполнения действий**, чтобы просмотреть сведения о нем (действие Hive в нашем сценарии) в окне **Подробности о выполнении операции**. 
  
    ![СВЕДЕНИЯ О ВЫПОЛНЕННОМ ДЕЙСТВИИ](./media/data-factory-build-your-first-pipeline-using-vs/activity-window-blade.png)    

    В файлах журналов содержатся сведения о выполненном запросе Hive и его состоянии. Эти журналы полезны при устранении неполадок.  

Инструкции по использованию портала Azure для мониторинга конвейера и наборов данных, созданных с помощью этого руководства, см. в разделе [Отслеживание конвейера](data-factory-monitor-manage-pipelines.md).

### <a name="monitor-pipeline-using-monitor--manage-app"></a>Мониторинг конвейера с использованием приложения по мониторингу и управлению
Для мониторинга конвейеров также можно использовать приложение по мониторингу и управлению. Дополнительные сведения об использовании этого приложения см. в статье [Мониторинг конвейеров фабрики данных Azure и управление ими с помощью нового приложения по мониторингу и управлению](data-factory-monitor-manage-app.md).

1. Щелкните плитку Monitor & Manage (Мониторинг и управление).

    ![Плитка Monitor & Manage (Мониторинг и управление)](./media/data-factory-build-your-first-pipeline-using-vs/monitor-and-manage-tile.png)
2. Вы должны увидеть приложение по мониторингу и управлению. Для параметров **времени начала** и **времени окончания** введите значения "01-04-2016 12:00" и "02-04-2016 12:00" для конвейера и щелкните **Применить**.

    ![Приложение по мониторингу и управлению](./media/data-factory-build-your-first-pipeline-using-vs/monitor-and-manage-app.png)
3. Выберите окно действия в списке Activity Windows (Окна действий), чтобы просмотреть сведения о нем.
    ![Сведения об окне действия](./media/data-factory-build-your-first-pipeline-using-vs/activity-window-details.png)

> [!IMPORTANT]
> В случае успешной обработки среза входной файл удаляется. Если вы хотите повторно обработать срез или еще раз выполнить инструкции из руководства, передайте входной файл (input.log) в папку `inputdata` в контейнере `adfgetstarted`.
>
>

## <a name="use-server-explorer-to-view-data-factories"></a>Использование обозревателя серверов для просмотра фабрик данных
1. В **Visual Studio** щелкните **Вид** в меню и выберите **Обозреватель серверов**.
2. В окне обозревателя серверов разверните элементы **Azure** и **Фабрика данных**. Когда отобразится окно **Выполните вход в Visual Studio**, введите данные **учетной записи**, связанной с вашей подпиской Azure, и нажмите кнопку **Продолжить**. Введите **пароль** и нажмите кнопку **Войти**. Visual Studio пытается получить сведения обо всех фабриках данных Azure в подписке. В окне **Data Factory Task List** (Список задач фабрики данных) будет отображено состояние операции.

    ![Обозреватель серверов](./media/data-factory-build-your-first-pipeline-using-vs/server-explorer.png)
3. Щелкните фабрику данных правой кнопкой мыши и выберите пункт **Export Data Factory to New Project** (Экспорт фабрики данных в новый проект), чтобы создать проект Visual Studio на основе имеющейся фабрики данных.

    ![Экспорт фабрики данных](./media/data-factory-build-your-first-pipeline-using-vs/export-data-factory-menu.png)

## <a name="update-data-factory-tools-for-visual-studio"></a>Обновление средств фабрик данных для Visual Studio
Чтобы обновить средства фабрики данных Azure для Visual Studio, сделайте следующее:

1. Щелкните в меню пункт **Сервис** и выберите **Расширения и обновления**.
2. Выберите пункт **Обновления** слева, а затем — **Галерея Visual Studio**.
3. Выберите **Azure Data Factory tools for Visual Studio** (Средства фабрики данных Azure для Visual Studio) и нажмите кнопку **Обновить**. Если эта запись отсутствует, у вас уже установлена последняя версия средства.

## <a name="use-configuration-files"></a>Использование файлов конфигурации
Файлы конфигурации в Visual Studio можно использовать для индивидуальной настройки свойств связанных служб, таблиц и конвейеров для каждой среды.

Рассмотрим следующее определение JSON для связанной службы хранилища Azure. В нем нужно указать свойство **connectionString**. В зависимости от того, в какую среду вы развертываете сущности фабрики данных (среда разработки, среда тестирования или рабочая среда), значения accountname и accountkey будут разными. Это можно сделать с помощью отдельного файла конфигурации для каждой среды.

```JSON
{
    "name": "StorageLinkedService",
    "properties": {
        "type": "AzureStorage",
        "description": "",
        "typeProperties": {
            "connectionString": "DefaultEndpointsProtocol=https;AccountName=<accountname>;AccountKey=<accountkey>"
        }
    }
}
```

### <a name="add-a-configuration-file"></a>Добавление файла конфигурации
Добавьте файл конфигурации для каждой среды, выполнив следующие действия.   

1. Щелкните правой кнопкой мыши проект фабрики данных в решении Visual Studio и последовательно выберите **Добавить** и **Новый элемент**.
2. В левой части окна в списке установленных шаблонов последовательно выберите пункты **Конфигурация** и **Файл конфигурации**, укажите **имя** файла конфигурации и нажмите кнопку **Добавить**.

    ![Добавление файла конфигурации](./media/data-factory-build-your-first-pipeline-using-vs/add-config-file.png)
3. Добавьте параметры конфигурации и их значения в следующем формате.

    ```JSON
    {
        "$schema": "http://datafactories.schema.management.azure.com/vsschemas/V1/Microsoft.DataFactory.Config.json",
        "AzureStorageLinkedService1": [
            {
                "name": "$.properties.typeProperties.connectionString",
                "value": "DefaultEndpointsProtocol=https;AccountName=<accountname>;AccountKey=<accountkey>"
            }
        ],
        "AzureSqlLinkedService1": [
            {
                "name": "$.properties.typeProperties.connectionString",
                "value":  "Server=tcp:spsqlserver.database.windows.net,1433;Database=spsqldb;User ID=spelluru;Password=Sowmya123;Trusted_Connection=False;Encrypt=True;Connection Timeout=30"
            }
        ]
    }
    ```

    В этом примере настраивается свойство connectionString связанной службы хранилища Azure и связанной службы Azure SQL. Обратите внимание, что имя указывается с использованием синтаксиса [JsonPath](http://goessner.net/articles/JsonPath/).   

    Если JSON-файл содержит свойство, которое имеет массив значений (см. ниже):  

    ```JSON
    "structure": [
          {
              "name": "FirstName",
            "type": "String"
          },
          {
            "name": "LastName",
            "type": "String"
        }
    ],
    ```

    Настройте свойства, как показано в следующем файле конфигурации (используйте индекс, начинающийся с нуля).

    ```JSON
    {
        "name": "$.properties.structure[0].name",
        "value": "FirstName"
    }
    {
        "name": "$.properties.structure[0].type",
        "value": "String"
    }
    {
        "name": "$.properties.structure[1].name",
        "value": "LastName"
    }
    {
        "name": "$.properties.structure[1].type",
        "value": "String"
    }
    ```

### <a name="property-names-with-spaces"></a>Имена свойств c пробелами
Если имя свойства содержит пробелы, используйте квадратные скобки, как показано в следующем примере (имя сервера базы данных):

```JSON
 {
     "name": "$.properties.activities[1].typeProperties.webServiceParameters.['Database server name']",
     "value": "MyAsqlServer.database.windows.net"
 }
```

### <a name="deploy-solution-using-a-configuration"></a>Развертывание решения с помощью конфигурации
Во время публикации сущностей фабрики данных Azure в Visual Studio можно указать конфигурацию, которая будет использоваться для этой операции публикации.

Чтобы опубликовать сущности в проекте фабрики данных Azure с помощью файла конфигурации, выполните следующие действия.   

1. Щелкните правой кнопкой мыши проект фабрики данных и выберите пункт **Publish** (Опубликовать). Откроется диалоговое окно **Publish Items** (Публикация элементов).
2. На странице **Configure data factory** (Настройка фабрики данных) выберите имеющуюся фабрику данных или укажите значения для создания новой, а затем нажмите кнопку **Next** (Далее).   
3. На странице **Publish Items** (Публикация элементов) вы найдете раскрывающийся список **Select Deployment Config** (Выбор конфигурации развертывания) с доступными конфигурациями.

    ![Выбор файла конфигурации](./media/data-factory-build-your-first-pipeline-using-vs/select-config-file.png)
4. Выберите нужный **файл конфигурации** и нажмите кнопку **Next** (Далее).
5. Убедитесь, что на странице **Summary** (Сводка) отображается имя нужного JSON-файла, и нажмите кнопку **Next** (Далее).
6. По завершении развертывания нажмите кнопку **Готово** .

При развертывании значения из файла конфигурации используются, чтобы указать значения свойств в JSON-файлах для сущностей фабрики данных, прежде чем сущности будут развернуты в службе фабрики данных Azure.   

## <a name="summary"></a>Сводка
Следуя инструкциям из этого руководства, вы создали фабрику данных Azure для обработки данных путем выполнения сценария Hive в кластере Hadoop HDInsight. Вы использовали редактор фабрики данных на портале Azure для выполнения следующих действий:  

1. создание **фабрики данных Azure**;
2. создание двух **связанных служб**.
   1. **Служба хранилища Azure** — связанная служба для связывания хранилища BLOB-объектов Azure, которое содержит входные и выходные файлы, с фабрикой данных.
   2. **Azure HDInsight** — связанная служба по запросу для связывания кластера HDInsight Hadoop с фабрикой данных. Фабрика данных Azure своевременно создает кластер HDInsight Hadoop для обработки входных данных и генерирования выходных данных.
3. Создание двух **наборов данных**, которые описывают входные и выходные данные для действия HDInsight Hive в конвейере.
4. Создание **конвейера** с действием **HDInsight Hive**.  

## <a name="next-steps"></a>Дальнейшие действия
В этой статье вы создали конвейер с действием преобразования (действие HDInsight), которое выполняет сценарий Hive в кластере HDInsight по требованию. Сведения о том, как копировать данные из хранилища BLOB-объектов Azure в SQL Azure с помощью действия копирования, см. в статье [Копирование данных из хранилища BLOB-объектов Azure в базу данных SQL с помощью фабрики данных](data-factory-copy-data-from-azure-blob-storage-to-sql-database.md).

## <a name="see-also"></a>См. также
| Раздел | Описание |
|:--- |:--- |
| [Конвейеры](data-factory-create-pipelines.md) |Эта статья поможет вам понять сущность конвейеров и действий в фабрике данных Azure, а также научиться с их помощью создавать комплексные рабочие процессы, управляемые данными, для конкретных бизнес-сценариев. |
| [Наборы данных](data-factory-create-datasets.md) |Эта статья поможет вам понять, что такое наборы данных в фабрике данных Azure. |
| [Действия по преобразованию данных](data-factory-data-transformation-activities.md) |В этой статье рассматриваются действия по преобразованию данных (например, преобразование HDInsight Hive, используемое в этом руководстве), поддерживаемые фабрикой данных Azure. |
| [Планирование и исполнение с использованием фабрики данных](data-factory-scheduling-and-execution.md) |Здесь объясняются аспекты планирования и исполнения в модели приложений фабрики данных. |
| [Мониторинг конвейеров фабрики данных Azure и управление ими с помощью нового приложения по мониторингу и управлению](data-factory-monitor-manage-app.md) |В этой статье описывается мониторинг и отладка конвейеров, а также управление ими с помощью приложения мониторинга и управления. |

