<properties
	pageTitle="Построение первого конвейера с помощью фабрики данных Azure"
	description="В этом учебнике показано, как, используя Visual Studio, создать конвейер, преобразующий данные с помощью Azure HDInsight."
	services="data-factory"
	documentationCenter=""
	authors="spelluru"
	manager="jhubbard"
	editor="monicar"/>

<tags
	ms.service="data-factory"
	ms.workload="data-services"
	ms.tgt_pltfrm="na"
	ms.devlang="na"
	ms.topic="get-started-article" 
	ms.date="07/27/2015"
	ms.author="spelluru"/>

# Построение первого конвейера с помощью фабрики данных Azure
> [AZURE.SELECTOR]
- [Tutorial Overview](data-factory-build-your-first-pipeline.md)
- [Using Data Factory Editor](data-factory-build-your-first-pipeline-using-editor.md)
- [Using PowerShell](data-factory-build-your-first-pipeline-using-powershell.md)
- [Using Visual Studio](data-factory-build-your-first-pipeline-using-vs.md)


Из этой статьи вы узнаете, как создать конвейер с помощью Visual Studio. В учебнике рассматриваются следующие действия:

1.	Создание фабрики данных.
2.	Создание связанных служб (хранилищ данных и служб вычислений) и наборов данных.
3.	Создание конвейера.

Здесь не приводятся общие сведения о службе фабрики данных Azure. Подробный обзор службы см. в статье [Введение в фабрику данных Azure](data-factory-introduction.md).

## Шаг 1. Создание фабрики данных

1.	Войдите на [портал предварительной версии Azure](http://portal.azure.com/) и выполните следующие действия:
	1.	Щелкните **СОЗДАТЬ** в левом нижнем углу. 
	2.	Щелкните **Аналитика данных** в колонке **Создание**.
	3.	Щелкните **Фабрика данных** в колонке **Аналитика данных**.

		![Колонка «Создание»](./media/data-factory-build-your-first-pipeline-using-vs/create-blade.png)

2.	В колонке **Создание фабрики данных** введите **DataFactoryMyFirstPipeline** в поле «Имя».

	![Создать колонку "Фабрика данных"](./media/data-factory-build-your-first-pipeline-using-vs/new-data-factory-blade.png)

	> [AZURE.IMPORTANT]Имена фабрики данных Azure являются глобально уникальными. Для успешного создания фабрики добавьте свое имя в качестве префикса имени фабрики. 
3.	Если вы еще не создали группу ресурсов, сделайте это сейчас. Для этого:
	1.	Щелкните **ИМЯ ГРУППЫ РЕСУРСОВ**.
	2.	Выберите команду **Создать группу ресурсов** в колонке **Группа ресурсов**.
	3.	В колонке **Создание группы ресурсов** введите значение **ADF** в поле **Имя**.
	4.	Нажмите кнопку **ОК**.
	
		![Создать группу ресурсов](./media/data-factory-build-your-first-pipeline-using-vs/create-resource-group.png)
4.	После выбора группы ресурсов убедитесь, что используется именно та подписка, в которой вы хотите создать фабрику данных.
5.	Нажмите кнопку **Создать** в колонке **Создание фабрики данных**.
6.	Созданная фабрика данных появится на **начальной панели** портала предварительной версии Azure.   

	![Статус создания фабрики данных](./media/data-factory-build-your-first-pipeline-using-vs/creating-data-factory-image.png)
7. Поздравляем! Вы успешно создали свою первую фабрику данных! Ее содержимое отображается на специальной странице. 	

	![Колонка "Фабрика данных"](./media/data-factory-build-your-first-pipeline-using-vs/data-factory-blade.png)

Из следующих разделов учебника вы узнаете, как создать связанные службы, наборы данных и конвейер.

## Пошаговое руководство. Создание и развертывание сущностей фабрики данных с помощью Visual Studio 

### Предварительные требования

На вашем компьютере должны быть установлены следующие компоненты: 
- Visual Studio 2013.
- Скачайте пакет SDK Azure для Visual Studio 2013. Перейдите на [страницу загрузки Azure](http://azure.microsoft.com/downloads/) и нажмите кнопку **Установить VS 2013** в разделе **.NET**.


### Создание проекта Visual Studio 
1. Запустите **Visual Studio 2013**. Щелкните **Файл**, наведите указатель мыши на пункт **Создать** и щелкните **Проект**. Откроется диалоговое окно **Новый проект**.  
2. В диалоговом окне **Новый проект** выберите шаблон **DataFactory** и щелкните **Пустой проект фабрики данных**. Если вы не видите шаблон DataFactory, закройте Visual Studio, установите пакет SDK Azure для Visual Studio 2013 и снова откройте Visual Studio.  

	![Диалоговое окно «Новый проект»](./media/data-factory-build-your-first-pipeline-using-vs/new-project-dialog.png)

3. Введите **имя** проекта, **расположение** и имя для **решения**, а затем нажмите кнопку **ОК**.

	![Обозреватель решений](./media/data-factory-build-your-first-pipeline-using-vs/solution-explorer.png)

### Создание связанных служб
На этом этапе вы свяжете учетную запись хранения Azure и кластер Azure HDInsight по требованию с фабрикой данных, а затем создадите набор данных, представляющий результаты выполнения сценария Hive.


#### Создание связанной службы хранения Azure


4. Щелкните правой кнопкой мыши **Связанные службы** в обозревателе решений, наведите указатель мыши на команду **Добавить** и щелкните **Новый элемент**.      
5. В диалоговом окне **Добавление нового элемента** выберите в списке пункт **Связанные службы хранилища Azure** и нажмите кнопку **Добавить**. 

	![Новая связанная служба](./media/data-factory-build-your-first-pipeline-using-vs/new-linked-service-dialog.png)
 
3. Замените **accountname** и **accountkey** на имя вашей учетной записи хранения Azure и ее ключ.

	![Связанная служба хранилища Azure](./media/data-factory-build-your-first-pipeline-using-vs/azure-storage-linked-service.png)

4. Сохраните файл **AzureStorageLinkedService1.json**.

#### Создание связанной службы Azure HDInsight
Теперь вы создадите связанную службу для кластера HDInsight по требованию, который будет использоваться для выполнения сценария Hive.

1. В **обозревателе решений** щелкните правой кнопкой мыши **Связанные службы**, наведите указатель мыши на команду **Добавить** и щелкните **Новый элемент**.
2. Выберите **Связанная служба HDInsight по запросу**, а затем щелкните **Добавить**. 
3. Замените фрагмент **JSON** на приведенный ниже код.

		{
		    "name": "HDInsightOnDemandLinkedService",
		    "properties": {
		        "version": "3.1",
		        "clusterSize": 1,
		        "timeToLive": "00:05:00",
		        "jobsContainer": "adfjobs",
		        "linkedServiceName": "StorageLinkedService",
		        "type": "HDInsightOnDemandLinkedService"
		    }
		}
	
	В следующей таблице приведены описания свойств JSON, используемых в этом фрагменте кода.
	
	Свойство | Описание
	-------- | -----------
	Version (версия) | Указывает, что версия создаваемого кластера HDInsight — 3.1. 
	ClusterSize (размер кластера) | Создает кластер HDInsight с одним узлом. 
	TimeToLive (срок жизни) | Указывает, сколько времени может простаивать кластер HDInsight, прежде чем он будет удален.
	JobsContainer (контейнер заданий) | Указывает имя контейнера заданий, в котором будут храниться журналы, создаваемые HDInsight.
	linkedServiceName (имя связанной службы) | Указывает имя учетной записи хранения, в которой будут храниться журналы, создаваемые HDInsight.

4. Сохраните файл **HDInsightOnDemandLinkedService1.json**.
 
### Создание выходного набора данных
Теперь вы создадите выходной набор данных, представляющий данные, которые хранятся в хранилище BLOB-объектов Azure.

1. В **обозревателе решений** щелкните команду **Добавить** правой кнопкой мыши и выберите пункт **Новый элемент**. 
2. Выберите из списка пункт **BLOB-объект Azure** и нажмите кнопку **Добавить**. 
3. Замените фрагмент **JSON** на приведенный ниже. Он создает набор данных с именем **AzureBlobOutput** и задает структуру данных, получаемых с помощью сценария Hive. В нем мы также указываем, что результаты должны храниться в BLOB-контейнере **data** и в папке **partitioneddata**. В разделе **availability** мы задаем частоту создания выходного набора данных (ежемесячно).
	
		{
		    "name": "AzureBlobOutput",
		    "properties": {
		        "location": {
		            "type": "AzureBlobLocation",
		            "folderPath": "data/partitioneddata",
		            "format": {
		                "type": "TextFormat",
		                "columnDelimiter": ","
		            },
		            "linkedServiceName": "StorageLinkedService"
		        },
		        "availability": {
		            "frequency": "Month",
		            "interval": 1
		        }
		    }
		}

4. Сохраните файл **AzureBlobLocation1.json**.


### Создание конвейера
На этом этапе вы создадите свой первый конвейер.

1. В **обозревателе решений** щелкните правой кнопкой мыши **Конвейеры**, наведите указатель мыши на команду **Добавить** и выберите **Новый элемент**. 
2. Выберите в списке пункт **Конвейер преобразования Hive** и нажмите кнопку **Добавить**. 
3. Замените фрагмент **JSON** на следующий код и укажите вместо **storageaccountname** имя вашей учетной записи хранения.

		{
			"name": "MyFirstPipeline",
			"properties": {
			"description": "My first Azure Data Factory pipeline",
		 	"activities": [
		      {
		            "type": "HDInsightActivity",
		            "transformation": {
		                    "scriptPath": "script/partitionweblogs.hql",
		                    "scriptLinkedService": "StorageLinkedService",
		                    "type": "Hive",
		                    "extendedProperties": {
		                        "partitionedtable": "wasb://data@<storageaccountname>.blob.core.windows.net/partitioneddata"
		                    }
		                },
		                "outputs": [   {  "name": "AzureBlobOutput"    }   ],
		                "policy": {  
		                    "concurrency": 1,
		                    "retry": 3
						},
		                "name": "RunSampleHiveActivity",
		                "linkedServiceName": "HDInsightOnDemandLinkedService"
		            }
		        ],
		        "start": "2014-01-01",
		        "end": "2014-01-02"
		    }
		}
 
	Этот фрагмент создает конвейер из одного действия, использующего Hive для обработки данных в кластере HDInsight.
	
	Файл сценария Hive **partitionweblogs.hql** хранится в учетной записи хранения Azure (задается с помощью связанной службы **StorageLinkedService**) и в контейнере с именем **script**.

	Раздел **extendedProperties** используется для настройки параметров среды выполнения, которые будут передаваться в сценарий Hive в качестве значений конфигурации (например, ${hiveconf:PartitionedData}).

	Период активности конвейера задается с помощью свойств **start** и **end**.

	В JSON действия указывается, что сценарий Hive будет выполняться с использованием ресурса, указанного связанной службой **HDInsightOnDemandLinkedService**.
3. Сохраните файл **HiveActivity1.json**. 

### Публикация и развертывание сущностей фабрики данных
  
1. Если инструменты фабрики данных не отображаются, включите их, щелкнув правой кнопкой мыши в любой точке панели инструментов и выбрав пункт **Фабрика данных**. 
19. На **панели инструментов фабрики данных** щелкните **раскрывающийся список**, чтобы отобразить все фабрики данных в подписке Azure. Если вы видите диалоговое окно **Выполните вход в Visual Studio**, сделайте следующее. 
	20. Укажите **учетную запись электронной почты**, связанную с подпиской Azure, в которой требуется создать фабрику данных, введите **пароль** и нажмите кнопку **Вход**.
	21. После успешного входа вы увидите все фабрики данных в подписке Azure. В этом учебнике мы создадим новую фабрику данных.       
22. В раскрывающемся списке выберите **DataFactoryMyFirstPipeline** и нажмите кнопку **Опубликовать**, чтобы развернуть и опубликовать связанные службы, наборы данных и конвейер.    

	![Кнопка "Опубликовать"](./media/data-factory-build-your-first-pipeline-using-vs/publish.png)

23. Вы увидите состояние публикации в окне **Список задач фабрики данных**, представленном на рисунке выше. Убедитесь, что публикация выполнена успешно.


## Использование обозревателя серверов для просмотра сущностей фабрики данных

1. В **Visual Studio** щелкните **Вид** в меню и нажмите кнопку **Обозреватель серверов**.
2. В окне обозревателя серверов разверните узлы **Azure** и **Фабрика данных**. Если вы видите окно **Вход в Visual Studio**, введите данные **учетной записи**, связанной с подпиской Azure, и нажмите кнопку **Продолжить**. Введите свой **пароль** и щелкните **Войти**. Visual Studio пытается получить сведения обо всех фабриках данных Azure в подписке. Вы увидите состояние операции в окне **Список задач фабрики данных**.

	![Обозреватель серверов](./media/data-factory-build-your-first-pipeline-using-vs/server-explorer.png)
3. Щелкните фабрику данных правой кнопкой мыши и выберите пункт **Экспорт фабрики данных в новый проект**, чтобы создать проект Visual Studio на основе существующей фабрики данных.

	![Экспорт фабрики данных](./media/data-factory-build-your-first-pipeline-using-vs/export-data-factory-menu.png)

## Обновление средств фабрик данных для Visual Studio

Чтобы обновить средства фабрики данных Azure для Visual Studio, выполните следующие действия.

1. Щелкните **Средства** в меню и выберите команду **Расширения и обновления**.
2. Выберите в левой области пункт **Обновления**, а затем — **Коллекция Visual Studio**.
3. Выберите **Средства фабрики данных Azure для Visual Studio** и нажмите кнопку **Обновить**. Если эта запись отсутствует, у вас уже установлена последняя версия средства. 

Инструкции по использованию портала предварительной версии Azure для мониторинга конвейера и наборов данных, созданных в этом учебнике, см. в разделе [Мониторинг наборов данных и конвейера](data-factory-monitor-manage-pipelines.md).
 

## Дальнейшие действия
В этой статье вы создали конвейер с действием преобразования (действие HDInsight), которое выполняет сценарий Hive в кластере HDInsight по требованию. Сведения о том, как копировать данные из хранилища BLOB-объектов Azure в SQL Azure с помощью действия копирования, см. в учебнике [Копирование данных из хранилища BLOB-объектов Azure в Azure SQL](data-factory-get-started.md).
  

<!----HONumber=August15_HO6-->