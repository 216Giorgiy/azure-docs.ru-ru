---
title: Сопоставление преобразованного приемника потоков данных Фабрики данных Azure
description: Сопоставление преобразованного приемника потоков данных Фабрики данных Azure
author: kromerm
ms.author: makromer
ms.service: data-factory
ms.topic: conceptual
ms.date: 02/03/2019
ms.openlocfilehash: a39fa0949276b7e86c7fdd0d0861492a9a0b723e
ms.sourcegitcommit: 70550d278cda4355adffe9c66d920919448b0c34
ms.translationtype: MT
ms.contentlocale: ru-RU
ms.lasthandoff: 03/26/2019
ms.locfileid: "58438638"
---
# <a name="mapping-data-flow-sink-transformation"></a>Сопоставление преобразованного приемника потока данных

[!INCLUDE [notes](../../includes/data-factory-data-flow-preview.md)]

![Параметры приемника](media/data-flow/sink1.png "Приемник 1")

По завершении преобразования потока данных можно принять преобразованные данные в целевом наборе данных. В преобразовании приемника можно выбрать определение набора данных, которые необходимо использовать для назначения выходных данных. У вас может быть столько преобразований приемников, сколько необходимо потоку данных.

Распространенной практикой учета изменений поступающих данных и учета смещения схемы является прием выходных данных в папку без определенной схемы в наборе выходных данных. Вы можете дополнительно учесть все изменения столбцов в источниках, выбрав "Разрешить смещение схемы" в источнике, а затем автоматизировать все поля в приемнике.

Вы можете перезаписать, добавить или завершить с ошибкой поток данных при переходе к набору данных.

Кроме того, вы можете выбрать "Автосопоставление", чтобы записывать в приемник все входящие поля. Если нужно выбрать поля, которые вы хотите передать к месту назначения, или если вы хотите изменить имена полей в месте назначения, выберите "Отключить" для параметра "Автосопоставление", а затем щелкните вкладку "Сопоставление", чтобы отобразить выходные поля:

![Параметры приемника](media/data-flow/sink2.png "Приемник 2")

## <a name="output-to-one-file"></a>Выходные данные в одном файле
Для типов приемников Azure Storage Blob или Data Lake Store преобразованные данные будут выводиться в папку. Spark создает секционированные файлы выходных данных на основе схемы секционирования, используемой при преобразовании приемника. Вы можете задать схему секционирования, щелкнув вкладку "Оптимизировать". Если вы хотите, чтобы ADF объединил выходные данные в один файл, щелкните переключатель "Одна секция".

![Параметры приемника](media/data-flow/opt001.png "Параметры приемника")

## <a name="field-mapping"></a>Сопоставление полей

На вкладке "Сопоставление" преобразования приемника можно сопоставить исходящие столбцы слева с местом назначения справа. При приеме потоков данных в файлы ADF всегда будет записывать новые файлы в папку. При подключении к набору данных базы данных вы можете либо создать таблицу с помощью этой схемы (задайте для параметра "Сохранить политику" значение "Перезаписать"), либо вставить новые строки в имеющуюся таблицу и сопоставить поля со схемой.

Множественный выбор в таблице сопоставления позволяет связать несколько столбцов с одним щелчком мыши, удаляют ссылки на несколько столбцов или сопоставить несколько строк, то же имя столбца.

Если вы хотите всегда принимают входящие набор полей и сопоставить их с целевой-установите для параметра «Разрешить смещение схемы».

![Сопоставления полей](media/data-flow/multi1.png "несколько вариантов")

Если вы хотите сбросить сопоставления столбцов, нажмите кнопку "Переназначение", чтобы восстановить сопоставления.

![Параметры приемника](media/data-flow/sink1.png "Приемник 1")

![Параметры приемника](media/data-flow/sink2.png "Приемники")

* Параметры Allow Schema Drift (Разрешить смещения схемы) и Validate Schema (Проверить схему) теперь доступны в приемнике. Это позволит вам проинструктировать ADF либо полностью принять гибкие определения схемы (смещение схемы), либо отказаться от приемника, если схема изменится (проверка схемы).

* Очистка папки. ADF усечет содержимое папки приемника, прежде чем записать конечные файлы в эту папку.

## <a name="file-name-options"></a>Параметры имени файла

   * Значение по умолчанию: Разрешение Spark называть файлы на основе значений по умолчанию PART
   * Шаблон. Ввести шаблон для выходных файлов. Например, «ссуд [n]» создаст loans1.csv, loans2.csv,...
   * На один раздел. Введите имя файла для одного раздела.
   * Как данные в столбце. Задайте для выходного файла значение столбца

> [!NOTE]
> Файловые операции будут выполняться только при выполнении действия "Выполнить поток данных", а не в режиме отладки потока данных.

## <a name="database-options"></a>Параметры базы данных

* Разрешить insert, update, delete, операция Upsert. Значение по умолчанию — разрешить операции вставки. Предназначается для обновления, вставки-обновления или удаления строк, необходимо сначала добавить на преобразование строки alter в тег строки для этих конкретных действий. Отключение «Разрешить вставку» перестанет ADF вставлять новые строки из источника.
* Усечение таблицы (удаляет все строки из целевой таблицы до завершения потока данных)
* Создайте таблицу заново (выполняет удаляют или создают целевой таблицы до завершения потока данных)
* размер пакета для больших объемов данных. Введите число для записи контейнеров на фрагменты
* Включите промежуточный режим: Это даст ADF, чтобы использовать Polybase при загрузке хранилище данных Azure в качестве набора данных приемника

> [!NOTE]
> В поток данных вы можете попросить ADF, чтобы создать новое определение таблицы в целевой базе данных, задав набор данных в приемник преобразование, которое имеет имя новой таблицы. В наборе данных SQL щелкните «Изменить» под именем таблицы и введите новое имя таблицы. После этого в преобразовании приемника, включите «Разрешить смещение схемы». Сет параметр «Импорт схемы» значение None.

![Исходная схема преобразования](media/data-flow/dataset2.png "SQL схемы")

![Параметры приемника SQL](media/data-flow/alter-row2.png "параметры SQL")

> [!NOTE]
> При обновлении или удалении строк в приемник вашей базы данных, необходимо задать ключевой столбец. Таким образом, строка Alter является возможность определить уникальную строку в DML.

## <a name="next-steps"></a>Дальнейшие действия

Теперь, после создания потока данных, добавьте [действие выполнения потока данных в свой конвейер](concepts-data-flow-overview.md).
