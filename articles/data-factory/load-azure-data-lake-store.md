---
title: "Загрузка данных в Azure Data Lake Store с помощью фабрики данных Azure | Документация Майкрософт"
description: "Копирование данных в Azure Data Lake Store с помощью фабрики данных Azure"
services: data-factory
documentationcenter: 
author: linda33wj
manager: jhubbard
editor: spelluru
ms.service: data-factory
ms.workload: data-services
ms.topic: article
ms.date: 01/17/2018
ms.author: jingwang
ms.openlocfilehash: 3f73cd65b0ceb3148ce8ceb83d7b4e1be1280077
ms.sourcegitcommit: 828cd4b47fbd7d7d620fbb93a592559256f9d234
ms.translationtype: HT
ms.contentlocale: ru-RU
ms.lasthandoff: 01/18/2018
---
# <a name="load-data-into-azure-data-lake-store-using-azure-data-factory"></a>Загрузка данных в Azure Data Lake Store с помощью фабрики данных Azure

[Azure Data Lake Store](../data-lake-store/data-lake-store-overview.md) — это крупномасштабный репозиторий корпоративного уровня для рабочих нагрузок анализа больших данных. Azure Data Lake позволяет сохранять данные с любым размером, типом и скоростью приема в одном месте для эксплуатационной и исследовательской аналитики.

Фабрика данных Azure — это полностью управляемая облачная служба интеграции данных, которую можно использовать для заполнения озера данными из имеющейся системы, экономя ценное время при создании решений на основе аналитики. Ниже приведены ключевые преимущества загрузки данных в Azure Data Lake Store с помощью фабрики данных Azure.

* **Простота настройки**: вам доступен 5-этапный интуитивно понятный мастер без необходимости создавать сценарии.
* **Расширенная поддержка хранилищ данных.** Встроенная поддержка обширного набора локальных и облачных хранилищ. Полный список см. в таблице [поддерживаемых хранилищ данных](copy-activity-overview.md#supported-data-stores-and-formats).
* **Безопасность и совместимость**: данные передаются по протоколу HTTPS или ExpressRoute, а наличие глобальной службы гарантирует, что ваши данные никогда не покинут заданных географических границ.
* **Высокая производительность.** Скорость загрузки данных в Azure Data Lake Store — до 1 Гбит/с. Дополнительные сведения см. в статье [Руководство по настройке производительности действия копирования](copy-activity-performance.md).

В этой статье показано, как с помощью средства копирования данных фабрики данных **загружать данные из Amazon S3 в Azure Data Lake Store**. Для копирования данных из других типов хранилищ данных необходимо выполнить аналогичные шаги.

> [!NOTE]
>  В статье [Копирование данных в хранилище Azure Data Lake Store и из него с помощью фабрики данных Azure](connector-azure-data-lake-store.md) приведены общие сведения о возможностях фабрики данных по копированию данных в хранилище данных Azure Data Lake Store и из него.
>
> Эта статья относится к версии 2 фабрики данных, которая в настоящее время доступна в предварительной версии. Если используется служба фабрики данных версии 1, которая является общедоступной версией, ознакомьтесь со статьей [Move data by using Copy Activity](v1/data-factory-data-movement-activities.md) (Перемещение данных с помощью действия копирования).

## <a name="prerequisites"></a>предварительным требованиям

* **Подписка Azure**. Если у вас еще нет подписки Azure, создайте [бесплатную](https://azure.microsoft.com/free/) учетную запись Azure, прежде чем начинать работу.
* **Azure Data Lake Store** Если у вас нет учетной записи Data Lake Store, см. раздел о [создании учетных записей Data Lake Store](../data-lake-store/data-lake-store-get-started-portal.md#create-an-azure-data-lake-store-account), чтобы узнать, как создать ее.
* **Amazon S3**. В этой статье показано, как скопировать данные из Amazon S3. Вы можете использовать другие хранилища данных, выполнив аналогичные действия.

## <a name="create-a-data-factory"></a>Создание фабрики данных

1. Щелкните **Создать** в меню слева, выберите **Данные+аналитика** и щелкните **Фабрика данных**. 
   
   ![Создать -> Фабрика данных](./media/load-data-into-azure-data-lake-store/new-azure-data-factory-menu.png)
2. На странице **Новая фабрика данных** задайте значения, как показано на следующем снимке экрана: 
      
     ![Страница "Новая фабрика данных"](./media/load-data-into-azure-data-lake-store//new-azure-data-factory.png)
 
   * **Name** (Имя). Введите глобальное уникальное имя фабрики данных. При возникновении указанной ниже ошибки измените имя фабрики данных (например, на ваше_имя_ADFTutorialDataFactory) и попробуйте создать фабрику данных снова. Ознакомьтесь со статьей [Фабрика данных Azure — правила именования](naming-rules.md), чтобы узнать правила именования для артефактов службы "Фабрика данных".
  
            `Data factory name "LoadADLSDemo" is not available`

    * **Subscription** (Подписка). Выберите **подписку** Azure, в рамках которой вы хотите создать фабрику данных. 
    * **Resource Group** (Группа ресурсов). Выберите имеющуюся группу ресурсов из раскрывающегося списка или щелкните вариант **Создать новую** и введите имя группы ресурсов. Сведения о группах ресурсов см. в статье, где описывается [использование групп ресурсов для управления ресурсами Azure](../azure-resource-manager/resource-group-overview.md).  
    * **Version** (Версия). Выберите **V2 (Preview)** (V2 (предварительная версия)).
    * **Местоположение**. Укажите расположение фабрики данных. В раскрывающемся списке отображаются только поддерживаемые расположения. Хранилища данных (служба хранилища Azure, Azure Data Lake Store, база данных SQL Azure и т. д.), используемые фабрикой данных, могут располагаться в других расположениях или регионах.

3. Нажмите кнопку **Создать**.
4. Когда завершится создание, перейдите в фабрику данных и откроется страница **Фабрика данных**, как показано на рисунке ниже. Щелкните плитку **Author & Monitor** (Создание и мониторинг), чтобы открыть на отдельной вкладке приложение интеграции данных. 
   
   ![Домашняя страница фабрики данных](./media/load-data-into-azure-data-lake-store/data-factory-home-page.png)

## <a name="load-data-into-azure-data-lake-store"></a>Загрузка данных в Azure Data Lake Store

1. На странице начала работы щелкните плитку **Копировать данные**, чтобы запустить средство копирования данных. 

   ![Плитка средства копирования данных](./media/load-data-into-azure-data-lake-store/copy-data-tool-tile.png)
2. На странице **свойств** для средства копирования данных укажите **CopyFromAmazonS3ToADLS** в качестве **имени задачи** и щелкните **Next** (Далее). 

    ![Средство копирования данных — страница свойств](./media/load-data-into-azure-data-lake-store/copy-data-tool-properties-page.png)
3. На странице **Исходное хранилище данных** выберите **Amazon S3** и щелкните **Next** (Далее).

    ![Страница исходного хранилища данных](./media/load-data-into-azure-data-lake-store/source-data-store-page.png)
4. На странице **Specify Amazon S3 connection** (Указать подключение Amazon S3) выполните следующие действия: 
    1. Укажите **идентификатор ключа доступа**.
    2. Укажите **секретный ключ доступа**.
    3. Нажмите кнопку **Далее**. 

        ![Указать учетную запись Amazon S3](./media/load-data-into-azure-data-lake-store/specify-amazon-s3-account.png)
5. На странице **Choose the input file or folder** (Выбрать входную папку или файл) перейдите в папку или файл, которые необходимо скопировать, выберите и щелкните **Выбрать**, а затем — **Next** (Далее). 

    ![Выбор файла или папки входных данных](./media/load-data-into-azure-data-lake-store/choose-input-folder.png)

6. На странице **Целевое хранилище данных** выберите **Azure Data Lake Store** и щелкните **Next** (Далее). 

    ![Страница целевого хранилища данных](./media/load-data-into-azure-data-lake-store/destination-data-storage-page.png)

7. На этой странице выберите поведение копирования, установив флажки **Copy files recursively** (Копировать файлы рекурсивно) и **Binary copy** (Двоичное копирование) (скопируйте файлы как есть). Нажмите кнопку **Далее**.

    ![Укажите выходную папку.](./media/load-data-into-azure-data-lake-store/specify-binary-copy.png)

8. На странице **Specify Data Lake Store connection** (Указать подключение Data Lake Store) выполните следующие действия: 

    1. Выберите Data Lake Store для **имени учетной записи Data Lake Store**.
    2. Укажите сведения о субъекте-службе, включая **клиента**, **идентификатор субъекта-службы** и **ключ субъекта-службы**.
    3. Нажмите кнопку **Далее**. 

    > [!IMPORTANT]
    > В этом пошаговом руководстве используется **субъект-служба** для аутентификации хранилища озера данных. Следуйте [этим](connector-azure-data-lake-store.md#using-service-principal-authentication) инструкциям и убедитесь, что в Azure Data Lake Store субъекту-службе предоставлено правильное разрешение.

    ![Указание учетной записи Azure Data Lake Store](./media/load-data-into-azure-data-lake-store/specify-adls.png)

9. На странице **Choose the output file or folder** (Выбор целевого файла или папки) укажите **copyfroms3**, а затем щелкните **Next** (Далее). 

    ![Укажите выходную папку.](./media/load-data-into-azure-data-lake-store/specify-adls-path.png)


10. На странице **Параметры** нажмите кнопку **Далее**. 

    ![Страница «Параметры»](./media/load-data-into-azure-data-lake-store/copy-settings.png)
11. На странице **Summary** (Сводка) проверьте все настройки и щелкните **Next** (Далее).

    ![Страница "Сводка"](./media/load-data-into-azure-data-lake-store/copy-summary.png)
12. На **странице развертывания** щелкните **Monitor** (Мониторинг), чтобы отслеживать созданный конвейер (задачу).

    ![Страница развертывания](./media/load-data-into-azure-data-lake-store/deployment-page.png)
13. Обратите внимание, что слева автоматически выбирается вкладка **Мониторинг**. В столбце **действий** отображаются ссылки для просмотра сведений о запусках действий и (или) повторного выполнения конвейере. 

    ![Мониторинг выполнений конвейера](./media/load-data-into-azure-data-lake-store/monitor-pipeline-runs.png)
14. Чтобы просмотреть сведения о выполнении действий, связанных с этим запуском конвейера, щелкните ссылку **View Activity Runs** (Просмотр сведений о выполнении действий) в столбце **Действия**. В этом конвейере определено только одно действие (действие копирования), поэтому вы увидите только одну запись. Чтобы вернуться к представлению запусков конвейера, щелкните ссылку **Pipelines** (Конвейеры) в верхней части окна. Щелкните **Refresh** (Обновить), чтобы обновить этот список. 

    ![Мониторинг выполнений действий](./media/load-data-into-azure-data-lake-store/monitor-activity-runs.png)

15. Дополнительно можно отслеживать сведения о выполнении каждого действия копирования, щелкнув ссылку **Подробности** в разделе **Действия** в представлении мониторинга действия. Оно содержит сведения, включая объем данных, копируемых из источника в приемник, пропускную способность, действия, которые выполняются для него с соответствующей длительностью и используемыми параметрами.

    ![Мониторинг сведений о выполнении действия](./media/load-data-into-azure-data-lake-store/monitor-activity-run-details.png)

16. Убедитесь, что данные скопированы в Azure Data Lake Store. 

    ![Проверка выходных данных Azure Data Lake Store](./media/load-data-into-azure-data-lake-store/adls-copy-result.png)

## <a name="next-steps"></a>Дополнительная информация

Перейдите к следующей статье, чтобы узнать о поддержке Azure Data Lake Store: 

> [!div class="nextstepaction"]
>[Соединитель Azure Data Lake Store](connector-azure-data-lake-store.md)