.<properties 
	pageTitle="Планирование и исполнение с использованием фабрики данных" 
	description="Сведения об аспектах планирования и исполнения в модели приложений фабрики данных Azure." 
	services="data-factory" 
	documentationCenter="" 
	authors="spelluru" 
	manager="jhubbard" 
	editor="monicar"/>

<tags 
	ms.service="data-factory" 
	ms.workload="data-services" 
	ms.tgt_pltfrm="na" 
	ms.devlang="na" 
	ms.topic="article" 
	ms.date="08/22/2016" 
	ms.author="spelluru"/>

# Планирование и исполнение с использованием фабрики данных
  
Здесь объясняются аспекты планирования и исполнения в модели приложений фабрики данных. Эта статья основана на статьях о [создании конвейеров](data-factory-create-pipelines.md) и [наборов данных](data-factory-create-datasets.md). Чтобы понимать ее, нужно знать основные концепции, связанные с моделью приложений фабрики данных: действия, конвейеры, связанные службы и наборы данных.

## Планирование действий

С помощью раздела **scheduler** в JSON действия можно указать регулярное расписание данного действия. Например, можно запланировать выполнение действия каждый час следующим образом:

	"scheduler": {
		"frequency": "Hour",
	    "interval": 1
	},  
    
![Пример планировщика](./media/data-factory-scheduling-and-execution/scheduler-example.png)

Как показано на схеме, при задании расписания для действия создается последовательность "переворачивающихся" окон. "Переворачивающиеся" окна — это ряд не перекрывающихся и не соприкасающихся интервалов фиксированного размера. Эти логические стыкующиеся окна для действия называются **окнами действия**.
 
Для выполнения текущего окна действия доступ к связанному с ним интервалу времени можно получить с помощью системных переменных [WindowStart](data-factory-functions-variables.md#data-factory-system-variables) и [WindowEnd](data-factory-functions-variables.md#data-factory-system-variables) в JSON действия. Эти переменные можно использовать для различных целей в JSON действия, включая выбор данных из входных и выходных наборов данных, соответствующих временным рядам.

Свойство **scheduler** поддерживает те же подсвойства, что и свойство **availability** в наборе данных. Дополнительные сведения см. в разделе [Доступность набора данных](data-factory-create-datasets.md#Availability). Примеры свойств: планирование с определенным смещением времени, установка режима выравнивания обработки в начале или в конце интервала окна действия.

Указывать свойства планировщика для действия необязательно. Если свойства указываются, они должны соответствовать периодичности, заданной в определении выходного набора данных. В настоящее время расписание активируется с помощью выходного набора данных, поэтому его необходимо создать, даже если действие не создает никаких выходных данных. Если действие не принимает никаких входных данных, входной набор данных можно не создавать.

## Наборы данных и срезы данных временных рядов

Данные временного ряда — это непрерывная последовательность точек данных, состоящая, как правило, из последовательных измерений, выполненных с некоторым интервалом времени. Распространенными примерами данных временных рядов являются данные датчиков, данные телеметрии приложений и т. д.

С помощью фабрики данных Azure данные временных рядов можно обрабатывать в пакетном режиме с выполнением действий. Обычно входные данные поступают, а выходные данные требуют обработки с повторяющейся периодичностью. Эта периодичность моделируется путем указания раздела **availability** в наборе данных приведенным ниже образом.

    "availability": {
      "frequency": "Hour",
      "interval": 1
    },

Каждая единица данных, потребляемых и производимых запуском действия, называется **срезом** данных. На следующей схеме показан пример действия с входным и выходным наборами данных, для каждого из которых доступность установлена с почасовой частотой.

![Планировщик доступности](./media/data-factory-scheduling-and-execution/availability-scheduler.png)

На схеме также показаны почасовые срезы данных для входного и выходного наборов данных, а также три входных среза, готовых к обработке, и выполняемое действие 11–10 AM, выдающее выходной срез 10–11 AM.

К интервалу времени, связанному с текущим обрабатываемым срезом, можно получить доступ в JSON набора данных посредством переменных [SliceStart](data-factory-functions-variables.md#data-factory-system-variables) и [SliceEnd](data-factory-functions-variables.md#data-factory-system-variables).

В настоящее время для фабрики данных требуется, чтобы расписание, указанное в действии, в точности соответствовало расписанию, указанному в разделе доступности выходного набора данных. Таким образом, WindowStart, WindowEnd, SliceStart и SliceEnd всегда сопоставляются с одним и тем же периодом времени и одиночным выходным срезом.

Дополнительные сведения о различных свойствах из раздела availability см. в статье о [создании наборов данных](data-factory-create-datasets.md).

## Пример. Действие копирования, перемещающее данные из SQL Azure в BLOB-объект Azure

Давайте объединим некоторые функции в действии, создав конвейер, где данные копируются каждый час из таблицы SQL Azure в большой двоичный объект Azure.

**Входные данные: набор данных SQL Azure**

	{
	    "name": "AzureSqlInput",
	    "properties": {
	        "published": false,
	        "type": "AzureSqlTable",
	        "linkedServiceName": "AzureSqlLinkedService",
	        "typeProperties": {
	            "tableName": "MyTable"
	        },
	        "availability": {
	            "frequency": "Hour",
	            "interval": 1
	        },
	        "external": true,
	        "policy": {}
	    }
	}


В разделе **availability** для параметра **frequency** установлено значение **Hour**, а для параметра **interval** — значение **1**.

**Выходные данные: набор данных BLOB-объекта Azure**
	
	{
	    "name": "AzureBlobOutput",
	    "properties": {
	        "published": false,
	        "type": "AzureBlob",
	        "linkedServiceName": "StorageLinkedService",
	        "typeProperties": {
	            "folderPath": "mypath/{Year}/{Month}/{Day}/{Hour}",
	            "format": {
	                "type": "TextFormat"
	            },
	            "partitionedBy": [
	                {
	                    "name": "Year",
	                    "value": {
	                        "type": "DateTime",
	                        "date": "SliceStart",
	                        "format": "yyyy"
	                    }
	                },
	                {
	                    "name": "Month",
	                    "value": {
	                        "type": "DateTime",
	                        "date": "SliceStart",
	                        "format": "%M"
	                    }
	                },
	                {
	                    "name": "Day",
	                    "value": {
	                        "type": "DateTime",
	                        "date": "SliceStart",
	                        "format": "%d"
	                    }
	                },
	                {
	                    "name": "Hour",
	                    "value": {
	                        "type": "DateTime",
	                        "date": "SliceStart",
	                        "format": "%H"
	                    }
	                }
	            ]
	        },
	        "availability": {
	            "frequency": "Hour",
	            "interval": 1
	        }
	    }
	}


В разделе **availability** для параметра **frequency** установлено значение **Hour**, а для параметра **interval** — значение **1**.



**Действие: действие копирования**

	{
	    "name": "SamplePipeline",
	    "properties": {
	        "description": "copy activity",
	        "activities": [
	            {
	                "type": "Copy",
	                "name": "AzureSQLtoBlob",
	                "description": "copy activity",	
	                "typeProperties": {
	                    "source": {
	                        "type": "SqlSource",
	                        "sqlReaderQuery": "$$Text.Format('select * from MyTable where timestampcolumn >= \\'{0:yyyy-MM-dd HH:mm}\\' AND timestampcolumn < \\'{1:yyyy-MM-dd HH:mm}\\'', WindowStart, WindowEnd)"
	                    },
	                    "sink": {
	                        "type": "BlobSink",
	                        "writeBatchSize": 100000,
	                        "writeBatchTimeout": "00:05:00"
	                    }
	                },
	                "inputs": [
	                    {
	                        "name": "AzureSQLInput"
	                    }
	                ],
	                "outputs": [
	                    {
	                        "name": "AzureBlobOutput"
	                    }
	                ],
	       			"scheduler": {
	          			"frequency": "Hour",
	          			"interval": 1
	        		}
	            }
	        ],
	        "start": "2015-01-01T08:00:00Z",
	        "end": "2015-01-01T11:00:00Z"
	    }
	}


В примере показаны разделы расписания действий и доступности набора данных, для которых установлена почасовая частота. В примере показано, как можно использовать значения **WindowStart** и **WindowEnd**, чтобы выбрать соответствующие данные для выполнения действия и скопировать их в большой двоичный объект с соответствующим значением **folderPath**. Значение folderPath параметризовано таким образом, чтобы каждый час использовалась отдельная папка.

После выполнения 3 срезов в периоде 8–11 AM в среде SQL Azure выводятся следующие данные:

![Пример ввода](./media/data-factory-scheduling-and-execution/sample-input-data.png)

При развертывании конвейера большой двоичный объект Azure заполняется следующим образом:

1.	Файл mypath/2015/1/1/8/Data.&lt;Guid&gt;.txt с данными.

			10002345,334,2,2015-01-01 08:24:00.3130000
			10002345,347,15,2015-01-01 08:24:00.6570000
			10991568,2,7,2015-01-01 08:56:34.5300000

	> [AZURE.NOTE] Вместо &lt;Guid&gt; будет указан фактический идентификатор GUID. Пример имени файла: Data.bcde1348-7620-4f93-bb89-0eed3455890b.txt.
2.	Файл mypath/2015/1/1/9/Data.&lt;Guid&gt;.txt с данными:

			10002345,334,1,2015-01-01 09:13:00.3900000
			24379245,569,23,2015-01-01 09:25:00.3130000
			16777799,21,115,2015-01-01 09:47:34.3130000
3.	Файл mypath/2015/1/1/10/Data.&lt;Guid&gt;.txt без данных.


## Срезы данных, активный период конвейера и параллельное выполнение срезов

В статье о [создании конвейеров](data-factory-create-pipelines.md) представлена концепция активного периода для конвейера, указываемого установкой свойств **start** и **end**.
 
Для активного периода конвейера можно задать прошедшую дату начала. Затем фабрика данных автоматически вычисляет все срезы данных из прошлого (выполнит обратное заполнение) и начнет их обработку.

После обратного заполнения срезов данных можно настроить их параллельное выполнение. Вы можете это сделать, задав свойство **concurrency** в разделе **policy** JSON действия, как показано в статье [Создание конвейеров](data-factory-create-pipelines.md).

## Повторный запуск сбойных срезов данных и автоматическое отслеживание зависимостей данных

Существуют широкие визуальные возможности для мониторинга выполнения срезов. Дополнительные сведения см. в статьях о **мониторинге конвейеров и управлении ими с помощью** [портала Azure](data-factory-monitor-manage-pipelines.md) (или) [мониторинге и управлении с помощью приложений](data-factory-monitor-manage-app.md).

Рассмотрим следующий пример, в котором показаны два действия. Действие Activity1 выдает набор данных временного ряда со срезами в качестве выходных данных, которые потребляются как входные данные действием Activity2 для формирования конечного выходного набора данных временного ряда.

.![Срез, в котором произошла ошибка](./media/data-factory-scheduling-and-execution/failed-slice.png)

<br/>

На схеме показано, что среди трех последних срезов произошла ошибка создания среза 9–10 AM для набора данных **Dataset2**. Фабрика данных автоматически отслеживает зависимости набора данных временного ряда и в результате задерживает запуск действия для нижестоящего среза 9-10 AM.


Средства мониторинга и управления фабриками данных позволяют детально просмотреть журналы диагностики на предмет неудачного среза, легко найти причину неполадки и устранить ее. После устранения неполадки можно также легко инициировать запуск действия для создания среза, в котором произошла ошибка. Дополнительные сведения о повторных запусках, а также о переходах от одного состояния срезов данных к другому, см. в статьях о **мониторинге конвейеров и управлении ими с помощью** [портала Azure](data-factory-monitor-manage-pipelines.md) (или) [мониторинге и управлении с помощью приложений](data-factory-monitor-manage-app.md).

После повторного запуска, когда срез 9–10 AM для dataset2 будет готов, фабрика данных инициирует запуск для зависимого среза 9–10 AM в конечном наборе данных, как показано на следующей схеме.

![Повторный запуск среза, в котором произошла ошибка](./media/data-factory-scheduling-and-execution/rerun-failed-slice.png)

Для более подробного знакомства с указанием и отслеживанием зависимостей в цепочках действий см. следующие разделы.

## Цепочки действий
Можно объединить в цепочку два действия, используя выходной набор данных одного действия как входной набор данных другого действия. Действия могут находиться в одном конвейере или разных конвейерах. Второе действие выполняется только после успешного завершения первого.

Например, рассмотрим следующий случай.
 
1.	В конвейере P1 есть действие A1, для которого требуется внешний входной набор данных D1. Оно создает **выходной** набор данных **D2**.
2.	В конвейере P2 есть действие A2, для которого требуется **ввод** из набора данных **D2**. Оно создает выходной набор данных D3.
 
В этом случае действие A1 выполняется, когда доступны внешние данные и достигнута запланированная частота доступности. Действие A2 выполняется, когда доступны запланированные срезы из D2 и достигнута запланированная частота доступности. В случае ошибки в одном из срезов в наборе данных D2 действие A2 не запустится для этого среза, пока он не станет доступным.

Представление схемы будет выглядеть, как на следующей схеме:

![Построение цепочки действий в двух конвейерах](./media/data-factory-scheduling-and-execution/chaining-two-pipelines.png)

Представление схемы с обоими действиями в одном конвейере будет выглядеть, как на следующей схеме:

![Построение цепочки действий в одном конвейере](./media/data-factory-scheduling-and-execution/chaining-one-pipeline.png)

### Упорядоченное копирование
Несколько операций копирования можно выполнить друг за другом последовательно или упорядоченно. Предположим, что у вас в конвейере есть два действия копирования: CopyActivity1 и CopyActivity2 со следующими наборами входных и выходных данных.

CopyActivity1: входные данные — Dataset1, выходные данные — Dataset2

CopyActivity2: входные данные — Dataset2, выходные данные — Dataset4

Действие копирования CopyActivity2 будет выполнено только в том случае, если действие копирования CopyActivity1 прошло успешно и набор данных Dataset2 доступен.

В примере действие копирования CopyActivity2 может иметь другие входные данные, например набор данных Dataset3, но необходимо также указать набор Dataset2 в качестве входных данных, чтобы действие копирования CopyActivity2 не запускалось, пока не завершится действие копирования CopyActivity1. Например:

CopyActivity1: входные данные — Dataset1, выходные данные — Dataset2

CopyActivity2: входные данные — Dataset3, Dataset2, выходные данные —Dataset4

Если указано несколько наборов входных данных, то для копирования используется только первый набор, а другие наборы используются в качестве зависимостей. Действие CopyActivity2 запустилось бы только при соблюдении следующих условий:

- Действие CopyActivity1 успешно завершено, и набор данных Dataset2 доступен. Этот набор данных не используется при копировании данных в Dataset4. Он используется только как зависимость для планирования CopyActivity2.
- Набор данных Dataset3 доступен. Этот данные, которые копируются в место назначения.



## Моделирование наборов данных с разной частотой

В примерах частота входных и выходных наборов данных и окон расписания действий была одинаковой. В некоторых сценариях требуется возможность создавать выходные данные с частотой, отличной от частоты одного или нескольких наборов входных данных. Фабрика данных поддерживает моделирование таких сценариев.

### Пример 1. Создание ежедневного выходного отчета по входным данным, которые доступны каждый час

Рассмотрим сценарий, где имеются входные данные измерений датчиков, доступные каждый час в большом двоичном объекте Azure. Нам требуется формировать ежедневный совокупный отчет со статистикой средних, максимальных, минимальных и т. п. показателей за день с помощью фабрики данных [Действие Hive](data-factory-hive-activity.md).

Смоделировать этот сценарий с помощью фабрики данных можно приведенным ниже способом.

**Входной набор данных BLOB-объекта Azure**

Почасовые входные файлы за заданный день удаляются из папки. Для входных данных устанавливается почасовая доступность (frequency: Hour, interval: 1).

	{
	  "name": "AzureBlobInput",
	  "properties": {
	    "type": "AzureBlob",
	    "linkedServiceName": "StorageLinkedService",
	    "typeProperties": {
	      "folderPath": "mycontainer/myfolder/{Year}/{Month}/{Day}/",
	      "partitionedBy": [
	        { "name": "Year", "value": {"type": "DateTime","date": "SliceStart","format": "yyyy"}},
	        { "name": "Month","value": {"type": "DateTime","date": "SliceStart","format": "%M"}},
	        { "name": "Day","value": {"type": "DateTime","date": "SliceStart","format": "%d"}}
	      ],
	      "format": {
	        "type": "TextFormat"
	      }
	    },
		"external": true,
	    "availability": {
	      "frequency": "Hour",
	      "interval": 1
	    }
	  }
	}

**Выходной набор данных BLOB-объекта Azure**

Каждый день в папке создается один выходной файл за целый день. Для выходных данных устанавливается ежедневная доступность (frequency: Day, interval: 1).


	{
	  "name": "AzureBlobOutput",
	  "properties": {
	    "type": "AzureBlob",
	    "linkedServiceName": "StorageLinkedService",
	    "typeProperties": {
	      "folderPath": "mycontainer/myfolder/{Year}/{Month}/{Day}/",
	      "partitionedBy": [
	        { "name": "Year", "value": {"type": "DateTime","date": "SliceStart","format": "yyyy"}},
	        { "name": "Month","value": {"type": "DateTime","date": "SliceStart","format": "%M"}},
	        { "name": "Day","value": {"type": "DateTime","date": "SliceStart","format": "%d"}}
	      ],
	      "format": {
	        "type": "TextFormat"
	      }
	    },
	    "availability": {
	      "frequency": "Day",
	      "interval": 1
	    }
	  }
	}

**Действие: действие Hive в конвейере**

Скрипт hive получает соответствующие сведения о дате и времени в качестве параметров, используя переменную **WindowStart**, как показано во фрагменте кода ниже. Эту переменную скрипт hive использует для загрузки данных из нужной папки за день и для создания выходных данных путем агрегирования.

		{  
		    "name":"SamplePipeline",
		    "properties":{  
		    "start":"2015-01-01T08:00:00",
		    "end":"2015-01-01T11:00:00",
		    "description":"hive activity",
		    "activities": [
		        {
		            "name": "SampleHiveActivity",
		            "inputs": [
		                {
		                    "name": "AzureBlobInput"
		                }
		            ],
		            "outputs": [
		                {
		                    "name": "AzureBlobOutput"
		                }
		            ],
		            "linkedServiceName": "HDInsightLinkedService",
		            "type": "HDInsightHive",
		            "typeProperties": {
		                "scriptPath": "adftutorial\\hivequery.hql",
		                "scriptLinkedService": "StorageLinkedService",
		                "defines": {
		                    "Year": "$$Text.Format('{0:yyyy}',WindowStart)",
		                    "Month": "$$Text.Format('{0:%M}',WindowStart)",
		                    "Day": "$$Text.Format('{0:%d}',WindowStart)"
		                }
		            },
		            "scheduler": {
		                "frequency": "Day",
		                "interval": 1
		            },			
		            "policy": {
		                "concurrency": 1,
		                "executionPriorityOrder": "OldestFirst",
		                "retry": 2,
		                "timeout": "01:00:00"
		            }
	             }
		     ]
		   }
		}

На схеме ниже показан сценарий с точки зрения зависимостей данных.

![Зависимость данных](./media/data-factory-scheduling-and-execution/data-dependency.png)

Выходной срез за каждый день зависит от 24 почасовых срезов из входного набора данных. Фабрика данных автоматически вычисляет эти зависимости, определяя срезы, которые попадают в тот же период времени, что и создаваемый выходной срез. Если какой-либо из 24 входных срезов недоступен, фабрика данных дожидается готовности входного среза перед запуском ежедневного действия.


### Пример 2. Указание зависимости с использованием выражений и функций фабрики данных

Рассмотрим другой сценарий. Предположим, имеется действие Hive, которое обрабатывает два входных набора данных, в одном из которых новые данные появляются ежедневно, а в другом — раз в неделю. Предположим, что требуется выполнить соединение двух входных наборов и выдать ежедневный выходной набор данных.
 
Простой подход заключается в том, чтобы фабрика данных автоматически определяла нужные входные срезы для обработки путем согласования с периодом времени выходного среза данных. Сейчас этот подход уже не работает.

Необходим способ указать фабрике данных для каждого действия, что следует использовать срез данных за последнюю неделю из еженедельного входного набора данных. Это можно сделать с помощью функций фабрики данных Azure, как показано в следующем фрагменте кода.

**Входной набор 1: BLOB-объект Azure**

Первый входной набор данных представляет собой BLOB-объект Azure, обновляемый **ежедневно**.
	
	{
	  "name": "AzureBlobInputDaily",
	  "properties": {
	    "type": "AzureBlob",
	    "linkedServiceName": "StorageLinkedService",
	    "typeProperties": {
	      "folderPath": "mycontainer/myfolder/{Year}/{Month}/{Day}/",
	      "partitionedBy": [
	        { "name": "Year", "value": {"type": "DateTime","date": "SliceStart","format": "yyyy"}},
	        { "name": "Month","value": {"type": "DateTime","date": "SliceStart","format": "%M"}},
	        { "name": "Day","value": {"type": "DateTime","date": "SliceStart","format": "%d"}}
	      ],
	      "format": {
	        "type": "TextFormat"
	      }
	    },
		"external": true,
	    "availability": {
	      "frequency": "Day",
	      "interval": 1
	    }
	  }
	}

**Входной набор 2: BLOB-объект Azure**

Второй входной набор — BLOB-объект Azure, обновляемый **еженедельно**.

	{
	  "name": "AzureBlobInputWeekly",
	  "properties": {
	    "type": "AzureBlob",
	    "linkedServiceName": "StorageLinkedService",
	    "typeProperties": {
	      "folderPath": "mycontainer/myfolder/{Year}/{Month}/{Day}/",
	      "partitionedBy": [
	        { "name": "Year", "value": {"type": "DateTime","date": "SliceStart","format": "yyyy"}},
	        { "name": "Month","value": {"type": "DateTime","date": "SliceStart","format": "%M"}},
	        { "name": "Day","value": {"type": "DateTime","date": "SliceStart","format": "%d"}}
	      ],
	      "format": {
	        "type": "TextFormat"
	      }
	    },
		"external": true,
	    "availability": {
	      "frequency": "Day",
	      "interval": 7
	    }
	  }
	}

**Выходной набор данных: BLOB-объект Azure**

Каждый день в папке создается один выходной файл за целый день. Для выходных данных задается ежедневная доступность (frequency: Day, interval: 1).
	
	{
	  "name": "AzureBlobOutputDaily",
	  "properties": {
	    "type": "AzureBlob",
	    "linkedServiceName": "StorageLinkedService",
	    "typeProperties": {
	      "folderPath": "mycontainer/myfolder/{Year}/{Month}/{Day}/",
	      "partitionedBy": [
	        { "name": "Year", "value": {"type": "DateTime","date": "SliceStart","format": "yyyy"}},
	        { "name": "Month","value": {"type": "DateTime","date": "SliceStart","format": "%M"}},
	        { "name": "Day","value": {"type": "DateTime","date": "SliceStart","format": "%d"}}
	      ],
	      "format": {
	        "type": "TextFormat"
	      }
	    },
	    "availability": {
	      "frequency": "Day",
	      "interval": 1
	    }
	  }
	}

**Действие: действие Hive в конвейере**

Действие hive принимает два входных набора данных и создает выходной срез данных каждый день. Зависимость ежедневного выходного среза от входного среза прошлой недели вы можете задать для еженедельных входных данных приведенным ниже образом.
	
	{  
	    "name":"SamplePipeline",
	    "properties":{  
	    "start":"2015-01-01T08:00:00",
	    "end":"2015-01-01T11:00:00",
	    "description":"hive activity",
	    "activities": [
	      {
	        "name": "SampleHiveActivity",
	        "inputs": [
	          {
	            "name": "AzureBlobInputDaily"
	          },
	          {
	            "name": "AzureBlobInputWeekly",
	            "startTime": "Date.AddDays(SliceStart, - Date.DayOfWeek(SliceStart))",
	            "endTime": "Date.AddDays(SliceEnd,  -Date.DayOfWeek(SliceEnd))"  
	          }
	        ],
	        "outputs": [
	          {
	            "name": "AzureBlobOutputDaily"
	          }
	        ],
	        "linkedServiceName": "HDInsightLinkedService",
	        "type": "HDInsightHive",
	        "typeProperties": {
	          "scriptPath": "adftutorial\\hivequery.hql",
	          "scriptLinkedService": "StorageLinkedService",
	          "defines": {
	            "Year": "$$Text.Format('{0:yyyy}',WindowStart)",
	            "Month": "$$Text.Format('{0:%M}',WindowStart)",
	            "Day": "$$Text.Format('{0:%d}',WindowStart)"
	          }
	        },
	        "scheduler": {
	          "frequency": "Day",
	          "interval": 1
	        },			
	        "policy": {
	          "concurrency": 1,
	          "executionPriorityOrder": "OldestFirst",
	          "retry": 2,  
	          "timeout": "01:00:00"
	        }
		   } 
	     ]
	   }
	}


## Функции и системные переменные фабрики данных   

В статье [Фабрика данных Azure — функции и системные переменные](data-factory-functions-variables.md) приведен список функций и системных переменных, поддерживаемых фабрикой данных Azure.

## Подробный обзор зависимостей данных

Для создания среза набора данных путем запуска действия фабрика данных использует следующую **модель зависимостей**, позволяющую определить связи между наборами данных, потребляемые действием, и наборами данных, которые оно создает.

Диапазон времени входных наборов данных, необходимых для создания выходного среза набора данных, называется **периодом зависимости**.

При запуске действия срез набора данных создается только после того, как будут доступны срезы во входных наборах данных в пределах периода зависимости. Это значит, что все входные срезы, составляющие период зависимости, должны быть в статусе **Готово** для того, чтобы при запуске действия был создан выходной срез набора данных.

Для создания среза набора данных [start, end] требуется функция, сопоставляющая срез набора данных с его периодом зависимости. Эта функция, по сути, является формулой, которая преобразует начало и окончание среза набора данных, чтобы они соответствовали началу и окончанию периода зависимости. Более формально:
	
	DatasetSlice = [start, end]
	DependecyPeriod = [f(start, end), g(start, end)]

где f и g — функции сопоставления, которые вычисляют начало и окончание периода зависимости для каждого входного набора данных действия.

Как видно на примерах, период зависимости совпадает с периодом создания среза данных. В этих случаях фабрика данных автоматически вычисляет входные срезы данных, попадающие в период зависимости.

В примере с агрегированием, где выходные данные формируются ежедневно, а входные доступны каждый час, период среза данных равен 24 часам. Фабрика данных находит актуальные почасовые входные срезы данных для этого периода времени и устанавливает зависимость выходного среза от входного.

Кроме того, вы можете указать собственное сопоставление для периода зависимости, как показано в примере, где один из входных наборов данных создавался еженедельно, а выходной набор — ежедневно.
   
## Зависимость и проверка данных

Для набора данных при необходимости можно определить политику проверки, указывающую, как данные, созданные выполнением среза, могут быть проверены перед готовностью к потреблению. Подробные сведения см. в статье [Создание наборов данных](data-factory-create-datasets.md).

В таких случаях после завершения выполнения среза состояние выходного среза меняется на **Ожидание** с подсостоянием **Проверка**. После проверки срезов их статус меняется на **Готово**.
   
Если срез данных был сформирован, но не прошел проверку, запуски действий для нижестоящих срезов, зависимых от не прошедшего проверку среза, не будут обрабатываться.

Различные состояния срезов данных в фабрике данных описаны в статье [Мониторинг конвейеров и управление ими](data-factory-monitor-manage-pipelines.md).

## Внешние данные

Набор данных можно пометить как внешний (как показано в следующем фрагменте кода JSON), подразумевая, что он не был создан с помощью фабрики данных Azure. В таком случае политика набора данных может содержать дополнительный набор параметров для описания политики проверки и повторных попыток обработки набора данных. Описание всех свойств см. в статье о [создании конвейеров](data-factory-create-pipelines.md).

Аналогично наборам данных, формируемым фабрикой данных, срезы внешних данных должны быть готовы до того, как можно будет обработать зависимые срезы.

	{
		"name": "AzureSqlInput",
		"properties": 
		{
			"type": "AzureSqlTable",
			"linkedServiceName": "AzureSqlLinkedService",
			"typeProperties": 
			{
				"tableName": "MyTable"	
			},
			"availability": 
			{
				"frequency": "Hour",
				"interval": 1     
			},
			"external": true,
			"policy": 
			{
				"externalData": 
				{
					"retryInterval": "00:01:00",
					"retryTimeout": "00:10:00",
					"maximumRetry": 3
				}
			}  
		} 
	} 


## Однократный конвейер
Вы можете создать конвейер и настроить для него периодическое выполнение (например, ежечасно и ежедневно) в пределах между временем начала и окончания, заданным в определении конвейера. Дополнительные сведения см. в разделе [Планирование действий](#scheduling-and-execution). Вы также можете создать конвейер, выполняемый однократно. Для этого свойству **pipelineMode** в определении конвейера необходимо присвоить значение **onetime** (однократный), как показано в следующем примере файла JSON. По умолчанию для этого свойства используется значение **scheduled** (по расписанию).

	{
	    "name": "CopyPipeline",
	    "properties": {
	        "activities": [
	            {
	                "type": "Copy",
	                "typeProperties": {
	                    "source": {
	                        "type": "BlobSource",
	                        "recursive": false
	                    },
	                    "sink": {
	                        "type": "BlobSink",
	                        "writeBatchSize": 0,
	                        "writeBatchTimeout": "00:00:00"
	                    }
	                },
	                "inputs": [
	                    {
	                        "name": "InputDataset"
	                    }
	                ],
	                "outputs": [
	                    {
	                        "name": "OutputDataset"
	                    }
	                ]
	                "name": "CopyActivity-0"
	            }
	        ]
	        "pipelineMode": "OneTime"
	    }
	}

Обратите внимание на следующее.
 
- Время **начала** и **окончания** для конвейера не указывается.
- При этом нужно указывать **доступность** входных и выходных наборов данных (периодичность и интервал), несмотря на то что фабрика данных эти значения не использует.
- В представлении диаграммы однократные конвейеры не отображаются. В этом весь замысел.
- Однократные конвейеры не обновляются. Однократный конвейер можно клонировать, переименовать, обновить его свойства и развернуть, чтобы создать другой конвейер.

  




  









 
 












      

  

<!---HONumber=AcomDC_0824_2016-->