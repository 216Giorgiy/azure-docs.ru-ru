<properties
	pageTitle="Начало работы с фабрикой данных Azure с помощью портала Azure"
	description="В этом учебнике вы создадите образец конвейера фабрики данных Azure с помощью редактора фабрики данных на портале Azure."
	services="data-factory"
	documentationCenter=""
	authors="spelluru"
	manager="jhubbard"
	editor="monicar"/>

<tags
	ms.service="data-factory"
	ms.workload="data-services"
	ms.tgt_pltfrm="na"
	ms.devlang="na"
	ms.topic="hero-article" 
	ms.date="12/18/2015"
	ms.author="spelluru"/>

# Начало работы с фабрикой данных Azure с помощью редактора фабрики данных
> [AZURE.SELECTOR]
- [Tutorial Overview](data-factory-build-your-first-pipeline.md)
- [Using Data Factory Editor](data-factory-build-your-first-pipeline-using-editor.md)
- [Using PowerShell](data-factory-build-your-first-pipeline-using-powershell.md)
- [Using Visual Studio](data-factory-build-your-first-pipeline-using-vs.md)
- [Using Resource Manager Template](data-factory-build-your-first-pipeline-using-arm.md)

Из этой статьи вы узнаете, как создать свою первую фабрику данных с помощью [портала Azure](https://portal.azure.com/).

## Предварительные требования

1. Прежде чем продолжать, **обязательно** прочтите [обзорную статью](data-factory-build-your-first-pipeline.md) по этой теме и выполните предварительные условия.
2. Здесь не приводятся общие сведения о службе фабрики данных Azure. Рекомендуем ознакомиться со статьей [Введение в службу фабрики данных Azure](data-factory-introduction.md), в которой вы найдете подробный обзор этой службы.  

## Шаг 1. Создание фабрики данных
Фабрика данных может иметь один или несколько конвейеров. Конвейер может содержать одно или несколько действий. Это может быть, например, действие копирования, копирующее данные из исходного хранилища данных в конечное, и действие HDInsight Hive для выполнения скрипта Hive, преобразующего входные данные в выходные данные продукта. Начнем с создания фабрики данных.

1.	Войдите на [портал Azure](http://portal.azure.com/) и сделайте следующее:
	1.	В меню слева нажмите кнопку **Создать**. 
	2.	В колонке **Создание** щелкните **Аналитика данных**.
	3.	В колонке **Аналитика данных** щелкните **Фабрика данных**.

		![Колонка "Создание"](./media/data-factory-build-your-first-pipeline-using-editor/create-blade.png)

2.	В колонке **Новая фабрика данных** введите **GetStartedDF** в поле «Имя».

	![Создать колонку "Фабрика данных"](./media/data-factory-build-your-first-pipeline-using-editor/new-data-factory-blade.png)

	> [AZURE.IMPORTANT]Имя фабрики данных Azure должно быть глобально уникальным. Получив сообщение об ошибке **Имя фабрики данных «GetStartedDF» недоступно**, измените имя фабрики данных (например, на yournameGetStartedDF) и попробуйте создать ее еще раз. Ознакомьтесь с разделом [Фабрика данных — правила именования](data-factory-naming-rules.md), чтобы узнать о правилах именования артефактов фабрики данных.
	>  
	> В будущем имя фабрики данных может быть зарегистрировано в качестве DNS-имени и, следовательно, стать отображаемым.

3.	Выберите **подписку Azure**, в рамках которой вы хотите создать фабрику данных.
4.	Выберите существующую **группу ресурсов** или создайте новую. Для примера в этом руководстве создайте группу ресурсов с именем **ADFGetStartedRG**.    
5.	В колонке **Новая фабрика данных** нажмите кнопку **Создать**.
6.	Созданная фабрика данных появится на **начальной панели** портала Azure.   

	![Статус создания фабрики данных](./media/data-factory-build-your-first-pipeline-using-editor/creating-data-factory-image.png)
7. Поздравляем! Вы успешно создали свою первую фабрику данных! Ее содержимое отображается на специальной странице. 	

	![Колонка "Фабрика данных"](./media/data-factory-build-your-first-pipeline-using-editor/data-factory-blade.png)

Прежде чем создавать конвейер, необходимо создать несколько сущностей фабрики данных. Сначала создайте связанные службы, чтобы связать хранилища данных и вычисления со своим хранилищем данных, и определите входные и выходные наборы данных, которые будут представлять данные в связанных хранилищах. Затем создайте конвейер с действием, в котором используются эти наборы данных.

## Шаг 2. Создание связанных служб
На этом этапе вы свяжете учетную запись службы хранилища Azure и используемый по запросу кластер Azure HDInsight с фабрикой данных. В этом примере учетная запись хранения Azure содержит входные и выходные данные для конвейера. Для выполнения скрипта Hive, указанного в действии конвейера, в этом примере используется связанная служба HDInsight. Необходимо определить, какие данные хранилища и службы вычислений используются в сценарии, и связать эти службы с фабрикой данных путем создания связанных служб.

### Создание связанной службы хранения Azure
На этом этапе вы свяжете учетную запись хранения Azure с фабрикой данных. В целях данного руководства используйте одну и ту же учетную запись хранения Azure для хранения входных и выходных данных и файла скрипта HQL.

1.	Щелкните **Создать и развернуть** в колонке **Фабрика данных** для **GetStartedDF**. Откроется редактор фабрики данных. 
	 
	![Плитка "Создание и развертывание"](./media/data-factory-build-your-first-pipeline-using-editor/data-factory-author-deploy.png)
2.	Щелкните **Новое хранилище данных** и выберите **Служба хранилища Azure**.
	
	![Связанная служба хранения Azure](./media/data-factory-build-your-first-pipeline-using-editor/azure-storage-linked-service.png)

	В редакторе отобразится сценарий JSON для создания связанной службы хранилища Azure. 
4. Замените **account name** именем своей учетной записи хранения Azure, а **account key** — ключом доступа к учетной записи хранения Azure. Сведения о получении ключа доступа к хранилищу см. в разделах о [просмотре, копировании и повторном создании ключей доступа к хранилищу](../storage/storage-create-storage-account.md#view-copy-and-regenerate-storage-access-keys).
5. Чтобы развернуть эту службу, нажмите кнопку **Развернуть** на панели команд.

	![Кнопка "Развернуть"](./media/data-factory-build-your-first-pipeline-using-editor/deploy-button.png)

   После успешного развертывания связанной службы окно **Draft-1** должно исчезнуть, а в представлении в виде дерева слева должен появиться пункт **StorageLinkedService**.
   	![Связанная служба хранилища в меню](./media/data-factory-build-your-first-pipeline-using-editor/StorageLinkedServiceInTree.png)

 
### Создание связанной службы Azure HDInsight
На этом этапе вы свяжете используемый по запросу кластер HDInsight с фабрикой данных. Кластер HDInsight автоматически создается в среде выполнения и удаляется после завершения обработки и простоя в течение указанного времени. Вместо используемого по запросу кластера HDInsight можно использовать собственный кластер HDInsight. Дополнительные сведения см. в статье [Связанные службы вычислений](data-factory-compute-linked-services.md).

1. В **редакторе фабрики данных** на панели команд щелкните **Новое вычисление** и выберите **Кластер HDInsight по запросу**.

	![Новая служба вычислений](./media/data-factory-build-your-first-pipeline-using-editor/new-compute-menu.png)
2. Скопируйте и вставьте приведенный ниже фрагмент в окно **Draft-1**. Он описывает свойства, которые будут использоваться для создания кластера HDInsight по требованию. 

		{
		  "name": "HDInsightOnDemandLinkedService",
		  "properties": {
		    "type": "HDInsightOnDemand",
		    "typeProperties": {
		      "version": "3.2",
		      "clusterSize": 1,
		      "timeToLive": "00:30:00",
		      "linkedServiceName": "StorageLinkedService"
		    }
		  }
		}
	
	В следующей таблице приведены описания свойств JSON, используемых в этом фрагменте кода.
	
	| Свойство | Описание |
	| :------- | :---------- |
	| Version (версия) | Указывает, что версия создаваемого кластера HDInsight — 3.2. | 
	| ClusterSize (размер кластера) | Создает кластер HDInsight с одним узлом. | 
	| TimeToLive (срок жизни) | Указывает, сколько времени может простаивать кластер HDInsight, прежде чем он будет удален. |
	| linkedServiceName (имя связанной службы) | Указывает имя учетной записи хранения, в которой будут храниться журналы, создаваемые HDInsight. |
3. Чтобы развернуть эту службу, нажмите кнопку **Развернуть** на панели команд. 
4. Убедитесь, что обе службы (**StorageLinkedService** и **HDInsightOnDemandLinkedService**) отображаются в представлении в виде дерева слева.

	![Иерархическое представление со связанными службами](./media/data-factory-build-your-first-pipeline-using-editor/tree-view-linked-services.png)

## Шаг 3. Создание наборов данных
На этом этапе вы создадите наборы данных, которые представляют входные и выходные данные для обработки Hive. Эти наборы данных ссылаются на службу **StorageLinkedService**, созданную ранее в ходе работы с этим руководством. Точки связанной службы указывают на учетную запись хранения Azure, а наборы данных указывают контейнер, папку и имя файла в хранилище, в котором содержатся входные и выходные данные.

### Создание входного набора данных

1. На панели команд **редактора фабрики данных** щелкните **Создать набор данных** и выберите **Хранилище BLOB-объектов Azure**.  

	![Новый набор данных](./media/data-factory-build-your-first-pipeline-using-editor/new-data-set.png)
2. Вставьте приведенный ниже фрагмент JSON в окно Draft-1. В фрагменте JSON создается набор данных с именем **AzureBlobInput**, представляющий входные данные для действия в конвейере. Кроме того, нужно указать, что входные данные размещаются в контейнере BLOB-объектов **adfgetstarted** и в папке **inputdata**.
		
		{
			"name": "AzureBlobInput",
		    "properties": {
		        "type": "AzureBlob",
		        "linkedServiceName": "StorageLinkedService",
		        "typeProperties": {
		            "fileName": "input.log",
		            "folderPath": "adfgetstarted/inputdata",
		            "format": {
		                "type": "TextFormat",
		                "columnDelimiter": ","
		            }
		        },
		        "availability": {
		            "frequency": "Month",
		            "interval": 1
		        },
		        "external": true,
		        "policy": {}
		    }
		} 

	В следующей таблице приведены описания свойств JSON, используемых в этом фрагменте кода.

	| Свойство | Описание |
	| :------- | :---------- |
	| type | Для свойства типа задано значение AzureBlob, так как данные хранятся в хранилище BLOB-объектов Azure. |  
	| linkedServiceName (имя связанной службы) | Ссылается на созданную ранее службу StorageLinkedService. |
	| fileName | Это необязательное свойство. Если это свойство не указано, выбираются все файлы из папки folderPath. В этом случае обрабатывается только файл input.log. |
	| type | Файлы журнала представлены в текстовом формате, поэтому мы используем значение TextFormat. | 
	| columnDelimiter | Столбцы в файлах журнала разделяются запятыми («,»). |
	| frequency и interval | Для свойства frequency задано значение Month, а для свойства interval — значение 1. Это означает, что срезы входных данных доступны ежемесячно. | 
	| external | Это свойство имеет значение true, если входные данные не создаются службой фабрики данных. | 
	  
	
3. На панели команд нажмите кнопку **Развернуть**, чтобы развернуть только что созданный набор данных. Вы увидите набор данных в представлении в виде дерева слева.


### Создадите выходной набор данных.
Теперь создайте выходной набор данных, представляющий выходные данные, которые хранятся в хранилище BLOB-объектов Azure.

1. На панели команд **редактора фабрики данных** щелкните **Новый набор данных** и выберите **Хранилище BLOB-объектов Azure**.  
2. Вставьте приведенный ниже фрагмент JSON в окно Draft-1. Этот фрагмент кода JSON создает набор данных с именем **AzureBlobOutput** и определяет структуру данных, получаемых с помощью скрипта Hive. Кроме того, нужно указать, что результаты будут храниться в контейнере больших двоичных объектов с именем **adfgetstarted** и в папке с именем **partitioneddata**. В разделе **availability** указывается частота, с которой будет создаваться выходной набор данных (ежемесячно).
	
		{
		  "name": "AzureBlobOutput",
		  "properties": {
		    "type": "AzureBlob",
		    "linkedServiceName": "StorageLinkedService",
		    "typeProperties": {
		      "folderPath": "adfgetstarted/partitioneddata",
		      "format": {
		        "type": "TextFormat",
		        "columnDelimiter": ","
		      }
		    },
		    "availability": {
		      "frequency": "Month",
		      "interval": 1
		    }
		  }
		}

	Описание этих свойств можно найти в разделе **Создание входного набора данных**. Значение свойства external для выходного набора данных не указывается, так как набор данных создается службой фабрики данных.
3. На панели команд нажмите кнопку **Развернуть**, чтобы развернуть только что созданный набор данных.
4. Убедитесь, что набор данных успешно создан.

	![Иерархическое представление со связанными службами](./media/data-factory-build-your-first-pipeline-using-editor/tree-view-data-set.png)

## Шаг 4. Создание конвейера
На этом этапе вы создадите свой первый конвейер с действием **HDInsightHive**. Обратите внимание, что срез входных данных создается ежемесячно (frequency: Month, interval: 1), срез выходных данных создается ежемесячно, а свойство scheduler для действия тоже имеет значение Month (см. ниже). Параметры выходного набора данных (outputs) и планировщика действия (scheduler) должны совпадать. В настоящее время расписание активируется с помощью выходного набора данных, поэтому его необходимо создать, даже если действие не создает никаких выходных данных. Если действие не принимает никаких входных данных, входной набор данных можно не создавать. Свойства, используемые в следующем фрагменте JSON, описаны в конце этого раздела.

1. В **редакторе фабрики данных** щелкните **значок многоточия (…)**, а затем щелкните **Новый конвейер**.
	
	![Кнопка "Создать конвейер"](./media/data-factory-build-your-first-pipeline-using-editor/new-pipeline-button.png)
2. Вставьте приведенный ниже фрагмент JSON в окно Draft-1.

	> [AZURE.IMPORTANT]В JSON-файле замените свойство **storageaccountname** именем своей учетной записи хранения.
		
		{
		    "name": "MyFirstPipeline",
		    "properties": {
		        "description": "My first Azure Data Factory pipeline",
		        "activities": [
		            {
		                "type": "HDInsightHive",
		                "typeProperties": {
		                    "scriptPath": "adfgetstarted/script/partitionweblogs.hql",
		                    "scriptLinkedService": "StorageLinkedService",
		                    "defines": {
		                        "inputtable": "wasb://adfgetstarted@<storageaccountname>.blob.core.windows.net/inputdata",
		                        "partitionedtable": "wasb://adfgetstarted@<storageaccountname>.blob.core.windows.net/partitioneddata"
		                    }
		                },
		                "inputs": [
		                    {
		                        "name": "AzureBlobInput"
		                    }
		                ],
		                "outputs": [
		                    {
		                        "name": "AzureBlobOutput"
		                    }
		                ],
		                "policy": {
		                    "concurrency": 1,
		                    "retry": 3
		                },
		                "scheduler": {
		                    "frequency": "Month",
		                    "interval": 1
		                },
		                "name": "RunSampleHiveActivity",
		                "linkedServiceName": "HDInsightOnDemandLinkedService"
		            }
		        ],
		        "start": "2014-02-01T00:00:00Z",
		        "end": "2014-02-02T00:00:00Z",
		        "isPaused": false
		    }
		}
 
	Этот фрагмент создает конвейер из одного действия, использующего Hive для обработки данных в кластере HDInsight.
	
	Файл **partitionweblogs.hql** скрипта Hive хранится в учетной записи хранения Azure (указывается с помощью свойства scriptLinkedService с именем **StorageLinkedService**) в папке **script** в контейнере **adfgetstarted**.

	Раздел **defines** используется для настройки параметров среды выполнения, которые будут переданы в скрипт Hive в качестве значений конфигурации Hive (например, ${hiveconf:inputtable}, ${hiveconf:partitionedtable}).

	Активный период конвейера задается с помощью свойств **start** и **end**.

	В JSON действия укажите, что скрипт Hive будет выполняться в среде вычислений, указанной в свойстве **linkedServiceName**, — **HDInsightOnDemandLinkedService**.


3. Убедитесь, что файл input.log отображается в папке adfgetstarted/inputdata в хранилище BLOB-объектов Azure, и нажмите кнопку **Развернуть** на панели команд, чтобы развернуть конвейер. Так как время в свойствах **start** и **end** задано в прошлом, а для свойства **isPaused** задано значение false, конвейер (действие в конвейере) запускается сразу после развертывания.
4. Убедитесь, что конвейер отображается в иерархической структуре.

	![Иерархическое представление с конвейером](./media/data-factory-build-your-first-pipeline-using-editor/tree-view-pipeline.png)
5. Поздравляем! Вы создали свой первый конвейер!

## Шаг 4. Мониторинг конвейера

6. Щелкните **X**, чтобы закрыть колонки редактора фабрики данных и вернуться в колонку фабрики данных. Затем щелкните элемент **Схема**.
  
	![Плитка "Схема"](./media/data-factory-build-your-first-pipeline-using-editor/diagram-tile.png)
7. В представлении диаграммы вы увидите все конвейеры и наборы данных, используемые в этом учебнике.
	
	![Представление схемы](./media/data-factory-build-your-first-pipeline-using-editor/diagram-view-2.png) 
8. Чтобы просмотреть все действия в конвейере, щелкните конвейер в схеме правой кнопкой мыши и выберите пункт «Открыть конвейер». 

	![Откройте меню конвейера](./media/data-factory-build-your-first-pipeline-using-editor/open-pipeline-menu.png)
9. Убедитесь, что действие HDInsightHive отображается в конвейере. 
  
	![Откройте представление конвейера](./media/data-factory-build-your-first-pipeline-using-editor/open-pipeline-view.png)

	Чтобы перейти к предыдущему представлению, щелкните **Фабрики данных** в меню навигации вверху. 
10. В **представлении схемы** дважды щелкните набор данных **AzureBlobInput**. Убедитесь, что срез находится в состоянии **Готово**. Для отображения этого состояния может потребоваться несколько минут. Если это не произойдет через некоторое время, убедитесь, что входной файл (input.log) расположен в правильном контейнере (adfgetstarted) и папке (inputdata).

	![Срез входных данных в состоянии «Готово»](./media/data-factory-build-your-first-pipeline-using-editor/input-slice-ready.png)
11. Щелкните **X**, чтобы закрыть колонку **AzureBlobInput**. 
12. В **представлении схемы** дважды щелкните набор данных **AzureBlobOutput**. Вы увидите срез, который обрабатывается в данный момент.

	![Выборка](./media/data-factory-build-your-first-pipeline-using-editor/dataset-blade.png)
9. Как только обработка завершится, срез перейдет в состояние **Готово**.
	>[AZURE.IMPORTANT]Создание используемого по требованию кластера HDInsight обычно занимает некоторое время (около 20 минут).  

	![Выборка](./media/data-factory-build-your-first-pipeline-using-editor/dataset-slice-ready.png)
	
10. Когда срез перейдет в состояние **Готово**, проверьте выходные данные в папке **partitioneddata** контейнера **adfgetstarted** в хранилище BLOB-объектов.
 
	![выходные данные](./media/data-factory-build-your-first-pipeline-using-editor/three-ouptut-files.png)

## Дальнейшие действия
В этой статье вы создали конвейер с действием преобразования (действие HDInsight), которое выполняет сценарий Hive в кластере HDInsight по требованию. Сведения о том, как копировать данные из хранилища BLOB-объектов Azure в SQL Azure с помощью действия копирования, см. в статье [Учебник. Копирование данных из хранилища BLOB-объектов Azure в Azure SQL](./data-factory-get-started.md).

### Ссылки
| Раздел | Описание |
| :---- | :---- |
| [Конвейеры](data-factory-create-pipelines.md) | Эта статья поможет вам понять сущность конвейеров и действий в фабрике данных Azure, а также научиться с их помощью создавать комплексные рабочие процессы, управляемые данными, для конкретных бизнес-сценариев. |
| [Наборы данных](data-factory-create-datasets.md) | Эта статья поможет вам понять, что такое наборы данных в фабрике данных Azure.
| [Планирование и выполнение](data-factory-scheduling-and-execution.md) | Здесь объясняются аспекты планирования и исполнения в модели приложений фабрики данных. |
| [Мониторинг конвейеров фабрики данных Azure и управление ими](data-factory-monitor-manage-pipelines.md) | В этой статье описываются мониторинг, управление и отладка конвейеров. В ней также приводятся инструкции по настройке оповещений в случае сбоев. |


  

<!---HONumber=AcomDC_1223_2015-->