---
title: "Создание наборов данных в фабрике данных Azure | Документация Майкрософт"
description: "Узнайте, как создавать наборы данных в фабрике данных Azure, на основе примеров с использованием свойств offset, anchorDateTime и т. д."
keywords: "создание набора данных, пример набора данных, пример offset"
services: data-factory
documentationcenter: 
author: sharonlo101
manager: jhubbard
editor: monicar
ms.assetid: 0614cd24-2ff0-49d3-9301-06052fd4f92a
ms.service: data-factory
ms.workload: data-services
ms.tgt_pltfrm: na
ms.devlang: na
ms.topic: article
ms.date: 04/12/2017
ms.author: shlo
translationtype: Human Translation
ms.sourcegitcommit: e0c999b2bf1dd38d8a0c99c6cdd4976cc896dd99
ms.openlocfilehash: 88e653f6e46f3e8eb72e620b495d1769f17bdfbf
ms.lasthandoff: 04/20/2017


---
# <a name="datasets-in-azure-data-factory"></a>Наборы данных в фабрике данных Azure
В этой статье описываются наборы данных в фабрике данных Azure, а также приведены примеры для баз данных с использованием параметров offset, anchorDateTime и offset/style.

> [!NOTE]
> Если вы не знакомы с фабрикой данных Azure, см. статью [Общие сведения о службе фабрики данных Azure, службе интеграции данных в облаке](data-factory-introduction.md). Если у вас нет практического опыта создания фабрик данных, рекомендуем для лучшего понимания статьи изучить [руководство по преобразованию данных](data-factory-build-your-first-pipeline.md) и (или) [руководство по перемещению данных](data-factory-copy-data-from-azure-blob-storage-to-sql-database.md). 

## <a name="overview"></a>Обзор
Фабрика данных может иметь один или несколько конвейеров. **Конвейер** — это логическая группа **действий**, которые вместе выполняют задачу. Действия в конвейере определяют операции с данными. Например, действие копирования позволяет скопировать данные из локальной базы данных SQL Server в хранилище BLOB-объектов Azure. Затем можно использовать действие Hive для запуска сценария Hive в кластере Azure HDInsight, чтобы обработать данные из хранилища BLOB-объектов и получить выходные данные. Наконец, можно использовать второе действие копирования, чтобы скопировать выходные данные в хранилище данных SQL Azure, на основе которого созданы решения для создания отчетов бизнес-аналитики. Дополнительные сведения о конвейерах и действиях см. в статье [Конвейеры и действия в фабрике данных Azure](data-factory-create-pipelines.md).

У каждого действия может быть несколько входных **наборов данных** или же ни одного, и каждое действие может производить один или несколько выходных наборов данных. Входной набор данных представляет входные данные для действия в конвейере, а выходной набор данных — выходные данные для действия. Наборы данных представляют данные в разных хранилищах, например в таблицах, файлах, папках и документах. Например, набор данных больших двоичных объектов Azure указывает контейнер больших двоичных объектов и папку в хранилище BLOB-объектов, из которой конвейер должен считывать данные. 

Перед созданием набора данных необходимо создать **связанную службу**, чтобы связать хранилище данных с фабрикой данных. Связанные службы напоминают строки подключения, определяющие сведения о подключении, необходимые для подключения фабрики данных к внешним ресурсам. Наборы данных представляют данные в связанных хранилищах данных, например в таблицах SQL, файлах, папках и документах. Например, связанная служба хранилища Azure связывает учетную запись хранения Azure с фабрикой данных. Набор данных больших двоичных объектов Azure представляет контейнер больших двоичных объектов и папку, содержащую входные большие двоичные объекты для обработки. 

Ниже приведен пример сценария. Чтобы скопировать данные из хранилища BLOB-объектов Azure в базу данных SQL Azure, создайте две связанные службы: служба хранилища Azure и служба базы данных SQL Azure. Затем создайте два набора данных: набор данных больших двоичных объектов Azure (для связанной службы хранилища Azure) и набор данных таблицы SQL Azure (для связанной службы базы данных SQL Azure). Связанные службы хранилища Azure и базы данных SQL Azure содержат строки подключения, которые фабрика данных использует во время выполнения для подключения к службе хранилища Azure и базе данных Azure SQL соответственно. Набор данных больших двоичных объектов Azure указывает контейнер и папку больших двоичных объектов, содержащую входные большие двоичные объекты в хранилище BLOB-объектов Azure. Набор данных таблицы SQL Azure указывает таблицу SQL в базе данных Azure SQL, в которую будут копироваться данные.

На следующей схеме показана связь между конвейером, действием, набором данных и связанной службой в фабрике данных. 

![Связь между конвейером, действием, набором данных и связанными службами](media/data-factory-create-datasets/relationship-between-data-factory-entities.png)

## <a name="dataset-json"></a>JSON набора данных
Набор данных в фабрике Azure определяется в формате JSON следующего вида.

```json
{
    "name": "<name of dataset>",
    "properties": {
        "type": "<type of dataset: AzureBlob, AzureSql etc...>",
        "external": <boolean flag to indicate external data. only for input datasets>,
        "linkedServiceName": "<Name of the linked service that refers to a data store.>",
        "structure": [
            {
                "name": "<Name of the column>",
                "type": "<Name of the type>"
            }
        ],
        "typeProperties": {
            "<type specific property>": "<value>",
            "<type specific property 2>": "<value 2>",
        },
        "availability": {
            "frequency": "<Specifies the time unit for data slice production. Supported frequency: Minute, Hour, Day, Week, Month>",
            "interval": "<Specifies the interval within the defined frequency. For example, frequency set to 'Hour' and interval set to 1 indicates that new data slices should be produced hourly>"
        },
       "policy":
        {      
        }
    }
}
```

В следующей таблице описаны свойства приведенного выше объекта JSON.   

| Свойство | Описание | Обязательно | значение по умолчанию |
| --- | --- | --- | --- |
| name |Имя набора данных. Правила именования для фабрики данных Azure описаны [здесь](data-factory-naming-rules.md) . |Да |Нет данных |
| type |Тип набора данных. Укажите один из типов, которые поддерживаются фабрикой данных Azure (например: AzureBlob, AzureSqlTable). <br/><br/>Дополнительные сведения см. в разделе [Тип набора данных](#Type). |Да |Нет данных |
| structure |Схема набора данных<br/><br/>Дополнительные сведения см. в разделе [Структура набора данных](#Structure). |Нет. |Нет данных |
| typeProperties | Свойства каждого типа отличаются (например, свойства большого двоичного объекта Azure и таблицы SQL Azure). Сведения о поддерживаемых типах и их свойствах см. в разделе [Тип набора данных](#Type). |Да |Нет данных |
| external | Этот логический флаг указывает, создается ли набор данных конвейером фабрики данных явным образом. Если входной набор данных для действия не создается текущим конвейером, присвойте этому флагу значение true. Присвойте этому флагу значение true для входного набора данных первого действия в конвейере.  |Нет |нет |
| availability | Определяет окно обработки (ежечасно, ежедневно и т. д.) или модель среза для создания набора данных. Каждая единица данных, потребляемых и создаваемых запуском действия, называется срезом данных. Если для выходного набора данных задана ежедневная доступность (параметр frequency имеет значение Day, а параметр interval имеет значение 1), то срез создается каждый день. <br/><br/>Дополнительные сведения см. в разделе [Доступность набора данных](#Availability). <br/><br/>Дополнительные сведения о модели срезов набора данных см. в статье [Планирование и исполнение с использованием фабрики данных](data-factory-scheduling-and-execution.md). |Да |Нет данных |
| policy |Определяет условия, которым должен соответствовать срез данных. <br/><br/>Дополнительные сведения см. в разделе [Политика наборов данных](#Policy). |Нет |Нет данных |

## <a name="dataset-example"></a>Пример набора данных
В следующем примере набор данных представляет таблицу **MyTable** в **базе данных SQL Azure**.

```json
{
    "name": "DatasetSample",
    "properties": {
        "type": "AzureSqlTable",
        "linkedServiceName": "AzureSqlLinkedService",
        "typeProperties":
        {
            "tableName": "MyTable"
        },
        "availability":
        {
            "frequency": "Day",
            "interval": 1
        }
    }
}
```

Обратите внимание на следующие моменты.

* для параметра type задано значение AzureSqlTable;
* свойство типа tableName (используется только для типа AzureSqlTable) имеет значение MyTable;
* параметр linkedServiceName ссылается на связанную службу типа AzureSqlDatabase, определение которой указано во фрагменте кода JSON ниже; 
* в разделе availability параметр frequency имеет значение Day, а параметр interval равен 1. Это означает, что срез набора данных создается ежедневно.  

AzureSqlLinkedService определяется следующим образом.

```json
{
    "name": "AzureSqlLinkedService",
    "properties": {
        "type": "AzureSqlDatabase",
        "description": "",
        "typeProperties": {
            "connectionString": "Data Source=tcp:<servername>.database.windows.net,1433;Initial Catalog=<databasename>;User ID=<username>@<servername>;Password=<password>;Integrated Security=False;Encrypt=True;Connect Timeout=30"
        }
    }
}
```

В приведенном выше коде JSON:

* параметр type имеет значение AzureSqlDatabase;
* свойство типа connectionString задает информацию для подключения к базе данных Azure SQL.  

Как видите, связанная служба определяет способ подключения к базе данных SQL Azure. Набор данных определяет, какие таблицы используются в качестве входных и выходных данных для действия в конвейере.   

> [!IMPORTANT]
> Если набор данных не создается конвейером, он должен быть помечен как **external**. Этот параметр обычно относится к входным данным для первого действия в конвейере.   


## <a name="Type"></a>Тип набора данных
Тип набора данных зависит от хранилища данных, которые вы используете. В таблице ниже перечислены хранилища данных, поддерживаемые фабрикой данных. Щелкните хранилище данных, чтобы узнать, как для него создать связанную службу и набор данных.

[!INCLUDE [data-factory-supported-data-stores](../../includes/data-factory-supported-data-stores.md)]

> [!NOTE]
> Хранилища данных, отмеченные звездочкой (*), могут находиться в локальном расположении или в IaaS Azure и требовать установки [шлюза управления данными](data-factory-data-management-gateway.md) на локальном компьютере или компьютере IaaS Azure.

В примере в предыдущем разделе задан тип набора данных **AzureSqlTable**. Аналогично, для набора данных больших двоичных объектов Azure задается тип **AzureBlob**, как показано в следующем фрагменте JSON.

```json
{
    "name": "AzureBlobInput",
    "properties": {
        "type": "AzureBlob",
        "linkedServiceName": "AzureStorageLinkedService",
        "typeProperties": {
            "fileName": "input.log",
            "folderPath": "adfgetstarted/inputdata",
            "format": {
                "type": "TextFormat",
                "columnDelimiter": ","
            }
        },
        "availability": {
            "frequency": "Month",
            "interval": 1
        },
        "external": true,
        "policy": {}
    }
}
```

## <a name="Structure"></a>Структура набора данных
**structure** — это **необязательный** раздел, в котором определяется схема набора данных. Схема содержит коллекцию имен и типов данных для столбцов. Используйте раздел structure, чтобы указать сведения о типах, которые используются для преобразования типов и сопоставления столбцов из источника с приемником. В приведенном ниже примере набор данных содержит три столбца: `slicetimestamp`, `projectname` и `pageviews` с типом String, String и Decimal соответственно.

```json
structure:  
[
    { "name": "slicetimestamp", "type": "String"},
    { "name": "projectname", "type": "String"},
    { "name": "pageviews", "type": "Decimal"}
]
```

В каждом столбце раздела structure содержатся следующие свойства.

| Свойство | Описание | Обязательно |
| --- | --- | --- |
| name |Имя столбца. |Да |
| type |Тип данных столбца.  |Нет |
| culture |Язык и региональные параметры на основе .NET, используемые, если указан тип .NET `Datetime` или `Datetimeoffset`. Значение по умолчанию — `en-us`. |Нет |
| свойства |Строка формата, используемая, если указан тип .NET `Datetime` или `Datetimeoffset`. |Нет |

Используйте приведенные ниже рекомендации о том, когда следует включать сведения о структуре и что включать в раздел **structure**.

* **Для структурированных источников данных**, в которых наряду с данными хранятся схема данных и сведения о типах (например, SQL Server, Oracle, таблица Azure), раздел structure следует указывать только при сопоставлении исходных столбцов со столбцами в приемнике, если их имена различаются. 
  
    Для структурированных источников данных информация о типах уже доступна, поэтому ее не следует включать при добавлении раздела structure.
* **Для схемы на основе считываемых источников данных (а именно большого двоичного объекта Azure)** вы можете выбрать хранение данных без сохранения схемы или сведений о типах вместе с данными. Для источников данных этих типов раздел structure следует включать, если нужно сопоставить столбцы источника со столбцами приемника или если набор данных является входным набором данных для операции копирования и типы данных из исходного набора данных следует преобразовать в собственные типы для приемника. 
    
    Фабрика данных поддерживает следующие CLS-совместимые значения типов на основе .NET, когда нужно указывать сведения о типах в разделе structure для схемы по считываемым источникам данных, таким как большие двоичные объекты Azure: Int16, Int32, Int64, Single, Double, Decimal, Byte[], Bool, String, Guid, Datetime, Datetimeoffset, Timespan.

Фабрика данных автоматически преобразует типы при переносе данных из источника в приемник. 
  

## <a name="Availability"></a>Доступность набора данных
В разделе **availability** набора данных определяется его окно обработки (ежечасно, ежедневно, еженедельно и т. п.). Дополнительные сведения об окнах действий см. в статье [Планирование и исполнение с использованием фабрики данных](data-factory-scheduling-and-execution.md).

В следующем примере раздел availability определяет то, что набор выходных данных создается ежечасно (или) доступен каждый час.

```json
"availability":    
{    
    "frequency": "Hour",        
    "interval": 1    
}
```

Предположим, для конвейера заданы следующие время начала и окончания.  

```json
    "start": "2016-08-25T00:00:00Z",
    "end": "2016-08-25T05:00:00Z",
```

Выходной набор данных создается каждый час в пределах времени начала и времени окончания для конвейера. Таким образом, в этом конвейере создаются пять срезов данных — по одному для каждого окна действий (с 12:00 до 01:00, с 01:00 до 02:00, с 02:00 до 03:00, с 03:00 до 04:00, с 04:00 до 05:00). 

Ниже перечислены свойства, которые можно использовать в разделе availability.

| Свойство | Описание | Обязательно | значение по умолчанию |
| --- | --- | --- | --- |
| frequency |Указывает единицу времени, которая определяет частоту создания среза данных.<br/><br/><b>Поддерживаемые значения</b>: Minute, Hour, Day, Week, Month. |Да |Нет данных |
| interval |Задает множитель для частоты.<br/><br/>"Интервал х частоты" определяет частоту создания срезов.<br/><br/>Если нужно, чтобы срез в наборе данных создавался каждый час, задайте для параметра <b>frequency</b> значение <b>Hour</b>, а для параметра <b>interval</b> — значение <b>1</b>.<br/><br/><b>Примечание.</b> Если вы выбрали значение Minute для параметра Frequency, рекомендуем, чтобы интервал длился не менее 15 минут. |Да |Нет данных |
| style |Указывает, когда выполняется срез: в начале или в конце интервала.<ul><li>StartOfInterval</li><li>EndOfInterval</li></ul><br/><br/>Если для Frequency задано значение Month, а для Style — EndOfInterval, срез данных будет создаваться в последний день месяца. Если для Style задано значение StartOfInterval, срез создается в первый день месяца.<br/><br/>Если для frequency задано значение Day, а для style — EndOfInterval, срез данных будет создаваться в последний час дня.<br/><br/>Если для Frequency задано значение Hour, а для Style — EndOfInterval, срез создается в конце часа. Например, для периода с 13:00 до 14:00 срез создается в 14:00. |Нет |EndOfInterval |
| anchorDateTime |Определяет момент времени, на основе которого планировщик вычисляет границы среза набора данных. <br/><br/><b>Примечание</b>. Если параметр AnchorDateTime содержит элементы с большей степенью детализации, чем значение параметра frequency, эти элементы игнорируются. <br/><br/>Например, если для <b>интервала</b> задано значение <b>ежечасно</b> (frequency = Hour, interval = 1), а <b>AnchorDateTime</b> содержит <b>минуты и секунды</b>, то <b>минуты и секунды</b> из параметра AnchorDateTime не учитываются. |Нет |01/01/0001 |
| offset |Интервал времени, на который сдвигаются начало и конец всех срезов данных. <br/><br/><b>Примечание</b>. Если указаны значения для обоих параметров (anchorDateTime и offset), сдвиг вычисляется с учетом обоих значений. |Нет |Нет данных |

### <a name="offset-example"></a>Пример смещения
По умолчанию создание ежедневных срезов (`"frequency": "Day", "interval": 1`) начинается в 00:00 (UTC). Если требуется начинать их создание 06:00 (UTC), задайте смещение, как показано в следующем фрагменте. 

```json
"availability":
{
    "frequency": "Day",
    "interval": 1,
    "offset": "06:00:00"
}
```
### <a name="anchordatetime-example"></a>Пример для anchorDateTime
В следующем примере набор данных создается каждые 23 часа. Создание первого среза начинается в момент, определяемый параметром anchorDateTime, для которого задано значение `2017-04-19T08:00:00` (время в формате UTC).

```json
"availability":    
{    
    "frequency": "Hour",        
    "interval": 23,    
    "anchorDateTime":"2017-04-19T08:00:00"    
}
```

### <a name="offsetstyle-example"></a>Пример для Offset и Style
Следующий набор данных создается ежемесячно в 3-й день каждого месяца в 08:00 (`3.08:00:00`).

```json
"availability": {
    "frequency": "Month",
    "interval": 1,
    "offset": "3.08:00:00",    
    "style": "StartOfInterval"
}
```

## <a name="Policy"></a>Политика наборов данных
Раздел **policy** в определении набора данных содержит условия, которым должен соответствовать срез данных.

### <a name="validation-policies"></a>Политики проверки
| Имя политики | Описание | Применяется к | Обязательно | значение по умолчанию |
| --- | --- | --- | --- | --- |
| minimumSizeMB |Проверяет, удовлетворяют ли данные в **большом двоичном объекте Azure** требованиям к минимальному размеру (в мегабайтах). |большом двоичном объекте Azure |Нет |Нет данных |
| minimumRows |Проверяет, содержат ли данные в **базе данных SQL Azure** или **таблице Azure** минимально необходимое количество строк. |<ul><li>База данных SQL Azure</li><li>таблице Azure</li></ul> |Нет |Нет данных |

#### <a name="examples"></a>Примеры
**minimumSizeMB:**

```json
"policy":

{
    "validation":
    {
        "minimumSizeMB": 10.0
    }
}
```

**minimumRows:**

```json
"policy":
{
    "validation":
    {
        "minimumRows": 100
    }
}
```

### <a name="external-datasets"></a>Внешние наборы данных
Внешними считаются такие наборы данных, которые не создаются запущенным конвейером в фабрике данных. Если набор данных помечен как **external**, вы можете изменить доступность соответствующих срезов данных с помощью политики **ExternalData**.

Если набор данных не создается фабрикой данных Azure, он должен быть помечен как **external**. Обычно этот параметр относится к входным данным для первого действия в конвейере, если не используется цепочка действий или конвейеров.

| name | Описание | Обязательно | По умолчанию |
| --- | --- | --- | --- |
| dataDelay |Время задержки проверки на наличие внешних данных для определенного среза. Например, если данные доступны ежечасно, проверку доступности внешних данных (и того, находится ли соответствующий срез в состоянии Ready) можно отложить, используя политику dataDelay.<br/><br/>Применяется только к настоящему времени.  Например, если сейчас 13:00 и для dataDelay задано значение "10 минут", то проверка начинается в 13:10.<br/><br/>Этот параметр не влияет на срезы в прошлом (срезы, у которых параметры Slice End Time и dataDelay имеют значение раньше текущего времени), и они обрабатываются без задержки.<br/><br/>Время после 23:59 необходимо указать в формате `day.hours:minutes:seconds`. Например, чтобы задать 24 часа, не используйте формат 24:00:00; вместо этого укажите 1.00:00:00. Значение 24:00:00 обозначает 24 дня (24.00:00:00). Чтобы задать 1 день и 4 часа, укажите 1:04:00:00. |Нет |0 |
| retryInterval |Время ожидания после сбоя до повторной попытки. Относится к настоящему времени. Если предыдущая попытка была неудачной, то по истечении периода retryInterval предпринимается следующая попытка. <br/><br/>Предположим, что первая попытка началась в 13:00. Если она длится одну минуту и завершается сбоем, то повторная попытка начнется в 13:02 (13:00 + время выполнения первой проверки (1 минута) + интервал повтора (1 минута)). <br/><br/>Срезы в прошлом обрабатываются без задержки. Повторная попытка происходит незамедлительно. |Нет |00:01:00 (1 минута) |
| retryTimeout |Время ожидания для каждой следующей повторной попытки.<br/><br/>Если это значение составляет 10 минут, проверка должна занимать не более 10 минут. Если проверка длится больше 10 минут, возникает ошибка времени ожидания.<br/><br/>Если такая ошибка возникает во время всех попыток, срез помечается как TimedOut. |Нет |00:10:00 (10 минут) |
| maximumRetry |Максимальное количество попыток проверки доступности внешних данных. Максимальное допустимое значение — 10. |Нет |3 |


## <a name="create-datasets"></a>Создание наборов данных
Наборы данных можно создать с помощью одного из указанных ниже инструментов или пакетов SDK. 

- Мастер копирования. 
- Портал Azure
- Visual Studio
- Azure PowerShell
- Шаблон диспетчера ресурсов Azure
- Интерфейс REST API
- .NET API

Пошаговые инструкции по созданию конвейеров и наборов данных с помощью одного из указанных ниже инструментов или пакетов SDK приведены в указанных ниже руководствах.
 
- [Учебник. Создание первого конвейера для преобразования данных с помощью кластера Hadoop](data-factory-build-your-first-pipeline.md)
- [Руководство. Копирование данных из хранилища BLOB-объектов Azure в базу данных SQL с помощью фабрики данных](data-factory-copy-data-from-azure-blob-storage-to-sql-database.md)

После создания и развертывания конвейера вы можете управлять конвейерами и отслеживать их с помощью колонок на портале Azure или приложения для мониторинга и управления. Пошаговые инструкции представлены в указанных ниже статьях. 

- [Мониторинг конвейеров фабрики данных Azure и управление ими с помощью портала Azure и PowerShell](data-factory-monitor-manage-pipelines.md)
- [Мониторинг конвейеров фабрики данных Azure и управление ими с помощью приложения для мониторинга и управления](data-factory-monitor-manage-app.md)


## <a name="scoped-datasets"></a>Контекст наборов данных
С помощью свойства **datasets** вы можете создавать наборы данных, прикрепленные к контексту конкретного конвейера. Такие наборы данных могут использоваться только действиями в пределах указанного конвейера, но не действиями в других конвейерах. В следующем примере определяется конвейер с двумя наборами данных (InputDataset-rdc и OutputDataset-rdc), которые будут использоваться только в рамках этого конвейера.  

> [!IMPORTANT]
> Наборы данных с заданной областью поддерживаются только разовыми конвейерами (для которых параметр pipelineMode имеет значение OneTime). Дополнительные сведения см. в разделе [Однократный конвейер](data-factory-scheduling-and-execution.md#onetime-pipeline).
>
>

```json
{
    "name": "CopyPipeline-rdc",
    "properties": {
        "activities": [
            {
                "type": "Copy",
                "typeProperties": {
                    "source": {
                        "type": "BlobSource",
                        "recursive": false
                    },
                    "sink": {
                        "type": "BlobSink",
                        "writeBatchSize": 0,
                        "writeBatchTimeout": "00:00:00"
                    }
                },
                "inputs": [
                    {
                        "name": "InputDataset-rdc"
                    }
                ],
                "outputs": [
                    {
                        "name": "OutputDataset-rdc"
                    }
                ],
                "scheduler": {
                    "frequency": "Day",
                    "interval": 1,
                    "style": "StartOfInterval"
                },
                "name": "CopyActivity-0"
            }
        ],
        "start": "2016-02-28T00:00:00Z",
        "end": "2016-02-28T00:00:00Z",
        "isPaused": false,
        "pipelineMode": "OneTime",
        "expirationTime": "15.00:00:00",
        "datasets": [
            {
                "name": "InputDataset-rdc",
                "properties": {
                    "type": "AzureBlob",
                    "linkedServiceName": "InputLinkedService-rdc",
                    "typeProperties": {
                        "fileName": "emp.txt",
                        "folderPath": "adftutorial/input",
                        "format": {
                            "type": "TextFormat",
                            "rowDelimiter": "\n",
                            "columnDelimiter": ","
                        }
                    },
                    "availability": {
                        "frequency": "Day",
                        "interval": 1
                    },
                    "external": true,
                    "policy": {}
                }
            },
            {
                "name": "OutputDataset-rdc",
                "properties": {
                    "type": "AzureBlob",
                    "linkedServiceName": "OutputLinkedService-rdc",
                    "typeProperties": {
                        "fileName": "emp.txt",
                        "folderPath": "adftutorial/output",
                        "format": {
                            "type": "TextFormat",
                            "rowDelimiter": "\n",
                            "columnDelimiter": ","
                        }
                    },
                    "availability": {
                        "frequency": "Day",
                        "interval": 1
                    },
                    "external": false,
                    "policy": {}
                }
            }
        ]
    }
}
```

## <a name="next-steps"></a>Дальнейшие действия
- Дополнительные сведения о конвейерах см. в статье [Создание конвейеров](data-factory-create-pipelines.md). 
- Дополнительные сведения о планировании и выполнении конвейеров см. в статье [Планирование и исполнение с использованием фабрики данных](data-factory-scheduling-and-execution.md). 
