---
title: Фабрика данных Azure. Часто задаваемые вопросы | Документация Майкрософт
description: Получите ответы на часто задаваемые вопросы о фабрике данных Azure.
services: data-factory
documentationcenter: ''
author: sharonlo101
manager: craigg
ms.assetid: 532dec5a-7261-4770-8f54-bfe527918058
ms.service: data-factory
ms.workload: data-services
ms.tgt_pltfrm: na
ms.topic: conceptual
ms.date: 06/27/2018
ms.author: shlo
ms.openlocfilehash: be0cdeed81c66e1a848b44d2429c1c67bce9b4f3
ms.sourcegitcommit: 25936232821e1e5a88843136044eb71e28911928
ms.translationtype: HT
ms.contentlocale: ru-RU
ms.lasthandoff: 01/04/2019
ms.locfileid: "54024099"
---
# <a name="azure-data-factory-faq"></a>Часто задаваемые вопросы о фабрике данных Azure
Эта статья содержит ответы на часто задаваемые вопросы о фабрике данных Azure.  

## <a name="what-is-azure-data-factory"></a>Что такое фабрика данных Azure? 
Фабрика данных представляет собой полностью управляемую облачную службу интеграции информации, которая автоматизирует перемещение и преобразование данных. Как на фабрике сырье превращается в готовую продукцию с помощью оборудования, так и в фабриках данных Azure необработанные данные собираются и преобразовываются в готовые к использованию сведения с помощью специальных служб. 

Фабрика данных Azure позволяет создавать управляемые данными рабочие процессы для перемещения данных между локальными и облачными хранилищами данных. Вы также можете обрабатывать или преобразовывать данные с помощью служб вычислений, таких как Azure HDInsight, Azure Data Lake Analytics и среды выполнения интеграции SQL Server Integration Services (SSIS). 

С помощью фабрики данных вы можете выполнить обработку данных, используя облачную службу на основе Azure или собственную вычислительную среду с локальным размещением, например SSIS, SQL Server или Oracle. Для созданного конвейера, который выполняет необходимое действие, можно запланировать периодический запуск (например, ежечасно, ежедневно или еженедельно), запуск по временному окну или запуск на основе произошедшего события. Дополнительную информацию см. в статье [Общие сведения о службе фабрики данных Azure, службе интеграции данных в облаке](introduction.md).

### <a name="control-flows-and-scale"></a>Потоки управления и масштабирование 
Чтобы обеспечить поддержку разнообразных последовательностей и шаблонов интеграции в современных хранилищах данных, фабрика данных предлагает гибкую модель конвейеров данных, которая включает в себя парадигмы программирования потоков с полным контролем, в том числе условное выполнение, ветвление конвейеров данных и явную передачу параметров внутри и между потоками. Поток управления также обеспечивает преобразование данных путем отправки действий на внешние модули выполнения и возможности передачи данных, в том числе перемещение данных в масштабе, с применением действия копирования.

Фабрика данных позволяет создать любой поток для своего сценария интеграции данных и запускать его по запросу или постоянно по расписанию. Ниже приведены несколько общих потоков, которые эта модель поддерживает.   

- Потоки управления:
    - Цепочки действий в последовательности в конвейере.
    - Ветви действий в конвейере.
    - Параметры
        - Определяйте параметры на уровне конвейера и передавайте аргументы при вызове конвейера по запросу или из триггера.
        - Действия могут использовать аргументы, передаваемые в конвейер.
    - Передача пользовательского состояния:
        - Выходные данные действия содержат состояние, которое можно использовать в следующем действии в конвейере.
    - Контейнеры зацикливания:
        - Оператор for-each 
- Потоки на основе триггеров:
    - Конвейеры можно вызывать по требованию или в определенное время.
- Разностные потоки:
    - Используйте параметры и определяйте отметку пиковой активности для разностного копирования при перемещении справочных таблиц или измерений из локального или облачного реляционного хранилища в озеро данных. 

Дополнительные сведения см. в статье [Руководство. Ветвления и создание цепочки действий в конвейере фабрики данных](tutorial-control-flow.md).

### <a name="transform-your-data-at-scale-with-code-free-pipelines"></a>Преобразование данных в масштабе с использованием конвейеров без кода
Новый браузерный инструментарий позволяет писать и развертывать конвейеры без кода с помощью современного интерактивного веб-интерфейса.

Пользовательский веб-интерфейс ADF представляет собой среду проектирования без необходимости писать код, которую разработчики, занимающиеся визуализацией данных, и специалисты по обработке и анализу данных могут использовать для создания конвейеров. Он полностью интегрирован с Visual Studio Online Git и обеспечивает внедрение процессов непрерывной интеграции и доставки (CI/CD), а также последовательной разработки с возможностями отладки.

### <a name="rich-cross-platform-sdks-for-advanced-users"></a>Расширенный кроссплатформенный пакет SDK для опытных пользователей
Если вам как опытному пользователю нужен программный интерфейс, вам понравится широкий выбор пакетов SDK в ADF версии 2, которые позволяют создавать конвейеры, управлять ими и отслеживать их из любой удобной среды IDE.
1.  Пакет SDK для Python
2.  PowerShell CLI.
3.  Пользователи пакета SDK для C# также могут использовать задокументированные REST API для обмена данными с ADF V2.

### <a name="iterative-development-and-debugging-using-visual-tools"></a>Последовательная разработка и отладка с использованием визуальных средств
Визуальные средства фабрики данных Azure (ADF) позволяют выполнять последовательную разработку и отладку. Вы можете создавать конвейеры и выполнять тестовые запуски с помощью функции "Отладка" на холсте конвейера, не написав ни строки кода. Просмотреть результаты тестовых запусков можно в окне "Выходные данные" на холсте конвейера. После успешных тестовых запусков можно добавить дополнительные действия в конвейер и продолжать отладку итеративным методом. Выполняемые тестовые запуски также можно отменить. Перед выбором функции отладки необязательно публиковать изменения в службе фабрики данных. Это помогает в сценариях, когда перед обновлением рабочих процессов фабрики данных в среде разработки, тестирования и рабочей среде необходимо убедиться, что добавленные элементы и изменения работают, как и ожидалось. 

### <a name="deploy-ssis-packages-to-azure"></a>Развертывание пакетов служб SSIS в Azure 
Если вы хотите перемещать рабочие нагрузки служб SSIS, то создайте фабрику данных и подготовьте среду выполнения интеграции Azure SSIS. Среда выполнения интеграции Azure SSIS — это полностью управляемый кластер виртуальных машин (узлов) Azure, выделенный для выполнения пакетов служб SSIS в облаке. Пошаговые инструкции см. в руководстве [Развертывание пакетов служб интеграции SQL Server (SSIS) в Azure](tutorial-create-azure-ssis-runtime-portal.md). 
 
### <a name="sdks"></a>Пакеты SDK
Если вам как опытному пользователю нужен программный интерфейс, вам понравится широкий выбор пакетов SDK в ADF, которые позволяют создавать конвейеры, управлять ими или отслеживать их из любой удобной интегрированной среды разработки. Поддерживаются такие языки, как .NET, Python, PowerShell и REST.

### <a name="monitoring"></a>Мониторинг
Фабрики данных можно отслеживать с помощью PowerShell, пакета SDK и визуальных средств наблюдения в браузерном пользовательском интерфейсе. Вы можете отслеживать пользовательские потоки, запускаемые по требованию, на основе триггера и по времени, и управлять ими эффективно и без лишних затрат. Отменяйте существующие задачи, просматривайте общие сведения о сбоях, детализируйте сбои, чтобы получить подробные сообщения об ошибках, и выполняйте отладку неполадок на одной панели без переключения контекста или перехода между экранами. 

### <a name="new-features-for-ssis-in-adf"></a>Новые возможности служб SSIS в ADF
С момента первоначального выпуска общедоступной предварительной версии в 2017 году в фабрике данных были добавлены следующие возможности и компоненты для служб SSIS.

-   Поддержка трех дополнительных конфигураций и вариантов Базы данных SQL Azure (DB) для размещения каталога проектов и пакетов SSIS (SSISDB).
-   База данных SQL Azure с конечными точками службы виртуальной сети.
-   Управляемый экземпляр (MI).
-   Эластичный пул
-   Поддержка виртуальной сети Azure Resource Manager поверх классической виртуальной сети (будет прекращена). Благодаря этому вы можете присоединять среду выполнения интеграции Azure SSIS к виртуальной сети, настроенной для базы данных SQL Azure с конечными точками службы виртуальной сети, управляемым экземпляром и доступом к локальным данным. (См. страницу https://docs.microsoft.com/azure/data-factory/join-azure-ssis-integration-runtime-virtual-network.) 
-   Поддержка проверки подлинности Azure Active Directory (AAD) поверх проверки подлинности SQL для подключения к SSISDB. Таким образом, можно использовать проверку подлинности AAD с управляемым удостоверением ADF для ресурсов Azure
-   Поддержка использования собственной лицензии на локальную версию SQL Server для существенной экономии благодаря программе "Преимущество гибридного Azure" (AHB).
-   Поддержка выпуска Enterprise среды выполнения интеграции Azure SSIS, позволяющего использовать расширенные возможности и премиум-возможности, выборочную установку для установки дополнительных компонентов или расширений и экосистему решений сторонних производителей. (См. страницу https://blogs.msdn.microsoft.com/ssis/2018/04/27/enterprise-edition-custom-setup-and-3rd-party-extensibility-for-ssis-in-adf/.) 
-   Более глубокая интеграция служб SSIS в ADF, что позволяет вызывать и инициировать действия выполнения пакетов служб SSIS первого класса в конвейерах ADF и планировать их в SSMS. (См. страницу https://blogs.msdn.microsoft.com/ssis/2018/05/23/modernize-and-extend-your-etlelt-workflows-with-ssis-activities-in-adf-pipelines/.) 


## <a name="what-is-integration-runtime"></a>Что такое среда выполнения интеграции?
Среда выполнения интеграции — это вычислительная инфраструктура, с помощью которой фабрика данных Azure обеспечивает перечисленные ниже возможности интеграции данных в разных сетевых средах.

- **Перемещение данных**. При перемещении данных Integration Runtime перемещает данные между исходными и конечными хранилищами данных, а также предоставляет поддержку встроенных соединителей, преобразования формата, сопоставления столбцов и передачи производительных и масштабируемых данных.
- **Диспетчеризация действий**. Для преобразования Integration Runtime предоставляет изначальную возможность выполнять пакеты служб SSIS.
- **Выполнение пакетов служб SSIS**. Выполнение пакетов служб SSIS в собственном коде в управляемой среде вычислений Azure. Среда IR также поддерживает отправку и отслеживание действий по преобразованию, выполняющихся в различных службах вычисления, таких как Azure HDInsight, Машинное обучение Azure, База данных SQL Azure, SQL Server и другие.

Вы можете развертывать один или несколько экземпляров среды выполнения интеграции по необходимости, чтобы переместить или преобразовать данные. Среда выполнения интеграции может работать в общедоступной сети Azure или в частной сети (локальной сети, виртуальной сети Azure или виртуальном частном облаке Amazon Web Services [VPC]). 

Дополнительные сведения см. в статье [Среда выполнения интеграции в фабрике данных Azure](concepts-integration-runtime.md).

## <a name="what-is-the-limit-on-the-number-of-integration-runtimes"></a>Что такое ограничение количества сред выполнения интеграции?
В фабрике данных нет жестких ограничений на количество экземпляров среды выполнения интеграции. Однако есть ограничение на число ядер виртуальной машины, которые среда выполнения интеграции может использовать для каждой подписки при выполнении пакетов служб SSIS. Дополнительные сведения см. в разделе [Ограничения фабрики данных](../azure-subscription-service-limits.md#data-factory-limits).

## <a name="what-are-the-top-level-concepts-of-azure-data-factory"></a>Какие основные концепции в фабрике данных Azure?
В подписке Azure может быть один или несколько экземпляров фабрики данных Azure. Фабрика данных Azure содержит четыре ключевых компонента. Они образуют платформу, на которой можно создавать управляемые данными рабочие процессы, предусматривающие перемещение и преобразование данных.

### <a name="pipelines"></a>Конвейеры
Фабрика данных может иметь один или несколько конвейеров. Конвейер — это логическая группа действий, которые выполняют определенный блок задач. Действия в конвейере совместно выполняют задачу. Например, конвейер может включать группу действий, которые принимают данные из большого двоичного объекта Azure и выполняют запрос Hive в кластере HDInsight для секционирования данных. Преимуществом является то, что конвейер позволяет управлять группами действий, а не каждым отдельным действием. Вы можете связать вместе действия в конвейере, чтобы выполнять их последовательно, или выполнять их параллельно и независимо друг от друга.

### <a name="activity"></a>Действие
Действия представляют отдельные этапы обработки в конвейере. Например, действие *копирования* может использоваться для копирования данных из одного хранилища данных в другое. Точно так же можно использовать действие Hive, которое выполняет запрос Hive к кластеру Azure HDInsight для преобразования или анализа данных. Фабрика данных поддерживает три типа действий: действия перемещения данных, действия преобразования данных и действия управления.

### <a name="datasets"></a>Наборы данных
Наборы данных представляют структуры данных в хранилищах. Эти структуры указывают данные, необходимые для использования в действиях, разделяя их на входные и выходные. 

### <a name="linked-services"></a>Связанные службы
Связанные службы напоминают строки подключения, определяющие сведения о подключении, необходимые для подключения фабрики данных к внешним ресурсам. Таким образом, набор данных представляет структуру данных, а связанная служба определяет подключение к источнику данных. Например, связанная служба хранилища Azure определяет строку подключения для подключения к учетной записи хранения Azure. А набор данных больших двоичных объектов Azure определяет контейнер больших двоичных объектов и папку, которая содержит данные.

Связанные службы используются в фабрике данных для двух целей:

- Для представления *хранилища данных*, включая, помимо прочего, локальный экземпляр SQL Server, экземпляр базы данных Oracle, общую папку и учетную запись хранилища BLOB-объектов Azure. Список поддерживаемых хранилищ данных см. в статье [Действие копирования в фабрике данных Azure](copy-activity-overview.md).
- Для представления *вычислительного ресурса*, в котором можно выполнить действие. Например, действие HDInsightHive выполняется в кластере Hadoop в HDInsight. Список поддерживаемых действий преобразования и вычислительных сред см. в статье [Преобразование данных в фабрике данных Azure](transform-data.md).

### <a name="triggers"></a>триггеры;
Триггеры обозначают единицу обработки, которая определяет время запуска для выполнения конвейера. Существует несколько типов триггеров для разных событий. 

### <a name="pipeline-runs"></a>Запуски конвейера
Запуск конвейера — это экземпляр выполнения конвейера. Запуск конвейера обычно выполняется путем передачи аргументов для параметров, определенных в конвейере. Вы можете передать аргументы вручную или в определении триггера.

### <a name="parameters"></a>Параметры
Параметры представляют собой пары "ключ — значение" в конфигурации только для чтения. Вы определяете параметры в конвейере и передаете для них аргументы во время выполнения из контекста запуска. Контекст запуска создается триггером или из конвейера, который выполняется вручную. Действия в конвейере используют значения параметров.

Набор данных — это строго типизированный параметр и сущность, на которую можно ссылаться и использовать повторно. Действие может ссылаться на наборы данных и использовать параметры, определенные в определении набора данных.

Связанная служба также является строго типизированным параметром, который содержит сведения о подключении к хранилищу данных или среде вычислений. Это также сущность, доступная для ссылок или повторного использования.

### <a name="control-flows"></a>Потоки управления
Потоки управления выполняют оркестрацию действий в конвейере, которая включает цепочки действий в последовательности, ветвление и параметры, определяемые на уровне конвейера, а также аргументы, которые передаются во время вызова конвейера по запросу или из триггера. Сюда также входит передача пользовательского состояния и контейнеры зацикливания (то есть итераторы For-each).


Дополнительные сведения о понятиях фабрики данных см. в следующих статьях:

- [Наборы данных и связанные службы в фабрике данных Azure](concepts-datasets-linked-services.md)
- [Конвейеры и действия](concepts-pipelines-activities.md)
- [Среда выполнения интеграции в фабрике данных Azure](concepts-integration-runtime.md)

## <a name="what-is-the-pricing-model-for-data-factory"></a>Какая модель ценообразования применяется для фабрики данных?
Подробные сведения о ценах на фабрику данных Azure см. на [этой странице](https://azure.microsoft.com/pricing/details/data-factory/).

## <a name="how-can-i-stay-up-to-date-with-information-about-data-factory"></a>Как оставаться в курсе последних новостей о фабрике данных?
Чтобы узнавать о последних новостях о фабрике данных Azure, используйте следующие сайты:

- [Блог](https://azure.microsoft.com/blog/tag/azure-data-factory/)
- [Документация по фабрике данных Azure V2](/azure/data-factory)
- [Домашняя страница продукта](https://azure.microsoft.com/services/data-factory/)

## <a name="technical-deep-dive"></a>Подробное техническое руководство 

### <a name="how-can-i-schedule-a-pipeline"></a>Как запланировать конвейер? 
Для планирования конвейера можно использовать триггер планировщика или триггер по временному окну. Триггер использует календарное расписание с указанием времени. Вы можете использовать его, чтобы планировать конвейеры, выполняемые периодически или по повторяющимся шаблонам на основе календаря (например, еженедельно по понедельникам в 18:00 и по четвергам в 21:00). Дополнительные сведения см. в статье [Выполнение конвейера и триггеры в фабрике данных Azure](concepts-pipeline-execution-triggers.md).

### <a name="can-i-pass-parameters-to-a-pipeline-run"></a>Можно ли передать параметры в выполнение конвейера?
Да, параметры являются полноправной основной концепцией в ADF. Вы можете определить параметры на уровне конвейера и передать аргументы при выполнении конвейера, запускаемого по требованию или с помощью триггера.  

### <a name="can-i-define-default-values-for-the-pipeline-parameters"></a>Можно ли определить значения по умолчанию для параметров конвейера? 
Да. Вы можете определить значения по умолчанию для параметров в конвейерах. 

### <a name="can-an-activity-in-a-pipeline-consume-arguments-that-are-passed-to-a-pipeline-run"></a>Может ли действие в конвейере использовать аргументы, передаваемые в конвейер? 
Да. Каждое действие в рамках конвейера может использовать значение параметра, переданное в конвейер и запущенное с помощью конструкции `@parameter`. 

### <a name="can-an-activity-output-property-be-consumed-in-another-activity"></a>Может ли свойство из выходных данных действия использоваться в другом действии? 
Да. Выходные данные действия могут использоваться в последующем действии. Для этого применяется конструкция `@activity`.
 
### <a name="how-do-i-gracefully-handle-null-values-in-an-activity-output"></a>Как корректно обрабатывать значения null в выходных данных действия? 
Для корректной обработки значений null в выражениях можно использовать конструкцию `@coalesce`. 

## <a name="next-steps"></a>Дополнительная информация
Пошаговые инструкции по созданию фабрики данных см. в следующих руководствах:

- [Краткое руководство Создание фабрики данных и конвейера с помощью пакета SDK .NET](quickstart-create-data-factory-dot-net.md)
- [Руководство Копирование данных из хранилища BLOB-объектов Azure в базу данных SQL Azure с помощью фабрики данных Azure](tutorial-copy-data-dot-net.md)
