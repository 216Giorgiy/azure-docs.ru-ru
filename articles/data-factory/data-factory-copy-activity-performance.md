<properties
	pageTitle="Руководство по настройке производительности действия копирования | Microsoft Azure"
	description="Узнайте о ключевых факторах, которые влияют на производительность перемещения данных в фабрике данных Azure с использованием действия копирования."
	services="data-factory"
	documentationCenter=""
	authors="spelluru"
	manager="jhubbard"
	editor="monicar"/>

<tags
	ms.service="data-factory"
	ms.workload="data-services"
	ms.tgt_pltfrm="na"
	ms.devlang="na"
	ms.topic="article"
	ms.date="03/07/2016"
	ms.author="spelluru"/>


# Руководство по настройке производительности действия копирования
В этой статье описываются ключевые факторы, которые влияют на производительность перемещения данных (с помощью действия копирования) в фабрике данных Azure. В ней также приведены сведения о производительности, наблюдаемой во время внутреннего тестирования, и рассматриваются различные способы оптимизировать производительность действия копирования.

## Общие сведения о перемещении данных в фабрике данных Azure
Действие копирования означает перемещение данных в фабрику данных Azure и выполняется [глобально доступной службой перемещения данных](data-factory-data-movement-activities.md#global), обеспечивающей безопасное, надежное, масштабируемое и высокопроизводительное копирование данных [из одного хранилища в другое](data-factory-data-movement-activities.md#supported-data-stores-for-copy-activity). В зависимости от расположения исходного (источник) и целевого (приемник) хранилищ данных служба перемещения данных автоматически выбирает для операции перемещения данных наиболее оптимальный регион. В настоящее время используется регион, расположенный ближе всего к приемнику данных.

Рассмотрим, как происходит перемещение данных в различных ситуациях.

### Копирование данных из одного облачного хранилища в другое
Если источник и приемник находятся в облаке, действие копирования включает описанные ниже этапы копирования и перемещения данных:

1.	Считывает данные из источника данных.
2.	Сериализация или десериализация, сжатие или распаковка данных, сопоставление столбцов и преобразование данных из одного типа в другой в соответствии с конфигурациями входного и выходного наборов данных и действия копирования.
3.	Записывает данные в целевое хранилище данных.

![Копирование данных из одного облачного хранилища в другое](./media/data-factory-copy-activity-performance/copy-data-between-two-cloud-stores.png)

**Примечание.** В прямоугольниках с пунктирной линией указаны функции (сжатие, сопоставление столбцов и т. д.), которые могут не применяться в вашем варианте использования.


### Копирование данных из локального хранилища данных и облачное и наоборот
Для [перемещения данных между локальным и облачным хранилищем данных](data-factory-move-data-between-onprem-and-cloud.md) на локальный компьютер необходимо установить шлюз управления данными — агент, обеспечивающий гибридное перемещение и обработку данных. В этом сценарии шлюз управления данными выполняет сериализацию и десериализацию, сжимает или распаковывает данные, сопоставляет столбцы и преобразует данные из одного типа в другой в соответствии с конфигурациями входного и выходного наборов данных и действия копирования.

![Копирование данных между локальным и облачным хранилищем данных](./media/data-factory-copy-activity-performance/copy-data-between-onprem-and-cloud.png)

## Этапы настройки производительности
Ниже приведены этапы настройки производительности решения фабрики данных Azure с использованием действия копирования.

1.	**Определение исходной конфигурации.** Протестируйте конвейер на этапе разработки с помощью действия копирования на примере репрезентативных данных. Чтобы ограничить объем данных для тестирования, можно использовать [модель среза](data-factory-scheduling-and-execution.md#time-series-datasets-and-data-slices) фабрики данных Azure.

	Соберите показатели времени выполнения и производительности. Их можно просмотреть в колонке "Срез данных" и "Сведения о выполнении действия" выходного набора данных на портале предварительной версии Azure, где отображаются длительность выполнения действия копирования и объем скопированных данных.

	![Сведения о цикле выполнения действия](./media/data-factory-copy-activity-performance/activity-run-details.png)

	Вы можете сравнить показатели производительности и конфигурацию вашего сценария с приведенными ниже [базовыми показателями производительности](#performance-reference) действия копирования, которые основаны на внутренних наблюдениях.
2. **Диагностика и оптимизация производительности.** Если наблюдаемая производительность не соответствует вашим ожиданиям, необходимо определить проблемы и выполнить оптимизацию, чтобы устранить их или уменьшить их влияние. В этой статье не приведено полное описание диагностики производительности. Однако здесь перечислены некоторые общие рекомендации.
	- [Источник](#considerations-on-source)
	- [Приемник](#considerations-on-sink)
	- [Сериализация и десериализация](#considerations-on-serializationdeserialization)
	- [Сжатие](#considerations-on-compression)
	- [Сопоставление столбцов](#considerations-on-column-mapping)
	- [Шлюз управления данными](#considerations-on-data-management-gateway)
	- [Дополнительные рекомендации](#other-considerations)
3. **Задание конфигурации для работы со всеми данными.** Если вас устраивают результаты выполнения и производительность, можно задать определение набора данных и активный период конвейера для всех данных.

## Базовые показатели производительности
> [AZURE.IMPORTANT] **Отказ от ответственности.** Приведенные ниже данные опубликованы исключительно с целью предоставления рекомендаций и помощи в общем процессе планирования. Предполагается использование лучших в своем классе пропускной способности, оборудования, конфигурации и т. д. Используйте эти сведения только в качестве справочных материалов. Пропускная способность перемещения данных зависит от диапазона переменных. Дополнительные сведения о способах настройки и достижения более высокой производительности в соответствии с потребностями перемещения данных см. в разделах ниже. Эти данные будут обновлены после добавления усовершенствований и новых функциональных возможностей для повышения производительности.

![Матрица производительности](./media/data-factory-copy-activity-performance/CopyPerfRef.png)

> [AZURE.NOTE] **Ожидается в ближайшее время.** Мы работаем над улучшением базовых показателей производительности, и в таблице выше вскоре будут приведены улучшенные показатели пропускной способности.

Примечания:

- Для вычисления пропускной способности используется следующая формула: [размер данных, считанных из источника]/[длительность выполнения действия копирования].
- Для вычисления указанных выше показателей использовался набор данных [TPC-H](http://www.tpc.org/tpch/).
- При использовании хранилищ данных Microsoft Azure источник и приемник находились в одном регионе Azure.
- В случае гибридного перемещения данных (из локальной среды в облако или наоборот) шлюз управления данными (один экземпляр) размещался не на том компьютере, где находилось локальное хранилище данных. При этом использовалась указанная ниже конфигурация. Обратите внимание, что если в шлюзе выполняется одно действие, во время выполнения действия копирования ресурсы ЦП и памяти, а также сетевая пропускная способность компьютера задействуются в незначительной степени.
	<table>
	<tr>
		<td>ЦП</td>
		<td>32&#160;ядра, 2,20&#160;ГГц, Intel Xeon® E5-2660 v2</td>
	</tr>
	<tr>
		<td>Память</td>
		<td>128&#160;ГБ</td>
	</tr>
	<tr>
		<td>Сеть</td>
		<td>Веб-интерфейс: 10&#160;Гбит/с, интерфейс интрасети: 40&#160;Гбит/с</td>
	</tr>
	</table>

## Рекомендации относительно источника
### Общие сведения
Убедитесь, что базовое хранилище данных не переполнено другими рабочими нагрузками, выполняемыми в нем или при его задействовании, включая, помимо прочего, действие копирования.

Дополнительные сведения о хранилищах данных Microsoft см. в [разделах мониторинга и настройки](#appendix-data-store-performance-tuning-reference) для конкретных типов хранилищ данных. В них подробно рассмотрены базовые показатели производительности хранилища данных, способы сокращения времени отклика и повышения пропускной способности.

### Файловые хранилища данных
*(Большой двоичный объект Azure, озеро данных Azure, локальная файловая система.)*

- **Средний размер файла и их количество**. Действие копирования передает данные в пофайловом режиме. При одинаковом объеме данных общая пропускная способность перемещения данных, которые состоят из большого количества небольших файлов, будет ниже, чем в случае перемещения данных, которые состоят из небольшого количества файлов большего размера. Это происходит из-за времени начальной загрузки каждого файла. Поэтому для получения более высокой пропускной способности по возможности следует объединить небольшие файлы в файлы большего размера.
- **Формат файла и сжатие**. Дополнительные сведения о способах повышения производительности см. в разделах [Рекомендации по сериализации и десериализации](#considerations-on-serializationdeserialization) и [Рекомендации по сжатию](#considerations-on-compression).
- Дополнительные сведения о сценарии с использованием **локальной файловой системы**, в котором применяется **шлюз управления данными**, см. в разделе [с рекомендациями относительно шлюза](#considerations-on-data-management-gateway).

### Реляционные хранилища данных
*(База данных SQL Azure, хранилище данных SQL Azure, база данных SQL Server, Oracle, MySQL, DB2, Teradata, Sybase и PostgreSQL.)*

- **Шаблон данных**. Схема таблицы влияет на пропускную способность копирования. Во время копирования данных одинакового объема использование строк большого размера позволяет добиться лучшей производительности, чем при использовании строк небольшого размера. Это связано с тем, что база данных более эффективно извлекает меньшее количество пакетов данных с меньшим количеством строк.
- **Запрос или хранимая процедура**. Оптимизируйте логику запроса или хранимой процедуры, указываемую в источнике действия копирования, чтобы более эффективно извлекать данные.
- Дополнительные сведения о **локальных реляционных базах данных**, таких как SQL Server и Oracle, где требуется **шлюз управления данными**, см. в разделе [Рекомендации относительно шлюза](#considerations-on-data-management-gateway).

## Рекомендации относительно приемника

### Общие сведения
Убедитесь, что базовое хранилище данных не переполнено другими рабочими нагрузками, выполняемыми в нем или при его задействовании, включая, помимо прочего, действие копирования.

Дополнительные сведения о хранилищах данных Microsoft см. в [разделах мониторинга и настройки](#appendix-data-store-performance-tuning-reference) для конкретных типов хранилищ данных. В них подробно рассмотрены базовые показатели производительности хранилища данных, способы сокращения времени отклика и повышения пропускной способности.

### Файловые хранилища данных
*(Большой двоичный объект Azure, озеро данных Azure, локальная файловая система.)*

- **Поведение копирования**. При копировании данных из другого файлового хранилища данных действие копирования предусматривает три вида поведения, которые можно задать с помощью свойства copyBehavior: сохранение иерархии, преобразование в плоскую структуру и объединение файлов. Сохранение иерархии или преобразование в плоскую структуру практически не оказывает влияния на производительность, в то время как объединение файлов существенно ее ухудшает.
- **Формат файла и сжатие**. Дополнительные сведения о способах повышения производительности см. в разделах [Рекомендации по сериализации и десериализации](#considerations-on-serializationdeserialization) и [Рекомендации по сжатию](#considerations-on-compression).
- Что касается **больших двоичных объектов Azure**, в настоящее время оптимизация передачи данных и пропускной способности поддерживается только для блочных BLOB-объектов.
- Дополнительные сведения о сценарии с использованием **локальной файловой системы**, в котором применяется **шлюз управления данными**, см. в разделе [с рекомендациями относительно шлюза](#considerations-on-data-management-gateway).

### Реляционные хранилища данных
*(База данных SQL Azure, хранилище данных SQL Azure, база данных SQL Server.)*

- **Поведение копирования**. В зависимости от свойств, настроенных для параметра sqlSink, существует несколько вариантов записи данных в базу данных назначения при выполнении действия копирования:
	- По умолчанию служба перемещения данных использует интерфейс API массового копирования для вставки данных в режиме добавления, что обеспечивает лучшую производительность.
	- Если настроить хранимую процедуру в приемнике, вместо массовой загрузки данные будут загружаться в базу данных построчно, что приведет к значительному снижению производительности. В случае с данными большого размера рекомендуется использовать свойство sqlWriterCleanupScript (см. ниже), если это применимо.
	- Если настроить свойство sqlWriterCleanupScript, при каждом действии копирования для вставки данных служба сначала запустит сценарий, а затем использует интерфейс API массового копирования. Например, чтобы перезаписать всю таблицу последними данными, перед массовой загрузкой новых данных из источника можно указать сценарий для удаления всех записей.
- **Шаблон данных и размер пакета**.
	- Схема таблицы влияет на пропускную способность копирования. Во время копирования данных одинакового объема использование строк большого размера позволяет добиться лучшей производительности, чем при использовании строк небольшого размера. Это связано с тем, что база данных более эффективно сохраняет меньшее количество пакетов данных.
	- Действие копирования вставляет данные в виде последовательности пакетов, где количество строк в пакете можно задать с помощью свойства writeBatchSize. Если данные содержатся в строках небольшого размера, можно задать для свойства writeBatchSize более высокое значение, чтобы использовать меньшее количество пакетов и тем самым увеличить пропускную способность. Следует с осторожностью увеличивать значение свойства writeBatchSize при большом размере строк данных, так как большое значение может привести к ошибке копирования из-за перегрузки базы данных.
- Дополнительные сведения о **локальных реляционных базах данных**, таких как SQL Server и Oracle, где требуется **шлюз управления данными**, см. в разделе [Рекомендации относительно шлюза](#considerations-on-data-management-gateway).


### Хранилища NoSQL
*(Таблица Azure и Azure DocumentDB.)*

- Для **таблицы SQL Azure**:
	- **Секционирование**. Запись данных в секции с чередованием значительно снижает производительность. Можно сортировать исходные данные по ключу секции, чтобы эффективно вставлять данные секция за секцией. Можно также настроить логику для записи данных в одну секцию.
- Для **Azure DocumentDB**:
	- **Размер пакета**. Свойство writeBatchSize указывает количество параллельных запросов на создание документов в службе DocumentDB. Если увеличить значение свойства writeBatchSize, то производительность повышается, потому что в DocumentDB начинает уходить больше параллельных запросов. Однако имейте в виду вероятность регулирования во время записи в DocumentDB (сообщение об ошибке: "Слишком большая частота запросов"). Регулирование может произойти по ряду причин, включая размер документов, количество терминов в документах и политику индексации целевой коллекции. Чтобы добиться более высокой пропускной способности копирования, рекомендуется использовать лучшую коллекцию (например, S3).

## Рекомендации по сериализации и десериализации
Сериализация и десериализация может произойти, если входной набор данных или выходной набор данных представляет собой файл. В настоящее время действие копирования поддерживает формат данных Avro и текстовый формат данных (например, CSV и TSV).

**Поведение копирования.**

- При копировании файлов между файловыми хранилищами данных:
	- Если параметры формата файла входного и выходного наборов данных одинаковые, служба перемещения данных выполнит двоичное копирование без сериализации или десериализации. Поэтому в этом сценарии наблюдается лучшая пропускная способность, по сравнению со сценарием, где параметры формата файла источника или приемника разные.
	- Если входной и выходной наборы данных находятся в текстовом формате и отличаются только типом кодирования, служба перемещения данных выполнит только преобразование кодирования без сериализации и десериализации. По сравнению с двоичным копированием, это совсем незначительно повлияет на производительность.
	- Если входной и выходной наборы данных находятся в разных форматах файлов или имеют разные конфигурации, например отличаются разделителями, служба перемещения данных десериализирует исходные данные для потоковой передачи, преобразования и сериализации в желаемый формат выходных данных. В отличие от предыдущих сценариев, это приведет к более значительному снижению производительности.
- При копировании файлов в хранилище данных, не являющееся файловым, или из него (например, из файлового хранилища в реляционное хранилище) потребуется выполнить сериализацию или десериализацию, что значительно снизит производительность.

**Формат файла.** Формат файла может повлиять на производительность копирования. К примеру, Avro — это компактный двоичный формат, в котором хранятся метаданные с данными. Этот формат поддерживает экосистема Hadoop для обработки и выполнения запросов. Однако стоимость формата Avro для сериализации или десериализации выше, а пропускная способность копирования ниже по сравнению с текстовым форматом. Формат файла, который необходимо использовать в процессе обработки, следует выбирать, принимая во внимание все элементы — от формы данных, хранимых в исходных хранилищах данных или извлекаемых из внешних систем, лучшего формата для хранения, аналитической обработки и выполнения запросов до формата, в котором следует экспортировать данные в киоски данных для средств создания отчетов и визуализации данных. Иногда формат файла, который является недостаточно оптимальным для производительности операций чтения и записи, может отлично подойти, учитывая общий аналитический процесс.

## Рекомендации по сжатию
Если входной или выходной набор данных представляет собой файл, можно настроить действие копирования для сжатия или распаковки данных при записи в место назначения. Использование сжатия — это компромисс между количеством операций ввода-вывода и потреблением ЦП, так как для сжатия данных требуются дополнительные вычислительные ресурсы, но взамен уменьшается количество сетевых операций ввода-вывода и используемый объем хранилища. В зависимости от данных это может повысить общую пропускную способность копирования.

**Кодек.** Поддерживаемые типы сжатия: GZIP, BZIP2 и Deflate. Все три типа можно использовать для обработки в Azure HDInsight. Каждый кодек сжатия уникален. Например, кодек BZIP2 обладает минимальной пропускной способностью копирования, но предоставляет лучшую производительность выполнения запросов Hive, если ее можно разделить для обработки. Кодек GZIP — это наиболее оптимальный вариант, который используется чаще всего. Следует выбрать кодек, который лучше всего подходит для комплексного полного сценария.

**Уровень.** Для каждого кодека сжатия можно выбрать один из двух параметров — самое быстрое сжатие или оптимальное сжатие. Если использовать параметр самого быстрого сжатия, данные сжимаются как можно быстрее, даже если итоговый файл сжимается не оптимально. Если использовать параметр оптимального сжатия, данные сжимаются дольше, предоставляя минимальный объем данных. Можно испытать оба варианта, чтобы увидеть, который из них обеспечивает лучшую общую производительность в определенном случае.

**Рекомендация.** При копировании данных большого объема между локальным хранилищем и облаком, где Azure и корпоративная сеть пропускной способности являются ограничивающим фактором и требуется, чтобы входной и выходной наборы данных были в несжатом виде, для сжатия можно использовать **промежуточный большой двоичный объект Azure**. В частности, можно разбить одно действие копирования на два действия: первое действие копирования будет копировать данные из источника в промежуточный большой двоичный объект в сжатом виде, а второе действие копирования будет копировать сжатые данные из этого объекта и распаковывать их во время записи в приемник.

## Рекомендации по сопоставлению столбцов
В действии копирования можно использовать свойство columnMappings для сопоставления всех входных столбцов или их подмножества с выходными столбцами. После считывания данных из источника службе перемещения данных требуется выполнить сопоставление столбцов данных, прежде чем записать их в приемник. Эта дополнительная обработка снижает пропускную способность копирования.

Если исходное хранилище данных поддерживает запросы, например реляционное хранилище (SQL Azure и SQL Server) или хранилище NoSQL (таблицы Azure или Azure DocumentDB), вместо использования сопоставления столбцов для свойства запроса можно применить логику фильтрации или переупорядочивания столбцов. Этот способ намного эффективнее, и при его использовании во время считывания данных из исходного хранилища данных выполняется проекция.

## Рекомендации относительно шлюза управления данными
Рекомендации по настройке шлюза см. в разделе [Особенности использования шлюза управления данными](data-factory-move-data-between-onprem-and-cloud.md#Considerations-for-using-Data-Management-Gateway).

**Среда компьютера шлюза.** Для размещения шлюза управления данными рекомендуется использовать выделенный компьютер. Чтобы проверить использование ЦП, памяти и пропускной способности во время выполнения копирования на компьютере шлюза, используйте такое средство, как PerfMon. Если ЦП, память или пропускная способность сети становится узким местом, следует использовать более мощный компьютер.

**Одновременное выполнение действий копирования.** Один экземпляр шлюза управления данными может обработать несколько запусков действия копирования, т. е. шлюз может выполнять несколько заданий копирования одновременно (для вычисления количества одновременно выполняемых заданий используется конфигурация оборудования компьютера шлюза). Дополнительные задания копирования находятся в очереди, пока их не выберет шлюз или пока не истечет время ожидания выполнения задания (в зависимости от того, что произойдет раньше). Чтобы избежать состязания ресурсов в шлюзе, можно составить график выполнения действий таким образом, чтобы уменьшить количество поставленных в очередь заданий копирования, или разделить нагрузку между несколькими шлюзами.


## Дополнительные рекомендации
Если размер данных для копирования достаточно большой, можно настроить бизнес-логику для дальнейшего секционирования данных с помощью механизма создания срезов фабрики данных Azure и запланировать более частое выполнение действия копирования, чтобы уменьшить размер данных для каждого действия копирования.

Необходимо следить за количеством наборов данных и действий копирования, которые попадают в одно и то же хранилище данных в любой момент времени. Большое количество одновременно выполняемых заданий копирования может привести к регулированию хранилища данных, что ведет к ухудшению производительности, внутренним повторным попыткам выполнения действия копирования и в некоторых случаях к сбоям выполнения.

## Пример использования. Копирование из локального SQL Server в большой двоичный объект Azure
**Сценарий.** Конвейер предназначен для копирования данных из локального SQL Server в большой двоичный объект Azure в формате CSV. Для ускорения копирования необходимо сжать CSV-файлы в формат BZIP2.

**Тестирование и анализ.** Отмечено, что пропускная способность действия копирования составляет меньше 2 МБ/с, что гораздо меньше, чем в тесте производительности.

**Анализ и настройка производительности.** Чтобы устранить проблемы производительности, сначала необходимо подробно рассмотреть процесс обработки и перемещения данных.

1.	**Чтение данных.** Шлюз устанавливает подключение с SQL Server и отправляет запрос. SQL Server отвечает, отправляя поток данных в шлюз через интрасеть.
2.	Шлюз **сериализует** поток данных в формат CSV и **сжимает** данные в поток BZIP2.
3.	**Запись данных.** Шлюз отправляет поток BZIP2 в большой двоичный объект Azure через Интернет.

Как видите, обработка и перемещение данных происходит в последовательном режиме потоковой передачи: SQL Server -> локальная сеть -> шлюз -> глобальная сеть -> большой двоичный объект Azure. **Общая производительность достигается при минимальной пропускной способности в конвейере**.

![поток данных](./media/data-factory-copy-activity-performance/case-study-pic-1.png)

Один или несколько следующих факторов могут быть узким местом производительности.

1.	**Источник.** SQL Server отличается низкой пропускной способностью из-за высокой нагрузки.
2.	**Шлюз управления данными.**
	1.	**Локальная сеть.** Шлюз находится далеко от SQL Server, а для подключения наблюдается низкая пропускная способность.
	2.	Выполнение следующих действий приводит к достижению ограничений **нагрузки на компьютере шлюза**:
		1.	**сериализация** — сериализация потока данных в формат CSV характеризуется низкой пропускной способностью;
		2.	**сжатие** — выбран кодек медленного сжатия (например, BZIP2 со скоростью 2,8 МБ/с и процессором Core i7).
	3.	**Глобальная сеть.** Низкая пропускная способность между корпоративной сетью и Azure (например, T1 — 1544 Кбит/с, T2 — 6312 Кбит/с).
4.	**Приемник.** Большой двоичный объект Azure характеризуется низкой пропускной способностью (хотя это маловероятно, потому что соглашение об уровне обслуживания гарантирует не менее 60 МБ/с).

В этом случае сжатие данных в формат BZIP2 может замедлять работу всего конвейера. Этого можно избежать, если перейти на использование кодека сжатия в формат GZIP.

## Приложение. Справочные материалы по настройке производительности хранилища данных
Ниже приведены некоторые справочные материалы по мониторингу и настройке производительности для нескольких поддерживаемых хранилищ данных.

- Служба хранилища Azure (включая хранилища Blob-объектов Azure и таблиц Azure): [Целевые показатели масштабируемости службы хранилища](../storage/storage-scalability-targets.md) и [Контрольный список производительности и масштабируемости хранилища Azure](../storage//storage-performance-checklist.md).
- База данных SQL Azure: вы можете [наблюдать за производительностью](../sql-database/sql-database-service-tiers.md#monitoring-performance) и проверять процент использования единиц транзакций базы данных (DTU).
- Хранилище данных SQL Azure: его возможности измеряются в единицах использования хранилища данных (DWU). См. статью [Эластичная производительность и масштабирование в хранилище данных SQL](../sql-data-warehouse/sql-data-warehouse-performance-scale.md).
- Azure DocumentDB: [Уровень производительности в DocumentDB](../documentdb/documentdb-performance-levels.md).
- Локальный SQL Server: [Мониторинг и настройка производительности](https://msdn.microsoft.com/library/ms189081.aspx).
- Локальный файловый сервер: [Настройка производительности для файловых серверов](https://msdn.microsoft.com/library/dn567661.aspx).

<!---HONumber=AcomDC_0309_2016-->