<properties
	pageTitle="Руководство по настройке производительности действия копирования | Microsoft Azure"
	description="Узнайте о ключевых факторах, которые влияют на производительность перемещения данных в фабрике данных Azure с использованием действия копирования."
	services="data-factory"
	documentationCenter=""
	authors="spelluru"
	manager="jhubbard"
	editor="monicar"/>

<tags
	ms.service="data-factory"
	ms.workload="data-services"
	ms.tgt_pltfrm="na"
	ms.devlang="na"
	ms.topic="article"
	ms.date="06/03/2016"
	ms.author="spelluru"/>


# Руководство по настройке производительности действия копирования
В этой статье описываются ключевые факторы, которые влияют на производительность перемещения данных (с помощью действия копирования) в фабрике данных Azure. В ней также приведены сведения о производительности, наблюдаемой во время внутреннего тестирования, и рассматриваются различные способы оптимизировать производительность действия копирования.

С помощью действия копирования вы можете достичь высокой пропускной способности при перемещении данных, как показано в следующих примерах.

- Прием 1 ТБ данных в хранилище BLOB-объектов Azure из локальной файловой системы и хранилища BLOB-объектов Azure менее чем за 3 часа (т. е. со скоростью 100 Мбит/с).
- Прием 1 ТБ данных в хранилище озера данных Azure из локальной файловой системы и хранилища BLOB-объектов Azure менее чем за 3 часа (т. е. со скоростью 100 Мбит/с).
- Прием 1 ТБ данных в хранилище данных SQL Azure из хранилища BLOB-объектов Azure менее чем за 3 часа (т. е. со скоростью 100 Мбит/с).

Ознакомьтесь со следующими разделами, чтобы узнать больше о производительности действия копирования и изучить рекомендации по настройке для ее повышения.

> [AZURE.NOTE] Если вам в целом не знакомо действие копирования, перед чтением этой статьи ознакомьтесь с разделом [Действия перемещения данных](data-factory-data-movement-activities.md).

## Этапы настройки производительности
Ниже приведены этапы настройки производительности решения фабрики данных Azure с использованием действия копирования.

1.	**Определение исходной конфигурации.** Протестируйте конвейер на этапе разработки с помощью действия копирования на примере репрезентативных данных. Чтобы ограничить объем данных для тестирования, можно использовать [модель среза](data-factory-scheduling-and-execution.md#time-series-datasets-and-data-slices) фабрики данных Azure.

	Собирайте данные о времени выполнения и характеристиках производительности с помощью **приложения по мониторингу и управлению**: щелкните элемент **Мониторинг и управление** на домашней странице фабрики данных, выберите **выходной набор данных** в представлении в виде дерева, а затем из списка **окон действий** выберите выполнение действия копирования. Вы должны увидеть длительность действия копирования в списке **окон действий**, а также размер данных, которые копируются, и пропускную способность в окне **обозревателя окон действий** справа. Чтобы узнать больше об этом приложении, ознакомьтесь с разделом [Мониторинг конвейеров фабрики данных Azure и управление ими с помощью нового приложения по мониторингу и управлению](data-factory-monitor-manage-app.md).
	
	![Сведения о цикле выполнения действия](./media/data-factory-copy-activity-performance/mmapp-activity-run-details.png)

	Вы можете сравнить показатели производительности и конфигурацию вашего сценария с приведенными ниже [базовыми показателями производительности](#performance-reference) действия копирования, которые основаны на внутренних наблюдениях.
2. **Диагностика и оптимизация производительности.** Если наблюдаемая производительность не соответствует вашим ожиданиям, необходимо определить узкие места и выполнить оптимизацию, чтобы устранить их или уменьшить их влияние. В этой статье не приведено полное описание диагностики производительности. Однако здесь перечислены некоторые общие рекомендации.
	- [Источник](#considerations-on-source)
	- [Приемник](#considerations-on-sink)
	- [Сериализация и десериализация](#considerations-on-serializationdeserialization)
	- [Сжатие](#considerations-on-compression)
	- [Сопоставление столбцов](#considerations-on-column-mapping)
	- [Шлюз управления данными](#considerations-on-data-management-gateway)
	- [Дополнительные рекомендации](#other-considerations)
	- [Параллельное копирование](#parallel-copy)
	- [Облачные единицы перемещения данных](#cloud-data-movement-units)

3. **Задание конфигурации для работы со всеми данными.** Если вас устраивают результаты выполнения и производительность, можно задать определение набора данных и активный период конвейера для всех данных.

## Базовые показатели производительности
> [AZURE.IMPORTANT] **Отказ от ответственности.** Приведенные ниже данные опубликованы исключительно с целью предоставления рекомендаций и помощи в общем процессе планирования. Предполагается использование лучших в своем классе пропускной способности, оборудования, конфигурации и т. д. Используйте эти сведения только в качестве справочных материалов. Пропускная способность перемещения данных зависит от диапазона переменных. Дополнительные сведения о способах настройки и достижения более высокой производительности в соответствии с потребностями перемещения данных см. в разделах ниже. Эти данные будут обновлены после добавления усовершенствований и новых функциональных возможностей для повышения производительности.

![Матрица производительности](./media/data-factory-copy-activity-performance/CopyPerfRef.png)

Примечания:

- Для вычисления пропускной способности используется следующая формула: [размер данных, считанных из источника]/[длительность выполнения действия копирования].
- Для вычисления указанных выше показателей использовался набор данных [TPC-H](http://www.tpc.org/tpch/).
- При использовании хранилищ данных Microsoft Azure источник и приемник находились в одном регионе Azure.
- **cloudDataMovementUnits** имеет значение 1, а **parallelCopies** не указан.
- В случае гибридного перемещения данных (из локальной среды в облако или наоборот) шлюз управления данными (один экземпляр) размещался не на том компьютере, где находилось локальное хранилище данных. При этом использовалась указанная ниже конфигурация. Обратите внимание, что если в шлюзе выполняется одно действие, во время выполнения действия копирования ресурсы ЦП и памяти, а также сетевая пропускная способность компьютера задействуются в незначительной степени.
	<table>
	<tr>
		<td>ЦП</td>
		<td>32&#160;ядра, 2,20&#160;ГГц, Intel Xeon® E5-2660 v2</td>
	</tr>
	<tr>
		<td>Память</td>
		<td>128&#160;ГБ</td>
	</tr>
	<tr>
		<td>Сеть</td>
		<td>Веб-интерфейс: 10&#160;Гбит/с, интерфейс интрасети: 40&#160;Гбит/с</td>
	</tr>
	</table>

## Параллельное копирование
Один из способов повысить пропускную способность операции копирования и сократить время переноса данных — считывать данные из источника и (или) записывать их в место назначения **параллельно с действием копирования**.
 
Обратите внимание, что этот параметр отличается от **concurrency** свойства в определении действия. Свойство concurrency определяет число **одновременных действий копирования**, которые работают вместе во время выполнения для обработки данных из других окон действий (01:00–02:00, 02:00–03:00, 03:00–04:00 и т. д.). Это весьма полезно в случаях значительной загрузки. В то время как возможность параллельного копирования, рассматриваемая здесь, относится к **выполнению одного действия**.

Рассмотрим **пример сценария**: представим себе ситуацию, в которой требуется обработать несколько срезов, полученных в прошлом. Служба фабрики данных запускает экземпляр действия копирования (выполнение действия) для каждого среза.

- Срез данных из 1-го окна действий (01:00–02:00) == > выполнение действия 1.
- Срез данных из 2-го окна действий (02:00–03:00) == > выполнение действия 2.
- Срез данных из 3-го окна действий (03:00–04:00) == > выполнение действия 3.
- и т. д.

Значение **2** параметра **concurrency** в этом примере позволяет **выполнению действия 1** и **выполнению действия 2** копировать данные из двух окон действий **одновременно**, что повышает производительность перемещения данных. Тем не менее, если с действием 1 связано несколько файлов, одновременно из источника в место назначения копируется один файл.

### parallelCopies
Можно использовать свойство **parallelCopies**, чтобы задать параллелизм для действия копирования. Проще говоря, считайте это свойство максимальным числом потоков в рамках действия копирования, которые параллельно считывают данные из источника и (или) записывают их в хранилища данных-приемники.

Для каждого выполнения действия копирования фабрика данных Azure интеллектуально определяет количество параллельных копий для копирования данных из исходного хранилища данных в целевое хранилище данных. Количество параллельных копий, которое используется по умолчанию, зависит от типов источника и приемника.

Источник и приемник |	Число параллельных копий по умолчанию, определенное службой
------------- | -------------------------------------------------
Копирование данных между **файловыми хранилищами** (хранилище BLOB-объектов Azure, хранилище озера данных Azure, локальная файловая система, локальная среда HDFS) | Примерно от **1 до 32**, в зависимости от **размера файлов** и **числа облачных единиц перемещения данных** (см. определение в следующем разделе), используемых для копирования данных между двумя облачными хранилищами данных или в пределах физической конфигурации компьютера шлюза, используемой для гибридного копирования (копирования данных из локального хранилища данных и в него).
Копирование данных из **любого хранилища данных в таблицу Azure** | 4\.
Все прочие сочетания источника и приемника | 1

Для большинства случаев режим по умолчанию должен обеспечить оптимальную пропускную способность. Тем не менее значение по умолчанию можно переопределить, указав значение свойства **parallelCopies**, чтобы управлять нагрузкой на компьютеры в хранилище данных или настроить производительность копирования. Значение должно быть от **1 до 32 (включая оба числа)**. Во время выполнения действие копирования выберет значение, которое меньше или равно заданному значению, чтобы обеспечить оптимальную производительность.

	"activities":[  
	    {
	        "name": "Sample copy activity",
	        "description": "",
	        "type": "Copy",
	        "inputs": [{ "name": "InputDataset" }],
	        "outputs": [{ "name": "OutputDataset" }],
	        "typeProperties": {
	            "source": {
	                "type": "BlobSource",
	            },
	            "sink": {
	                "type": "AzureDataLakeStoreSink"
	            },
	            "parallelCopies": 8
	        }
	    }
	]

Обратите внимание на следующее.

- Для копирования данных между файловыми хранилищами параллелизм осуществляется на уровне файла. Другими словами, нет фрагментирования в пределах файла. Фактическое число параллельных копий, используемых для копирования во время выполнения, не будет превышать количество файлов. Если режим копирования — mergeFile, то параллелизм не будет использоваться.
- При указании значения свойства parallelCopies учтите увеличение нагрузки на хранилище данных источника и приемника, которое оно повлечет, а также на шлюз, если это гибридное копирование, особенно при наличии нескольких действий или параллельных выполнений одного действия с одним и тем же хранилищем данных. Если вы заметите, что хранилище данных или шлюз перегружены, уменьшите значение parallelCopies, чтобы снизить загрузку.
- При копировании данных из не файловых хранилищ в файловые хранилища свойство parallelCopies игнорируется, даже если указано, и параллелизм не будет использоваться.

> [AZURE.NOTE] Чтобы воспользоваться преимуществами функции parallelCopies при гибридном копировании, необходимо использовать шлюз управления данными версии не ниже 1.11.

### Облачные единицы перемещения данных
**Облачная единица перемещения данных** — это мера, представляющая производительность (сочетание выделенных ресурсов ЦП, памяти и сети) одной единицы в службе фабрики данных Azure, которая используется для операции копирования из облака в облако. Она не имеет отношения к гибридному копированию. По умолчанию служба фабрики данных Azure использует одну облачную единицу перемещения данных для одного выполнения действия копирования. Это значение по умолчанию можно переопределить, указав значение для свойства **cloudDataMovementUnits**. В настоящее время параметр cloudDataMovementUnits **поддерживается только** при копировании данных **между двумя хранилищами BLOB-объектов Azure** или из **хранилища BLOB-объектов Azure в хранилище озера данных Azure**, и он вступает в действие при наличии нескольких файлов для копирования, имеющих размер не меньше 16 МБ каждый.

При копировании нескольких относительно больших файлов задание слишком большого значения для свойства **parallelCopies** может не повысить производительность из-за ограничения ресурсов одной облачной единицы перемещения данных. В таких случаях можно использовать больше облачных единиц перемещения данных для копирования большого объема данных с высокой пропускной способностью. Чтобы указать число облачных единиц перемещения данных для действия копирования, задайте значение свойства **cloudDataMovementUnits**, как показано ниже.

	"activities":[  
	    {
	        "name": "Sample copy activity",
	        "description": "",
	        "type": "Copy",
	        "inputs": [{ "name": "InputDataset" }],
	        "outputs": [{ "name": "OutputDataset" }],
	        "typeProperties": {
	            "source": {
	                "type": "BlobSource",
	            },
	            "sink": {
	                "type": "AzureDataLakeStoreSink"
	            },
	            "cloudDataMovementUnits": 4
	        }
	    }
	]

**Допустимые значения** свойства cloudDataMovementUnits: 1 (по умолчанию), 2, 4 и 8. Если вам требуется больше облачных единиц перемещения данных, чтобы повысить пропускную способность, обратитесь в [службу поддержки Azure](https://azure.microsoft.com/blog/2014/06/04/azure-limits-quotas-increase-requests/). **Фактическое число облачных единиц перемещения данных**, используемых во время выполнения операции копирования, будет меньше или равно заданному значению, в зависимости от числа файлов, которые должны быть скопированы из источника, удовлетворяющих критериям размера.

> [AZURE.NOTE] Значение parallelCopies должно быть больше или равно значению cloudDataMovementUnits, если оно задано. И если значение cloudDataMovementUnits больше 1, то параллельное перемещение данных распределяется на cloudDataMovementUnits единиц для данного действия копирования, что повышает пропускную способность.

В случае копирования нескольких больших файлов при **cloudDataMovementUnits**, равном 2, 4 и 8, может быть достигнуто 2-, 4- и 7-кратное повышение производительности, соответственно, относительно базовых значений, перечисленных в разделе "Базовые показатели производительности".

Ознакомьтесь с приведенными [примерами использования](#case-study---parallel-copy), чтобы эффективнее использовать рассмотренные выше два свойства и повысить пропускную способность перемещения данных.
 
**Важно** помнить, что оплата будет взиматься на основе общего времени операции копирования. Следовательно, если задание копирования обычно занимало 1 час с 1 облачной единицей, а теперь на это требуется 15 минут с 4 облачными единицами, то общий счет практически не изменится. Рассмотрим другую ситуацию: предположим, вы используете 4 облачные единицы, первая единица работает 10 минут, вторая — 10 минут, третья — 5 минут, четвертая — 5 минут при выполнении действия копирования. Вы будете оплачивать общее время копирования (перемещение данных), которое составит 10+10+5+5=30 минут. Использование **parallelCopies** не влияет на выставление счетов.

## Промежуточное копирование
При копировании данных из источника в приемник можно использовать хранилище BLOB-объектов Azure в качестве промежуточного пространства для хранения. Это очень удобно в следующих ситуациях.

1.	**Иногда для гибридного переноса данных (т. е. для перемещения данных из локального хранилища в облако и наоборот) требуется некоторое время из-за низкой скорости сетевого подключения.** Чтобы передача в промежуточное хранилище занимала меньше времени, можно сжать данные в локальном хранилище. Затем данные в промежуточном хранилище распаковываются и загружаются в целевое расположение.
2.	**В соответствии с политиками ИТ в брандмауэре не рекомендуется открывать порты, отличные от 80 и 443.** Например, при копировании данных из локального хранилища в приемник базы данных SQL Azure или приемник хранилища данных SQL Azure необходимо включить исходящие TCP-подключения через порт 1433 для брандмауэра Windows и корпоративного брандмауэра. В такой ситуации можно использовать шлюз управления данными и сначала скопировать данные в промежуточное хранилище BLOB-объектов Azure через HTTP(S), т. е. через порт 443, а уже оттуда загрузить их в базу данных SQL или хранилище данных SQL. Для этого не нужно включать порт 1433.
3.	**Прием данных из различных расположений в хранилище SQL Azure с помощью PolyBase.** Хранилище данных SQL Azure предоставляет функцию PolyBase, которая обеспечивает высокую пропускную способность при загрузке больших объемов данных в хранилище SQL. Но для этого исходные данные должны находиться в хранилище BLOB-объектов Azure и удовлетворять некоторым дополнительным условиям. При загрузке данных из хранилищ, отличных от хранилища BLOB-объектов Azure, можно включить копирование данных в промежуточное хранилище BLOB-объектов Azure. В таком случае в фабрике данных Azure данные будут преобразованы и приведены в соответствие с требованиями PolyBase. Затем PolyBase используется для загрузки данных в хранилище SQL. Дополнительные сведения и примеры см. в разделе [Use PolyBase to load data into Azure SQL Data Warehouse](data-factory-azure-sql-data-warehouse-connector.md#use-polybase-to-load-data-into-azure-sql-data-warehouse) (Загрузка данных в хранилище данных SQL Azure с помощью PolyBase).

### Принцип промежуточного копирования
При включении этой функции данные сначала копируются из исходного хранилища в промежуточное (ваше собственное), а оттуда переносятся в приемник. Фабрика данных Azure автоматически управляет двумя этапами процесса и удаляет временные данные из промежуточного хранилища после переноса.

В **случае облачного копирования**, когда источник и приемник данных размещены в облаке, а шлюз управления данными не используется, операции копирования выполняются **службой фабрики данных Azure**.

![Промежуточное копирование — облачный сценарий](media/data-factory-copy-activity-performance/staged-copy-cloud-scenario.png)

В **случае гибридного копирования**, когда источник является локальным, а приемник размещен в облаке, данные из источника переносятся в промежуточное хранилище при помощи **шлюза управления данными**, а оттуда загружаются в приемник **службой фабрики данных Azure**. Копирование данных из облачного хранилища в локальное с использованием промежуточного хранилища также поддерживается при обратном потоке.

![Промежуточное копирование — гибридный сценарий](media/data-factory-copy-activity-performance/staged-copy-hybrid-scenario.png)

При включении функции промежуточного копирования перемещаемых данных можно настроить их сжатие перед переносом из источника в промежуточное хранилище, а также распаковку перед перемещением из промежуточного хранилища в приемник.

При копировании данных между двумя локальными хранилищами функция промежуточного хранилища пока не поддерживается. Но вскоре эта возможность будет реализована.

### Конфигурация
С помощью параметра **enableStaging** в разделе действий копирования можно указать, следует ли копировать данные в промежуточное хранилище BLOB-объектов Azure перед загрузкой в целевое хранилище. Если для параметра enableStaging задано значение true, необходимо указать дополнительные свойства, перечисленные в таблице ниже. Кроме того, необходимо создать связанную промежуточную службу хранилища Azure или хранилища Azure SAS, если такая служба еще не создана.

Свойство | Описание | Значение по умолчанию | Обязательно
--------- | ----------- | ------------ | --------
enableStaging | Укажите, следует ли копировать данные в промежуточное хранилище. | Ложь | Нет
linkedServiceName (имя связанной службы) | Укажите имя связанной службы [AzureStorage](data-factory-azure-blob-connector.md#azure-storage-linked-service) или [AzureStorageSas](data-factory-azure-blob-connector.md#azure-storage-sas-linked-service), которая будет ссылаться на используемое в качестве промежуточного хранилище Azure. <br/><br/> Обратите внимание, что хранилище Azure с SAS (подписанным URL-адресом) нельзя использовать для загрузки данных в хранилище SQL Azure с помощью PolyBase. Его можно использовать в других случаях. | Недоступно | Да, если для параметра enableStaging задано значение true. 
path | Укажите путь к хранилищу BLOB-объектов, в которое будут помещены промежуточные данные. В противном случае служба создаст контейнер для хранения временных данных. <br/><br/> Путь необходимо указывать, только если используется хранилище Azure с SAS или расположение временных данных ограничено строгими требованиями. | Недоступно | Нет
enableCompression | Укажите, следует ли сжимать данные при переносе из источника в приемник, чтобы уменьшить их объем при передаче по сети. | Ложь | Нет

Ниже приведен пример определения действия копирования с указанными выше свойствами.

	"activities":[  
	{
		"name": "Sample copy activity",
		"type": "Copy",
		"inputs": [{ "name": "OnpremisesSQLServerInput" }],
		"outputs": [{ "name": "AzureSQLDBOutput" }],
		"typeProperties": {
			"source": {
				"type": "SqlSource",
			},
			"sink": {
				"type": "SqlSink"
			},
	    	"enableStaging": true,
			"stagingSettings": {
				"linkedServiceName": "MyStagingBlob",
				"path": "stagingcontainer/path",
				"enableCompression": true
			}
		}
	}
	]


### Принцип выставления счетов
Обратите внимание, что счет будет выставляться на основе двух факторов: длительности и типа копирования.

- При использовании промежуточного хранилища для облачного копирования (копирование данных между облачными хранилищами, например из озера данных Azure в хранилище данных SQL Azure) счет формируется так: [сумма длительности копирования для этапов 1 и 2] x [цена за единицу облачного копирования].
- При использовании промежуточного хранилища для гибридного копирования (копирование данных из локального хранилища в облако, например из локальной базы данных SQL Server в хранилище данных SQL Azure) счет формируется так: [длительность гибридного копирования] x [цена за единицу гибридного копирования] + [длительность облачного копирования] x [цена за единицу облачного копирования].


## Рекомендации относительно источника
### Общие сведения
Убедитесь, что базовое хранилище данных не переполнено другими рабочими нагрузками, выполняемыми в нем или при его задействовании, включая, помимо прочего, действие копирования.

Дополнительные сведения о хранилищах данных Microsoft см. в [разделах мониторинга и настройки](#appendix-data-store-performance-tuning-reference) для конкретных типов хранилищ данных. В них подробно рассмотрены базовые показатели производительности хранилища данных, способы сокращения времени отклика и повышения пропускной способности.

При копировании данных из **хранилища BLOB-объектов Azure** в **хранилище данных SQL Azure** рекомендуется включить **PolyBase** для повышения производительности. Дополнительные сведения см. в разделе [Use PolyBase to load data into Azure SQL Data Warehouse](data-factory-azure-sql-data-warehouse-connector.md###use-polybase-to-load-data-into-azure-sql-data-warehouse) (Загрузка данных в хранилище данных SQL Azure с помощью PolyBase).


### Файловые хранилища данных
*(Большой двоичный объект Azure, озеро данных Azure, локальная файловая система.)*

- **Средний размер файла и их количество**. Действие копирования передает данные в пофайловом режиме. При одинаковом объеме данных общая пропускная способность перемещения данных, которые состоят из большого количества небольших файлов, будет ниже, чем в случае перемещения данных, которые состоят из небольшого количества файлов большего размера. Это происходит из-за времени начальной загрузки каждого файла. Поэтому для получения более высокой пропускной способности по возможности следует объединить небольшие файлы в файлы большего размера.
- **Формат файла и сжатие**. Дополнительные сведения о способах повышения производительности см. в разделах [Рекомендации по сериализации и десериализации](#considerations-on-serializationdeserialization) и [Рекомендации по сжатию](#considerations-on-compression).
- Дополнительные сведения о сценарии с использованием **локальной файловой системы**, в котором применяется **шлюз управления данными**, см. в разделе [Рекомендации относительно шлюза](#considerations-on-data-management-gateway).

### Реляционные хранилища данных
*(База данных SQL Azure, хранилище данных SQL Azure, база данных SQL Server, Oracle, MySQL, DB2, Teradata, Sybase и PostgreSQL.)*

- **Шаблон данных**. Схема таблицы влияет на пропускную способность копирования. Во время копирования данных одинакового объема использование строк большого размера позволяет добиться лучшей производительности, чем при использовании строк небольшого размера. Это связано с тем, что база данных более эффективно извлекает меньшее количество пакетов данных с меньшим количеством строк.
- **Запрос или хранимая процедура**. Оптимизируйте логику запроса или хранимой процедуры, указываемую в источнике действия копирования, чтобы более эффективно извлекать данные.
- Дополнительные сведения о **локальных реляционных базах данных**, таких как SQL Server и Oracle, где требуется **шлюз управления данными**, см. в разделе [Рекомендации относительно шлюза](#considerations-on-data-management-gateway).

## Рекомендации относительно приемника

### Общие сведения
Убедитесь, что базовое хранилище данных не переполнено другими рабочими нагрузками, выполняемыми в нем или при его задействовании, включая, помимо прочего, действие копирования.

Дополнительные сведения о хранилищах данных Microsoft см. в [разделах мониторинга и настройки](#appendix-data-store-performance-tuning-reference) для конкретных типов хранилищ данных. В них подробно рассмотрены базовые показатели производительности хранилища данных, способы сокращения времени отклика и повышения пропускной способности.

При копировании данных из **хранилища BLOB-объектов Azure** в **хранилище данных SQL Azure** рекомендуется включить **PolyBase** для повышения производительности. Дополнительные сведения см. в разделе [Use PolyBase to load data into Azure SQL Data Warehouse](data-factory-azure-sql-data-warehouse-connector.md###use-polybase-to-load-data-into-azure-sql-data-warehouse) (Загрузка данных в хранилище данных SQL Azure с помощью PolyBase).


### Файловые хранилища данных
*(Большой двоичный объект Azure, озеро данных Azure, локальная файловая система.)*

- **Поведение копирования**. При копировании данных из другого файлового хранилища данных действие копирования предусматривает три вида поведения, которые можно задать с помощью свойства copyBehavior: сохранение иерархии, преобразование в плоскую структуру и объединение файлов. Сохранение иерархии или преобразование в плоскую структуру практически не оказывает влияния на производительность, в то время как объединение файлов существенно ее ухудшает.
- **Формат файла и сжатие**. Дополнительные сведения о способах повышения производительности см. в разделах [Рекомендации по сериализации и десериализации](#considerations-on-serializationdeserialization) и [Рекомендации по сжатию](#considerations-on-compression).
- Что касается **больших двоичных объектов Azure**, в настоящее время оптимизация передачи данных и пропускной способности поддерживается только для блочных BLOB-объектов.
- Дополнительные сведения о сценарии с использованием **локальной файловой системы**, в котором применяется **шлюз управления данными**, см. в разделе [Рекомендации относительно шлюза](#considerations-on-data-management-gateway).

### Реляционные хранилища данных
*(База данных SQL Azure, хранилище данных SQL Azure, база данных SQL Server.)*

- **Поведение копирования**. В зависимости от свойств, настроенных для параметра sqlSink, существует несколько вариантов записи данных в базу данных назначения при выполнении действия копирования:
	- По умолчанию служба перемещения данных использует интерфейс API массового копирования для вставки данных в режиме добавления, что обеспечивает лучшую производительность.
	- Если настроить хранимую процедуру в приемнике, вместо массовой загрузки данные будут загружаться в базу данных построчно, что приведет к значительному снижению производительности. В случае с данными большого размера рекомендуется использовать свойство sqlWriterCleanupScript (см. ниже), если это применимо.
	- Если настроить свойство sqlWriterCleanupScript, при каждом действии копирования для вставки данных служба сначала запустит сценарий, а затем использует интерфейс API массового копирования. Например, чтобы перезаписать всю таблицу последними данными, перед массовой загрузкой новых данных из источника можно указать сценарий для удаления всех записей.
- **Шаблон данных и размер пакета**.
	- Схема таблицы влияет на пропускную способность копирования. Во время копирования данных одинакового объема использование строк большого размера позволяет добиться лучшей производительности, чем при использовании строк небольшого размера. Это связано с тем, что база данных более эффективно сохраняет меньшее количество пакетов данных.
	- Действие копирования вставляет данные в виде последовательности пакетов, где количество строк в пакете можно задать с помощью свойства writeBatchSize. Если данные содержатся в строках небольшого размера, можно задать для свойства writeBatchSize более высокое значение, чтобы использовать меньшее количество пакетов и тем самым увеличить пропускную способность. Следует с осторожностью увеличивать значение свойства writeBatchSize при большом размере строк данных, так как большое значение может привести к ошибке копирования из-за перегрузки базы данных.
- Дополнительные сведения о **локальных реляционных базах данных**, таких как SQL Server и Oracle, где требуется **шлюз управления данными**, см. в разделе [Рекомендации относительно шлюза](#considerations-on-data-management-gateway).


### Хранилища NoSQL
*(Таблица Azure и Azure DocumentDB.)*

- Для **таблицы SQL Azure**:
	- **Секционирование**. Запись данных в секции с чередованием значительно снижает производительность. Можно сортировать исходные данные по ключу секции, чтобы эффективно вставлять данные секция за секцией. Можно также настроить логику для записи данных в одну секцию.
- Для **Azure DocumentDB**:
	- **Размер пакета**. Свойство writeBatchSize указывает количество параллельных запросов на создание документов в службе DocumentDB. Если увеличить значение свойства writeBatchSize, то производительность повышается, потому что в DocumentDB начинает уходить больше параллельных запросов. Однако имейте в виду вероятность регулирования во время записи в DocumentDB (сообщение об ошибке: "Слишком большая частота запросов"). Регулирование может произойти по ряду причин, включая размер документов, количество терминов в документах и политику индексации целевой коллекции. Чтобы добиться более высокой пропускной способности копирования, рекомендуется использовать лучшую коллекцию (например, S3).

## Рекомендации по сериализации и десериализации
Сериализация и десериализация может произойти, если входной набор данных или выходной набор данных представляет собой файл. В настоящее время действие копирования поддерживает формат данных Avro и текстовый формат данных (например, CSV и TSV).

**Поведение копирования.**

- При копировании файлов между файловыми хранилищами данных:
	- Если параметры формата файла входного и выходного наборов данных одинаковые, служба перемещения данных выполнит двоичное копирование без сериализации или десериализации. Поэтому в этом сценарии наблюдается лучшая пропускная способность, по сравнению со сценарием, где параметры формата файла источника или приемника разные.
	- Если входной и выходной наборы данных находятся в текстовом формате и отличаются только типом кодирования, служба перемещения данных выполнит только преобразование кодирования без сериализации и десериализации. По сравнению с двоичным копированием, это совсем незначительно повлияет на производительность.
	- Если входной и выходной наборы данных находятся в разных форматах файлов или имеют разные конфигурации, например отличаются разделителями, служба перемещения данных десериализирует исходные данные для потоковой передачи, преобразования и сериализации в желаемый формат выходных данных. В отличие от предыдущих сценариев, это приведет к более значительному снижению производительности.
- При копировании файлов в хранилище данных, не являющееся файловым, или из него (например, из файлового хранилища в реляционное хранилище) потребуется выполнить сериализацию или десериализацию, что значительно снизит производительность.

**Формат файла.** Формат файла может повлиять на производительность копирования. К примеру, Avro — это компактный двоичный формат, в котором хранятся метаданные с данными. Этот формат поддерживает экосистема Hadoop для обработки и выполнения запросов. Однако стоимость формата Avro для сериализации или десериализации выше, а пропускная способность копирования ниже по сравнению с текстовым форматом. Формат файла, который необходимо использовать в процессе обработки, следует выбирать, принимая во внимание все элементы — от формы данных, хранимых в исходных хранилищах данных или извлекаемых из внешних систем, лучшего формата для хранения, аналитической обработки и выполнения запросов до формата, в котором следует экспортировать данные в киоски данных для средств создания отчетов и визуализации данных. Иногда формат файла, который является недостаточно оптимальным для производительности операций чтения и записи, может отлично подойти, учитывая общий аналитический процесс.

## Рекомендации по сжатию
Если входной или выходной набор данных представляет собой файл, можно настроить действие копирования для сжатия или распаковки данных при записи в место назначения. Использование сжатия — это компромисс между количеством операций ввода-вывода и потреблением ЦП, так как для сжатия данных требуются дополнительные вычислительные ресурсы, но взамен уменьшается количество сетевых операций ввода-вывода и используемый объем хранилища. В зависимости от данных это может повысить общую пропускную способность копирования.

**Кодек.** Поддерживаемые типы сжатия: GZIP, BZIP2 и Deflate. Все три типа можно использовать для обработки в Azure HDInsight. Каждый кодек сжатия уникален. Например, кодек BZIP2 обладает минимальной пропускной способностью копирования, но предоставляет лучшую производительность выполнения запросов Hive, если ее можно разделить для обработки. Кодек GZIP — это наиболее оптимальный вариант, который используется чаще всего. Следует выбрать кодек, который лучше всего подходит для комплексного полного сценария.

**Уровень.** Для каждого кодека сжатия можно выбрать один из двух параметров — самое быстрое сжатие или оптимальное сжатие. Если использовать параметр самого быстрого сжатия, данные сжимаются как можно быстрее, даже если итоговый файл сжимается не оптимально. Если использовать параметр оптимального сжатия, данные сжимаются дольше, предоставляя минимальный объем данных. Можно испытать оба варианта, чтобы увидеть, который из них обеспечивает лучшую общую производительность в определенном случае.

**Рекомендация.** При копировании данных большого объема между локальным хранилищем и облаком, где Azure и корпоративная сеть пропускной способности являются ограничивающим фактором и требуется, чтобы входной и выходной наборы данных были в несжатом виде, для сжатия можно использовать **промежуточный большой двоичный объект Azure**. В частности, можно разбить одно действие копирования на два действия: первое действие копирования будет копировать данные из источника в промежуточный большой двоичный объект в сжатом виде, а второе действие копирования будет копировать сжатые данные из этого объекта и распаковывать их во время записи в приемник.

## Рекомендации по сопоставлению столбцов
В действии копирования можно использовать свойство columnMappings для сопоставления всех входных столбцов или их подмножества с выходными столбцами. После считывания данных из источника службе перемещения данных требуется выполнить сопоставление столбцов данных, прежде чем записать их в приемник. Эта дополнительная обработка снижает пропускную способность копирования.

Если исходное хранилище данных поддерживает запросы, например реляционное хранилище (SQL Azure и SQL Server) или хранилище NoSQL (таблицы Azure или Azure DocumentDB), вместо использования сопоставления столбцов для свойства запроса можно применить логику фильтрации или переупорядочивания столбцов. Этот способ намного эффективнее, и при его использовании во время считывания данных из исходного хранилища данных выполняется проекция.

## Рекомендации относительно шлюза управления данными
Рекомендации по настройке шлюза см. в разделе [Особенности использования шлюза управления данными](data-factory-move-data-between-onprem-and-cloud.md#Considerations-for-using-Data-Management-Gateway).

**Среда компьютера шлюза.** Для размещения шлюза управления данными рекомендуется использовать выделенный компьютер. Чтобы проверить использование ЦП, памяти и пропускной способности во время выполнения копирования на компьютере шлюза, используйте такое средство, как PerfMon. Если ЦП, память или пропускная способность сети становится узким местом, следует использовать более мощный компьютер.

**Одновременное выполнение действий копирования.** Один экземпляр шлюза управления данными может обработать несколько запусков действия копирования, т. е. шлюз может выполнять несколько заданий копирования одновременно (для вычисления количества одновременно выполняемых заданий используется конфигурация оборудования компьютера шлюза). Дополнительные задания копирования находятся в очереди, пока их не выберет шлюз или пока не истечет время ожидания выполнения задания (в зависимости от того, что произойдет раньше). Чтобы избежать состязания ресурсов в шлюзе, можно составить график выполнения действий таким образом, чтобы уменьшить количество поставленных в очередь заданий копирования, или разделить нагрузку между несколькими шлюзами.


## Дополнительные рекомендации
Если размер данных для копирования достаточно большой, можно настроить бизнес-логику для дальнейшего секционирования данных с помощью механизма создания срезов фабрики данных Azure и запланировать более частое выполнение действия копирования, чтобы уменьшить размер данных для каждого действия копирования.

Необходимо следить за количеством наборов данных и действий копирования, которые попадают в одно и то же хранилище данных в любой момент времени. Большое количество одновременно выполняемых заданий копирования может привести к регулированию хранилища данных, что ведет к ухудшению производительности, внутренним повторным попыткам выполнения действия копирования и в некоторых случаях к сбоям выполнения.

## Пример использования. Копирование из локального SQL Server в большой двоичный объект Azure
**Сценарий.** Конвейер предназначен для копирования данных из локального SQL Server в большой двоичный объект Azure в формате CSV. Для ускорения копирования необходимо сжать CSV-файлы в формат BZIP2.

**Тестирование и анализ.** Отмечено, что пропускная способность действия копирования составляет меньше 2 МБ/с, что гораздо меньше, чем в тесте производительности.

**Анализ и настройка производительности.** Чтобы устранить проблемы производительности, сначала необходимо подробно рассмотреть процесс обработки и перемещения данных.

1.	**Чтение данных.** Шлюз устанавливает подключение с SQL Server и отправляет запрос. SQL Server отвечает, отправляя поток данных в шлюз через интрасеть.
2.	Шлюз **сериализует** поток данных в формат CSV и **сжимает** данные в поток BZIP2.
3.	**Запись данных.** Шлюз отправляет поток BZIP2 в большой двоичный объект Azure через Интернет.

Как видите, обработка и перемещение данных происходит в последовательном режиме потоковой передачи: SQL Server -> локальная сеть -> шлюз -> глобальная сеть -> большой двоичный объект Azure. **Общая производительность достигается при минимальной пропускной способности в конвейере**.

![поток данных](./media/data-factory-copy-activity-performance/case-study-pic-1.png)

Один или несколько следующих факторов могут быть узким местом производительности.

1.	**Источник.** SQL Server отличается низкой пропускной способностью из-за высокой нагрузки.
2.	**Шлюз управления данными.**
	1.	**Локальная сеть.** Шлюз находится далеко от SQL Server, а для подключения наблюдается низкая пропускная способность.
	2.	Выполнение следующих действий приводит к достижению ограничений **нагрузки на компьютере шлюза**:
		1.	**сериализация** — сериализация потока данных в формат CSV характеризуется низкой пропускной способностью;
		2.	**сжатие** — выбран кодек медленного сжатия (например, BZIP2 со скоростью 2,8 МБ/с и процессором Core i7).
	3.	**Глобальная сеть.** Низкая пропускная способность между корпоративной сетью и Azure (например, T1 — 1544 Кбит/с, T2 — 6312 Кбит/с).
4.	**Приемник.** Большой двоичный объект Azure характеризуется низкой пропускной способностью (хотя это маловероятно, потому что соглашение об уровне обслуживания гарантирует не менее 60 МБ/с).

В этом случае сжатие данных в формат BZIP2 может замедлять работу всего конвейера. Этого можно избежать, если перейти на использование кодека сжатия в формат GZIP.


## Практический пример: параллельное копирование  

**Сценарий I**. Копирование 1000 файлов размером 1 МБ из локальной файловой системы в хранилище BLOB-объектов Azure

**Анализ и оптимизация производительности**. Предположим, что вы установили шлюз управления данными на четырехъядерном компьютере, а фабрика данных будет по умолчанию использовать 16 параллельных копий для одновременного перемещения файлов из файловой системы в большой двоичный объект Azure. Это должно обеспечить высокую производительность. Вы также можете явно указать число параллельных копий, если хотите. При копировании большого количества небольших файлов параллельные копии радикально повысят пропускную способность за счет более эффективного использования задействованных ресурсов.

![Сценарий 1](./media/data-factory-copy-activity-performance/scenario-1.png)

**Сценарий II**. Копирование 20 больших двоичных объектов размером 500 МБ из хранилища BLOB-объектов Azure в хранилище озера данных Azure с анализом и настройкой производительности

**Анализ и оптимизация производительности**. В этом сценарии фабрика данных по умолчанию будет копировать данные из большого двоичного объекта Azure в озеро данных Azure, используя одну копию (parallelCopies равно 1) и одну облачную единицу перемещения данных. Наблюдаемая пропускная способность будет близка к указанной в разделе с [показателями производительности](#performance-reference) выше.

![Сценарий 2](./media/data-factory-copy-activity-performance/scenario-2.png)

Когда размер отдельного файла превышает десятки мегабайтов и общий объем достаточно велик, увеличение значения parallelCopies не приведет к повышению производительности копирования ввиду ограничения ресурсов одной облачной единицы перемещения данных. Вместо этого следует задать больше облачных единиц перемещения данных, чтобы получить дополнительные ресурсы для перемещения данных. Не указывайте значение свойства parallelCopies, чтобы фабрика данных сама управляла параллелизмом. В этом случае задайте cloudDataMovementUnits значение 4. Это повысит пропускную способность примерно в 4 раза.

![Сценарий 3](./media/data-factory-copy-activity-performance/scenario-3.png)

## Справочник по настройке производительности хранилища данных
Ниже приведены некоторые справочные материалы по мониторингу и настройке производительности для нескольких поддерживаемых хранилищ данных.

- Служба хранилища Azure (включая хранилища Blob-объектов Azure и таблиц Azure): [Целевые показатели масштабируемости службы хранилища](../storage/storage-scalability-targets.md) и [Контрольный список производительности и масштабируемости хранилища Azure](../storage//storage-performance-checklist.md).
- База данных SQL Azure: вы можете [наблюдать за производительностью](../sql-database/sql-database-service-tiers.md#monitoring-performance) и проверять процент использования единиц транзакций базы данных (DTU).
- Хранилище данных SQL Azure: его возможности измеряются в единицах использования хранилища данных (DWU). См. статью [Эластичная производительность и масштабирование в хранилище данных SQL](../sql-data-warehouse/sql-data-warehouse-manage-compute-overview.md).
- Azure DocumentDB: [Уровень производительности в DocumentDB](../documentdb/documentdb-performance-levels.md).
- Локальный SQL Server: [Мониторинг и настройка производительности](https://msdn.microsoft.com/library/ms189081.aspx).
- Локальный файловый сервер: [Настройка производительности для файловых серверов](https://msdn.microsoft.com/library/dn567661.aspx).

<!---HONumber=AcomDC_0727_2016-->