<properties 
	pageTitle="Действия перемещения данных | Microsoft Azure" 
	description="Дополнительные сведения о перемещении данных в конвейерах фабрики данных: перенос данных между облачными хранилищами, а также между локальным и облачным хранилищами. Использование действия копирования." 
	keywords="перемещение данных, перенос данных, копирование данных, передача данных"
	services="data-factory" 
	documentationCenter="" 
	authors="spelluru" 
	manager="jhubbard" 
	editor="monicar"/>

<tags 
	ms.service="data-factory" 
	ms.workload="data-services" 
	ms.tgt_pltfrm="na" 
	ms.devlang="na" 
	ms.topic="article" 
	ms.date="05/31/2016" 
	ms.author="spelluru"/>

# Перемещение данных и действие копирования. Перенос данных в облако и между облачными хранилищами
[Действие копирования](#copyactivity) в фабрике данных Azure выполняет перемещение данных из источника в приемник (место назначения). Действием копирования управляет защищенная, надежная, масштабируемая и [глобально доступная служба](#global). Эта служба автоматически выбирает оптимальный регион для перемещения данных. Обычно это — регион, расположенный ближе всего к хранилищу данных приемника.

Далее описано, как происходит перенос данных между двумя облачными хранилищами данных, между локальным и облачным хранилищем данных, а также в хранилище данных на виртуальной машине Azure Iaas или из него.

## Копирование данных из одного облачного хранилища в другое
Если источник и приемник (целевое хранилище) данных находятся в облаке, действие копирования включает описанные ниже этапы копирования и переноса данных. Служба, на базе которой реализовано действие копирования, выполняет следующие действия:

1. Считывает данные из источника данных.
2.	Выполняет сериализацию и десериализацию, сжимает или распаковывает данные, сопоставляет столбцы и преобразует данные из одного типа в другой в соответствии с конфигурациями наборов входных данных, наборов выходных данных и действия копирования.
3.	Записывает данные в целевое хранилище данных.

![cloud-to-cloud copy](.\media\data-factory-data-movement-activities\cloud-to-cloud.png)


## Копирование данных из локального хранилища данных в облачное и наоборот
Для [безопасного переноса данных между локальными хранилищами, защищенными корпоративным брандмауэром и облачным хранилищем данных](#moveonpremtocloud), необходимо установить на локальный компьютер шлюз управления данными — агент, обеспечивающий гибридное перемещение и обработку данных. Шлюз управления данными можно установить на тот же компьютер, где находится хранилище данных, или на отдельную машину с доступом к этому хранилищу. В этом случае сериализацию и десериализацию данных, сжатие и распаковку, сопоставление столбцов и преобразование типов выполняет шлюз управления данными. При этом данные не передаются через службу фабрики данных Azure. Шлюз управления данными напрямую записывает данные в целевое хранилище.

![onprem-to-cloud copy](.\media\data-factory-data-movement-activities\onprem-to-cloud.png)

## Копирование данных в хранилище на виртуальной машине Azure Iaas и из него 
Используя шлюз управления данными, можно также перемещать данные в поддерживаемые хранилища данных, расположенные на виртуальных машинах Azure Iaas (инфраструктура как услуга), и из таких хранилищ. В этом случае шлюз управления данными можно установить на ту же виртуальную машину Azure, где находится хранилище данных, или на отдельную виртуальную машину с доступом к этому хранилищу.

## Поддерживаемые хранилища данных
Действие копирования копирует данные из **хранилища-источника** в **хранилище-приемник**. Фабрика данных поддерживает следующие хранилища данных, и **данные из любого источника можно записывать в любой приемник**. Щелкните название хранилища, чтобы узнать, как скопировать данные из него или в него.

| Источники| Приемники |
|:------- | :---- |
| <ul><li>[Большой двоичный объект Azure](data-factory-azure-blob-connector.md)</li><li>[Таблица Azure](data-factory-azure-table-connector.md)</li><li>[База данных SQL Azure](data-factory-azure-sql-connector.md)</li><li>[Хранилище данных SQL Azure](data-factory-azure-sql-data-warehouse-connector.md)</li><li>[Azure DocumentDB (см. примечание ниже)](data-factory-azure-documentdb-connector.md)</li><li>[Хранилище озера данных Azure](data-factory-azure-datalake-connector.md)</li><li>[SQL Server в локальной среде или Azure IaaS](data-factory-sqlserver-connector.md)</li><li>[Файловая система в локальной среде или Azure IaaS](data-factory-onprem-file-system-connector.md)</li><li>[База данных Oracle в локальной среде или Azure IaaS](data-factory-onprem-oracle-connector.md)</li><li>[База данных MySQL в локальной среде или Azure IaaS](data-factory-onprem-mysql-connector.md)</li><li>[База данных DB2 в локальной среде или Azure IaaS](data-factory-onprem-db2-connector.md)</li><li>[База данных Teradata в локальной среде или Azure IaaS](data-factory-onprem-teradata-connector.md)</li><li>[База данных Sybase в локальной среде или Azure IaaS](data-factory-onprem-sybase-connector.md)</li><li>[База данных PostgreSQL в локальной среде или Azure IaaS](data-factory-onprem-postgresql-connector.md)</li><li>[Источники данных ODBC в локальной среде или Azure IaaS](data-factory-odbc-connector.md)</li><li>[Распределенная файловая система Hadoop (HDFS) в локальной среде или Azure IaaS](data-factory-hdfs-connector.md)</li><li>[Источники OData](data-factory-odata-connector.md)</li><li>[Веб-таблица (в формате HTML)](data-factory-web-table-connector.md)</li><li>[Решение GE Historian в локальной среде или Azure IaaS](data-factory-odbc-connector.md#ge-historian-store)</li></ul> | <ul><li>[BLOB-объект Azure](data-factory-azure-blob-connector.md)</li><li>[Таблица Azure](data-factory-azure-table-connector.md)</li><li>[База данных Azure SQL](data-factory-azure-sql-connector.md)</li><li>[Хранилище данных Azure SQL](data-factory-azure-sql-data-warehouse-connector.md)</li><li>[Azure DocumentDB (см. примечание ниже)](data-factory-azure-documentdb-connector.md)</li><li>[Хранилище озера данных Azure](data-factory-azure-datalake-connector.md)</li><li>[База данных SQL Server в локальной среде или Azure IaaS](data-factory-sqlserver-connector.md)</li><li>[Файловая система в локальной среде или Azure IaaS](data-factory-onprem-file-system-connector.md)</li><li>[База данных Oracle в локальной среде или Azure IaaS](data-factory-onprem-oracle-connector.md)</li></ul> |


> [AZURE.NOTE] Копирование данных из Azure DocumentDB в хранилище данных в локальной среде или Azure IaaS и наоборот сейчас не поддерживается. Полная поддержка для DocumentDB в Azure будет обеспечена в ближайшее время.

Если **действие копирования** не поддерживает хранилище данных, в которое или из которого вам нужно переместить данные, вы можете создать в фабрике данных **настраиваемое действие** с собственной логикой для копирования или перемещения данных. Сведения о создании и использовании настраиваемого действия см. в статье [Использование настраиваемых действий в конвейере фабрики данных Azure](data-factory-use-custom-activities.md).

## Учебник
Краткий учебник по использованию действия копирования см. в разделе [Учебник. Использование действия копирования в конвейере фабрики данных Azure](data-factory-copy-data-from-azure-blob-storage-to-sql-database.md). В этом учебнике действие копирования будет использоваться для копирования данных из хранилища больших двоичных объектов Azure в базу данных SQL Azure.

## <a name="copyactivity"></a>Действие копирования
Действие копирования копирует данные из одного входного набора данных (**источник**) в один выходной набор данных (**приемник**). Данные копируются в пакетном режиме в соответствии с заданным для действия расписанием. Общие сведения об определении действий см. в статье [Конвейеры и действия в фабрике данных Azure](data-factory-create-pipelines.md).

Действие копирования предоставляет приведенные ниже возможности.

### <a name="global"></a>Глобально доступное перемещение данных
Хотя фабрика данных Azure доступна только в западной части США, восточной части США и Северной Европе, служба, на базе которой реализовано действие копирования, доступна глобально в следующих регионах и географических областях. Глобально доступная топология обеспечивает эффективное перемещение данных, в большинстве случаев позволяя избежать "прыжков" по разным регионам.

Перемещение данных выполняет **шлюз управления данными** или **фабрика данных Azure** в зависимости от расположения исходного и целевого хранилищ данных для операции копирования. Дополнительные сведения см. в таблице ниже.

Расположение исходного хранилища данных | Расположение целевого хранилища данных | Что используется для перемещения данных  
-------------------------- | ------------------------------- | ----------------------------- 
локальная система или виртуальная машина Azure (IaaS) | облако | **Шлюз управления данными** на локальном компьютере или виртуальной машине Azure. Данные не передаются через службу в облаке. <br/><br/> Примечание. Шлюз управления данными может находиться на том же локальном компьютере или виртуальной машине Azure, что и хранилище данных, или на другом локальном компьютере или виртуальной машине Azure. Главное, чтобы он мог подключаться к обоим хранилищам данных.
облако | локальная система или виртуальная машина Azure (IaaS) | То же, что и выше. 
локальная система или виртуальная машина Azure (IaaS) | локальная система или виртуальная машина | **Связанный с источником шлюз управления данными**. Данные не передаются через службу в облаке. См. примечание выше.   
облако | облако | **Облачная служба, которая управляет действием копирования**. Фабрика данных Azure развертывает эту службу в регионе, который находится ближе всего к расположению приемника в пределах одной с ним географической области. Особенности сопоставления см. в таблице ниже. <br/><br/><table><tr><th>Регион целевого хранилища данных</th> <th>Регион, используемый для перемещения данных</th></tr><tr><td>Восточная часть США</td><td>Восточная часть США</td></tr><tr><td>Восточная часть США 2</td><td>Восточная часть США 2</td><tr/><tr><td>Центральная часть США</td><td>Центральная часть США</td><tr/><tr><td>Западная часть США</td><td>Западная часть США</td></tr><tr><td>Северо-Центральный регион США</td><td>Северо-Центральный регион США</td></tr><tr><td>Юго-Центральный регион США</td><td>Юго-Центральный регион США</td></tr><tr><td>Северная Европа</td><td>Северная Европа</td></tr><tr><td>Западная Европа</td><td>Западная Европа</td></tr><tr><td>Юго-Восточная Азия</td><td>Юго-Восточная Азия</td></tr><tr><td>Восточная Азия</td><td>Юго-Восточная Азия</td></tr><tr><td>Восточная Япония</td><td>Восточная Япония</td></tr><tr><td>Западная Япония</td><td>Восточная Япония</td></tr><tr><td>Южная Бразилия</td><td>Южная Бразилия</td></tr><tr><td>Восточная Австралия</td><td>Восточная Австралия</td></tr><tr><td>Юго-Восточная Австралия</td><td>Юго-Восточная Австралия</td></tr></table>


> [AZURE.NOTE] Если регион целевого хранилища данных не указан в упомянутом выше списке, действие копирования не будет выполнено через другой регион и завершится ошибкой.



### <a name="moveonpremtocloud"></a>Безопасное перемещение данных между локальным расположением и облаком
Одной из важнейших современных задач интеграции данных является незаметное для пользователя перемещение данных между локальной средой и облаком. Шлюз управления данными — это локально-устанавливаемый агент, который позволяет использовать гибридные конвейеры.

Шлюз данных предоставляет следующие возможности:

1.	Безопасное управление доступом к локальным хранилищам данных.
2.	Моделирование локальных и облачных хранилищ данных в пределах одной фабрики, а также перемещение данных.
3.	Мониторинг и контроль состояния шлюза и управление им с помощью единой облачной панели мониторинга фабрики данных.

Источник данных следует считать локальным (то есть защищенным брандмауэром), даже если используется **ExpressRoute**, а для связи между службой и источником данных **используется шлюз**.

Дополнительные сведения см. в статье [Перемещение данных между локальными источниками и облаком](data-factory-move-data-between-onprem-and-cloud.md).


### Надежное и экономичное перемещение данных
Действие копирования предназначено для перемещения больших объемов данных из самых разных источников с защитой от временных ошибок. Для экономии копируемые данные можно сжать.

### Преобразование типов из различных систем
Различные хранилища данных используют разные собственные системы типов. Во время копирования типы источников автоматически преобразовываются в типы приемников. Такое преобразование выполняется в 2 этапа:

1. Преобразование собственных типов источников в тип .NET.
2. Преобразование типа .NET в собственный тип приемника.

Сведения о сопоставлениях собственных типов с типами .NET см. в статьях, посвященных конкретным соединителям для хранилищ данных. Эти сопоставления позволяют выбрать подходящие типы при создании таблиц и обеспечить правильность преобразований в процессе копирования.

### Работа с различными форматами файлов
Действие копирования поддерживает разнообразные форматы файлов для файловых хранилищ, включая двоичный, текстовый, Avro, ORC и JSON. Действие копирования можно использовать для преобразования из одного формата в другой. Пример: преобразование текста (CSV) в Avro. Если данные не структурированы, свойство **Structure** в JSON-файле определения объекта [dataset](data-factory-create-datasets.md) можно опустить.

### Свойства действия копирования
Такие свойства, как имя, описание, входные и выходные таблицы, различные политики и т. д., доступны для всех типов действий. С другой стороны, свойства, доступные в разделе **typeProperties** действия, зависят от конкретного типа действия.

Для действия копирования содержимое раздела **typeProperties** зависит от типов источников и приемников. Щелкните источник или приемник в разделе [Поддерживаемые хранилища данных](#supported-data-stores), чтобы получить сведения о свойствах типа, поддерживаемых действием копирования для этого хранилища данных.

Сведения о свойствах, используемых для конкретных типов хранилищ, см. на страницах, посвященных этим типам.

### Упорядоченное копирование
Несколько операций копирования можно выполнить друг за другом последовательно или упорядоченно. Предположим, что у вас в конвейере есть два действия копирования: CopyActivity1 и CopyActivity2 со следующими наборами входных и выходных данных.

CopyActivity1: входные данные — Dataset1, выходные данные — Dataset2

CopyActivity2: входные данные — Dataset2, выходные данные — Dataset4

Действие копирования CopyActivity2 будет выполнено только в том случае, если действие копирования CopyActivity1 прошло успешно и набор данных Dataset2 доступен.

В приведенном выше примере действие копирования CopyActivity2 может иметь другие входные данные, например набор данных Dataset3, но необходимо также указать набор Dataset2 в качестве входных данных, чтобы действие копирования CopyActivity2 не запускалось, пока не завершится действие копирования CopyActivity1. Например:

CopyActivity1: входные данные — Dataset1, выходные данные — Dataset2

CopyActivity2: входные данные — Dataset3, Dataset2, выходные данные —Dataset4

Если указано несколько наборов входных данных, то для копирования используется только первый набор, а другие наборы используются в качестве зависимостей. Действие CopyActivity2 запустилось бы только при соблюдении следующих условий:

- Действие CopyActivity2 успешно завершено, и набор данных Dataset2 доступен. Этот набор данных не будет использоваться при копировании данных в Dataset4. Он используется только как зависимость для планирования CopyActivity2.
- Набор данных Dataset3 доступен. Этот набор данных представляет данные, которые копируются в место назначения.


### Настройка производительности действия копирования 
См. статью [Руководство по настройке производительности действия копирования](data-factory-copy-activity-performance.md), в которой описываются ключевые факторы, влияющие на производительность перемещения данных (действие копирования) в фабрике данных Azure. В ней также приведены сведения о производительности, наблюдаемой во время внутреннего тестирования, и рассматриваются различные способы оптимизировать производительность действия копирования.


## Мастер копирования фабрики данных
**Мастер копирования фабрики данных** позволяет создать конвейер для копирования данных из поддерживаемых источников в места назначения без написания определений JSON для связанных служб, наборов данных и конвейеров. Чтобы запустить мастер копирования, на домашней странице фабрики данных щелкните плитку **Копирование данных**.

![Мастер копирования данных](./media/data-factory-data-movement-activities/copy-data-wizard.png)

### Функции

#### Интуитивно понятный и простой мастер для копирования данных 
Этот мастер позволяет легко перемещать данные из источника в место назначения за несколько минут с помощью следующих простых действий:

1.	Выберите **источник**.
2.	Выберите **место назначения**.
3.	Задайте **настройки**.

![Выберите источник данных](./media/data-factory-data-movement-activities/select-data-source-page.png)

#### Широкие возможности просмотра данных и сопоставления схем
Вы можете просматривать таблицы и папки, выполнять предварительный просмотр данных, сопоставление схем, проверять выражения и выполнять простые преобразования данных в мастере.

**Обзор таблиц и папок** ![Обзор таблиц и папок](./media/data-factory-data-movement-activities/browse-tables-folders.png)

#### Интерфейс масштабирования для разнообразных данных и типов объектов
Интерфейс изначально предполагает работу с большими объемами данных. Вы сможете легко и эффективно создавать конвейеры фабрики данных для перемещения сотен папок, файлов или таблиц.

**Предварительный просмотр данных, сопоставление схем и простые трансформации** ![Параметры формата файла](./media/data-factory-data-movement-activities/file-format-settings.png) ![Сопоставление схем](./media/data-factory-data-movement-activities/schema-mapping.png) ![Проверка выражений](./media/data-factory-data-movement-activities/validate-expressions.png)

#### Интерфейс масштабирования для разнообразных данных и типов объектов
Интерфейс изначально предполагает работу с большими объемами данных. Перемещайте сотни папок, файлов или таблиц легко и эффективно с помощью мастера копирования.

![Выбор таблиц для копирования данных](./media/data-factory-data-movement-activities/select-tables-to-copy-data.png)

#### Расширенные параметры планирования
Операцию копирования можно запускать только один раз или по расписанию (ежечасно, ежедневно и т. д.). Оба этих параметра могут использоваться для расширения соединителей в локальной сети, в облаке и локальной копии на рабочем столе. Однократное копирование обеспечивает однократное перемещение данных из источника в место назначения и применяется к данным любого размера и любых поддерживаемых форматов. Запланированное копирование включает копирование данных с указанной периодичностью. Для настройки запланированного копирования можно использовать широкий набор настроек (повторение, время ожидания, предупреждения и т. д).

![Планирование свойств](./media/data-factory-data-movement-activities/scheduling-properties.png)


### Попробуйте сейчас 
Краткое описание создания конвейера с действием копирования при помощи **мастера копирования фабрики данных** см. в статье [Руководство. Создание конвейера с действием копирования с помощью мастера копирования фабрики данных](data-factory-copy-data-wizard-tutorial.md).


### Переменные в пути к папке BLOB-объекта Azure
Вы можете использовать переменные в пути к папке, чтобы расположение папки с данными определялось во время выполнения операции на основе [системной переменной WindowStart](data-factory-functions-variables.md#data-factory-system-variables). Поддерживаемые переменные: **year**, **month**, **day**, **hour**, **minute** и **{custom}**. Пример: inputfolder/{year}/{month}/{day}.

Предположим, что у вас есть входные каталоги в следующем формате:
	
	2016/03/01/01
	2016/03/01/02
	2016/03/01/03
	...

Нажмите кнопку **Обзор** в разделе **Файл или папка**, перейдите к одной из этих папок, например, 2016->03->01->02, и щелкните **Выбрать**. В текстовом поле должно появиться: **2016/03/01/02**. Теперь измените **2016** на **{year}**, **03** на **{month}**, **01** на **{day}**, **02** на **{hour}** и нажмите клавишу **TAB**. Вы увидите раскрывающиеся списки, в которых можно выбрать **формат** для этих четырех переменных, как показано ниже.

![Использование системных переменных](./media/data-factory-data-movement-activities/blob-standard-variables-in-folder-path.png)

Также можно использовать переменную **custom**, как показано ниже, и любые [поддерживаемые строки формата](https://msdn.microsoft.com/library/8kb3ddd4.aspx). Сначала выберите папку в этой структуре с помощью кнопки "Обзор", затем измените значение переменной на **{custom}** и нажмите клавишу **TAB** для отображения текстового поля, в которое можно ввести строку формата.

![Использование пользовательской переменной](./media/data-factory-data-movement-activities/blob-custom-variables-in-folder-path.png)

<!---HONumber=AcomDC_0629_2016-->