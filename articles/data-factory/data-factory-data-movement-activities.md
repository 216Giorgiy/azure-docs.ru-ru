.<properties 
	pageTitle="Копирование данных с помощью действия копирования | Microsoft Azure" 
	description="Дополнительные сведения о перемещении данных в конвейерах фабрики данных: перенос данных между облачными хранилищами, а также между локальным и облачным хранилищами. Использование действия копирования." 
	keywords="перемещение данных, перенос данных, копирование данных, передача данных"
	services="data-factory" 
	documentationCenter="" 
	authors="spelluru" 
	manager="jhubbard" 
	editor="monicar"/>

.<tags 
	ms.service="data-factory" 
	ms.workload="data-services" 
	ms.tgt_pltfrm="na" 
	ms.devlang="na" 
	ms.topic="article" 
	ms.date="08/08/2016" 
	ms.author="spelluru"/>

# Перемещение данных с помощью действия копирования

## Обзор
Фабрика данных Azure позволяет с помощью действия копирования копировать различные данные с разных локальных и облачных источников данных в Azure для дальнейшего преобразования и анализа. С помощью действия копирования можно также публиковать результаты преобразования и анализа для бизнес-аналитики и использования приложения.

.![Роль действия копирования](media/data-factory-data-movement-activities/copy-activity.png)

Действием копирования управляет защищенная, надежная, масштабируемая и [глобально доступная служба](#global). Эта статья содержит сведения о перемещении данных в фабрике данных и в рамках действия копирования. Сначала давайте рассмотрим, как происходит перенос данных между двумя облачными хранилищами данных, а также между локальным и облачным хранилищами.

> [AZURE.NOTE] Общие сведения об определении действий см. в статье [Конвейеры и действия в фабрике данных Azure: создание конвейеров, цепочки действий и расписаний для них](data-factory-create-pipelines.md).

### Копирование данных из одного облачного хранилища в другое
Если источник и приемник (целевое хранилище) данных находятся в облаке, действие копирования включает описанные ниже этапы копирования и переноса данных. Служба, на базе которой реализовано действие копирования, выполняет следующие действия:

1. Считывает данные из источника данных.
2. Выполняет сериализацию и десериализацию, сжимает или распаковывает данные, сопоставляет столбцы и преобразует данные из одного типа в другой в соответствии с конфигурациями наборов входных данных, наборов выходных данных и действия копирования.
3.	Записывает данные в целевое хранилище данных.

Эта служба автоматически выбирает оптимальный регион для перемещения данных. Обычно это — регион, расположенный ближе всего к хранилищу данных приемника.

.![cloud-to-cloud copy](./media/data-factory-data-movement-activities/cloud-to-cloud.png)


### Копирование данных из локального хранилища данных в облачное и наоборот
Для безопасного переноса данных между локальными хранилищами, защищенными корпоративным брандмауэром и облачным хранилищем данных, необходимо установить на локальный компьютер шлюз управления данными — агент, обеспечивающий гибридное перемещение и обработку данных. Шлюз управления данными можно установить на тот же компьютер, где находится хранилище данных, или на отдельную машину с доступом к этому хранилищу. В этом случае сериализацию и десериализацию данных, сжатие и распаковку, сопоставление столбцов и преобразование типов выполняет шлюз управления данными. При этом данные не передаются через службу фабрики данных Azure. Шлюз управления данными напрямую записывает данные в целевое хранилище.

.![onprem-to-cloud copy](./media/data-factory-data-movement-activities/onprem-to-cloud.png)

В статье [Перемещение данных между локальными источниками и облаком с помощью шлюза управления данными](data-factory-move-data-between-onprem-and-cloud.md) представлены вводные сведения и пошаговое руководство, а статья [Шлюз управления данными](data-factory-data-management-gateway.md) содержит дополнительные сведения о шлюзе управления данными.

Используя шлюз управления данными, можно также перемещать данные в поддерживаемые хранилища данных, расположенные на виртуальных машинах Azure Iaas (инфраструктура как услуга), и из таких хранилищ. В этом случае шлюз управления данными можно установить на ту же виртуальную машину Azure, где находится хранилище данных, или на отдельную виртуальную машину с доступом к этому хранилищу.

## Поддерживаемые хранилища данных и форматы
Действие копирования копирует данные из **хранилища-источника** в **хранилище-приемник**. Фабрика данных поддерживает приведенные ниже хранилища данных, и **данные из любого источника можно записывать в любой приемник**. Щелкните название хранилища, чтобы узнать, как скопировать данные из него или в него.

Категория | Хранилище данных | Поддерживается в качестве источника | Поддерживается в качестве приемника
:------- | :--------- | :------------------ | :-----------------
Таблицы Azure | [Большой двоичный объект Azure](data-factory-azure-blob-connector.md) <br/> [Azure Data Lake Store](data-factory-azure-datalake-connector.md) <br/> [База данных SQL Azure](data-factory-azure-sql-connector.md) <br/> [Хранилище данных SQL Azure](data-factory-azure-sql-data-warehouse-connector.md) <br/> [Таблица Azure](data-factory-azure-table-connector.md) <br/> [База данных Azure DocumentDB](data-factory-azure-documentdb-connector.md) <br/> | ✓ <br/> ✓ <br/> ✓ <br/> ✓ <br/> ✓ <br/> ✓ | ✓ <br/> ✓ <br/> ✓ <br/> ✓ <br/> ✓ <br/> ✓ 
Базы данных | [SQL Server](data-factory-sqlserver-connector.md)* <br/> [Oracle](data-factory-onprem-oracle-connector.md)* <br/> [MySQL](data-factory-onprem-mysql-connector.md)* <br/> [DB2](data-factory-onprem-db2-connector.md)* <br/> [Teradata](data-factory-onprem-teradata-connector.md)* <br/> [PostgreSQL](data-factory-onprem-postgresql-connector.md)* <br/> [Sybase](data-factory-onprem-sybase-connector.md)* <br/>[Cassandra](data-factory-onprem-cassandra-connector.md)* <br/>[MongoDB](data-factory-on-premises-mongodb-connector.md)* | ✓ <br/> ✓ <br/> ✓ <br/> ✓ <br/> ✓ <br/> ✓<br/> ✓ <br/> ✓ <br/> ✓ | ✓ <br/> ✓ <br/> &nbsp; <br/> &nbsp; <br/> &nbsp; <br/> &nbsp;<br/> &nbsp;<br/> &nbsp;<br/> &nbsp; 
Файл | [Файловая система](data-factory-onprem-file-system-connector.md)* <br/> [Распределенная файловая система Hadoop](data-factory-hdfs-connector.md)* | ✓ <br/> ✓ <br/> | ✓ <br/> &nbsp; 
Прочее | [Salesforce](data-factory-salesforce-connector.md)<br/> [Универсальное ODBC](data-factory-odbc-connector.md)* <br/> [Универсальное OData](data-factory-odata-connector.md) <br/> [Веб-таблица (таблица из HTML)](data-factory-web-table-connector.md) <br/> [GE Historian](data-factory-odbc-connector.md#ge-historian-store)* | ✓ <br/> ✓ <br/> ✓ <br/> ✓ <br/> ✓ | &nbsp; <br/> &nbsp; <br/> &nbsp; <br/> &nbsp;<br/> &nbsp;<br/> &nbsp;

> [AZURE.NOTE] Хранилища данных, отмеченные звездочкой (*), могут находиться в локальном расположении или в IaaS Azure и требовать установки [шлюза управления данными](data-factory-data-management-gateway.md) на локальном компьютере или компьютере IaaS Azure.

Если необходимо переместить данные в хранилище данных или из хранилища данных, которое не поддерживается **действием копирования**, вы можете использовать в фабрике данных **настраиваемое действие** с собственной логикой для копирования и перемещения данных. Сведения о создании и использовании настраиваемого действия см. в статье [Использование настраиваемых действий в конвейере фабрики данных Azure](data-factory-use-custom-activities.md).

### Поддерживаемые форматы файлов
Действие копирования может копировать файлы "как есть" из одного файлового хранилища данных в другое (это такие хранилища, как большой двоичный объект Azure, файловая система и распределенная файловая система Hadoop (HDFS)). Для этого нужно пропустить [раздел формата](data-factory-create-datasets.md) в определениях наборов входных и выходных данных. Это позволяет эффективно копировать данные без какой-либо сериализации или десериализации.

Кроме того, действие копирования позволяет читать файлы таких форматов (и делать в них записи): текстовый формат, AVRO, ORC и JSON. Ниже приведены некоторые примеры действия копирования, которые доступны и для вас:

-	копирование данных в текстовом формате (CSV) из большого двоичного объекта Azure и запись в SQL Azure;
-	копирование файлов в текстовом формате (CSV) из локальной файловой системы и запись в большой двоичный объект Azure в формате AVRO;
-	копирование данных в базе данных SQL Azure и запись в локальную систему HDFS в формате ORC.



## <a name="global"></a>Глобально доступное перемещение данных
Хотя фабрика данных Azure доступна только в западной части США, восточной части США и Северной Европе, служба, на базе которой реализовано действие копирования, доступна глобально в указанных ниже регионах и географических областях. Глобально доступная топология обеспечивает эффективное перемещение данных, обычно позволяя избежать "прыжков" по разным регионам. Чтобы узнать, доступны ли в регионе служба фабрики данных и перемещение данных, см. раздел [Службы по региону](https://azure.microsoft.com/regions/#services).

### Копирование данных из одного облачного хранилища данных в другое
Когда исходный источник данных и приемник находятся в облаке, фабрика данных Azure, чтобы переместить данные, использует развертывание службы в регионе, который ближе всего к расположению приемника. Сопоставления см. в следующей таблице.

Регион целевого хранилища данных | Регион, используемый для перемещения данных
:----------------------------------- | :----------------------------
Восток США | Восток США
Восток США 2 | Восток США 2
Центральный регион США | Центральный регион США
Запад США | Запад США
Северо-центральный регион США | Северо-центральный регион США
Южно-центральный регион США | Южно-центральный регион США
Северная Европа | Северная Европа
Западная Европа | Западная Европа
Юго-Восточная Азия | Юго-Восточная Азия
Восточная Азия | Юго-Восточная Азия
Восточная часть Японии | Восточная часть Японии
Западная часть Японии | Восточная часть Японии
Южная часть Бразилии | Южная часть Бразилии
Восточная часть Австралии | Восточная часть Австралии
Юго-Восточная часть Австралии | Юго-Восточная часть Австралии


> [AZURE.NOTE] Если регион целевого хранилища данных не указан в упомянутом выше списке, действие копирования не будет выполнено через другой регион и завершится ошибкой.

### Копирование данных из локального хранилища данных в облачное и наоборот
Когда данные копируются между локальным компьютером (или виртуальной машиной IaaS Azure) и облаком, данные перемещает [шлюз управления данными](data-factory-data-management-gateway.md) на локальном компьютере или виртуальной машине IaaS Azure. Данные не проходят через службу в облако, если вы не используете функцию [промежуточного копирования](data-factory-copy-activity-performance.md#staged-copy) (в таком случае данные проходят через промежуточное хранилище BLOB-объектов Azure и а только потом записываются в хранилище данных приемника).


## Создание конвейера с действием копирования 
Создать конвейер с действием копирования можно несколькими способами.

### Мастер копирования
**Мастер копирования фабрики данных** позволяет создать конвейер (с действием копирования) для копирования данных из поддерживаемых источников в места назначения **без создания определений JSON** для связанных служб, наборов данных и конвейеров. Сведения о мастере см. в руководстве [Data Factory Copy Wizard](data-factory-copy-wizard.md) (Мастер копирования фабрики данных).

### С помощью сценариев JSON
Вы можете использовать редактор фабрики данных на портале Azure, в Visual Studio или в Azure PowerShell, чтобы создать определение JSON для конвейера с действием копирования и развернуть его с целью создать конвейер в фабрике данных. Пошаговые инструкции см. в руководстве [Копирование данных из хранилища BLOB-объектов Azure в базу данных SQL с помощью фабрики данных](data-factory-copy-data-from-azure-blob-storage-to-sql-database.md).

Такие свойства JSON, как имя, описание, входные и выходные таблицы, различные политики и т. д., доступны для всех типов действий. С другой стороны, свойства, доступные в разделе **typeProperties** действия, зависят от конкретного типа действия.

Для действия копирования содержимое раздела **typeProperties** зависит от типов источников и приемников. Щелкните источник или приемник в разделе [Supported Sources/Sinks](#supported-data-stores) (Поддерживаемые источники и приемники), чтобы получить сведения о свойствах типа, поддерживаемых действием копирования для этого хранилища данных.

Ниже приведен пример определения JSON.

	{
	  "name": "ADFTutorialPipeline",
	  "properties": {
	    "description": "Copy data from Azure blob to Azure SQL table",
	    "activities": [
	      {
	        "name": "CopyFromBlobToSQL",
	        "type": "Copy",
	        "inputs": [
	          {
	            "name": "InputBlobTable"
	          }
	        ],
	        "outputs": [
	          {
	            "name": "OutputSQLTable"
	          }
	        ],
	        "typeProperties": {
	          "source": {
	            "type": "BlobSource"
	          },
	          "sink": {
	            "type": "SqlSink",
	            "writeBatchSize": 10000,
	            "writeBatchTimeout": "60:00:00"
	          }
	        },
	        "Policy": {
	          "concurrency": 1,
	          "executionPriorityOrder": "NewestFirst",
	          "retry": 0,
	          "timeout": "01:00:00"
	        }
	      }
	    ],
	    "start": "2016-07-12T00:00:00Z",
	    "end": "2016-07-13T00:00:00Z"
	  }
	} 

Действия выполняются согласно расписанию, заданному в наборе выходных данных (например, **ежедневно**: частота: день и интервал: 1). Действие копирует данные из одного входного набора данных (**источник**) в один выходной набор данных (**приемник**). Действию копирования можно назначить несколько входных наборов данных. С их помощью проверяются зависимости перед выполнением действия, однако в целевой набор данных копируются данные только из первого набора данных. Подробные сведения см. в разделе [Планирование и исполнение с использованием фабрики данных](data-factory-scheduling-and-execution.md).

## Настройка производительности 
См. статью [Руководство по настройке производительности действия копирования](data-factory-copy-activity-performance.md), в которой описываются ключевые факторы, влияющие на производительность перемещения данных (действие копирования) в фабрике данных Azure. В ней также приведены сведения о производительности, наблюдаемой во время внутреннего тестирования, и рассматриваются различные способы оптимизировать производительность действия копирования.

## Планирование и последовательное копирование
Подробные сведения о планировании и выполнении в фабрике данных Azure см. в статье [Планирование и исполнение с использованием фабрики данных](data-factory-scheduling-and-execution.md).

Несколько операций копирования можно выполнить друг за другом последовательно или упорядоченно. См. раздел [Упорядоченное копирование](data-factory-scheduling-and-execution.md#ordered-copy) указанной статьи.

## Преобразование типов 
Различные хранилища данных используют разные собственные системы типов. Во время копирования типы источников автоматически преобразуются в типы приемников. Такое преобразование выполняется в два этапа:

1. Преобразование собственных типов источников в тип .NET.
2. Преобразование типа .NET в собственный тип приемника.

Сведения о сопоставлениях собственных типов с типами .NET см. в статьях, посвященных конкретным хранилищам данных (щелкните соответствующую ссылку в таблице [Поддерживаемые хранилища данных](#supported-data-stores)). Эти сопоставления позволяют выбрать подходящие типы при создании таблиц и обеспечить правильность преобразований в процессе копирования.

 
## Дальнейшие действия
- Ознакомьтесь со статьей [Копирование данных из хранилища BLOB-объектов Azure в базу данных SQL с помощью фабрики данных](data-factory-copy-data-from-azure-blob-storage-to-sql-database.md), чтобы получить общие сведения о перемещении данных из исходного хранилища данных в приемник данных с помощью действия копирования.
- Чтобы узнать о перемещении данных из локального хранилища данных в облачное хранилище данных, ознакомьтесь со статьей [Перемещение данных между локальными источниками и облаком с помощью шлюза управления данными](data-factory-move-data-between-onprem-and-cloud.md).
 

<!---HONumber=AcomDC_0810_2016-->