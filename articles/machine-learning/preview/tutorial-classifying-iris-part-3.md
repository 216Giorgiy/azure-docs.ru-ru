---
title: "Развертывание модели для службы \"Машинное обучение Azure\" (предварительная версия) | Документация Майкрософт"
description: "Из этого полного руководства вы узнаете, как использовать службу \"Машинное обучение Azure\" (предварительная версия). Это третья часть серии руководств. В ней рассматривается развертывание модели."
services: machine-learning
author: raymondl
ms.author: raymondl, aashishb
manager: mwinkle
ms.reviewer: garyericson, jasonwhowell, mldocs
ms.service: machine-learning
ms.workload: data-services
ms.custom: mvc, tutorial
ms.topic: hero-article
ms.date: 11/29/2017
ms.openlocfilehash: b48e5bc2552c92b45e0417e5a8a34705a473073e
ms.sourcegitcommit: cfd1ea99922329b3d5fab26b71ca2882df33f6c2
ms.translationtype: HT
ms.contentlocale: ru-RU
ms.lasthandoff: 11/30/2017
---
# <a name="classify-iris-part-3-deploy-a-model"></a>Часть 3. Классификация цветков ириса: развертывание модели
Служба "Машинное обучение Azure" (предварительная версия) — это полнофункциональное интегрированное аналитическое решение для специалистов по обработке и анализу данных. С помощью этого решения можно подготавливать данные, разрабатывать эксперименты и развертывать модели в масштабах облака.

Руководство представляет собой третью, заключительную часть серии. В этой части вы будете использовать службу "Машинное обучение Azure" (предварительная версия), чтобы научиться выполнять следующие задачи:

> [!div class="checklist"]
> * поиск файла модели;
> * создание скрипта оценки и файла схемы;
> * подготовка среды;
> * создание веб-службы в режиме реального времени;
> * запуск веб-службы в режиме реального времени;
> * изучение выходных данных в формате больших двоичных объектов. 

 В этом руководстве используется классический [набор данных "Ирисы Фишера"](https://en.wikipedia.org/wiki/iris_flower_data_set). Снимки экрана представляют среду Windows, но для Mac OS все процедуры практически идентичны.

## <a name="prerequisites"></a>Предварительные требования
Выполните инструкции первых двух частей этой серии руководств.

   * Выполните инструкции в руководстве по [подготовке данных](tutorial-classifying-iris-part-1.md), чтобы создать ресурсы службы "Машинное обучение" и установить приложение Azure Machine Learning Workbench.

   * Выполните инструкции в руководстве по [сборке модели](tutorial-classifying-iris-part-2.md), чтобы создать модель логистической регрессии в службе "Машинное обучение Azure".

У вас должен быть установлен и локально запущен модуль Docker. Кроме того, можно выполнить развертывание в кластер Службы контейнеров Azure в Azure.

## <a name="download-the-model-pickle-file"></a>Загрузка файла, содержащего модель
В предыдущей части этого руководства мы локально выполнили скрипт **iris_sklearn.py** в Machine Learning Workbench. При помощи этого скрипта была сериализована модель логистической регрессии с использованием популярного пакета Python [pickle](https://docs.python.org/2/library/pickle.html) для сериализации объектов. 

1. Откройте приложение Machine Learning Workbench, а затем — проект **myIris**, созданный в предыдущей части этой серии руководств.

2. Открыв проект, нажмите кнопку **Файлы** на панели слева, чтобы в папке проекта отобразился список файлов.

3. Выберите файл **iris_sklearn.py**. На новой вкладке текстового редактора в Workbench откроется код Python.

4. Просмотрите **iris_sklearn.py** файл и найдите, где создан сериализованный файл. При помощи сочетания клавиш CTRL+F откройте диалоговое окно **поиска**. Затем найдите в коде Python слово **pickle**.

   Этот фрагмент кода показывает, как создан сериализованный выходной файл. Выходной файл на диске называется **model.pkl**. 

   ```python
   print("Export the model to model.pkl")
   f = open('./outputs/model.pkl', 'wb')
   pickle.dump(clf1, f)
   f.close()
   ```

5. Найдите сериализованный файл модели в списке выходных файлов последнего запуска.
   
   Когда вы выполнили скрипт **iris_sklearn.py**, файл модели был сохранен в папке **outputs** с именем **model.pkl**. Эта папка находится в среде выполнения, которую вы выбрали для запуска скрипта, а не в локальной папке проекта. 
   
   - Чтобы найти файл, нажмите кнопку **Запуски** (значок часов) на панели слева для отображения списка **Все запуски**.  
   - Откроется вкладка **Все запуски**. В таблице выберите один из последних запусков, для которого были указаны целевой объект **local** (локально) и имя сценария **iris_sklearn.py**. 
   - Откроется панель **свойств запуска**. В верхней правой части этой панели вы увидите раздел **Выходные данные**. 
   - Загрузите сериализованный файл, установив флажок рядом с файлом **model.pkl** и нажав кнопку **Загрузить**. Сохраните файл в корневую папку проекта. Файл потребуется при выполнении дальнейших действий.

   ![Загрузка сериализованного файла](media/tutorial-classifying-iris/download_model.png)

   Дополнительные сведения о папке `outputs` см. в статье о [чтении и записи больших файлов данных](how-to-read-write-files.md).

## <a name="get-the-scoring-script-and-schema-files"></a>Получение скрипта оценки и файлов схемы
Для развертывания веб-службы вам потребуется не только файл модели, но и скрипт оценки. По желанию вы можете добавить к ним схему входных данных веб-службы. Скрипт оценки загружает файл **model.pkl** из текущей папки и использует его для создания прогнозируемого класса Iris.  

1. Запустите приложение Azure Machine Learning Workbench и откройте проект **myIris**, созданный в предыдущей части этой серии руководств.

2. Открыв проект, нажмите кнопку **Файлы** на панели слева, чтобы в папке проекта отобразился список файлов.

3. Выберите файл **score_iris.py**. Откроется скрипт Python. Этот файл используется как файл оценки.

   ![Файл оценки](media/tutorial-classifying-iris/model_data_collection.png)

4. Чтобы получить файл схемы, запустите этот скрипт. Выберите на панели команд среду **local** (локальная) и скрипт **score_iris.py**, а затем нажмите кнопку **Выполнить**. 

5. При помощи этого скрипта разделе **Выходные данные** создается JSON-файл со схемой входных данных для нашей модели.

6. Обратите внимание на панель **Задания** справа на **панели мониторинга проекта**. Подождите, пока для состояния последнего задания **score_iris.py** не отобразится надпись **Выполнено** зеленого цвета. После этого перейдите по гиперссылке **score_iris.py [1]** рядом с данными последнего запуска задания, чтобы просмотреть сведения о выполнении запуска **score_iris.py**. 

7. На панели **свойств запуска** в разделе **Выходные данные** выберите только что созданный файл **service_schema.json**.  Установите флажок рядом с именем файла и выберите **Загрузить**. Сохраните этот файл в корневой папке проекта.

8. Вернитесь к предыдущей вкладке, где вы открыли скрипт **score_iris.py**. Использование коллекции данных позволяет сохранять входные данные модели и прогнозы веб-службы. Для сбора данных особое значение имеют следующие этапы.

9. Изучите код в верхней части файла для импорта класса **ModelDataCollector**, который предназначен для сбора данных модели:

   ```python
   from azureml.datacollector import ModelDataCollector
   ```

10. Изучите следующий код функции **init()**, при помощи которого создается **ModelDataCollector**:

   ```python
   global inputs_dc, prediction_dc
   inputs_dc = ModelDataCollector('model.pkl',identifier="inputs")
   prediction_dc = ModelDataCollector('model.pkl', identifier="prediction")`
   ```

11. Изучите приведенный ниже код функции **run(input_df)**, предназначенный для сбора входных данных и прогнозов:

   ```python
   global clf2, inputs_dc, prediction_dc
   inputs_dc.collect(input_df)
   prediction_dc.collect(pred)
   ```

Теперь можно приступить к подготовке среды для ввода модели в эксплуатацию.



## <a name="prepare-to-operationalize-locally"></a>Подготовка к вводу в эксплуатацию в локальной среде
Используйте развертывание в _локальном режиме_, чтобы запустить контейнер Docker на локальном компьютере.

_Локальный режим_ удобно использовать для разработки и тестирования. Чтобы выполнить следующие действия, требуется локально запущенная подсистема Docker. Чтобы получить справку по команде, добавьте в конце строки флаг `-h`.

>[!NOTE]
>Если у вас нет локальной подсистемы Docker, создайте для развертывания кластер в Azure. Не забудьте удалить этот кластер после завершения работы с руководством, чтобы не оплачивать его использование.

1. Откройте интерфейс командной строки (CLI).
   В приложении Azure Machine Learning Workbench в меню **Файл** выберите **Открыть командную строку**.

   Откроется окно командной строки, где текущим каталогом будет папка проекта **c:\temp\myIris>**.

2. Убедитесь, что поставщик ресурсов Azure **Microsoft.ContainerRegistry** зарегистрирован в вашей подписке. Зарегистрировать этот поставщик ресурсов нужно до создания среды на шаге 3. С помощью следующей команды вы можете проверить, зарегистрирован ли он:
   ``` 
   az provider list --query "[].{Provider:namespace, Status:registrationState}" --out table 
   ``` 

   Вы должны увидеть примерно такой результат: 
   ```
   Provider                                  Status 
   --------                                  ------
   Microsoft.Authorization                   Registered 
   Microsoft.ContainerRegistry               Registered 
   microsoft.insights                        Registered 
   Microsoft.MachineLearningExperimentation  Registered 
   ... 
   ```
   
   Если поставщик **Microsoft.ContainerRegistry** не зарегистрирован, используйте эту команду:
   ``` 
   az provider register --namespace Microsoft.ContainerRegistry 
   ```
   Регистрация может занять несколько минут. Можно проверить ее состояние с помощью команды **az provider list** или следующей команды:
   ``` 
   az provider show -n Microsoft.ContainerRegistry 
   ``` 

   В третьей строке выходных данных отображается статус регистрации: **"registrationState": "Registering"**. Подождите немного и повторяйте команду **show**, пока в выходных данных не отобразится состояние **"registrationState": "Registered"**.

3. Создайте среду. Этот шаг однократно выполняется для каждой среды. Например, он один раз выполняется для среды разработки и один раз — для производства. Для первой среды используйте _локальный режим_. Позже вы можете подставить в эту команду параметры `-c` или `--cluster`, чтобы настроить среду в _режиме кластера_.

   Обратите внимание: для следующей команды установки требуется разрешение на доступ к подписке уровня участника. Если такого разрешения нет, требуется хотя бы соответствующее разрешение на доступ к группе ресурсов, в которую выполняется развертывание. Для этого вам нужно указать имя группы ресурсов как часть команды установки с помощью флага `-g`. 

   ```azurecli
   az ml env setup -n <new deployment environment name> --location <e.g. eastus2>
   ```
   
   Следуйте инструкциям на экране, чтобы подготовить учетную запись хранения для образов Docker, реестр контейнеров Azure для списка образов Docker и учетную запись AppInsight для сбора данных телеметрии. Если вы использовали параметр `-c`, будет создан еще и кластер Службы контейнеров Azure.
   
   Среду можно определить с помощью имени кластера. Расположение должно совпадать с тем, которое вы указали при создании учетной записи службы "Управление моделями" на портале Azure.

4. Создайте учетную запись службы "Управление моделями". (Выполнить эту операцию достаточно один раз.)  
   ```azurecli
   az ml account modelmanagement create --location <e.g. eastus2> -n <new model management account name> -g <existing resource group name> --sku-name S1
   ```
   
5. Настройте учетную запись службы "Управление моделями".  
   ```azurecli
   az ml account modelmanagement set -n <youracctname> -g <yourresourcegroupname>
   ```

6. Настройте среду.

   После установки с помощью приведенной ниже команды задайте переменные среды, которые нужны для ее ввода в эксплуатацию. Используйте то же имя среды, что и ранее на шаге 4. После установки используйте имя группы ресурсов, которое отображалось в окне команды.

   ```azurecli
   az ml env set -n <deployment environment name> -g <existing resource group name>
   ```

7. Чтобы проверить, правильно ли настроена среда реализации для локального развертывания веб-службы, введите следующую команду:

   ```azurecli
   az ml env show
   ```

Теперь все готово для создания веб-службы в режиме реального времени.

>[!NOTE]
>Учетную запись и среду службы "Управление моделями" можно повторно использовать для последующего развертывания веб-служб. Не нужно создавать их для каждой веб-службы. С учетной записью или средой может быть связано несколько веб-служб.

## <a name="create-a-real-time-web-service-in-one-command"></a>Создание веб-службы в режиме реального времени с помощью одной команды
1. Создайте веб-службу в режиме реального времени, используя следующую команду:

   ```azurecli
   az ml service create realtime -f score_iris.py --model-file model.pkl -s service_schema.json -n irisapp -r python --collect-model-data true 
   ```
   При помощи этой команды создается идентификатор веб-службы, который понадобится позднее.

   С командой **az ml service create realtime** используются следующие параметры:
   * `-n`: имя приложения (только в нижнем регистре).
   * `-f`: имя файла для скрипта оценки.
   * `--model-file`: файл модели. В нашем случае это сериализованный файл model.pkl.
   * `-r`: тип модели. В нашем случае это модель Python.
   * `--collect-model-data true`: включает сбор данных.

   >[!IMPORTANT]
   >Имя службы (которое совпадает с именем нового образа Docker) может содержать только строчные буквы. В противном случае возникает ошибка. 

2. С помощью этой команды модель и файл оценки передаются в учетную запись хранения, созданную при настройке среды. В процессе развертывания создается образ Docker, который содержит вашу модель, схему и файл оценки. Затем образ передается в реестр контейнеров Azure: **\<ACR_name\>.azureacr.io/\<imagename\>:\<version\>**. 

   При помощи этой команды образ переносится на локальный компьютер. Затем запускается контейнер Docker, созданный на основе этого образа. Если среда настроена в режиме кластера, контейнер Docker развертывается в кластер Kubernetes в облачных службах Azure.

   В процессе этого развертывания на локальной машине создается конечная точка HTTP REST для веб-службы. Через несколько минут должно отобразиться сообщение об успешном выполнении команды. Теперь веб-служба готова к работе.

3. Чтобы отобразился контейнер Docker, выполните команду **docker ps**:
   ```azurecli
   docker ps
   ```

## <a name="create-a-real-time-web-service-by-using-separate-commands"></a>Создание веб-службы в режиме реального времени с помощью отдельных команд
Вместо команды **az ml service create realtime**, представленной выше, можно выполнить действия по отдельности. 

Сначала зарегистрируйте модель. Затем создайте манифест, соберите образ Docker и создайте веб-службу. Этот пошаговый подход предоставляет больше гибкости. Кроме того, вы можете повторно использовать создаваемые сущности, чтобы перестраивать их только при необходимости.

1. Зарегистрируйте модель, указав имя сериализованного файла.

   ```azurecli
   az ml model register --model model.pkl --name model.pkl
   ```
   После выполнения этой команды вы получите идентификатор модели.

2. Создайте манифест.

   Чтобы создать манифест, используйте следующую команду с идентификатором модели, полученным на предыдущем этапе:

   ```azurecli
   az ml manifest create --manifest-name <new manifest name> -f score_iris.py -r python -i <model ID> -s service_schema.json
   ```
   После выполнения этой команды вы получите идентификатор манифеста.

3. Создайте образ Docker.

   Чтобы создать образ Docker, используйте следующую команду с идентификатором манифеста, полученным на предыдущем этапе:

   ```azurecli
   az ml image create -n irisimage --manifest-id <manifest ID>
   ```
   После выполнения этой команды вы получите идентификатор образа Docker.
   
4. Создайте службу.

   Чтобы создать службу, используйте следующую команду с идентификатором образа, полученным на предыдущем этапе:

   ```azurecli
   az ml service create realtime --image-id <image ID> -n irisapp --collect-model-data true
   ```
   После выполнения этой команды вы получите идентификатор веб-службы.

Теперь все готово к запуску веб-службы.

## <a name="run-the-real-time-web-service"></a>Запуск веб-службы в режиме реального времени

Чтобы проверить работу веб-службы **irisapp**, используйте запись в кодировке JSON, содержащую массив из четырех случайных чисел:

1. Веб-служба включает примеры данных. Если вы работаете в локальном режиме, вызовите команду **az ml service usage realtime**. После этого вызова вы получите пример выполнения команды, с помощью которого можно протестировать службу. Также вы получите URL-адрес для оценки, с помощью которого службу можно внедрить в пользовательское приложение:

   ```azurecli
   az ml service usage realtime -i <web service ID>
   ```

2. Чтобы проверить службу, выполните полученную команду запуска:

   ```azurecli
   az ml service run realtime -i irisapp -d "{\"input_df\": [{\"petal width\": 0.25, \"sepal length\": 3.0, \"sepal width\": 3.6, \"petal length\": 1.3}]}"
   ```
   Выходные данные будут содержать прогнозируемый класс **"2"**. Вы можете получить другой результат. 

3. Чтобы использовать службу вне интерфейса командной строки, получите ключи для аутентификации:

   ```azurecli
   az ml service keys realtime -i <web service ID>
   ```

## <a name="view-the-collected-data-in-azure-blob-storage"></a>Просмотр собранных данных в хранилище BLOB-объектов Azure

1. Выполните вход на [портал Azure](https://portal.azure.com).

2. Перейдите к учетным записям хранения. Для этого выберите **Другие службы**.

3. В поле поиска введите **учетные записи хранения** и нажмите клавишу **ВВОД**.

4. В поле поиска по фразе **учетные записи хранения** выберите ресурс **учетной записи хранения**, соответствующий целевой среде. 

   > [!TIP]
   > Чтобы определить, какая учетная запись хранения используется:
   > 1. Откройте Azure Machine Learning Workbench.
   > 2. Выберите проект, над которым работаете.
   > 3. Откройте командную строку из меню **Файл**.
   > 4. В командной строке введите `az ml env show -v` и проверьте значение *storage_account*. Это и есть имя учетной записи хранения.

5. Когда откроется панель **Учетная запись хранилища**, выберите **Контейнеры** в списке слева. Найдите контейнер с именем **modeldata**. 
 
   Если данные не отображаются, подождите немного. После первого запроса к веб-службе может пройти до 10 минут, прежде чем начнется передача данных в учетную запись хранения.

   Потоки данных передаются в большие двоичные объекты по следующему пути контейнера:

   ```
   /modeldata/<subscription_id>/<resource_group_name>/<model_management_account_name>/<webservice_name>/<model_id>-<model_name>-<model_version>/<identifier>/<year>/<month>/<day>/data.csv
   ```

6. Вы можете использовать эти данные из хранилища BLOB-объектов Azure. Программное обеспечение Майкрософт и средства с открытым кодом можно использовать разными способами:

   - Служба "Машинное обучение Azure". Откройте CSV-файл, добавив его как источник данных. 
   - Excel. Откройте CSV-файлы с данными за день в качестве электронной таблицы.
   - [Power BI.](https://powerbi.microsoft.com/documentation/powerbi-azure-and-power-bi/) Создавайте диаграммы на основе данных, извлеченных из CSV-файлов в больших двоичных объектах.
   - [Hive.](https://docs.microsoft.com/azure/hdinsight/hdinsight-hadoop-linux-tutorial-get-started) Загрузите данные в формате CSV в таблицу Hive и подавайте SQL-запросы непосредственно в большой двоичный объект.
   - [Spark.](https://docs.microsoft.com/azure/hdinsight/hdinsight-apache-spark-overview) Создайте кадр данных с большим сегментом данных в формате CSV.

      ```python
      var df = spark.read.format("com.databricks.spark.csv").option("inferSchema","true").option("header","true").load("wasb://modeldata@<storageaccount>.blob.core.windows.net/<subscription_id>/<resource_group_name>/<model_management_account_name>/<webservice_name>/<model_id>-<model_name>-<model_version>/<identifier>/<year>/<month>/<date>/*")
      ```


## <a name="next-steps"></a>Дальнейшие действия
Из заключительной третьей части этой серии руководств вы узнали, как с помощью службы "Машинное обучение Azure" выполнять следующие задания:
> [!div class="checklist"]
> * поиск файла модели;
> * создание скрипта оценки и файла схемы;
> * подготовка среды;
> * создание веб-службы в режиме реального времени;
> * запуск веб-службы в режиме реального времени;
> * изучение выходных данных в формате больших двоичных объектов. 

Вы успешно запустили скрипт обучения в нескольких средах вычислений, создали модель, сериализовали эту модель и ввели в эксплуатацию через веб-службу на базе Docker. 

Теперь можно переходить к расширенной подготовке данных:
> [!div class="nextstepaction"]
> [Advanced data preparation](tutorial-bikeshare-dataprep.md) (Расширенная подготовка данных)
