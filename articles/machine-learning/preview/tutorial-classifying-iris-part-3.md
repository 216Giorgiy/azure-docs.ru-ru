---
title: "Развертывание модели для службы \"Машинное обучение Azure\" (предварительная версия) | Документация Майкрософт"
description: "В этом полном руководстве описано, как использовать службу \"Машинное обучение Azure\" (предварительная версия). Часть 3 посвящена развертыванию модели."
services: machine-learning
author: raymondl
ms.author: raymondl, aashishb
manager: mwinkle
ms.reviewer: garyericson, jasonwhowell, mldocs
ms.service: machine-learning
ms.workload: data-services
ms.custom: mvc, tutorial
ms.topic: hero-article
ms.date: 09/25/2017
ms.translationtype: HT
ms.sourcegitcommit: 44e9d992de3126bf989e69e39c343de50d592792
ms.openlocfilehash: 0dfcc965d96949527b3e80285061bff320872621
ms.contentlocale: ru-ru
ms.lasthandoff: 09/25/2017

---

# <a name="classifying-iris-part-3-deploy-a-model"></a>Часть 3. Классификация цветков ириса: развертывание модели
Служба "Машинное обучение Azure" (предварительная версия) — это полнофункциональное интегрированное аналитическое решение для специалистов по обработке данных. Оно помогает подготавливать данные, разрабатывать эксперименты и развертывать модели в масштабе облака.

Это руководство представляет собой третью, заключительную часть серии. В этой части вы будете использовать службу "Машинное обучение Azure" (предварительная версия), чтобы научиться выполнять следующие задачи:

> [!div class="checklist"]
> * поиск файла модели;
> * создание скрипта оценки и файла схемы;
> * Подготовка среды
> * создание веб-службы в режиме реального времени;
> * запуск веб-службы в режиме реального времени;
> * изучение выходных данных в формате больших двоичных объектов. 

 В этом руководстве для простоты используется классический набор данных —[ирисы Фишера](https://en.wikipedia.org/wiki/iris_flower_data_set). Снимки экрана представляют среду Windows, но для macOS все процедуры являются практически идентичными.

## <a name="prerequisites"></a>Предварительные требования
Выполните инструкции первых двух частей этой серии руководств.
- Сначала выполните инструкции из руководства по [подготовке данных](tutorial-classifying-iris-part-1.md), чтобы создать ресурсы службы "Машинное обучение Azure" и установить приложение Azure Machine Learning Workbench.
- Затем выполните руководство по [сборке модели](tutorial-classifying-iris-part-2.md), чтобы создать модель логистической регрессии в службе "Машинное обучение Azure" Azure.

## <a name="download-the-model-pickle-file"></a>Загрузка файла, содержащего модель
В предыдущей части этого руководства мы локально выполнили скрипт `iris_sklearn.py` в Azure Machine Learning Workbench. Этот скрипт выполнил сериализацию модели логистической регрессии с помощью популярного пакета Python **[pickle](https://docs.python.org/2/library/pickle.html)** для сериализации объектов. 

1. Запустите приложение **Azure Machine Learning Workbench** и откройте проект **myIris**, созданный в предыдущей части этой серии руководств.

2. В открытом проекте щелкните **Файлы** (значок папки) на панели инструментов слева в Azure Machine Learning Workbench, чтобы открыть список файлов в папке проекта.

3. Выберите файл **iris_sklearn.py**. Откроется код Python на новой вкладке текстового редактора в Workbench.

4. Просмотрите **iris_sklearn.py** файл и найдите, где создан сериализованный файл. Нажмите сочетание клавиш CTRL+F, чтобы открыть диалоговое окно поиска. Затем найдите в коде слово **pickle**.

   Этот фрагмент кода показывает, как создан сериализованный выходной файл. Обратите внимание, что выходной файл на диске называется `model.pkl`. 

   ```python
   print("Export the model to model.pkl")
   f = open('./outputs/model.pkl', 'wb')
   pickle.dump(clf1, f)
   f.close()
   ```

5. Найдите сериализованный файл модели в списке выходных файлов последнего запуска.
   
   Когда вы выполнили скрипт **iris_sklearn.py**, файл модели был сохранен в папке `outputs` с именем `model.pkl`. Эта папка находится в среде выполнения, которую вы выбрали для запуска скрипта, а не в локальной папке проекта. 
   
   - Чтобы найти файл, используйте приложение Azure Machine Learning Workbench. Щелкните на панели инструментов слева кнопку **Запуски** (значок часов), которая открывает список **Все запуски**.  
   - Откроется вкладка **Все запуски**. В таблице запусков выберите один из последних запусков, для которого были указаны целевой объект **local** (локально) и имя сценария **iris_sklearn.py**. 
   - Откроется страница **свойства запуска**. В верхнем правом углу этой страницы вы увидите раздел **Выходные данные**. 
   - Загрузите сериализованный файл, установив флажок рядом с файлом **model.pkl** и нажав кнопку **Загрузить**. Сохраните файл в корневую папку проекта. Он потребуется позже.

   ![Загрузка сериализованного файла](media/tutorial-classifying-iris/download_model.png)

   Дополнительные сведения о папке `outputs` см. в статье о [чтении и записи больших файлов данных](how-to-read-write-files.md).

## <a name="get-scoring-and-schema-files"></a>Получение файлов оценки и схемы
Для развертывания веб-службы вам потребуется не только файл модели, но и скрипт оценки. По желанию вы можете к ним добавить схему входных данных веб-службы. Скрипт оценки загружает файл `model.pkl` из текущей папки и использует его для создания нового класса ирисов Фишера с прогнозами.  

1. Запустите приложение **Azure Machine Learning Workbench** и откройте проект **myIris**, созданный в предыдущей части этой серии руководств.

2. В открытом проекте щелкните **Файлы** (значок папки) на панели инструментов слева в Azure Machine Learning Workbench, чтобы открыть список файлов в папке проекта.

3. Выберите файл **iris_score.py**. Откроется скрипт Python. Этот файл используется как файл оценки.

4. Чтобы получить файл схемы, запустите этот скрипт. Выберите на панели команд среду **local** (локальная) и скрипт **iris_score.py**, а затем нажмите кнопку **Выполнить**. 

5. Этот скрипт создает в папке **outputs** (выходные данные) JSON-файл со схемой входных данных, которые нужны для нашей модели.

   ![Файл оценки](media/tutorial-classifying-iris/model_data_collection.png)

6. В области заданий в правой части окна Machine Learning Workbench отображается последнее задание **iris_score.py**. Дождитесь, пока оно перейдет в состояние **Завершено**, обозначаемое зеленым цветом. После этого перейдите по гиперссылке **iris_score.py [1]** рядом с последним запуском задания, чтобы просмотреть сведения о выполнении этого запуска **iris_score.py**. 

7. На странице свойств запуска в разделе **Выходные данные** выберите только что созданный файл **service_schema.json**. Сохраните этот файл в корневой папке проекта.

8. Вернитесь на вкладку, где вы открыли скрипт **iris_score.py**. 

   Обратите внимание, что использование коллекции данных позволяет сохранять входные данные модели и прогнозы веб-службы. Для сбора данных особенное значение имеют следующие факторы.

9. Изучите код в верхней части файла, который импортирует файл ModelDataCollector с функциями сбора данных модели:

   ```python
   from azureml.datacollector import ModelDataCollector
   ```

10. Изучите приведенный ниже код функции `init()`, который создает ModelDataCollector:

   ```python
   global inputs_dc, prediction_dc
   inputs_dc = ModelDataCollector('model.pkl',identifier="inputs")
   prediction_dc = ModelDataCollector('model.pkl', identifier="prediction")`
   ```

11. Изучите приведенный ниже код функции `run(input_df)`, который собирает входные данные и прогнозы:

   ```python
   global clf2, inputs_dc, prediction_dc
   inputs_dc.collect(input_df)
   prediction_dc.collect(pred)
   ```

Теперь можно начать подготовку среды для ввода модели в эксплуатацию.

## <a name="prepare-to-operationalize-locally"></a>Подготовка к вводу в эксплуатацию в локальной среде
Используйте развертывание в _локальном режиме_, чтобы запустить контейнер Docker на локальном компьютере.

_Локальный режим_ удобно использовать для разработки и тестирования. Локально запущенная подсистема Docker потребуется, чтобы выполнить следующие действия. Чтобы получить справку по команде, добавьте в конце строки флаг `-h`.

>[!NOTE]
>Если у вас нет локальной подсистемы Docker, создайте для развертывания кластер в Azure. Не забудьте удалить этот кластер после завершения работы с руководством, чтобы не оплачивать его использование.

1. Откройте интерфейс командной строки в Azure Machine Learning Workbench и щелкните пункт **Открыть командную строку** в меню "Файл".

   Откроется приглашение командной строки, где текущим каталогом будет папка проекта `c:\temp\myIris>`.

2. Убедитесь, что поставщик ресурсов Azure `Microsoft.ContainerRegistry`зарегистрирован в вашей подписке. Этот поставщик ресурсов нужно зарегистрировать до создания среды на этапе 3. С помощью следующей команды вы можете проверить, зарегистрирован ли он.
   ``` 
   az provider list --query "[].{Provider:namespace, Status:registrationState}" --out table 
   ``` 

   Должен отобразиться примерно такой результат: 
   ```
   Provider                                  Status 
   --------                                  ------
   Microsoft.Authorization                   Registered 
   Microsoft.ContainerRegistry               Registered 
   microsoft.insights                        Registered 
   Microsoft.MachineLearningExperimentation  Registered 
   ... 
   ```
   
   Если `Microsoft.ContainerRegistry` не зарегистрирован, используйте эту команду:
   ``` 
   az provider register --namespace Microsoft.ContainerRegistry 
   ```
   Регистрация может занять несколько минут, а ее состояние вы можете проверить с помощью указанной выше команды `az provider list` или другой команды:
   ``` 
   az provider show -n Microsoft.ContainerRegistry 
   ``` 

3. Создайте среду. Этот шаг нужно выполнить один раз для каждой среды, например для среды разработки или среды эксплуатации. Для первой среды используйте _локальный режим_. (Позже вы можете подставить в эту команду параметры `-c` или `--cluster`, чтобы настроить среду в _режиме кластера_).

   ```azurecli
   az ml env setup -n <new deployment environment name> --location <e.g. eastus2>
   ```
   
   Следуйте инструкциям на экране, чтобы подготовить учетную запись хранения для образов Docker, реестр контейнеров Azure (ACR) для списка образов Docker и учетную запись AppInsight для сбора данных телеметрии. Если вы использовали параметр `-c`, будет создан еще и кластер ACS (Службы контейнеров Azure).
   
   Имя кластера используется для идентификации среды. Расположение должно совпадать с тем, которое вы указали при создании учетной записи управления моделями на портале Azure.

4. Создание учетной записи управления моделями (выполняется однократно)  
   ```azurecli
   az ml account modelmanagement create --location <e.g. eastus2> -n <new model management account name> -g <existing resource group name> --sku-name S1
   ```
   
5. Настройка учетной записи управления моделями  
   ```azurecli
   az ml account modelmanagement set -n <youracctname> -g <yourresourcegroupname>
   ```

6. Настройте среду.
После завершения установки с помощью следующей команды задайте переменные среды, которые нужны для ввода в эксплуатацию. Имя среды совпадает с тем, которое использовалось выше на этапе 1. Имя группы ресурсов мы получили в выходных данных того же процесса. После завершения процесса установки это имя отображается в окне командной строки.
   ```azurecli
   az ml env set -n <deployment environment name> -g <existing resource group name>
   ```

   Чтобы проверить, правильно ли настроена среда ввода в эксплуатацию для локального развертывания веб-службы, введите следующую команду:

   ```azurecli
   az ml env show
   ```

Теперь все готово для создания веб-службы в реальном времени.

## <a name="create-a-real-time-web-service"></a>Создание веб-службы в режиме реального времени
Создайте веб-службу в режиме реального времени, используя следующую команду.

   ```azurecli
   az ml service create realtime -f iris_score.py --model-file model.pkl -s service_schema.json -n irisapp -r python --collect-model-data true 
   ```
   Этот код создает идентификатор веб-службы, который понадобится позднее.

   Команда `az ml service create realtime` использует следующие параметры:
   * -n: имя приложения в нижнем регистре;
   * -f: имя файла скрипта оценки;
   * --model-file: файл модели, для нашего примера это файл model.pkl;
   * -r: тип модели, в данном случае это модель python;
   * --collect-model-data true: активирует сбор данных.

   >[!IMPORTANT]
   >Имя службы (которое совпадает с именем нового образа Docker) может содержать только строчные буквы, в противном случае появится сообщение об ошибке. 

   При выполнении этой команды модель и файл оценки передаются в учетную запись хранения, созданную ранее в процессе настройки среды. Процесс развертывания создает образ Docker, содержащий вашу модель, схему и файл оценки, а затем передает его в реестр ACR: `<ACR_name>.azureacr.io/<imagename>:<version>`. Затем он забирает этот образ на локальный компьютер и запускает контейнер Docker, созданный на основе этого образа. Если среда настроена в режиме кластера, контейнер Docker развертывается в кластер ACS Kubernetes.

   В процессе этого развертывания на локальной машине создается конечная точка HTTP REST для веб-службы. Через несколько минут команда завершается сообщением об успешном выполнении. Теперь веб-служба готова к работе.

   Чтобы увидеть контейнер Docker, выполните эту команду: `docker ps`
   ```azurecli
   docker ps
   ```
### <a name="alternative-route"></a>Альтернативный метод
Вместо описанной выше команды `az ml service create realtime` вы можете выполнять все этапы отдельно: регистрацию модели, создание манифеста, сборку образа Docker и создание веб-службы. Это даст вам больше гибкости на каждом этапе, а также позволит повторно использовать создаваемые сущности, чтобы перестраивать их только при необходимости. Чтобы использовать этот метод, следуйте приведенным ниже инструкциям.

1. Зарегистрируйте модель, указав имя сериализованного файла.

   ```azurecli
   az ml model register --model model.pkl --name model.pkl
   ```
   Вы получите идентификатор модели.

2. Создайте манифест.

   Чтобы создать манифест, используйте следующую команду с идентификатором модели, полученным на предыдущем этапе.

   ```azurecli
   az ml manifest create --manifest-name <new manifest name> -f iris_score.py -r python -i <model ID> -s service_schema.json
   ```
   Вы получите идентификатор манифеста.

3. Создайте образ Docker.

   Чтобы создать образ Docker, используйте следующую команду с идентификатором манифеста, полученным на предыдущем этапе.

   ```azurecli
   az ml image create -n irisimage --manifest-id <manifest ID>
   ```
   В ответ вы получите идентификатор образа Docker.
   
4. Создание службы

   Чтобы создать службу, используйте следующую команду с идентификатором образа, полученным на предыдущем этапе.

   ```azurecli
   az ml service create realtime --image-id <image ID> -n irisapp --collect-model-data true
   ```
   В ответ вы получите идентификатор веб-службы.

Теперь все готово к запуску веб-службы.

## <a name="run-the-real-time-web-service"></a>Запуск веб-службы в режиме реального времени

Чтобы проверить работу веб-службы `irisapp`, передайте ей запись в кодировке JSON, содержащую массив из четырех случайных чисел.

1. Создание веб-службы включает примеры данных. При работе в локальном режиме вы можете вызвать `az ml service show realtime`, чтобы получить пример выполнения команды для тестирования службы. Одновременно с ним вы получите URL-адрес для оценки, с помощью которого службу можно внедрить в пользовательское приложение:

   ```azurecli
   az ml service show realtime -i <web service ID>
   ```

2. Чтобы проверить службу, выполните полученную команду запуска.

   ```azurecli
   az ml service run realtime -i irisapp -d "{\"input_df\": [{\"petal width\": 0.25, \"sepal length\": 3.0, \"sepal width\": 3.6, \"petal length\": 1.3}]}
   ```
   Выходные данные будут содержать прогнозируемый класс: `"2"`. Вы можете получить другой результат. 

3. Если вы хотите использовать службу вне интерфейса командной строки, получите ключи для аутентификации:

   ```azurecli
   az ml service keys realtime -i <web service ID>
   ```

## <a name="view-the-collected-data-in-azure-blob-storage"></a>Просмотр собранных данных в хранилище больших двоичных объектов Azure

1. Войдите на [портал Azure](https://portal.azure.com).

2. Перейдите к учетным записям хранения. Для этого выберите раздел **Другие службы**.

3. В поле поиска введите **учетные записи хранения** и нажмите клавишу **ВВОД**.

4. На странице результатов поиска по фразе **учетные записи хранения** выберите ресурс **учетной записи хранения**, соответствующий целевой среде. 

   > [!TIP]
   > Чтобы определить, какая учетная запись хранения используется, откройте Azure Machine Learning Workbench, выберите нужный проект и откройте окно командной строки через меню **Файл**. В приглашении командной строки введите `az ml env show -v`, вы получите значение *storage_account*. Это и есть имя учетной записи хранения.

5. После открытия страницы **учетной записи хранения** щелкните элемент **Контейнеры** в списке слева. Найдите контейнер с именем **modeldata**. 
 
   Если данные не отображаются, подождите немного. После первого запроса к веб-службе может пройти до 10 минут до начала передачи данных в учетную запись хранения.

   Потоки данных передаются в большие двоичные объекты по следующему пути контейнера:

   `/modeldata/<subscription_id>/<resource_group_name>/<model_management_account_name>/<webservice_name>/<model_id>-<model_name>-<model_version>/<identifier>/<year>/<month>/<day>/data.csv`

6. Эти данные вы можете извлекать из BLOB-объектов Azure разными способами с применением программного обеспечения корпорации Майкрософт или средств с открытым исходным кодом. 

   Вот несколько примеров использования полученных больших двоичных объектов.
   - Azure ML Workbench. Откройте CSV-файл в Azure ML Workbench, добавив его в качестве источника данных. 
   - Excel. Откройте CSV-файл с данными за день в качестве электронной таблицы.
   - [Power BI](https://powerbi.microsoft.com/documentation/powerbi-azure-and-power-bi/). Создайте диаграмму на основе данных, извлеченных из CSV-файлов в больших двоичных объектах.
   - [Spark](https://docs.microsoft.com/azure/hdinsight/hdinsight-apache-spark-overview). Создайте кадр данных с крупным сегментом данных в формате CSV.

      ```python
      var df = spark.read.format("com.databricks.spark.csv").option("inferSchema","true").option("header","true").load("wasb://modeldata@<storageaccount>.blob.core.windows.net/<subscription_id>/<resource_group_name>/<model_management_account_name>/<webservice_name>/<model_id>-<model_name>-<model_version>/<identifier>/<year>/<month>/<date>/*")
      ```
   - [Hive](https://docs.microsoft.com/azure/hdinsight/hdinsight-hadoop-linux-tutorial-get-started). Загрузите данные в формате CSV в таблицу Hive и выполняйте SQL-запросы прямо к большому двоичному объекту.

## <a name="next-steps"></a>Дальнейшие действия
Из заключительной третьей части этой серии руководств вы узнали, как с помощью службы "Машинное обучение Azure" выполнять следующие задания:
> [!div class="checklist"]
> * поиск файла модели;
> * создание скрипта оценки и файла схемы;
> * Подготовка среды
> * создание веб-службы в режиме реального времени;
> * запуск веб-службы в режиме реального времени;
> * изучение выходных данных в формате больших двоичных объектов. 

Вы успешно запустили скрипт обучения в нескольких средах вычислений, создали модель, сериализовали эту модель и ввели в эксплуатацию через веб-службу на базе Docker. 

Теперь можно переходить к расширенной подготовке данных.
> [!div class="nextstepaction"]
> [Advanced data preparation](tutorial-bikeshare-dataprep.md) (Расширенная подготовка данных)


