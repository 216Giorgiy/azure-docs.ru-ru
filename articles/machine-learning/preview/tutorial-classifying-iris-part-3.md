---
title: "Развертывание модели для службы \"Машинное обучение Azure\" (предварительная версия) | Документация Майкрософт"
description: "В этом полном руководстве описано, как использовать службу \"Машинное обучение Azure\" (предварительная версия). Часть 3 посвящена развертыванию модели."
services: machine-learning
author: raymondl
ms.author: raymondl, aashishb
manager: mwinkle
ms.reviewer: garyericson, jasonwhowell, mldocs
ms.service: machine-learning
ms.workload: data-services
ms.custom: mvc, tutorial
ms.topic: hero-article
ms.date: 09/27/2017
ms.openlocfilehash: 2325d0ffd369d85b9a21e2274a98dcb673d240e7
ms.sourcegitcommit: 6699c77dcbd5f8a1a2f21fba3d0a0005ac9ed6b7
ms.translationtype: HT
ms.contentlocale: ru-RU
ms.lasthandoff: 10/11/2017
---
# <a name="classifying-iris-part-3-deploy-a-model"></a>Часть 3. Классификация цветков ириса: развертывание модели
Служба "Машинное обучение Azure" (предварительная версия) — это полнофункциональное интегрированное аналитическое решение для специалистов по обработке данных. Оно помогает подготавливать данные, разрабатывать эксперименты и развертывать модели в масштабе облака.

Это руководство представляет собой третью, заключительную часть серии. В этой части вы будете использовать службу "Машинное обучение Azure" (предварительная версия), чтобы научиться выполнять следующие задачи:

> [!div class="checklist"]
> * поиск файла модели;
> * создание скрипта оценки и файла схемы;
> * Подготовка среды
> * Создание веб-службы в режиме реального времени
> * запуск веб-службы в режиме реального времени;
> * изучение выходных данных в формате больших двоичных объектов. 

 В этом руководстве для простоты используется классический набор данных —[ирисы Фишера](https://en.wikipedia.org/wiki/iris_flower_data_set). Снимки экрана представляют среду Windows, но для macOS все процедуры практически идентичны.

## <a name="prerequisites"></a>Предварительные требования
Выполните инструкции первых двух частей этой серии руководств.

1. Выполните инструкции из руководства по [подготовке данных](tutorial-classifying-iris-part-1.md), чтобы создать ресурсы службы "Машинное обучение Azure" и установить приложение Azure Machine Learning Workbench.

2. Выполните руководство по [сборке модели](tutorial-classifying-iris-part-2.md), чтобы создать модель логистической регрессии в службе "Машинное обучение Azure".

3. У вас должен быть установлен и локально запущен модуль Docker. Кроме того, можно выполнить развертывание в кластер Службы контейнеров Azure в Azure.

## <a name="download-the-model-pickle-file"></a>Загрузка файла, содержащего модель
В предыдущей части этого руководства мы локально выполнили скрипт **iris_sklearn.py** в Azure Machine Learning Workbench. Этот скрипт выполнил сериализацию модели логистической регрессии с помощью популярного пакета Python **[pickle](https://docs.python.org/2/library/pickle.html)** для сериализации объектов. 

1. Запустите приложение **Azure Machine Learning Workbench** и откройте проект **myIris**, созданный в предыдущей части этой серии руководств.

2. В открытом проекте щелкните **Файлы** (значок папки) на панели инструментов слева в Azure Machine Learning Workbench, чтобы открыть список файлов в папке проекта.

3. Выберите файл **iris_sklearn.py**. Откроется код Python на новой вкладке текстового редактора в Workbench.

4. Просмотрите **iris_sklearn.py** файл и найдите, где создан сериализованный файл. Нажмите сочетание клавиш CTRL+F, чтобы открыть диалоговое окно поиска. Затем найдите в коде слово **pickle**.

   Этот фрагмент кода показывает, как создан сериализованный выходной файл. Обратите внимание: выходной файл на диске называется **model.pkl**. 

   ```python
   print("Export the model to model.pkl")
   f = open('./outputs/model.pkl', 'wb')
   pickle.dump(clf1, f)
   f.close()
   ```

5. Найдите сериализованный файл модели в списке выходных файлов последнего запуска.
   
   Когда вы выполнили скрипт **iris_sklearn.py**, файл модели был сохранен в папке **outputs** с именем **model.pkl**. Эта папка находится в среде выполнения, которую вы выбрали для запуска скрипта, а не в локальной папке проекта. 
   
   - Чтобы найти файл, используйте приложение Azure Machine Learning Workbench. Щелкните на панели инструментов слева кнопку **Запуски** (значок часов), которая открывает список **Все запуски**.  
   - Откроется вкладка **Все запуски**. В таблице запусков выберите один из последних запусков, для которого были указаны целевой объект **local** (локально) и имя сценария **iris_sklearn.py**. 
   - Откроется страница **свойства запуска**. В верхнем правом углу этой страницы вы увидите раздел **Выходные данные**. 
   - Загрузите сериализованный файл, установив флажок рядом с файлом **model.pkl** и нажав кнопку **Загрузить**. Сохраните файл в корневую папку проекта. Он потребуется позже.

   ![Загрузка сериализованного файла](media/tutorial-classifying-iris/download_model.png)

   Дополнительные сведения о папке **outputs** см. в руководстве по [операциям чтения и записи больших файлов данных](how-to-read-write-files.md).

## <a name="get-scoring-and-schema-files"></a>Получение файлов оценки и схемы
Для развертывания веб-службы вам потребуется не только файл модели, но и скрипт оценки. По желанию вы можете к ним добавить схему входных данных веб-службы. Скрипт оценки загружает файл **model.pkl** из текущей папки и использует его для создания прогнозируемого класса Iris.  

1. Запустите приложение **Azure Machine Learning Workbench** и откройте проект **myIris**, созданный в предыдущей части этой серии руководств.

2. В открытом проекте щелкните **Файлы** (значок папки) на панели инструментов слева в Azure Machine Learning Workbench, чтобы открыть список файлов в папке проекта.

3. Выберите файл **iris_score.py**. Откроется скрипт Python. Этот файл используется как файл оценки.

   ![Файл оценки](media/tutorial-classifying-iris/model_data_collection.png)

4. Чтобы получить файл схемы, запустите этот скрипт. Выберите на панели команд среду **local** (локальная) и скрипт **iris_score.py**, а затем нажмите кнопку **Выполнить**. 

5. Этот скрипт создает в папке **outputs** (выходные данные) JSON-файл со схемой входных данных, которые нужны для нашей модели.

6. В правой части окна Machine Learning Workbench вы увидите область заданий. Подождите, пока последнее задание **iris\_score.py** не изменит состояние на **Готово**, отображающееся зеленым цветом. После этого перейдите по ссылке **iris\_score.py [1]** рядом с последним запуском задания, чтобы просмотреть сведения о выполнении запуска **iris_score.py**. 

7. На странице свойств запуска в разделе **Выходные данные** выберите только что созданный файл **service_schema.json**. **Выберите** файл и нажмите кнопку **Скачать**. Сохраните этот файл в корневой папке проекта.

8. Вернитесь на предыдущую вкладку, где вы открыли скрипт **iris_score.py**. 

   Обратите внимание, что использование коллекции данных позволяет сохранять входные данные модели и прогнозы веб-службы. Для сбора данных особое значение имеют следующие факторы.

9. Изучите код в верхней части файла, который импортирует файл ModelDataCollector с функциями сбора данных модели:

   ```python
   from azureml.datacollector import ModelDataCollector
   ```

10. Изучите следующий код функции **init()**, который создает ModelDataCollector:

   ```python
   global inputs_dc, prediction_dc
   inputs_dc = ModelDataCollector('model.pkl',identifier="inputs")
   prediction_dc = ModelDataCollector('model.pkl', identifier="prediction")`
   ```

11. Изучите приведенный ниже код функции **run(input_df)**, который собирает входные данные и прогнозы:

   ```python
   global clf2, inputs_dc, prediction_dc
   inputs_dc.collect(input_df)
   prediction_dc.collect(pred)
   ```

Теперь можно начать подготовку среды для ввода модели в эксплуатацию.

## <a name="prepare-to-operationalize-locally"></a>Подготовка к вводу в эксплуатацию в локальной среде
Используйте развертывание в _локальном режиме_, чтобы запустить контейнер Docker на локальном компьютере.

_Локальный режим_ удобно использовать для разработки и тестирования. Локально запущенная подсистема Docker потребуется, чтобы выполнить следующие действия. Чтобы получить справку по команде, добавьте в конце строки флаг `-h`.

>[!NOTE]
>Если у вас нет локальной подсистемы Docker, создайте для развертывания кластер в Azure. Не забудьте удалить этот кластер после завершения работы с руководством, чтобы не оплачивать его использование.

1. Откройте интерфейс командной строки в Azure Machine Learning Workbench и щелкните пункт **Открыть командную строку** в меню "Файл".

   Откроется окно командной строки, где текущим каталогом будет папка проекта **c:\temp\myIris>**.

2. Убедитесь, что поставщик ресурсов Azure **Microsoft.ContainerRegistry** зарегистрирован в вашей подписке. Зарегистрировать этот поставщик ресурсов нужно до создания среды на шаге 3. С помощью следующей команды вы можете проверить, зарегистрирован ли он.
   ``` 
   az provider list --query "[].{Provider:namespace, Status:registrationState}" --out table 
   ``` 

   Должен отобразиться примерно такой результат: 
   ```
   Provider                                  Status 
   --------                                  ------
   Microsoft.Authorization                   Registered 
   Microsoft.ContainerRegistry               Registered 
   microsoft.insights                        Registered 
   Microsoft.MachineLearningExperimentation  Registered 
   ... 
   ```
   
   Если поставщик **Microsoft.ContainerRegistry** не зарегистрирован, используйте эту команду:
   ``` 
   az provider register --namespace Microsoft.ContainerRegistry 
   ```
   Регистрация может занять несколько минут. Ее состояние вы можете проверить с помощью указанной выше команды **az provider list** или такой команды:
   ``` 
   az provider show -n Microsoft.ContainerRegistry 
   ``` 

   В третьей строке выходных данных отображается статус регистрации: **"registrationState": "Registering"**. Подождите немного и повторяйте команду show, пока в выходных данных не отобразится состояние **"registrationState": "Registered"**.

3. Создайте среду. Этот шаг обязательно нужно выполнить один раз в каждой среде (например, один раз в среде разработки и один раз в рабочей среде). Для первой среды используйте _локальный режим_. (Позже вы можете подставить в эту команду параметры `-c` или `--cluster`, чтобы настроить среду в _режиме кластера_).

   ```azurecli
   az ml env setup -n <new deployment environment name> --location <e.g. eastus2>
   ```
   
   Следуйте инструкциям на экране, чтобы подготовить учетную запись хранения для образов Docker, реестр контейнеров Azure (ACR) для списка образов Docker и учетную запись AppInsight для сбора данных телеметрии. Если вы использовали параметр `-c`, будет создан еще и кластер ACS (Службы контейнеров Azure).
   
   Среду можно определить с помощью имени кластера. Расположение должно совпадать с тем, которое вы указали при создании учетной записи управления моделями на портале Azure.

4. Создание учетной записи управления моделями (выполняется однократно)  
   ```azurecli
   az ml account modelmanagement create --location <e.g. eastus2> -n <new model management account name> -g <existing resource group name> --sku-name S1
   ```
   
5. Настройка учетной записи управления моделями  
   ```azurecli
   az ml account modelmanagement set -n <youracctname> -g <yourresourcegroupname>
   ```

6. Настройте среду.
После завершения установки с помощью следующей команды задайте переменные среды, которые нужны для ввода в эксплуатацию. Используйте то же имя среды, которое вы использовали ранее на шаге 4. После завершения установки используйте то же имя группы ресурсов, которое отображалось в окне команды.
   ```azurecli
   az ml env set -n <deployment environment name> -g <existing resource group name>
   ```

7. Чтобы проверить, правильно ли настроена среда реализации для локального развертывания веб-службы, введите следующую команду:

   ```azurecli
   az ml env show
   ```

Теперь все готово для создания веб-службы в реальном времени.

## <a name="create-a-real-time-web-service-in-one-command"></a>Создание веб-службы в режиме реального времени с помощью одной команды
1. Создайте веб-службу в режиме реального времени, используя следующую команду.

   ```azurecli
   az ml service create realtime -f iris_score.py --model-file model.pkl -s service_schema.json -n irisapp -r python --collect-model-data true 
   ```
   Этот код создает идентификатор веб-службы, который понадобится позднее.

   С командой **az ml service create realtime** используются следующие параметры:
   * -n: имя приложения в нижнем регистре;
   * -f: имя файла скрипта оценки;
   * --model-file: файл модели, для нашего примера это файл model.pkl;
   * -r: тип модели, в данном случае это модель python;
   * --collect-model-data true: активирует сбор данных.

   >[!IMPORTANT]
   >Имя службы (которое совпадает с именем нового образа Docker) может содержать только строчные буквы, в противном случае появится сообщение об ошибке. 

2. При выполнении этой команды модель и файл оценки передаются в учетную запись хранения, созданную в процессе настройки среды. Процесс развертывания создает образ Docker, содержащий вашу модель, схему и файл оценки, а затем передает его в реестр ACR: **\<ACR_name\>.azureacr.io/\<imagename\>:\<version\>**. 

   Затем он забирает этот образ на локальный компьютер и запускает контейнер Docker, созданный на основе этого образа. Если среда настроена в режиме кластера, контейнер Docker развертывается в кластер ACS Kubernetes.

   В процессе этого развертывания на локальной машине создается конечная точка HTTP REST для веб-службы. Через несколько минут команда завершается сообщением об успешном выполнении. Теперь веб-служба готова к работе.

3. Чтобы увидеть контейнер Docker, выполните команду **docker ps**:
   ```azurecli
   docker ps
   ```

## <a name="create-a-real-time-web-service-using-separate-commands"></a>Создание веб-службы в режиме реального времени с помощью отдельных команд
Вместо команды **az ml service create realtime**, показанной выше, можно также выполнить действия по отдельности. Сначала зарегистрируйте модель, затем создайте манифест, соберите образ Docker и создайте веб-службу. Этот пошаговый подход дает больше гибкости. Кроме того, вы можете повторно использовать создаваемые сущности, чтобы перестраивать их только при необходимости.

1. Зарегистрируйте модель, указав имя сериализованного файла.

   ```azurecli
   az ml model register --model model.pkl --name model.pkl
   ```
   После выполнения этой команды вы получите идентификатор модели.

2. Создание манифеста

   Чтобы создать манифест, используйте следующую команду с идентификатором модели, полученным на предыдущем этапе.

   ```azurecli
   az ml manifest create --manifest-name <new manifest name> -f iris_score.py -r python -i <model ID> -s service_schema.json
   ```
   После выполнения этой команды вы получите идентификатор манифеста.

3. Создайте образ Docker.

   Чтобы создать образ Docker, используйте следующую команду с идентификатором манифеста, полученным на предыдущем этапе.

   ```azurecli
   az ml image create -n irisimage --manifest-id <manifest ID>
   ```
   После выполнения этой команды вы получите идентификатор образа Docker.
   
4. Создание службы

   Чтобы создать службу, используйте следующую команду с идентификатором образа, полученным на предыдущем этапе.

   ```azurecli
   az ml service create realtime --image-id <image ID> -n irisapp --collect-model-data true
   ```
   После выполнения этой команды вы получите идентификатор веб-службы.

Теперь все готово к запуску веб-службы.

## <a name="run-the-real-time-web-service"></a>Запуск веб-службы в режиме реального времени

Чтобы проверить работу веб-службы **irisapp**, передайте ей запись в кодировке JSON, содержащую массив из четырех случайных чисел.

1. Создание веб-службы включает примеры данных. Если вы работаете в локальном режиме, вызовите команду **az ml service show realtime**. После этого вызова вы получите пример выполнения команды, с помощью которого можно протестировать службу. Также вы получите URL-адрес для оценки, с помощью которого службу можно внедрить в пользовательское приложение:

   ```azurecli
   az ml service show realtime -i <web service ID>
   ```

2. Чтобы проверить службу, выполните полученную команду запуска.

   ```azurecli
   az ml service run realtime -i irisapp -d "{\"input_df\": [{\"petal width\": 0.25, \"sepal length\": 3.0, \"sepal width\": 3.6, \"petal length\": 1.3}]}"
   ```
   Выходные данные будут содержать прогнозируемый класс: **2**. Вы можете получить другой результат. 

3. Если вы хотите использовать службу вне интерфейса командной строки, получите ключи для аутентификации:

   ```azurecli
   az ml service keys realtime -i <web service ID>
   ```

## <a name="view-the-collected-data-in-azure-blob-storage"></a>Просмотр собранных данных в хранилище больших двоичных объектов Azure

1. Войдите на [портал Azure](https://portal.azure.com).

2. Перейдите к учетным записям хранения. Для этого выберите раздел **Другие службы**.

3. В поле поиска введите **учетные записи хранения** и нажмите клавишу **ВВОД**.

4. На странице результатов поиска по фразе **учетные записи хранения** выберите ресурс **учетной записи хранения**, соответствующий целевой среде. 

   > [!TIP]
   > Чтобы определить, какая учетная запись хранения используется, откройте Azure Machine Learning Workbench, выберите нужный проект и откройте окно командной строки через меню **Файл**. В приглашении командной строки введите `az ml env show -v`, вы получите значение *storage_account*. Это и есть имя учетной записи хранения.

5. После открытия страницы **учетной записи хранения** щелкните элемент **Контейнеры** в списке слева. Найдите контейнер с именем **modeldata**. 
 
   Если данные не отображаются, подождите немного. После первого запроса к веб-службе может пройти до 10 минут до начала передачи данных в учетную запись хранения.

   Потоки данных передаются в большие двоичные объекты по следующему пути контейнера:

   ```
   /modeldata/<subscription_id>/<resource_group_name>/<model_management_account_name>/<webservice_name>/<model_id>-<model_name>-<model_version>/<identifier>/<year>/<month>/<day>/data.csv
   ```

6. Вы можете использовать эти данные из больших двоичных объектов Azure. Программное обеспечение Майкрософт и средства с открытым кодом можно использовать разными способами.

   - Azure ML Workbench. Откройте CSV-файл в Azure ML Workbench, добавив его в качестве источника данных. 
   - Excel. Откройте CSV-файл с данными за день в качестве электронной таблицы.
   - [Power BI](https://powerbi.microsoft.com/documentation/powerbi-azure-and-power-bi/). Создайте диаграмму на основе данных, извлеченных из CSV-файлов в больших двоичных объектах.
   - [Hive](https://docs.microsoft.com/azure/hdinsight/hdinsight-hadoop-linux-tutorial-get-started). Загрузите данные в формате CSV в таблицу Hive и выполняйте SQL-запросы прямо к большому двоичному объекту.
   - [Spark](https://docs.microsoft.com/azure/hdinsight/hdinsight-apache-spark-overview). Создайте кадр данных с крупным сегментом данных в формате CSV.

      ```python
      var df = spark.read.format("com.databricks.spark.csv").option("inferSchema","true").option("header","true").load("wasb://modeldata@<storageaccount>.blob.core.windows.net/<subscription_id>/<resource_group_name>/<model_management_account_name>/<webservice_name>/<model_id>-<model_name>-<model_version>/<identifier>/<year>/<month>/<date>/*")
      ```


## <a name="next-steps"></a>Дальнейшие действия
Из заключительной третьей части этой серии руководств вы узнали, как с помощью службы "Машинное обучение Azure" выполнять следующие задания:
> [!div class="checklist"]
> * поиск файла модели;
> * создание скрипта оценки и файла схемы;
> * Подготовка среды
> * Создание веб-службы в режиме реального времени
> * запуск веб-службы в режиме реального времени;
> * изучение выходных данных в формате больших двоичных объектов. 

Вы успешно запустили скрипт обучения в нескольких средах вычислений, создали модель, сериализовали эту модель и ввели в эксплуатацию через веб-службу на базе Docker. 

Теперь можно переходить к расширенной подготовке данных.
> [!div class="nextstepaction"]
> [Advanced data preparation](tutorial-bikeshare-dataprep.md) (Расширенная подготовка данных)

