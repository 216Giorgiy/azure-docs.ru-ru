---
title: "Общие сведения о службе выполнения экспериментов в Машинном обучении Azure"
description: "В этом документе приводится общий обзор службы выполнения экспериментов в Машинном обучении Azure"
services: machine-learning
author: gokhanuluderya-msft
ms.author: gokhanu
manager: haining
ms.reviewer: garyericson, jasonwhowell, mldocs
ms.service: machine-learning
ms.workload: data-services
ms.topic: article
ms.date: 09/17/2017
ms.translationtype: HT
ms.sourcegitcommit: c3a2462b4ce4e1410a670624bcbcec26fd51b811
ms.openlocfilehash: bb1c7d318939c42edb9a51e28dec31593f2485f9
ms.contentlocale: ru-ru
ms.lasthandoff: 09/25/2017

---

# <a name="overview-of-azure-machine-learning-experiment-execution-service"></a>Общие сведения о службе выполнения экспериментов в Машинном обучении Azure
Служба выполнения экспериментов в Машинном обучении Azure (Azure ML) позволяет специалистам по обработке и анализу данных выполнять эксперименты с помощью функций Azure ML по выполнению и управлению запусками. Она предоставляет платформу для гибкого экспериментирования и быстрых итераций. Azure ML Workbench позволяет начать выполнение на локальном компьютере, а затем легко увеличить масштаб эксперимента или развернуть его в других средах, например на удаленных виртуальных машинах для обработки и анализа данных с поддержкой графических процессоров или кластерах HDInsight под управлением Spark.

Служба выполнения экспериментов организовывает изолированные, воспроизводимые и согласованные запуски экспериментов. Она помогает управлять целевыми объектами вычислений, средами выполнения и конфигурациями запуска. Функции Azure ML Workbench для выполнения и управления запусками позволяют легко переходить из одной среды в другую. 

Вы можете выполнить скрипт Python или PySpark в проекте Azure ML Workbench как локально, так и в облаке с применением сред масштабирования. 

Для запуска скриптов доступны следующие среды. 

* Среда Python (3.5.2) на локальном компьютере, которая устанавливается в составе Azure ML Workbench.
* Среда Conda Python в контейнере Docker на локальном компьютере.
* Среда Conda Python в контейнере Docker на удаленном компьютере под управлением Linux. Например, [виртуальная машина для обработки и анализа данных на основе Ubuntu в Azure](https://azuremarketplace.microsoft.com/marketplace/apps/microsoft-ads.linux-data-science-vm-ubuntu).
* [HDInsight для Spark](https://azure.microsoft.com/services/hdinsight/apache-spark/) в Azure

>[!IMPORTANT]
>Служба выполнения в Azure ML в настоящее время поддерживает версии сред выполнения Python 3.5.2 и Spark 2.1.11. 


## <a name="key-concepts-in-azure-ml-experiment-execution"></a>Основные понятия службы выполнения экспериментов в Azure ML
При работе со службой выполнения экспериментов в Azure ML важно ознакомиться со следующими понятиями. В других разделах мы подробно расскажем, как их использовать. 
### <a name="compute-target"></a>Целевой объект вычисления
Целевой объект вычисления указывает, где будет выполняться программа пользователя, например на рабочем столе пользователя, в удаленном контейнере Docker на виртуальной машине или в кластере. Целевой объект вычисления должен быть адресуемым и доступным для пользователя. Azure ML Workbench дает возможность создавать целевые объекты вычисления и управлять ими с помощью приложения Workbench и интерфейса командной строки. 

Команда _az ml computetarget attach_ в интерфейсе командной строки позволяет создать целевой объект вычислений, который затем можно использовать в запусках экспериментов.

### <a name="supported-compute-targets-are"></a>Поддерживаются следующие целевые объекты вычислений.
* Локальная среда Python (3.5.2) на компьютере, которая устанавливается в составе Azure ML Workbench.
* Локальный контейнер Docker на персональном компьютере.
* Удаленный контейнер Docker на виртуальных машинах Linux или Ubuntu. Например, [виртуальная машина для обработки и анализа данных на основе Ubuntu в Azure](https://azuremarketplace.microsoft.com/marketplace/apps/microsoft-ads.linux-data-science-vm-ubuntu).
* [HDInsight для кластера Spark](https://azure.microsoft.com/services/hdinsight/apache-spark/) в Azure

Служба выполнения в Azure ML в настоящее время поддерживает версии сред выполнения Python 3.5.2 и Spark 2.1.11. 

>[!IMPORTANT]
> Виртуальные машины Windows, на которых выполняется контейнер Docker, **не** поддерживаются в качестве удаленных целевых объектов вычислений.

### <a name="execution-environment"></a>Среда выполнения
Среда выполнения определяет конфигурацию времени выполнения и зависимости, которые обязательны для запуска программы в Azure ML Workbench.

Пользователь может применять для управления локальной средой выполнения любые удобные средства и диспетчеры пакетов, если они работают в стандартной среде выполнения Azure ML Workbench. 

Для управления выполнением в локальном или удаленном контейнере Docker или выполнением на основе HDInsight используется среда Conda. В этих целевых объектах вычислений за управление конфигурацией среды выполнения отвечают файлы **Conda_dependencies.yml** и **Spark_dependencies.yml**. Эти файлы находятся в папке **aml_config** внутри проекта.

**Поддерживаются следующие среды выполнения для сред выполнения.**
* Python 3.5.2
* Spark 2.1.11

### <a name="run-configuration"></a>Конфигурация запуска
Помимо целевого объекта вычислений и среды выполнения Машинное обучение Azure предоставляет платформу для определения и изменения конфигураций запуска. В процессе итеративного экспериментирования для разных выполнений эксперимента могут потребоваться разные конфигурации. Вы можете применять разные диапазоны параметров, использовать разные источники данных или изменять настройки Spark. Служба выполнения Azure ML предоставляет платформу для управления конфигурациями запуска.

Команда _az ml computetarget attach_ создает в каталоге **aml_config** для вашего проекта файлы COMPUTE и RUNCONFIG, имена которых формируются так: _<имя_целевого_объекта_вычислений>.compute_ и _<имя_целевого_объекта_вычислений>.runconfig_. RUNCONFIG-файл создается автоматически при создании целевого объекта вычислений. Вы можете создавать дополнительные конфигурации и управлять ими с помощью команды _az ml runconfigurations_ в интерфейсе командной строки. Также вы можете создавать и редактировать их средствами файловой системы.

Конфигурации запуска в Azure ML Workbench позволяют настраивать переменные среды. Вы можете указать нужные переменные среды в соответствующем разделе RUNCONFIG-файла, чтобы затем использовать их в коде. 

```
EnvironmentVariables:
"EXAMPLE_ENV_VAR1": "Example Value1"
"EXAMPLE_ENV_VAR2": "Example Value2"
```

Эти переменные среды становятся доступными в пользовательском коде. Например, этот фрагмент кода Phyton выводит значение переменной среды с именем EXAMPLE_ENV_VAR1:
```
print(os.environ.get("EXAMPLE_ENV_VAR1"))
```

_**На следующем рисунке показан обобщенный процесс для начального запуска эксперимента.**_
![](media/experiment-execution-configuration/experiment-execution-flow.png)

## <a name="azure-ml-experiment-execution-scenarios"></a>Сценарии выполнения экспериментов в Машинном обучении Azure
В этом разделе мы подробно рассмотрим сценарии выполнения и узнаем, как Машинное обучение Azure запускает эксперименты на примерах работы в локальной среде, на удаленной виртуальной машине и в кластере HDInsight. Этот раздел содержит пошаговое руководство с момента создания целевого объекта вычислений до выполнения экспериментов.

>[!NOTE]
>В оставшейся части этой статьи мы будем демонстрировать основные понятия и возможности на примерах интерфейса командной строки. Все эти возможности можно также использовать в приложении Workbench для рабочего стола.

## <a name="launching-the-cli"></a>Запуск интерфейса командной строки
Чтобы запустить интерфейс командной строки, откройте проект в приложении Azure ML Workbench для рабочего стола и перейдите к пункту меню **Файл --> Открыть командную строку**.

![](media/experiment-execution-configuration/opening-cli.png)

Эта команда открывает окно терминала, в котором можно вводить команды для выполнения скриптов в текущей папке проекта. Для окна терминала применяется среда Python 3.5.2, которая устанавливается вместе с Workbench.

>[!NOTE]
> Для выполнения любой команды _az ml_ в командном окне необходимо пройти аутентификацию в Azure. Интерфейс командной строки использует отдельный кэш аутентификации, независимый от классического приложения, поэтому выполнение входа в приложении Workbench для рабочего стола не считается аутентификацией в среде CLI. Для аутентификации выполните следующие действия. Токен аутентификации кэшируется локально на некоторый период времени, поэтому этот процесс нужно повторять не каждый раз, а только по истечении срока действия токена. Когда истекает срок действия токена или появляются ошибки аутентификации, выполните следующие команды:

```
# to authenticate 
$ az login

# to list subscriptions
$ az account list -o table

# to set current subscription to a particular subscription ID 
$ az account set -s <subscription_id>

# to verify your current Azure subscription
$ az account show
```

>[!NOTE] 
>Перед выполнением команды _az ml_ в папке проекта убедитесь, что этот проект относится к учетной записи Экспериментирования в Машинном обучении Azure, включенной в _текущую_ подписку Azure. В противном случае могут возникнуть ошибки выполнения.


## <a name="running-scripts-and-experiments"></a>Выполнение скриптов и экспериментов
С помощью Azure ML Workbench вы можете выполнить скрипты Python и PySpark для разных целевых объектов вычислений, используя команду _az ml experiment submit_. Для этой команды нужно определить конфигурацию запуска. 

Azure ML Workbench создает соответствующий RUNCONFIG-файл при создании целевого объекта вычислений, но вы всегда можете создать дополнительные конфигурации запуска с помощью команды _az ml runconfiguration создать_. Можно также вручную изменить файлы конфигурации запуска.

Конфигурации запуска отображаются в интерфейсе запуска эксперимента в приложении Workbench. 

>[!NOTE]
>Дополнительные сведения о файле конфигурации запуска вы найдете в статье о [конфигурации выполнения экспериментов](experiment-execution-configuration-reference.md).

## <a name="running-a-script-locally-on-azure-ml-workbench-installed-runtime"></a>Локальное выполнение скрипта в среде выполнения, установленной вместе с Azure ML Workbench
Azure ML Workbench позволяет выполнять скрипты непосредственно в среде выполнения Python 3.5.2, устанавливаемой вместе с Azure ML Workbench. Эта среда выполнения по умолчанию устанавливается одновременно с Azure ML Workbench и включает все библиотеки и зависимости для Машинного обучения Azure. Результаты запусков и артефакты для локального выполнения по-прежнему сохраняются в облачной службе журнала запусков.

В отличие от выполнений на основе Docker эта конфигурация _не_ использует Conda. Пакеты зависимостей для локальной среды Python в Azure ML Workbench нужно подготовить вручную.

Для локального запуска скрипта в среде Python, установленной вместе с Workbench, вы можете выполнить следующую команду. 

```
$az ml experiment submit -c local myscript.py
```

Чтобы определить путь к среде Python по умолчанию, введите следующую команду в окне командной строки в Azure ML Workbench.
```
$ conda env list
```

>[!NOTE]
>Локальное выполнение PySpark с прямым обращением к локальной среде Spark в данный момент **не** поддерживается. Но Azure ML Workbench поддерживает запуск скриптов PySpark на локальном Docker. Базовый образ Docker для Машинного обучения Azure поставляется с предустановленным Spark 2.1.11. 

_**Обзор локального выполнения скриптов Python.**_
![](media/experiment-execution-configuration/local-native-run.png)

## <a name="running-a-script-on-local-docker"></a>Выполнение скрипта на локальном Docker
Вы можете выполнять проекты в контейнере Docker на локальном компьютере через службу Машинного обучения Azure. Azure ML Workbench содержит базовый образ Docker в комплекте с библиотеками для Машинного обучения Azure и средой выполнения Spark 2.1.11, что упрощает локальное выполнение Spark. На локальном компьютере уже должен работать Docker.

Чтобы запустить скрипт Python или PySpark на локальном Docker, выполните следующие команды в интерфейсе командной строки.

```
$az ml experiment submit -c docker myscript.py
```
или
```
az ml experiment submit --run-configuration docker myscript.py
```

Среда выполнения на локальном Docker подготавливается на основе базового образа Docker для Машинного обучения Azure. Azure ML Workbench загружает этот образ при первом запуске и дополняет его пакетами, указанными в пользовательском файле conda_dependencies.yml. Этот процесс замедляет первый запуск среды, но все последующие запуски будут значительно быстрее благодаря кэшированию слоев в Workbench. 

>[!IMPORTANT]
>Для подготовки образа Docker к первому запуску нужно запустить команду _az ml experiment prepare -c docker_. Также вы можете задать значение true для параметра **PrepareEnvironment** в файле docker.runconfig. В этом случае среда будет подготавливаться автоматически в процессе запуска выполнения.  

>[!NOTE]
>Если вы запускаете скрипт PySpark на Spark, помимо файла conda_dependencies.yml будет использоваться еще и spark_dependencies.yml.

Выполнение скриптов в образе Docker дает вам следующие преимущества.

1. Вы можете быть уверены, что скрипт можно выполнять в других средах выполнения. Контейнер Docker помогает обнаружить и обойти любые локальные ссылки, которые плохо влияют на переносимость. 

2. Вы можете быстро проверить код для разных сред выполнения и платформ, которые требуют сложной установки и настройки, таких как Apache Spark, без необходимости устанавливать их.


_**Обзор выполнения на локальном Docker скриптов Python.**_
![](media/experiment-execution-configuration/local-docker-run.png)

## <a name="running-a-script-on-a-remote-docker"></a>Выполнение скрипта на удаленном Docker
Иногда ресурсов локального компьютера недостаточно для обучения используемой модели. Для таких случаев служба выполнения Машинного обучения Azure поддерживает запуск скриптов Python или PySpark на более мощных виртуальных машинах с помощью выполнения на удаленном Docker. 

Удаленная виртуальная машина должна соответствовать следующим требованиям.
* Удаленная виртуальная машина должна работать под управлением Linux Ubuntu и должна быть доступна по протоколу SSH. 
* На удаленной виртуальной машине должен выполняться Docker.

>[!IMPORTANT]
> Виртуальные машины Windows, на которых выполняется Docker, **не** поддерживаются в качестве удаленных целевых объектов вычислений.


Вы можете создать определение целевого объекта вычислений и конфигурации запуска для удаленного выполнения на основе Docker, используя следующую команду.

```
az ml computetarget attach --name "remotevm" --address "remotevm_IP_address" --username "sshuser" --password "sshpassword" --type remotedocker
```

Когда вы завершите настройку целевого объекта вычислений, используйте следующую команду для запуска скрипта.
```
$ az ml experiment submit -c remotevm myscript.py
```
>[!NOTE]
>Следует помнить, что среда выполнения настраивается по параметрам, указанным в файле conda_dependencies.yml. Также используется файл spark_dependencies.yml, если в файле .runconfig указана платформа PySpark. 

Процесс построения Docker для удаленных виртуальных машин выполняется точно так же, как и для локального Docker, поэтому и выполнение будет проходить одинаково.

>[!TIP]
>Если вы хотите избежать задержки на построение образа Docker для первого запуска, используйте следующую команду для подготовки целевого объекта вычислений перед запуском скрипта. az ml experiment prepare -c <remotedocker>


_**Обзор удаленного выполнения скриптов Python на виртуальных машинах.**_
![](media/experiment-execution-configuration/remote-vm-run.png)


## <a name="running-a-script-on-hdinsight-cluster"></a>Запуск скрипта на кластере HDInsight
HDInsight — это популярная платформа для анализа больших данных, которая поддерживает Apache Spark. Azure ML Workbench позволяет выполнять экспериментирование с большими данными в кластерах HDInsight Spark. 

Вы можете создать целевой объект вычислений и запустить конфигурацию кластера HDInsight Spark с помощью следующей команды:

```
$ az ml computetarget attach --name "myhdi" --address "<FQDN or IP address>" --username "sshuser" --password "sshpassword" --type cluster 
```

>[!NOTE]
>Если вы будете использовать полное доменное имя вместо IP-адреса, имя кластера HDI Spark с именем _foo_ узел драйвера, на котором располагается конечная точка SSH, будет таким: _foo-ssh.azurehdinsight.net_. Не забывайте про постфикс **-ssh** в имени сервера, когда используете полное доменное имя для параметра _--address_.


Получив контекст вычислений, вы можете использовать следующую команду для выполнения скрипта PySpark.

```
$ az ml experiment submit -c myhdi myscript.py
```

Azure ML Workbench подготовит среду выполнения HDInsight и будет управлять ею с помощью Conda. Конфигурация определяется файлами _conda_dependencies.yml_ и _spark_dependencies.yml_. 

Чтобы выполнять эксперименты в этом режиме, пользователю нужен доступ к кластеру HDInsight по протоколу SSH. 

>[!NOTE]
>Поддерживается только выполнение кластеров HDInsight Spark под управлением Linux (Ubuntu для Python и PySpark 3.5.2 и Spark 2.1.11).

_**Общие сведения о выполнении скриптов PySpark под управлением PySpark**_
![](media/experiment-execution-configuration/hdinsight-run.png)


## <a name="running-a-script-on-gpu"></a>Выполнение скрипта на графическом процессоре
Чтобы выполнить скрипты на графическом процессоре, следуйте указаниям в статье [How to use GPU in Azure Machine Learning](how-to-use-gpu.md) (Как использовать графический процессор для Машинного обучения Azure).


## <a name="next-steps"></a>Дальнейшие действия
* [Create Azure Machine Learning preview accounts and install Azure Machine Learning Workbench](quickstart-installation.md) (Создание учетных записей для предварительной версии Машинного обучения Azure и установка Azure Machine Learning Workbench).
* [Управление моделями](model-management-overview.md)

