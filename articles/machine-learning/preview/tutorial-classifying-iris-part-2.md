---
title: "Создание модели для службы \"Машинное обучение Azure\" (предварительная версия) | Документация Майкрософт"
description: "В этом полном руководстве описано, как использовать службу \"Машинное обучение Azure\" (предварительная версия). Это — вторая часть нашего эксперимента."
services: machine-learning
author: hning86
ms.author: haining
manager: mwinkle
ms.reviewer: garyericson, jasonwhowell, mldocs
ms.service: machine-learning
ms.workload: data-services
ms.custom: mvc, tutorial
ms.topic: hero-article
ms.date: 09/25/2017
ms.openlocfilehash: 5d86f3bdf19603d2f92fc1a704376beefd7323c0
ms.sourcegitcommit: d03907a25fb7f22bec6a33c9c91b877897e96197
ms.translationtype: HT
ms.contentlocale: ru-RU
ms.lasthandoff: 10/12/2017
---
# <a name="classifying-iris-part-2-build-a-model"></a>Часть 2. Классификация цветков ириса: создание модели
Служба "Машинное обучение Azure" (предварительная версия) — это полнофункциональное интегрированное аналитическое решение для специалистов по обработке данных. Оно помогает подготавливать данные, разрабатывать эксперименты и развертывать модели в масштабе облака.

Это руководство представляет собой вторую часть серии (всего три части). В этой части вы будете использовать службу "Машинное обучение Azure" (предварительная версия), чтобы научиться выполнять следующие задачи:

> [!div class="checklist"]
> * Работа в Azure Machine Learning Workbench
> * Открытие скриптов и проверка кода
> * Выполнение скриптов в локальной среде
> * Просмотр журнала выполнения
> * Выполнение скриптов в локальной среде Docker
> * Выполнение скриптов в локальном окне Azure CLI
> * Выполнение скриптов в удаленной среде Docker
> * Выполнение скриптов в облачной среде HDInsight

В этом руководстве для простоты используется классический набор данных —[ирисы Фишера](https://en.wikipedia.org/wiki/Iris_flower_data_set). Снимки экрана представляют среду Windows, но для macOS все процедуры практически идентичны.

## <a name="prerequisites"></a>Предварительные требования
Вам нужно пройти первую часть этой серии руководств. Прежде чем начинать работу с этим руководством, выполните инструкции из руководства по [подготовке данных](tutorial-classifying-iris-part-1.md), чтобы создать ресурсы службы "Машинное обучение Azure" и установить приложение Azure Machine Learning Workbench.

Кроме того, можно попробовать выполнить скрипты с использованием локального контейнера Docker. В этом случае вам потребуется, чтобы модуль Docker (достаточно Community Edition) был установлен и работал локально на компьютере с Windows или macOS. См. дополнительные сведения по [установке Docker](https://docs.docker.com/engine/installation/).

Если вы хотите запустить выполнение скрипта в контейнере Docker на удаленной виртуальной машине Azure или в кластере HDInsight Spark, можно выполнить [инструкции по созданию виртуальной машины для обработки и анализа данных Azure на базе Ubuntu или кластера HDI](how-to-create-dsvm-hdi.md).

## <a name="review-irissklearnpy-and-configuration-files"></a>Просмотр файлов конфигурации и iris_sklearn.py
1. Запустите приложение **Azure Machine Learning Workbench** и откройте проект **myIris**, созданный в предыдущей части этой серии руководств.

2. В открытом проекте щелкните **Файлы** (значок папки) на панели инструментов слева в Azure Machine Learning Workbench, чтобы открыть список файлов в папке проекта.

3. Выберите файл **iris_sklearn.py**. Откроется код Python на новой вкладке текстового редактора в Workbench.

   ![Открытие файла](media/tutorial-classifying-iris/open_iris_sklearn.png)

   >[!NOTE]
   >Код, который вы видите, может не совпадать с изображенным, так как пример проекта постоянно обновляется.

4. Просмотрите код скрипта Python, чтобы ознакомиться со стилем программирования. Эта часть скрипта выполняет следующее:

   - Загружает пакет подготовки данных **iris.dprep** для создания [pandas DataFrame](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.html). 

        >[!NOTE]
        >Мы используем пакет подготовки данных `iris.dprep` из примера проекта. Он должен соответствовать файлу `iris-1.dprep`, созданному в первой части этой серии руководств.

   - Добавляет случайные компоненты, чтобы усложнить задачу. (Случайность необходима, так как ирисы Фишера — это небольшой набор данных, который можно легко классифицировать практически со 100 % точностью.)

   - Использует библиотеку машинного обучения [scikit-learn](http://scikit-learn.org/stable/index.html), чтобы создать простую модель логистической регрессии. 

   - Сериализует модель с помощью библиотеки [pickle](https://docs.python.org/2/library/pickle.html) в файл в папке `outputs`, затем загружает и десериализует его обратно в память.

   - Использует десериализованную модель для прогнозирования на основе новой записи. 

   - Отображает два графика —матрицу неточностей и многоклассовую кривую ROC — с помощью библиотеки [matplotlib](https://matplotlib.org/) и сохраняет их в папке `outputs`.

   - Объект `run_logger` используется для записи параметров регуляризации и сведений о точности модели в журналы. Эти журналы автоматически отображаются в журнале выполнения.


## <a name="execute-irissklearnpy-script-in-local-environment"></a>Выполнение скрипта iris_sklearn.py в локальной среде

Давайте подготовим скрипт **iris_sklearn.py** к первому выполнению. Для работы этого скрипта требуются пакеты scikit-learn и matplotlib. Пакет **scikit-learn** уже установлен Azure ML Workbench. Осталось установить пакет **matplotlib**. 

1. В Azure Machine Learning Workbench в меню **Файл** выберите **Открыть командную строку**, чтобы запустить средство командной строки. Мы называем это окно командной строки как Azure Machine Learning Workbench CLI или просто CLI для краткости.

2. В окне CLI введите следующую команду, чтобы установить пакета **matplotlib** Python. Операция не займет больше минуты.

   ```azurecli
   pip install matplotlib
   ```

   >[!NOTE]
   >Если пропустить используемую выше команду `pip install`, код в файле `iris_sklearn.py` будет выполнен, но он не создаст выходные данные матрицы неточностей и графики многоклассовой кривой ROC, как показано в визуализациях журнала.

3. Вернитесь в окно приложения Workbench. 

4. В левом верхнем углу вкладки **iris_sklearn.py** рядом со значком сохранения откройте раскрывающийся список, чтобы выбрать **Конфигурация запуска**.  Выберите **локальную** среду выполнения и `iris_sklearn.py` в качестве выполняемого скрипта.

5. Затем в правой части этой вкладки введите в поле **Аргументы** значение `0.01`. 

   ![Рисунок](media/tutorial-classifying-iris/run_control.png)

6. Нажмите кнопку **Запустить**. Будет запланировано выполнение задания. Задания перечислены на панели **Задания** с правой стороны окна Workbench. 

7. Через несколько секунд состояние задания изменится с **Отправка** на **Выполнение**, а затем — на **Завершено**.

   ![Запуск sklearn](media/tutorial-classifying-iris/run_sklearn.png)

8. Щелкните слово **Завершено** в тексте состояния задания на панели "Задания". Откроется всплывающее окно, отображающее текст стандартного потока вывода (stdout) выполняемого скрипта. Чтобы закрыть текст stdout, нажмите кнопку **X** в правом верхнем углу всплывающего окна.

9. В том же состоянии задания на панели "Задания" щелкните синий текст **iris_sklearn.py [n]** (_n_ — это номер выполнения) непосредственно над состоянием **Завершено** и временем начала. Откроется страница **Свойства запуска**. На ней отображается информация о свойствах запуска **выходных** файлов, **визуализации** и **журналы**, связанные с определенной процедурой выполнения. 

   По завершении выполнения во всплывающем окне будет отображено следующее:

   >[!NOTE]
   >Так как выше мы включили случайные компоненты в набор для обучения, результаты будут немного отличаться.

   ```text
   Python version: 3.5.2 |Continuum Analytics, Inc.| (default, Jul  5 2016, 11:41:13) [MSC v.1900 64 bit (AMD64)]
   
   Iris dataset shape: (150, 5)
   Regularization rate is 0.01
   LogisticRegression(C=100.0, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
   Accuracy is 0.6792452830188679
   
   ==========================================
   Serialize and deserialize using the outputs folder.
   
   Export the model to model.pkl
   Import the model from model.pkl
   New sample: [[3.0, 3.6, 1.3, 0.25]]
   Predicted class is ['Iris-setosa']
   Plotting confusion matrix...
   Confusion matrix in text:
   [[50  0  0]
    [ 1 37 12]
    [ 0  4 46]]
   Confusion matrix plotted.
   Plotting ROC curve....
   ROC curve plotted.
   Confusion matrix and ROC curve plotted. See them in Run History details page.
   ```

10. Закройте вкладку **Свойства запуска** и вернитесь на вкладку **iris_sklearn.py**. 

11. Повторите дополнительные процедуры выполнения. 

    Введите ряд числовых значений в поле **Аргументы** в диапазоне от `0.001` до `10`. Щелкните **Запустить**, чтобы выполнить код еще несколько раз. Значение аргумента, который вы каждый раз меняете, передается в алгоритм логистической регрессии в коде, в результате чего вы каждый раз получаете разные результаты.

## <a name="review-run-history-in-detail"></a>Подробный просмотр журнала выполнения
В Azure Machine Learning Workbench каждое выполнение скрипта записывается в журнале выполнения. Вы можете просмотреть журнал выполнения для определенного скрипта, открыв представление **Запуски**.

1. Нажмите кнопку **Запуски** (значок часов) на панели инструментов слева, чтобы открыть список **Запуски**. Затем щелкните **iris_sklearn.py**, чтобы отобразить **Панель мониторинга запуска** для `iris_sklearn.py`.

   ![Рисунок](media/tutorial-classifying-iris/run_view.png)

2. Откроется вкладка **Панель мониторинга запусков**. Просмотрите статистику, записанную для нескольких запусков. Диаграммы отображаются в верхней части вкладки, а каждый нумерованный запуск с подробными сведениями перечислен в таблице в нижней части страницы.

   ![Рисунок](media/tutorial-classifying-iris/run_dashboard.png)

3. Отфильтруйте таблицу. Затем щелкайте на диаграммах, чтобы просмотреть состояние, длительность, точность и параметры регуляризации для каждого запуска. 

4. Выберите два или три запуска в таблице **Запуски** и нажмите кнопку **Сравнить**, чтобы открыть страницу с подробными сведениями. Сравните результаты. Нажмите кнопку **Список запусков** со стрелкой назад вверху слева, чтобы вернуться на страницу сравнения **Панели мониторинга запусков**.

5. Щелкните отдельный запуск, чтобы просмотреть подробности выполнения. Обратите внимание: статистика для выбранного запуска доступна в разделе _Свойства запуска_. Файлы, записанные в выходную папку, перечислены в разделе **Выходные данные**. Их можно скачать.

   ![Рисунок](media/tutorial-classifying-iris/run_details.png)

   Два графика, матрица неточностей и многоклассовая кривая ROC отображаются в разделе **Визуализации**. Все файлы журнала также доступны в разделе **Журналы**.

## <a name="execute-scripts-in-the-local-docker-environment"></a>Выполнение скриптов в локальной среде Docker

Azure ML позволяет легко настраивать дополнительные вычислительные среды (такие как Docker) и выполнять в них скрипты. 

>[!IMPORTANT]
>Для этого требуется локально установленный и запущенный модуль Docker. Дополнительные сведения см. в руководстве по установке.

1. На панели инструментов слева выберите значок папки, чтобы открыть список **Файлы** для проекта. Разверните папку `aml_config`. 

2. Вы увидите несколько предварительно настроенных сред: **docker python**, **docker spark** и **local**. 

   Каждая среда имеет два файла — `docker-python.compute` и `docker-python.runconfig`. Откройте каждый тип файла и обратите внимание на то, что некоторые параметры могут быть изменены в текстовом редакторе.  

   Закройте (X) вкладки в текстовых редакторах, чтобы выполнить очистку.

3. Запустите скрипт **iris_sklearn.py** с помощью среды **docker python**. 

   - На панели инструментов слева щелкните значок часов, чтобы открыть панель **Запуски**. Щелкните **Все запуски**. 
   - В верхней части представления **Все запуски** выберите **docker python** как целевую среду вместо стандартного значения **local**. 
   - Затем выберите справа **iris_sklearn.py** в качестве скрипта для запуска. 
   - Оставьте поле **Аргументы** пустым, так как скрипт определит значение по умолчанию. 
   - Нажмите кнопку **Запустить**.

4. На панели **Задания** панели справа в Workbench вы увидите, как будет запущено новое задание.

   Первый запуск в Docker выполняется на несколько минут дольше. 

   В фоновом режиме Azure Machine Learning Workbench создает новый файл docker, который ссылается на базовый образ Docker, указанный в файле `docker.compute`, и пакеты зависимостей Python, указанные в файле `conda_dependencies.yml`. Модуль Docker скачивает базовый образ из Azure, устанавливает пакеты Python, указанные в файле `conda_dependencies.yml`, а затем запускает контейнер Docker. Затем он копирует (или создает ссылку в зависимости от конфигурации запуска) локальную копию папки проекта и выполняет скрипт `iris_sklearn.py`. В итоге вы увидите результат, аналогичный результату при выборе среды **local**.

5. Теперь поработаем со Spark. Базовый образ Docker содержит предварительно установленный и настроенный экземпляр Spark. Поэтому вы можете выполнять в нем скрипт PySpark. Это простой способ разработки и тестирования программы Spark, не тратя время на самостоятельные установку и настройку Spark. 

   Откройте файл `iris_pyspark.py` . Этот скрипт загружает файл данных `iris.csv` и использует алгоритм логистической регрессии из библиотеки Spark ML для классификации набора данных ирисов Фишера. Теперь измените среду выполнения на **docker spark**, а скрипт — на **iris_pyspark.py** и выполните еще один запуск. Это займет больше времени, так как сеанс Spark должен быть создан и запущен в контейнере Docker. Как видите, stdout отличается от stdout из `iris_pyspark.py`.

6. Выполните еще несколько запусков, используя разные аргументы. 

7. Откройте файл `iris_pyspark.py`, чтобы просмотреть простую модель логистической регрессии, созданную с использованием библиотеки Spark ML. 

8. Поработайте с панелью **Задания**, представлением списка журналов запусков и представлением сведений о запусках в разных средах выполнения.

## <a name="execute-scripts-in-the-azure-ml-cli-window"></a>Выполнение скриптов в локальном окне Azure ML CLI

1. С помощью Azure Machine Learning Workbench откройте окно командной строки, щелкнув меню **Файл** и выбрав **Открыть командную строку**. Командная строка откроется в папке проекта со строкой `C:\Temp\myIris\>`.

   >[!Important]
   >Для выполнения следующих действий необходимо использовать окно командной строки (запускается из Workbench):

2. С помощью командной строки (CLI) войдите в Azure. 

   Приложение Workbench и CLI используют независимые кэши учетных данных для аутентификации пользователя ресурсов Azure. Это необходимо сделать только один раз до истечения срока действия кэшированного маркера. Команда **az account list** возвращает список доступных подписок для вашего имени входа. Если у вас их несколько, используйте значение идентификатора из нужной подписки. Для этого укажите ее в качестве учетной записи по умолчанию для использования с командой **az set account -s**, указав значение идентификатора подписки. Подтвердите настройки с помощью команды для отображения учетной записи.

   ```azurecli
   REM login using aka.ms/devicelogin site.
   az login
   
   REM list all Azure subscriptions you have access to. 
   az account list -o table
   
   REM set the current Azure subscription to the one you want to use.
   az set account -s <subscriptionId>
   
   REM verify your current subscription is set correctly
   az account show
   ```

3. Выполнив аутентификацию и настроив контекст текущей подписки Azure, введите следующие команды в окне CLI. Так вы установите библиотеку matplotlib и отправите скрипт python в качестве эксперимента для запуска.

   ```azurecli
   REM You don't need to do this if you have installed matplotlib locally from the previous steps.
   pip install matplotlib
   
   REM Kick off an execution of the iris_sklearn.py file against local compute context
   az ml experiment submit -c local .\iris_sklearn.py
   ```

4. Просмотрите выходные данные. Обратите внимание на те же выходные данные и результат, что и при предыдущем запуске скрипта с помощью Workbench. 

5. Если у вас на компьютере установлен модуль Docker, запустите этот же скрипт, используя среду выполнения Docker.

   ```azurecli
   REM Execute iris_sklearn.py in local Docker container Python environment.
   az ml experiment submit -c docker-python .\iris_sklearn.py 0.01
   
   REM Execute iris_pyspark.py in local Docker container Spark environment.
   az ml experiment submit -c docker-spark .\iris_pyspark.py 0.1
   ```
6. В Azure Machine Learning Workbench щелкните значок папки на левой панели инструментов, чтобы открыть список файлов проекта. Затем откройте скрипт Python с именем **run.py**. 

   Этот скрипт используется в цикле для разных показателей регуляризации. Запустите эксперимент несколько раз с этими показателями. Этот скрипт запускает задание `iris_sklearn.py` с показателем регуляризации `10.0` (огромное число), уменьшает его вдвое при следующем запуске и т. д., пока это значение не будет меньше `0.005`. 

   ```python
   # run.py
   import os
   
   reg = 10
   while reg > 0.005:
       os.system('az ml experiment submit -c local ./iris_sklearn.py {}'.format(reg))
       reg = reg / 2
   ```

   Чтобы запустить скрипт **run.py** из командной строки, выполните следующие команды:

   ```cmd
   REM Submit iris_sklearn.py multiple times with different regularization rates
   python run.py
   ```

   По выполнении `run.py` вы увидите диаграмму в представлении списка журнала запусков в Azure Machine Learning Workbench.

## <a name="execute-in-a-docker-container-on-a-remote-machine"></a>Выполнение в контейнере Docker на удаленном компьютере
Чтобы выполнить скрипт в контейнере Docker на удаленном компьютере Linux, необходимо иметь доступ SSH (имя пользователя и пароль) к этому компьютеру. А на самом компьютере должен быть установлен и запущен модуль Docker. Самый простой способ получить доступ к такому компьютеру Linux — это создать [виртуальную машину для обработки и анализа данных на базе Ubuntu](https://azuremarketplace.microsoft.com/en-us/marketplace/apps/microsoft-ads.linux-data-science-vm-ubuntu) в Azure. (Обратите внимание, что виртуальная машина для обработки и анализа данных на базе CentOS НЕ поддерживается.) 

1. Созданную виртуальную машину можно присоединить в качестве среды выполнения, создав пару файлов `.runconfig` и `.compute` с помощью следующей команды. Назовем новую среду `myvm`.
 
   ```azurecli
   REM create myvm compute target
   az ml computetarget attach --name myvm --address <IP address> --username <username> --password <password> --type remotedocker
   ```
   
   >[!NOTE]
   >Область IP-адреса также может быть доступным для обращения полным доменным именем (FQDN), например `vm-name.southcentralus.cloudapp.azure.com`. Рекомендуется добавить FQDN в виртуальную машину для обработки и анализа данных и использовать его вместо IP-адреса, так как для экономии вы можете захотеть отключить виртуальную машину в определенный момент. Кроме того, при очередном запуске виртуальной машины, IP-адрес может быть изменен.

   Затем выполните следующую команду, чтобы создать образ Docker на виртуальной машине и подготовить ее для выполнения скриптов.
   
   ```azurecli
   REM prepare the myvm compute target
   az ml experiment prepare -c myvm
   ```
   >[!NOTE]
   >Можно также изменить значение `PrepareEnvironment` в `myvm.runconfig` со значения по умолчанию `false` на `true`. Так вы автоматически подготовите контейнер Docker при первом запуске.

2. Измените созданный файл `myvm.runconfig` в разделе `aml_config` и измените для параметра Framework значение с `PySpark` по умолчанию на `Python`:

   ```yaml
   "Framework": "Python"
   ```
   >[!NOTE]
   >Вы также можете оставить для параметра Framework значение PySpark. Но это будет менее эффективно, если вам не нужен сеанс Spark сеанс для выполнения скрипта Python.

3. Выполните ту же команду, что и в окне CLI, только на этот раз мы будем использовать _myvm_:
   ```azurecli
   REM execute iris_sklearn.py in remote Docker container
   az ml experiment submit -c myvm .\iris_sklearn.py
   ```
   Команда выполняется, как при использовании среды `docker-python`, — сейчас выполнение происходит на удаленной виртуальной машине Linux. Окно CLI отображает те же выходные данные.

4. Давайте воспользуемся Spark в контейнере. Откройте проводник (это также можно сделать в окне CLI, если вы привыкли использовать базовые команды для работы с файлами). Создайте копию файла `myvm.runconfig` и назовите ее `myvm-spark.runconfig`. Отредактируйте новый файл, чтобы изменить значение параметра `Framework` с `Python` на `PySpark`:
   ```yaml
   "Framework": "PySpark"
   ```
   Не вносите изменения в файл `myvm.compute`. Для выполнения Spark используется один и тот же образ Docker на одной и той же виртуальной машине. В новом файле `myvy-spark.runconfig` поле `target` указывает на тот же файл `myvm.compute`, ссылаясь на его имя `myvm`.

5. Введите следующую команду, чтобы выполнить запуск в экземпляре Spark в удаленном контейнере Docker:
   ```azureli
   REM execute iris_pyspark.py in Spark instance on remote Docker container
   az ml experiment submit -c myvm-spark .\iris_pyspark.py
   ```

## <a name="execute-script-in-an-hdinsight-cluster"></a>Выполнение скрипта в кластере HDInsight
Этот скрипт также можно выполнить в реальном кластере Spark. 

1. Если у вас есть доступ к Spark для кластера Azure HDInsight, создайте команду конфигурации запуска HDI, как показано ниже. Укажите в качестве параметров имя кластера HDInsight, имя пользователя HDInsight и пароль. Используйте следующую команду:

   ```azurecli
   REM create a compute target that points to a HDI cluster
   az ml computetarget attach --name myhdi --address <cluster head node FQDN> --username <username> --password <password> --type cluster

   REM prepare the HDI cluster
   az ml experiment prepare -c myhdi
   ```

   Как правило, полное доменное имя (FQDN) головного узла кластера — это `<cluster_name>-ssh.azurehdinsight.net`.

   >[!NOTE]
   >`username` — это имя пользователя SSH кластера. Значение по умолчанию — `sshuser`, если вы не меняли его при подготовке HDI. Это не `admin`, — другой пользователь, созданный при подготовке для включения доступа к веб-сайту администрирования кластера. 

2. Выполните следующую команду, чтобы запустить скрипт в кластере HDInsight:

   ```azurecli
   REM execute iris_pyspark on the HDI cluster
   az ml experiment submit -c myhdi .\iris_pyspark.py
   ```

   >[!NOTE]
   >Выполняя запуск в удаленном кластере HDI, вы можете подробные сведения о выполнении задания YARN в `https://<cluster_name>.azurehdinsight.net/yarnui` с помощью учетной записи `admin`.


## <a name="next-steps"></a>Дальнейшие действия
Из второй части серии руководств (всего три части) вы узнали, как с помощью службы "Машинное обучение Azure" выполнять следующие задания:
> [!div class="checklist"]
> * Работа в Azure Machine Learning Workbench
> * Открытие скриптов и проверка кода
> * Выполнение скриптов в локальной среде
> * Просмотр журнала выполнения
> * Выполнение скриптов в локальной среде Docker
> * Выполнение скриптов в локальном окне Azure CLI
> * Выполнение скриптов в удаленной среде Docker
> * Выполнение скриптов в облачной среде HDInsight

Вы готовы перейти к третьей части этой серии руководств. Теперь, когда мы создали модель логистической регрессии, давайте развернем ее как веб-службу, работающую в реальном времени.

> [!div class="nextstepaction"]
> [Развертывание модели](tutorial-classifying-iris-part-3.md)
