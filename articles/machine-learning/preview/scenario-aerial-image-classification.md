---
title: "Классификация изображений аэрофотосъемки | Документация Майкрософт"
description: "Содержит инструкции для реального сценария классификации изображений аэрофотосъемки."
author: mawah
ms.author: mawah
ms.reviewer: garyericson, jasonwhowell, mldocs
ms.topic: article
ms.service: machine-learning
services: machine-learning
ms.date: 09/15/2017
ms.openlocfilehash: e6b673527d77550d4213e6d742156ccc525f6b44
ms.sourcegitcommit: 9ae92168678610f97ed466206063ec658261b195
ms.translationtype: HT
ms.contentlocale: ru-RU
ms.lasthandoff: 10/17/2017
---
# <a name="aerial-image-classification"></a>Классификация изображений аэрофотосъемки

В этом примере показано использование Azure Machine Learning Workbench для координации распределенного обучения и ввода в эксплуатацию модели классификации изображений. Пакет [Машинного обучения Microsoft Azure для Apache Spark (MMLSpark)](https://github.com/Azure/mmlspark) используется для создания признаков изображений с помощью предварительно обученных моделей CNTK и для обучения по ним классификаторов. Затем обученные модели параллельно применяются для наборов крупных изображений в облаке. Эти действия выполняются в кластере [Azure HDInsight Spark](https://azure.microsoft.com/en-us/services/hdinsight/apache-spark/), что позволяет изменять скорость обучения и ввода в эксплуатацию за счет добавления или удаления рабочих узлов.

Продемонстрированная форма переноса обучения имеет значительные преимущества по сравнению с переобучением или точной настройкой глубокой нейронной сети: она не требует вычислений GPU, быстрая по своей природе, произвольно масштабируемая и соответствует меньшему числу параметров. Это лучший метод при отсутствии большого количества примеров, как это часто бывает в пользовательских вариантах использования. Множество пользователей сообщает, что при использовании такого метода создаются высокоэффективные модели, позволяя им избежать обучения нейронных сетей с нуля и сопутствующих затрат.

Кластер Spark, используемый в этом примере, имеет 40 рабочих узлов, и его эксплуатация обходится в 40 долл. США/час. Завершение этого пошагового руководства займет примерно два часа. После завершения выполните инструкции по очистке, чтобы удалить созданные ресурсы и не нести расходов.

## <a name="link-to-the-gallery-github-repository"></a>Ссылка на репозиторий коллекции на GitHub

Общедоступный репозиторий GitHub содержит все материалы для этого реального сценария, в том числе примеры кода, которые нам потребуются.

[https://github.com/Azure/MachineLearningSamples-AerialImageClassification](https://github.com/Azure/MachineLearningSamples-AerialImageClassification)

## <a name="use-case-description"></a>Описание варианта использования

В этом сценарии мы обучаем модель машинного обучения для классификации типа земли, показанного на изображениях аэрофотосъемки размером 224 x 224 м. Модели классификации землепользования позволяют отслеживать урбанизацию, исчезновение лесов, исчезновение болот и другие значительные тенденции в области окружающей среды с помощью периодически собираемых аэрофотоснимков. Мы подготовили наборы изображений для обучения и проверки, снятые в рамках программы изображений национального сельского хозяйства США, и метки землепользования, опубликованные в базе данных национального растительного покрова США. Ниже показаны примеры изображений каждого класса землепользования:

![Примеры регионов для каждой метки землепользования](media/scenario-aerial-image-classification/example-labels.PNG)

После обучения и проверки модели классификации она будет применена для изображений аэрофотосъемки, охватывающих округ Мидлсекс в штате Массачусетс, где находится центр исследований и разработок Новой Англии (NERD) корпорации Майкрософт, чтобы показать, как эти модели можно использовать для изучения тенденций городского развития.

Для создания классификатора изображений с переносом обучения специалисты по обработке и анализу данных часто создают несколько моделей, использующих различные методы, и выбирают наиболее эффективную. Azure Machine Learning Workbench может помочь специалистам по обработке и анализу данных координировать обучение в различных вычислительных средах, отслеживать и сравнивать эффективность нескольких моделей, а также применять выбранную модель к большим наборам данных в облаке.

## <a name="scenario-structure"></a>Структура сценария

В этом примере данные изображений и предварительно обученные модели включены в учетную запись хранения Azure. Кластер Azure HDInsight Spark считывает эти файлы и создает модель классификации изображений с помощью MMLSpark. Обученная модель и ее прогнозы затем записываются в учетной записи хранения, где их можно проанализировать и визуализировать, используя записную книжку Jupyter, выполняемую локально. Приложение Azure Machine Learning Workbench координирует удаленное выполнение скриптов в кластере Spark. Оно также отслеживает метрики точности для нескольких моделей, обученных с помощью разных методов, позволяя выбрать наиболее эффективную модель.

![Схема для реального сценария классификации изображений аэрофотосъемки](media/scenario-aerial-image-classification/scenario-schematic.PNG)

Эти пошаговые инструкции содержат сведения о создании и подготовке учетной записи хранения Azure и кластера Spark, включая передачу данных и установку зависимостей. Затем описывается запуск заданий обучения и сравнение эффективности итоговых моделей. Наконец, рассматривается, как применить выбранную модель к крупному набору изображений в кластере Spark и анализировать результаты прогноза локально.


## <a name="set-up-the-execution-environment"></a>Настройка среды выполнения

Следующие инструкции описывают процесс настройки среды выполнения для этого примера.

### <a name="prerequisites"></a>Предварительные требования
- [Учетная запись Azure](https://azure.microsoft.com/en-us/free/) (доступны бесплатные пробные версии).
    - В этом примере создается кластер HDInsight Spark с 40 рабочими узлами (всего 168 ядра). Убедитесь, что ваша учетная запись имеет достаточно доступных ядер, проверив вкладку "Использование и квоты" вашей подписки на портале Azure.
    - При отсутствии достаточного количества ядер можно изменить шаблон кластера HDInsight и уменьшить количество подготовленных рабочих узлов. Инструкции см. в разделе "Создание кластера HDInsight Spark".
- [Azure Machine Learning Workbench](./overview-what-is-azure-ml.md).
    - Чтобы установить эту программу и создать учетные записи Экспериментирования и Управления моделями, выполните инструкции из [краткого руководства по установке и созданию](quickstart-installation.md).
- [AzCopy](https://docs.microsoft.com/en-us/azure/storage/common/storage-use-azcopy) — это бесплатная служебная программа, координирующая передачу файлов между учетными записями хранения Azure.
    - Убедитесь, что папка, содержащая исполняемый файл AzCopy, находится в переменной среды PATH системы. Инструкции по изменению переменных среды доступны [здесь](https://support.microsoft.com/en-us/help/310519/how-to-manage-environment-variables-in-windows-xp). Этот пример был протестирован на компьютере с Windows 10, но его можно выполнить на любом компьютере Windows, включая виртуальные машины для обработки и анализа данных Azure. Могут потребоваться небольшие изменения (например, изменения в путях к файлам) при выполнении этого примера на macOS.

### <a name="set-up-azure-resources"></a>Настройка ресурсов Azure

Для этого примера требуется кластер HDInsight Spark и учетная запись хранения Azure для размещения соответствующих файлов. Выполните приведенные ниже действия для создания этих ресурсов в новой группе ресурсов Azure.

#### <a name="create-a-new-workbench-project"></a>Создание проекта в Workbench

Создайте проект, используя в качестве шаблона следующий пример:
1.  Откройте Azure Machine Learning Workbench.
2.  На странице **Projects** (Проекты) щелкните знак **+** и выберите **New Project** (Создать проект).
3.  В области **Create New Project** (Создание проекта) введите информацию о новом проекте.
4.  В поле поиска **Search Project Templates** (Поиск шаблонов проектов) введите Aerial Image Classification (Классификация изображений аэрофотосъемки) и выберите шаблон.
5.  Нажмите кнопку **Создать**
 
#### <a name="create-the-resource-group"></a>Создание группы ресурсов

1. В проекте Azure Machine Learning Workbench откройте интерфейс командной строки (CLI), щелкнув "Файл"-> Open Command Prompt (Открыть командную строку).
1. Из интерфейса командной строки войдите в свою учетную запись Azure с помощью следующей команды:

    ```
    az login
    ```

    Вам будет предложено перейти по URL-адресу и ввести предоставленный временный код. Веб-сайт запросит учетные данные учетной записи Azure.
    
1. Выполнив вход, вернитесь к интерфейсу командной строки и используйте указанную ниже команду, чтобы определить, какие подписки Azure доступны вашей учетной записи Azure.

    ```
    az account list
    ```

    Эта команда выводит список всех подписок, связанных с учетной записью Azure. Найдите идентификатор подписки, которую вы хотите использовать. Укажите идентификатор подписки, как указано в следующей команде, а затем задайте подписку, выполнив эту же команду:

    ```
    az account set --subscription [subscription ID]
    ```

1. Ресурсы Azure, созданные в этом примере, хранятся вместе в группе ресурсов Azure. Выберите уникальное имя группы ресурсов и укажите его в указанном месте, а затем выполните обе команды, чтобы создать группу ресурсов Azure.

    ```
    set AZURE_RESOURCE_GROUP=[resource group name]
    az group create --location eastus --name %AZURE_RESOURCE_GROUP%
    ```

#### <a name="create-the-storage-account"></a>Создание учетной записи хранения

Сейчас мы создадим учетную запись хранения, содержащую файлы проекта, к которым должен обращаться HDInsight Spark.

1. Выберите уникальное имя учетной записи хранения и укажите его, как показано в следующей команде `set`, а затем создайте учетную запись хранения Azure, выполнив обе команды.

    ```
    set STORAGE_ACCOUNT_NAME=[storage account name]
    az storage account create --name %STORAGE_ACCOUNT_NAME% --resource-group %AZURE_RESOURCE_GROUP% --sku Standard_LRS
    ```

1. Выполните следующую команду, чтобы вывести список ключей учетной записи хранения:

    ```
    az storage account keys list --resource-group %AZURE_RESOURCE_GROUP% --account-name %STORAGE_ACCOUNT_NAME%
    ```

    Укажите значение `key1` в качестве ключа к хранилищу данных в следующей команде, а затем выполните ее, чтобы сохранить значение.
    ```
    set STORAGE_ACCOUNT_KEY=[storage account key]
    ```
1. В предпочитаемом текстовом редакторе загрузите файл `settings.cfg` из подкаталога Code проекта Azure Machine Learning Workbench и вставьте имя и ключ учетной записи хранения в соответствии с полученными рекомендациями. Измененные строки в файле должны выглядеть следующим образом:
    ```
    [Settings]
        # Credentials for the Azure Storage account
        storage_account_name = storacctname
        storage_account_key = kpI...88 chars total...Q==
    ```
    Сохраните и закройте файл `settings.cfg`.
1. Если вы еще этого не сделали, скачайте и установите служебную программу [AzCopy](http://aka.ms/downloadazcopy). Убедитесь, что исполняемый файл AzCopy расположен в вашем системном пути. Для этого введите AzCopy и нажмите клавишу ВВОД, чтобы отобразить документацию о нем.
1. Выполните следующие команды, чтобы скопировать все примеры данных, предварительно обученные модели и скрипты для обучения моделей в соответствующие расположения в учетной записи хранения.

    ```
    AzCopy /Source:https://mawahsparktutorial.blob.core.windows.net/test /SourceSAS:"?sv=2017-04-17&ss=bf&srt=sco&sp=rwl&se=2037-08-25T22:02:55Z&st=2017-08-25T14:02:55Z&spr=https,http&sig=yyO6fyanu9ilAeW7TpkgbAqeTnrPR%2BpP1eh9TcpIXWw%3D" /Dest:https://%STORAGE_ACCOUNT_NAME%.blob.core.windows.net/test /DestKey:%STORAGE_ACCOUNT_KEY% /S
    AzCopy /Source:https://mawahsparktutorial.blob.core.windows.net/train /SourceSAS:"?sv=2017-04-17&ss=bf&srt=sco&sp=rwl&se=2037-08-25T22:02:55Z&st=2017-08-25T14:02:55Z&spr=https,http&sig=yyO6fyanu9ilAeW7TpkgbAqeTnrPR%2BpP1eh9TcpIXWw%3D" /Dest:https://%STORAGE_ACCOUNT_NAME%.blob.core.windows.net/train /DestKey:%STORAGE_ACCOUNT_KEY% /S
    AzCopy /Source:https://mawahsparktutorial.blob.core.windows.net/middlesexma2016 /SourceSAS:"?sv=2017-04-17&ss=bf&srt=sco&sp=rwl&se=2037-08-25T22:02:55Z&st=2017-08-25T14:02:55Z&spr=https,http&sig=yyO6fyanu9ilAeW7TpkgbAqeTnrPR%2BpP1eh9TcpIXWw%3D" /Dest:https://%STORAGE_ACCOUNT_NAME%.blob.core.windows.net/middlesexma2016 /DestKey:%STORAGE_ACCOUNT_KEY% /S
    AzCopy /Source:https://mawahsparktutorial.blob.core.windows.net/pretrainedmodels /SourceSAS:"?sv=2017-04-17&ss=bf&srt=sco&sp=rwl&se=2037-08-25T22:02:55Z&st=2017-08-25T14:02:55Z&spr=https,http&sig=yyO6fyanu9ilAeW7TpkgbAqeTnrPR%2BpP1eh9TcpIXWw%3D" /Dest:https://%STORAGE_ACCOUNT_NAME%.blob.core.windows.net/pretrainedmodels /DestKey:%STORAGE_ACCOUNT_KEY% /S
    ```

    Передача файлов займет до 20 минут. Пока вы ожидаете, ознакомьтесь с разделом ниже. Может понадобиться открыть другой интерфейс командной строки в Workbench и переопределить там временные переменные.

#### <a name="create-the-hdinsight-spark-cluster"></a>Создание кластера HDInsight Spark

Для создания кластера HDInsigh мы рекомендуем использовать шаблон Resource Manager кластера HDInsight Spark, который расположен во вложенной папке Code\01_Data_Acquisition_and_Understanding\01_HDInsight_Spark_Provisioning этого проекта.

1. Шаблон кластера HDInsight Spark — это файл template.json, расположенный во вложенной папке Code\01_Data_Acquisition_and_Understanding\01_HDInsight_Spark_Provisioning этого проекта. По умолчанию шаблон создает кластер Spark с 40 рабочими узлами. Если требуется изменить это число, откройте шаблон в предпочитаемом текстовом редакторе и замените все экземпляры с числом 40 необходимым количеством рабочих узлов.
    - Вы можете столкнуться с ошибками нехватки памяти, если выбрано небольшое количество рабочих узлов. Для решения этой проблемы можно запустить скрипты обучения и ввода в эксплуатацию с использованием подмножества доступных данных, как описано далее в этом документе.
2. Выберите уникальное имя и пароль для кластера HDInsight и запишите их, как показано в следующей команде. Затем создайте кластер, выполнив следующую команду:

    ```
    set HDINSIGHT_CLUSTER_NAME=[HDInsight cluster name]
    set HDINSIGHT_CLUSTER_PASSWORD=[HDInsight cluster password]
    az group deployment create --resource-group %AZURE_RESOURCE_GROUP% --name hdispark --template-file "Code\01_Data_Acquisition_and_Understanding\01_HDInsight_Spark_Provisioning\template.json" --parameters storageAccountName=%STORAGE_ACCOUNT_NAME%.blob.core.windows.net storageAccountKey=%STORAGE_ACCOUNT_KEY% clusterName=%HDINSIGHT_CLUSTER_NAME% clusterLoginPassword=%HDINSIGHT_CLUSTER_PASSWORD%
    ```

Развертывание кластера может занять до 30 минут (включая подготовку и выполнение действия скрипта).

### <a name="prepare-the-azure-machine-learning-workbench-execution-environment"></a>Подготовка среды выполнения Azure Machine Learning Workbench

#### <a name="register-the-hdinsight-cluster-as-an-azure-machine-learning-workbench-compute-target"></a>Регистрация кластера HDInsight в качестве целевого объекта вычисления Azure Machine Learning Workbench

Создав кластер HDInsight, зарегистрируйте его в качестве целевого объекта вычисления для вашего проекта следующим образом:

1.  Выполните следующую команду в интерфейсе командной строки Машинного обучения Azure:

    ```
    az ml computetarget attach --name myhdi --address %HDINSIGHT_CLUSTER_NAME%-ssh.azurehdinsight.net --username sshuser --password %HDINSIGHT_CLUSTER_PASSWORD% -t cluster
    ```

    Эта команда добавляет два файла, `myhdi.runconfig` и `myhdi.compute`, в папку `aml_config` проекта.

1. Откройте файл `myhdi.compute` в предпочитаемом текстовом редакторе. Измените строку `yarnDeployMode: cluster` на `yarnDeployMode: client`, а затем сохраните и закройте файл.
1. Выполните следующую команду, чтобы подготовить среду для использования:
   ```
   az ml experiment prepare -c myhdi
   ```

#### <a name="install-local-dependencies"></a>Установка локальных зависимостей

Откройте интерфейс командной строки из Azure Machine Learning Workbench и установите необходимые для локального выполнения зависимости, выполнив следующую команду:

```
pip install matplotlib azure-storage==0.36.0 pillow scikit-learn
```

## <a name="data-acquisition-and-understanding"></a>Получение и изучение данных

В этом сценарии используются общедоступные данные аэрофотоснимков из [программы изображений национального сельского хозяйства](https://www.fsa.usda.gov/programs-and-services/aerial-photography/imagery-programs/naip-imagery/) с разрешением 1 метр. Мы создали наборы PNG-файлов размером 224 x 224 пикселей, обрезанные копии исходных данных программы, которые отсортированы в соответствии с метками землепользования, опубликованными в [базе данных национального растительного покрова США](https://www.mrlc.gov/nlcd2011.php). Пример изображения с меткой Developed показан в полном размере:

![Пример района застройки](media/scenario-aerial-image-classification/sample-tile-developed.png)

Для обучения и проверки модели использовались наборы (с балансировкой классов) изображений в количестве примерно 44 000 и 11 000 соответственно. Мы демонстрируем развертывание модели для набора изображений в количестве примерно 67 000, который охватывает округ Мидлсекс в штате Массачусетс, где находится центр исследований и разработок Новой Англии (NERD) корпорации Майкрософт. Дополнительные сведения о том, как были созданы эти наборы изображений, см. в [репозитории Git, посвященном классификации изображений с усложненным параллелизмом](https://github.com/Azure/Embarrassingly-Parallel-Image-Classification).

![Расположение округа Мидлсекс в штате Массачусетс](media/scenario-aerial-image-classification/middlesex-ma.png)

Во время установки используемые в этом примере наборы изображений аэрофотосъемки были перенесены в созданную вами учетную запись хранения. Все изображения для обучения, проверки и практического применения — это PNG-файлы размером 224 x 224 пикселей с разрешением один пиксель на квадратный метр. Изображения для обучения и проверки упорядочены по вложенным папкам на основе их меток землепользования. (Метки землепользования изображений для практического применения неизвестны и во многих случаях неоднозначны. Некоторые из этих изображений содержат несколько типов земельных покровов.) Дополнительные сведения о том, как были созданы эти наборы изображений, см. в [репозитории Git, посвященном классификации изображений с усложненным параллелизмом](https://github.com/Azure/Embarrassingly-Parallel-Image-Classification).

Чтобы просмотреть примеры изображений в учетной записи хранения Azure (необязательно), сделайте следующее:
1. Войдите на [портал Azure](https://portal.azure.com).
1. Найдите имя вашей учетной записи хранения в строке поиска в верхней части экрана. Щелкните вашу учетную запись хранения в результатах поиска.
2. Щелкните ссылку больших двоичных объектов в главной области учетной записи хранения.
3. Щелкните контейнер с именем train. Должен отобразиться список каталогов, названных в соответствии с типом землепользования.
4. Щелкните любой из этих каталогов, чтобы загрузить список изображений, которые он содержит.
5. Щелкните любое изображение и загрузите его для просмотра.
6. Если нужно, щелкните контейнеры с именами test и middlesexma2016, чтобы также просмотреть их содержимое.

## <a name="modeling"></a>Моделирование

### <a name="training-models-with-mmlspark"></a>Обучение моделей с помощью MMLSpark
Скрипт `run_mmlspark.py` во вложенной папке Code\02_Modeling проекта Workbench используется для обучения модели [MMLSpark](https://github.com/Azure/mmlspark), предназначенной для классификации изображений. Сначала скрипт создает признаки изображений в обучающем наборе с помощью классификатора изображений DNN, предварительно обученного на наборе данных ImageNet (AlexNet или ResNet с 18 слоями). Затем он использует изображения с признаками для обучения модели MMLSpark (модель случайного леса или модель логистической регрессии), чтобы классифицировать изображения. После этого создаются признаки набора изображений тестирования, которые и оцениваются с помощью обученной модели. Точность прогнозов модели на основе тестового набора вычисляется и регистрируется в журнале выполнения Azure Machine Learning Workbench. Наконец, обученная модель MMLSpark и ее прогнозы на основе тестового набора сохраняются в хранилище BLOB-объектов.

Выберите уникальное имя модели вывода для обученной модели, типа предварительно обученной модели и типа модели MMLSpark. Запишите необходимые значения, как показано в шаблоне указанной ниже команды, а затем начните переобучение, выполнив команду в интерфейсе командной строки Машинного обучения Azure.

```
az ml experiment submit -c myhdi Code\02_Modeling\run_mmlspark.py --config_filename Code/settings.cfg --output_model_name [unique model name, alphanumeric characters only] --pretrained_model_type {alexnet,resnet18} --mmlspark_model_type {randomforest,logisticregression}
```

Дополнительный параметр `--sample_frac` можно использовать для обучения и тестирования модели с подмножеством доступных данных. Использование небольшой выборки данных уменьшает требования к среде выполнения и памяти, хотя и за счет точности обученной модели. Чтобы получить дополнительные сведения об этом и других параметрах, выполните команду `python Code\02_Modeling\run_mmlspark.py -h`.

Пользователям рекомендуется выполнить этот скрипт несколько раз, используя разные входные параметры. Эффективность итоговых моделей затем можно сравнить с помощью компонента "Журнал выполнения" приложения Azure Machine Learning Workbench.

### <a name="comparing-model-performance-using-the-workbench-run-history-feature"></a>Сравнение производительности модели с помощью журнала выполнения Workbench

Выполнив два или больше запусков для обучения каждого типа, перейдите к функции "Журнал выполнения" в Workbench, щелкнув значок часов в левой строке меню. Выберите `run_mmlspark.py` из списка скриптов слева. В области будет представлено сравнение точности тестовых наборов для всех запусков. Чтобы просмотреть дополнительные сведения, щелкните имя отдельного запуска.

## <a name="deployment"></a>Развертывание

Чтобы применить одну из ваших обученных моделей к изображениям аэросъемки, охватывающим округ Мидлсекс в штате Массачусетс, используя удаленное выполнение в HDInsight, вставьте имя нужной модели в следующую команду и выполните ее.

```
az ml experiment submit -c myhdi Code\03_Deployment\batch_score_spark.py --config_filename Code/settings.cfg --output_model_name [trained model name chosen earlier]
```

Вы можете использовать дополнительный параметр `--sample_frac`, чтобы ввести в эксплуатацию модель с подмножеством доступных данных. Использование небольшой выборки данных уменьшает требования к среде выполнения и памяти, хотя и за счет полноты прогнозирования. Чтобы получить дополнительные сведения об этом и других параметрах, выполните команду `python Code\03_Deployment\batch_score_spark -h`.

Этот скрипт записывает прогнозы модели в вашу учетную запись хранения. Прогнозы можно проверить, как описано в разделе ниже.

## <a name="visualization"></a>Визуализация:

Записная книжка Jupyter Model prediction analysis (Анализ прогнозирования модели) во вложенной папке Code\04_Result_Analysis проекта Workbench визуализирует прогнозы модели. Загрузите и запустите записную книжку следующим образом:
1. Откройте проект в Workbench и щелкните значок папки ("Файлы") в левом меню, чтобы загрузить список каталогов.
2. Перейдите во вложенную папку Code\04_Result_Analysis и щелкните записную книжку с именем Model prediction analysis (Анализ прогнозирования модели). Должна отобразиться предварительная версия записной книжки.
3. Выберите Start Notebook Server (Запустить сервер записных книжек), чтобы загрузить записную книжку.
4. В первой ячейке в указанной области введите имя модели, результаты которой вы хотите проанализировать.
5. Выберите Cell (Ячейка) > Run All (Запустить все), чтобы запустить все ячейки в записной книжке.
6. Читайте данные, отображаемые в ходе выполнения записной книжки, чтобы получить дополнительные сведения о функциях анализа и визуализации, которые она представляет.

## <a name="cleanup"></a>Очистка
После того как вы выполнили этот пример, мы советуем удалить все созданные ресурсы, запустив указанную ниже команду в интерфейсе командной строки Azure.

  ```
  az group delete --name %AZURE_RESOURCE_GROUP%
  ```

## <a name="references"></a>Ссылки

- [Репозиторий, посвященный классификации изображений с усложненным параллелизмом](https://github.com/Azure/Embarrassingly-Parallel-Image-Classification).
   - Описывает создание набора данных из общедоступных изображений и меток.
- Репозиторий GitHub [MMLSpark](https://github.com/Azure/mmlspark).
   - Содержит дополнительные примеры обучения и проверки модели с помощью MMLSpark.

## <a name="conclusions"></a>Заключение

Azure Machine Learning Workbench помогает специалистам по обработке и анализу данных легко развертывать свой код на удаленных целевых объектах вычислений. В этом примере локальный код был развернут для удаленного выполнения в кластере HDInsight. Журнал выполнения Azure Machine Learning Workbench отслеживает эффективность нескольких моделей и помогает определить наиболее точную модель. Функция записной книжки Jupyter Workbench помогает визуализировать прогнозы моделей в интерактивной графической среде.

## <a name="next-steps"></a>Дальнейшие действия
Чтобы глубже изучить этот пример, сделайте следующее:
- В функции "Журнал выполнения" Azure Machine Learning Workbench щелкните значок с шестеренкой, чтобы выбрать графики и метрики для отображения.
- Проанализируйте операторы, используемые в примерах скриптов, вызвав `run_logger`. Убедитесь, что понимаете, как записывается каждая метрика.
- Проанализируйте операторы, используемые в примерах скриптов, вызвав `blob_service`. Разберитесь в том, как обученные модели и прогнозы сохраняются в облаке и извлекаются из него.
- Просмотрите содержимое контейнеров, созданных в учетной записи хранилища BLOB-объектов. Убедитесь, что вы понимаете, какой скрипт или команда отвечает за создание каждой группы файлов.
- Измените скрипт обучения, чтобы обучить другой тип модели MMLSpark или изменить гиперпараметры модели. Журнал выполнения позволяет определить, увеличили или уменьшили ваши изменения точность модели.
