---
title: Руководство по развертыванию модели для Служб машинного обучения Azure
description: Из этого полного руководства вы узнаете, как использовать Службы машинного обучения Azure. Это третья часть серии руководств. В ней рассматривается развертывание модели.
services: machine-learning
author: aashishb
ms.author: aashishb
manager: mwinkle
ms.reviewer: jmartens, mldocs
ms.service: machine-learning
ms.component: core
ms.workload: data-services
ms.custom: mvc
ms.topic: tutorial
ms.date: 3/13/2018
ms.openlocfilehash: 2270080f8612c69a69955202ececab44136f335c
ms.sourcegitcommit: 1d850f6cae47261eacdb7604a9f17edc6626ae4b
ms.translationtype: HT
ms.contentlocale: ru-RU
ms.lasthandoff: 08/02/2018
ms.locfileid: "39445542"
---
# <a name="tutorial-3-classify-iris-deploy-a-model"></a>Руководство 3. Классификация цветков ириса: развертывание модели
Машинное обучение Azure (предварительная версия) — это полнофункциональное интегрированное аналитическое решение для специалистов по обработке и анализу данных. С помощью этого решения можно подготавливать данные, разрабатывать эксперименты и развертывать модели в масштабах облака.

Это руководство представляет собой **третью, заключительную часть серии**. В этой части руководства вы будете использовать службу "Машинное обучение Azure" (предварительная версия), чтобы научиться выполнять следующие задачи:

> [!div class="checklist"]
> * поиск файла модели;
> * создание скрипта оценки и файла схемы;
> * подготовка среды;
> * создание веб-службы в режиме реального времени;
> * запуск веб-службы в режиме реального времени;
> * изучение выходных данных в формате больших двоичных объектов. 

В этом руководстве используется классический [набор данных "Ирисы Фишера"](https://en.wikipedia.org/wiki/Iris_flower_data_set). 

## <a name="prerequisites"></a>Предварительные требования

Для работы с этим учебником необходимы указанные ниже компоненты.
- Подписка Azure. Если у вас еще нет подписки Azure, [создайте бесплатную учетную запись Azure](https://azure.microsoft.com/free/?WT.mc_id=A261C142F), прежде чем начинать работу. 
- Учетная запись службы экспериментирования и установленное решение Azure Machine Learning Workbench, как указано в этом [кратком руководстве](../service/quickstart-installation.md).
- Модель классификации из [второй части руководства](tutorial-classifying-iris-part-2.md).
- Установленный и локально запущенный модуль Docker.

## <a name="download-the-model-pickle-file"></a>Загрузка файла, содержащего модель
В предыдущей части этого руководства мы локально выполнили скрипт **iris_sklearn.py** в Machine Learning Workbench. При помощи этого скрипта была сериализована модель логистической регрессии с использованием популярного пакета Python [pickle](https://docs.python.org/3/library/pickle.html) для сериализации объектов. 

1. Откройте приложение Azure Machine Learning Workbench. Затем откройте проект **myIris**, созданный в предыдущих частях серии руководств.

1. Открыв проект, нажмите кнопку **Файлы** на панели слева, чтобы в папке проекта отобразился список файлов.

1. Выберите файл **iris_sklearn.py**. На новой вкладке текстового редактора в Workbench откроется код Python.

1. Просмотрите **iris_sklearn.py** файл и найдите, где создан сериализованный файл. При помощи сочетания клавиш CTRL+F откройте диалоговое окно **поиска**. Затем найдите в коде Python слово **pickle**.

   Этот фрагмент кода показывает, как создан сериализованный выходной файл. Выходной файл на диске называется **model.pkl**. 

   ```python
   print("Export the model to model.pkl")
   f = open('./outputs/model.pkl', 'wb')
   pickle.dump(clf1, f)
   f.close()
   ```

1. Найдите сериализованный файл модели в списке выходных файлов последнего запуска.
   
   Когда вы выполнили скрипт **iris_sklearn.py**, файл модели был сохранен в папке **outputs** с именем **model.pkl**. Эта папка находится в среде выполнения, которую вы выбрали для запуска скрипта, а не в локальной папке проекта. 
   
   a. Чтобы найти файл, нажмите кнопку **Запуски** (значок часов) на панели слева для отображения списка **Все запуски**. 

   b. Откроется вкладка **Все запуски**. В таблице выберите один из последних запусков, для которого были указаны целевой объект **local** (локально) и имя сценария **iris_sklearn.py**. 

   c. Откроется панель **свойств запуска**. В верхней правой части этой панели вы увидите раздел **Выходные данные**.

   d. Загрузите сериализованный файл, установив флажок рядом с файлом **model.pkl** и выбрав **Download** (Загрузить). Сохраните этот файл в корневую папку проекта. Файл потребуется при выполнении дальнейших действий.

   ![Загрузка сериализованного файла](media/tutorial-classifying-iris/download_model.png)

   Дополнительные сведения о папке `outputs` см. в статье [Сохранение изменений и работа с большими файлами](how-to-read-write-files.md).

## <a name="get-the-scoring-script-and-schema-files"></a>Получение скрипта оценки и файлов схемы
Чтобы развернуть веб-службу и файл модели, необходим также скрипт оценки. Может также понадобится схема для входных данных веб-службы (необязательно). Скрипт оценки загружает файл **model.pkl** из текущей папки и использует его для создания новых прогнозов.

1. Откройте приложение Azure Machine Learning Workbench. Затем откройте проект **myIris**, созданный в предыдущей части этой серии руководств.

1. Открыв проект, нажмите кнопку **Файлы** на панели слева, чтобы в папке проекта отобразился список файлов.

1. Выберите файл **score_iris.py**. Откроется скрипт Python. Этот файл используется как файл оценки.

   ![Файл оценки](media/tutorial-classifying-iris/model_data_collection.png)

1. Чтобы получить файл схемы, запустите этот скрипт. Выберите на панели команд среду **local** (локальная) и скрипт **score_iris.py**, а затем выберите **Запустить**. 

   При помощи этого скрипта разделе **Выходные данные** создается JSON-файл со схемой входных данных для нашей модели.

1. Обратите внимание на панель **Задания** справа на **панели мониторинга проекта**. Подождите, пока для состояния последнего задания **score_iris.py** не отобразится надпись **Выполнено** зеленого цвета. После этого перейдите по гиперссылке **score_iris.py** рядом с данными последнего запуска задания, чтобы просмотреть сведения. 

1. На панели **свойств запуска** в разделе **Выходные данные** выберите только что созданный файл **service_schema.json**. Установите флажок рядом с именем файла и выберите **Загрузить**. Сохраните этот файл в корневой папке проекта.

1. Вернитесь к предыдущей вкладке, где вы открыли скрипт **score_iris.py**. Использование коллекции данных позволяет сохранять входные данные модели и прогнозы веб-службы. Для сбора данных особое значение имеют следующие этапы.

1. В верхней части файла изучите код, который служит для импорта класса **ModelDataCollector**, так как он предназначен для сбора данных модели:

   ```python
   from azureml.datacollector import ModelDataCollector
   ```

1. Изучите следующий код функции **init()**, при помощи которого создается **ModelDataCollector**:

    ```python
    global inputs_dc, prediction_dc
    inputs_dc = ModelDataCollector('model.pkl',identifier="inputs")
    prediction_dc = ModelDataCollector('model.pkl', identifier="prediction")`
    ```

1. Изучите приведенный ниже код функции **run(input_df)**, предназначенный для сбора входных данных и прогнозов:

    ```python
    inputs_dc.collect(input_df)
    prediction_dc.collect(pred)
    ```

Теперь можно приступить к подготовке среды для ввода модели в эксплуатацию.

## <a name="prepare-to-operationalize-locally-for-development-and-testing-your-service"></a>Подготовка к вводу в эксплуатацию локально (для разработки и тестирования службы)
Используйте развертывание в _локальном режиме_, чтобы запустить контейнер Docker на локальном компьютере.

_Локальный режим_ удобно использовать для разработки и тестирования. Локально запущенная подсистема Docker потребуется, чтобы выполнить следующие действия. Для отображения соответствующего сообщения справки в конце каждой команды можно использовать флаг `-h`.

>[!NOTE]
>Если у вас нет локальной подсистемы Docker, создайте для развертывания кластер в Azure. Вы можете сохранить этот кластер для повторного применение или удалить его по завершении работы с руководством, чтобы не оплачивать использование кластера.

>[!NOTE]
>Веб-службы, которые развернуты локально, не отображаются в списке служб на портале Azure. Они будут запущены в Docker на локальном компьютере.

1. Откройте интерфейс командной строки (CLI).
   В приложении Machine Learning Workbench в меню **Файл** выберите **Open Command Prompt** (Открыть командную строку).

   Откроется окно командной строки, где текущим каталогом будет папка проекта **c:\temp\myIris>**.


1. Убедитесь, что поставщик ресурсов Azure **Microsoft.ContainerRegistry** зарегистрирован в вашей подписке. Зарегистрировать этот поставщик ресурсов нужно до создания среды на шаге 3. С помощью следующей команды вы можете проверить, зарегистрирован ли он:
   ``` 
   az provider list --query "[].{Provider:namespace, Status:registrationState}" --out table 
   ``` 

   Вы должны увидеть примерно такой результат: 
   ```
   Provider                                  Status 
   --------                                  ------
   Microsoft.Authorization                   Registered 
   Microsoft.ContainerRegistry               Registered 
   microsoft.insights                        Registered 
   Microsoft.MachineLearningExperimentation  Registered 
   ... 
   ```
   
   Если поставщик **Microsoft.ContainerRegistry** не зарегистрирован, используйте эту команду:
   ``` 
   az provider register --namespace Microsoft.ContainerRegistry 
   ```
   Регистрация может занять несколько минут. Можно проверить ее состояние с помощью команды **az provider list** или следующей команды:
   ``` 
   az provider show -n Microsoft.ContainerRegistry 
   ``` 

   В третьей строке выходных данных отображается статус регистрации: **"registrationState": "Registering"**. Подождите немного и повторяйте команду **show**, пока в выходных данных не отобразится состояние **"registrationState": "Registered"**.

   >[!NOTE] 
   При развертывании в кластер ACS вам нужно точно так же зарегистрировать еще и поставщик ресурсов **Microsoft.ContainerService**.

1. Создайте среду. Этот шаг однократно выполняется для каждой среды. Например, он один раз выполняется для среды разработки и один раз — для производства. Для первой среды используйте _локальный режим_. Позже вы можете подставить в эту команду параметры `-c` или `--cluster`, чтобы настроить среду в _режиме кластера_.

   Для следующей команды установки требуется разрешение на доступ к подписке уровня участника. Если такого разрешения нет, требуется хотя бы соответствующее разрешение на доступ к группе ресурсов, в которую выполняется развертывание. В последнем случае вам нужно указать имя группы ресурсов как часть команды установки с помощью флага `-g`. 

   ```azurecli
   az ml env setup -n <new deployment environment name> --location <e.g. eastus2>
   ```
   
   Следуйте инструкциям на экране, чтобы подготовить учетную запись хранения для образов Docker, реестр контейнеров Azure для списка образов Docker и учетную запись Azure Application Insights для сбора данных телеметрии. При использовании выключателя `-c` команда дополнительно создаст кластер службы контейнеров.
   
   Среду можно определить с помощью имени кластера. Расположение должно совпадать с тем, которое вы указали при создании учетной записи службы "Управление моделями" на портале Azure.

   Чтобы убедиться, что эта среда настроена успешно, выполните следующую команду для проверки состояния.

   ```azurecli
   az ml env show -n <deployment environment name> -g <existing resource group name>
   ```

   У параметра "Состояние подготовки" должно быть значение Succeeded (Успешно) (как показано ниже). Проверьте это, прежде чем продолжать настройку среды на шаге 5.

   ![Состояние подготовки](media/tutorial-classifying-iris/provisioning_state.png)
 
1. Если в предыдущей части этого руководства вы не создали учетную запись "Управление моделями", сделайте это сейчас. Выполнить эту операцию достаточно один раз.
   ```azurecli
   az ml account modelmanagement create --location <e.g. eastus2> -n <new model management account name> -g <existing resource group name> --sku-name S1
   ```
   
1. Настройте учетную запись службы "Управление моделями".
   ```azurecli
   az ml account modelmanagement set -n <youracctname> -g <yourresourcegroupname>
   ```

1. Настройте среду.

   После установки с помощью приведенной ниже команды задайте переменные среды, которые нужны для ее ввода в эксплуатацию. Используйте то же имя среды, что и на шаге 3. После установки используйте имя группы ресурсов, которое отображалось в окне команды.

   ```azurecli
   az ml env set -n <deployment environment name> -g <existing resource group name>
   ```

1. Чтобы проверить, правильно ли настроена среда реализации для локального развертывания веб-службы, введите следующую команду:

   ```azurecli
   az ml env show
   ```

Теперь все готово для создания веб-службы в режиме реального времени.

>[!NOTE]
>Учетную запись и среду службы "Управление моделями" можно повторно использовать для последующего развертывания веб-служб. Не нужно создавать их для каждой веб-службы. С учетной записью или средой может быть связано несколько веб-служб.

## <a name="create-a-real-time-web-service-in-one-command"></a>Создание веб-службы в режиме реального времени с помощью одной команды
1. Создайте веб-службу в режиме реального времени, используя следующую команду:

   ```azurecli
   az ml service create realtime -f score_iris.py --model-file model.pkl -s service_schema.json -n irisapp -r python --collect-model-data true -c aml_config\conda_dependencies.yml
   ```
   При помощи этой команды создается идентификатор веб-службы, который понадобится позднее.

   С командой **az ml service create realtime** используются следующие параметры:

   * `-f`: имя файла для скрипта оценки.

   * `--model-file`: файл модели. В нашем случае это сериализованный файл model.pkl.

   * `-s`: схема службы. Она была создана на предыдущем шаге путем локального запуска скрипта **score_iris.py**.

   * `-n`: имя приложения (только в нижнем регистре).

   * `-r`: среда выполнения модели. В нашем случае это модель Python. Допустимые среды выполнения — `python` и `spark-py`.

   * `--collect-model-data true`: этот параметр включает сбор данных.

   * `-c`: путь к файлу с зависимостями conda, в котором указаны дополнительные пакеты.

   >[!IMPORTANT]
   >Имя службы (которое совпадает с именем нового образа Docker) может содержать только строчные буквы. В противном случае возникает ошибка. 

1. При выполнении этой команды модель и файлы оценки передаются в учетную запись хранения, созданную в процессе настройки среды. В процессе развертывания создается образ Docker, который содержит вашу модель, схему и файл оценки. Затем образ передается в реестр контейнеров Azure: **\<ACR_name\>.azureacr.io/\<imagename\>:\<version\>**. 

   При помощи этой команды образ переносится на локальный компьютер. Затем запускается контейнер Docker, созданный на основе этого образа. Если среда настроена в режиме кластера, контейнер Docker развертывается в кластер Kubernetes в облачных службах Azure.

   В процессе этого развертывания на локальной машине создается конечная точка HTTP REST для веб-службы. Через несколько минут должно отобразиться сообщение об успешном выполнении команды. Теперь веб-служба готова к работе.

1. Чтобы отобразился контейнер Docker, выполните команду **docker ps**:

   ```azurecli
   docker ps
   ```

## <a name="optional-alternative-create-a-real-time-web-service-by-using-separate-commands"></a>Создание веб-службы в режиме реального времени с помощью отдельных команд (альтернативный метод)
Вместо команды **az ml service create realtime**, представленной выше, можно также выполнить действия по отдельности. 

Сначала зарегистрируйте модель. Затем создайте манифест, соберите образ Docker и создайте веб-службу. Этот пошаговый подход предоставляет больше гибкости. Кроме того, вы можете повторно использовать сущности, созданные на предыдущих шагах, чтобы перестраивать их только при необходимости.

1. Зарегистрируйте модель, указав имя сериализованного файла.

   ```azurecli
   az ml model register --model model.pkl --name model.pkl
   ```
   После выполнения этой команды вы получите идентификатор модели.

1. Создайте манифест.

   Чтобы создать манифест, используйте следующую команду с идентификатором модели, полученным на предыдущем этапе:

   ```azurecli
   az ml manifest create --manifest-name <new manifest name> -f score_iris.py -r python -i <model ID> -s service_schema.json -c aml_config\conda_dependencies.yml
   ```
   После выполнения этой команды вы получите идентификатор манифеста.

1. Создайте образ Docker.

   Чтобы создать образ Docker, используйте следующую команду с идентификатором манифеста, полученным на предыдущем этапе. Вы также можете включить файл с зависимостями conda с помощью параметра `-c`.

   ```azurecli
   az ml image create -n irisimage --manifest-id <manifest ID> 
   ```
   После выполнения этой команды вы получите идентификатор образа Docker.
   
1. Создайте службу.

   Чтобы создать службу, используйте следующую команду с идентификатором образа, полученным на предыдущем этапе:

   ```azurecli
   az ml service create realtime --image-id <image ID> -n irisapp --collect-model-data true
   ```
   После выполнения этой команды вы получите идентификатор веб-службы.

Теперь все готово к запуску веб-службы.

## <a name="run-the-real-time-web-service"></a>Запуск веб-службы в режиме реального времени

Чтобы проверить работу веб-службы **irisapp**, используйте запись в кодировке JSON, содержащую массив из четырех случайных чисел.

1. Веб-служба включает примеры данных. Если вы работаете в локальном режиме, вызовите команду **az ml service usage realtime**. После этого вызова вы получите пример выполнения команды, с помощью которого можно протестировать службу. Также вы получите URL-адрес для оценки, с помощью которого службу можно внедрить в пользовательское приложение.

   ```azurecli
   az ml service usage realtime -i <web service ID>
   ```

1. Чтобы проверить службу, выполните полученную команду запуска:
    
   ```azurecli
   az ml service run realtime -i <web service ID> -d "{\"input_df\": [{\"petal width\": 0.25, \"sepal length\": 3.0, \"sepal width\": 3.6, \"petal length\": 1.3}]}"
   ```

   Выходные данные будут содержать прогнозируемый класс **Iris-setosa**. Вы можете получить другой результат. 

## <a name="view-the-collected-data-in-azure-blob-storage"></a>Просмотр собранных данных в хранилище BLOB-объектов Azure

1. Войдите на [портале Azure](https://portal.azure.com).

1. Перейдите к учетным записям хранения. Для этого выберите **Все службы**.

1. В поле поиска введите **учетные записи хранения** и нажмите клавишу ВВОД.

1. В поле поиска по фразе **учетные записи хранения** выберите ресурс **учетной записи хранения**, соответствующий целевой среде. 

   > [!TIP]
   > Чтобы определить, какая учетная запись хранения используется:
   > 1. Откройте Machine Learning Workbench.
   > 1. Выберите проект, над которым работаете.
   > 1. Откройте командную строку из меню **Файл**.
   > 1. В командной строке введите `az ml env show -v` и проверьте значение *storage_account*. Это и есть имя учетной записи хранения.

1. После того как откроется панель **Учетная запись хранения**, выберите **BLOB-объекты** из раздела **Службы**. Найдите контейнер с именем **modeldata**. 
 
   Если данные не отображаются, подождите немного. После первого запроса к веб-службе может пройти до 10 минут, прежде чем начнется передача данных в учетную запись хранения.

   Потоки данных передаются в большие двоичные объекты по следующему пути контейнера:

   ```
   /modeldata/<subscription_id>/<resource_group_name>/<model_management_account_name>/<webservice_name>/<model_id>-<model_name>-<model_version>/<identifier>/<year>/<month>/<day>/data.csv
   ```

1. Вы можете использовать эти данные из хранилища BLOB-объектов Azure. Программное обеспечение Майкрософт и средства с открытым кодом можно использовать разными способами.

   * Служба "Машинное обучение". Откройте CSV-файл, добавив его как источник данных.

   * Excel. Откройте CSV-файлы с данными за день в качестве электронной таблицы.

   * [Power BI.](https://powerbi.microsoft.com/documentation/powerbi-azure-and-power-bi/) Создавайте диаграммы на основе данных, извлеченных из CSV-файлов в больших двоичных объектах.

   * [Hive.](https://docs.microsoft.com/azure/hdinsight/hdinsight-hadoop-linux-tutorial-get-started) Загрузите данные в формате CSV в таблицу Hive и выполняйте SQL-запросы непосредственно в большие двоичные объекты.

   * [Spark.](https://docs.microsoft.com/azure/hdinsight/hdinsight-apache-spark-overview) Создайте кадр данных с большим сегментом данных в формате CSV.

      ```python
      var df = spark.read.format("com.databricks.spark.csv").option("inferSchema","true").option("header","true").load("wasb://modeldata@<storageaccount>.blob.core.windows.net/<subscription_id>/<resource_group_name>/<model_management_account_name>/<webservice_name>/<model_id>-<model_name>-<model_version>/<identifier>/<year>/<month>/<date>/*")
      ```

## <a name="clean-up-resources"></a>Очистка ресурсов

[!INCLUDE [aml-delete-resource-group](../../../includes/aml-delete-resource-group.md)]

## <a name="next-steps"></a>Дополнительная информация
Из заключительной третьей части этой серии руководств вы узнали, как с помощью службы "Машинное обучение" выполнять следующие задания:
> [!div class="checklist"]
> * поиск файла модели;
> * создание скрипта оценки и файла схемы;
> * подготовка среды;
> * создание веб-службы в режиме реального времени;
> * запуск веб-службы в режиме реального времени;
> * изучение выходных данных в формате больших двоичных объектов. 

Вы успешно запустили скрипт обучения в нескольких средах вычислений, создали модель, сериализовали эту модель и ввели в эксплуатацию через веб-службу на базе Docker. 

Теперь можно переходить к расширенной подготовке данных:
> [!div class="nextstepaction"]
> [Руководство по расширенной подготовке данных для системы совместного использования велосипедов при помощи Azure Machine Learning Workbench](tutorial-bikeshare-dataprep.md)
