<properties 
	pageTitle="Настройка кластеров Hadoop под управлением службы Azure HDInsight для обработки и анализа данных | Azure" 
	description="Настройка кластеров Hadoop под управлением службы Azure HDInsight для обработки и анализа данных" 
	metaKeywords="" 
	services="machine-learning" 
	solutions="" 
	documentationCenter="" 
	authors="hangzh-msft" 
	manager="jacob.spoelstra" 
	editor="cgronlun"  />

<tags 
	ms.service="machine-learning" 
	ms.workload="data-services" 
	ms.tgt_pltfrm="na" 
	ms.devlang="na" 
	ms.topic="article" 
	ms.date="03/17/2015" 
	ms.author="hangzh;bradsev" />

# Настройка кластеров Hadoop под управлением службы Azure HDInsight для обработки и анализа данных

В этой статье рассказывается о том, как настроить кластер Hadoop под управлением службы HDInsight, установив 64-разрядную версию программы Anaconda (Python 2.7) на каждом узле в процессе подготовки кластера в службе HDInsight. Здесь также приведена информация о том, как получить доступ к головному узлу для отправки пользовательских заданий в кластер.

В результате этой настройки многие популярные модули Python, входящие в состав программы Anaconda, станут доступными для использования в определяемых пользователями функциях, предназначенных для обработки записей Hive в кластере. Указания по процедурам, используемым в этом сценарии, см. в статье [Отправка запросов Hive в кластеры HDInsight Hadoop при обработке данных в облаке](machine-learning-data-science-hive-queries.md).

## <a name="customize"></a>Настройка кластера Hadoop под управлением службы Azure HDInsight

Чтобы создать настраиваемый кластер Hadoop под управлением службы HDInsight, пользователям необходимо войти на [**портал управления Azure**](https://manage.windowsazure.com/), щелкнуть **Создать** в левом нижнем углу, а затем выбрать **СЛУЖБЫ ДАННЫХ -> HDINSIGHT -> НАСТРАИВАЕМОЕ СОЗДАНИЕ**, чтобы открыть окно **Сведения о кластере**. 

![Create workspace][1]

Введите имя создаваемого кластера на 1-й странице настройки конфигурации и примите значения по умолчанию для других полей. Щелкните стрелку, чтобы перейти к следующей странице конфигурации. 

![Create workspace][2]

На странице конфигурации 2 введите количество в поле **УЗЛЫ ДАННЫХ**, выберите значение в поле **РЕГИОН или ВИРТУАЛЬНАЯ СЕТЬ** и выберите размеры в полях **ГОЛОВНОЙ УЗЕЛ** и **УЗЕЛ ДАННЫХ**. Щелкните стрелку, чтобы перейти к следующей странице конфигурации.

>[AZURE.NOTE] Значение, выбранное в поле **РЕГИОН или ВИРТУАЛЬНАЯ СЕТЬ**, должно соответствовать региону, указанному для учетной записи хранения, которая будет использоваться для кластера Hadoop под управлением службы HDInsight. В противном случае учетная запись хранения, которую необходимо использовать, не будет отображаться в раскрывающемся списке **ИМЯ УЧЕТНОЙ ЗАПИСИ** на четвертой странице настройки конфигурации.

![Create workspace][3]

На 3-й странице настройки конфигурации укажите имя пользователя и пароль для кластера Hadoop под управлением службы HDInsight. **Не устанавливайте** флажок "Ввести метахранилище Hive или Oozie". Затем щелкните стрелку, чтобы перейти к следующей странице конфигурации. 

![Create workspace][4]

На 4-й странице настройки конфигурации задайте имя учетной записи хранения и контейнер кластера Hadoop под управлением службы HDInsight по умолчанию. Если выбрать в раскрывающемся списке **КОНТЕЙНЕР ПО УМОЛЧАНИЮ** параметр "Создать контейнер по умолчанию", будет создан контейнер с тем же именем, что у кластера. Щелкните стрелку, чтобы перейти к последней странице конфигурации.

![Create workspace][5]

На последней странице настройки конфигурации **Действия скриптов** нажмите кнопку **Добавить действие скрипта** и заполните текстовые поля следующими значениями.
 
* **ИМЯ** - любая строка, соответствующая имени этого действия сценария. 
* **ТИП УЗЛА** - выберите значение **Все узлы**. 
* **URI СЦЕНАРИЯ** - *http://getgoing.blob.core.windows.net/publicscripts/Azure_HDI_Setup_Windows.ps1* 
	* *publicscripts* - это общий контейнер в учетной записи хранения; 
	* *getgoing* - используется для совместного использования файлов сценариев PowerShell, чтобы упростить работу пользователей в Azure. 
* **ПАРАМЕТРЫ** - оставьте это поле пустым.

Наконец, щелкните значок с изображением флажка, чтобы начать создание настраиваемого кластера Hadoop под управлением службы HDInsight. 

![Create workspace][6]

## <a name="headnode"></a> Получение доступа к головному узлу кластера Hadoop

Чтобы получить доступ к головному узлу кластера Hadoop по протоколу RDP, пользователям необходимо включить удаленный доступ к кластеру Hadoop в Azure. 

1. Войдите на [**портал управления Azure**](https://manage.windowsazure.com/), щелкните **HDInsight** в левой части страницы, выберите кластер Hadoop из списка кластеров, перейдите на вкладку **КОНФИГУРАЦИЯ**, а затем щелкните значок **ВКЛЮЧИТЬ УДАЛЕННЫЙ ДОСТУП** в нижней части страницы.
	
	![Create workspace][7]

2. В окне **Настройка удаленного рабочего стола** введите значения в полях "ИМЯ ПОЛЬЗОВАТЕЛЯ" и "ПАРОЛЬ" и выберите дату окончания срока действия для удаленного доступа. Затем щелкните значок с изображением флажка, чтобы включить удаленный доступ к головному узлу кластера Hadoop.
	
	>[AZURE.NOTE] 
	>
	>1. Имя пользователя и пароль для удаленного доступа должны отличаться от имени пользователя и пароля, которые использовались при создании кластера Hadoop. Это отдельный набор учетных данных.
	>
	>2. Срок действия удаленного доступа должен истечь не позднее чем через 7 дней с текущей даты.

	![Create workspace][8]

3. После включения удаленного доступа щелкните **ПОДКЛЮЧИТЬСЯ** в нижней части страницы, чтобы получить удаленный доступ к головному узлу. Войдите на головной узел кластера Hadoop, указав заданные ранее учетные данные для удаленного доступа.

	 ![Create workspace][9]

Указания по получению доступа к модулям Python, которые входят в состав программы Anaconda, с головного узла кластера в определяемых пользователями функциях, предназначенных для обработки записей Hive, которые хранятся в кластере, см. в статье [Отправка запросов Hive в кластеры Hadoop под управлением службы HDInsight при обработке и анализе данных в облаке](machine-learning-data-science-hive-queries.md).

[1]: ./media/machine-learning-data-science-customize-hadoop-cluster/customize-cluster-img1.png
[2]: ./media/machine-learning-data-science-customize-hadoop-cluster/customize-cluster-img2.png
[3]: ./media/machine-learning-data-science-customize-hadoop-cluster/customize-cluster-img3.png
[4]: ./media/machine-learning-data-science-customize-hadoop-cluster/customize-cluster-img4.png
[5]: ./media/machine-learning-data-science-customize-hadoop-cluster/customize-cluster-img5.png
[6]: ./media/machine-learning-data-science-customize-hadoop-cluster/script-actions.png
[7]: ./media/machine-learning-data-science-customize-hadoop-cluster/enable-remote-access-1.png
[8]: ./media/machine-learning-data-science-customize-hadoop-cluster/enable-remote-access-2.png
[9]: ./media/machine-learning-data-science-customize-hadoop-cluster/enable-remote-access-3.png


<!--HONumber=49--> 