---
title: Настройка гиперпараметров модели с помощью службы "Машинное обучение Azure"
description: Здесь содержатся сведения о том, как настроить гиперпараметры для модели глубокого или машинного обучения с помощью службы "Машинное обучение Azure". Вы узнаете, как определить пространство поиска параметров и указать основную метрику, чтобы оптимизировать и досрочно завершать выполнение конфигураций с низкой эффективностью.
ms.author: swatig
author: swatig007
ms.reviewer: sgilley
services: machine-learning
ms.service: machine-learning
ms.component: core
ms.topic: conceptual
ms.date: 09/24/2018
ms.openlocfilehash: b6370fd9125c5b14df781b27e028c139175b7589
ms.sourcegitcommit: b7e5bbbabc21df9fe93b4c18cc825920a0ab6fab
ms.translationtype: HT
ms.contentlocale: ru-RU
ms.lasthandoff: 09/27/2018
ms.locfileid: "47405807"
---
# <a name="tune-hyperparameters-for-your-model"></a>Настройка гиперпараметров модели

В этой статье содержатся сведения о том, как эффективно настроить гиперпараметры модели. Вы узнаете, как определить пространство поиска параметров и указать основную метрику, чтобы оптимизировать и досрочно завершать выполнение конфигураций с низкой эффективностью. Вы также можете визуализировать различные обучающие прогоны и выбрать наиболее эффективную конфигурацию для своей модели.

## <a name="what-are-hyperparameters"></a>Сведения о гиперпараметрах
Гиперпараметры — это настраиваемые параметры, выбранные до обучения модели, которые регулируют сам процесс обучения. Например, перед обучением глубокой нейронной сети нужно выбрать количество скрытых уровней в сети и количество узлов на каждом уровне. Эти значения обычно не изменяются во время процесса обучения.

В сценариях глубокого и машинного обучения эффективность модели в значительной степени зависит от выбранных значений гиперпараметров. Цель изучения гиперпараметров — поиск среди множества конфигураций гиперпараметров ту, которая обеспечивает желаемую эффективность. Как правило, процесс изучения гиперпараметров часто выполняется вручную, учитывая, что пространство поиска очень широкое и оценка каждой конфигурации может быть дорогостоящей.

Служба "Машинное обучение Azure" позволяет автоматизировать исследование гиперпараметров эффективным образом, обеспечивая вам существенную экономию времени и ресурсов. Вы можете указать диапазон значений гиперпараметров для изучения и максимальное количество обучающих прогонов. Затем система автоматически запускает несколько одновременных обучающих прогонов с различными конфигурациями параметров и находит конфигурацию, которая обеспечивает наилучшую эффективность, измеряемую с помощью метрики, выбранной пользователем. Обучающие прогоны с низкой эффективностью автоматически заканчиваются досрочно, снижая потери вычислительных ресурсов. Вместо этого эти ресурсы используются для изучения других конфигураций гиперпараметров.

Чтобы настроить гиперпараметры для своей модели с помощью службы машинного обучения Azure, необходимо сделать следующее.
* Определить пространство поиска гиперпараметров.
* Указать основную метрику для оптимизации.
* Указать политику досрочного завершения.
* Выделить ресурсы для настройки гиперпараметров.
* Запустить эксперимент с использованием представленной выше конфигурации.

## <a name="define-the-hyperparameter-search-space"></a>Определение пространства поиска гиперпараметров
Служба машинного обучения Azure автоматически настраивает гиперпараметры, изучая диапазон значений, определенных для каждого из них.

### <a name="types-of-hyperparameters"></a>Типы гиперпараметров
Каждый гиперпараметр может быть либо дискретным, либо непрерывным.

#### <a name="discrete-hyperparameters"></a>Дискретные гиперпараметры 
Дискретные гиперпараметры могут быть определены как `choice` в дискретных значениях. `choice` может принимать одно или несколько значений, разделенных запятыми, объект `range` или любой произвольный объект `list`. Например:  

```Python
    {    
        "batch_size": choice(16, 32, 64, 128)
        "number_of_hidden_layers": choice(range(1,5))
    }
```

В этом случае batch_size может принимать одно из значений [16, 32, 64, 128], а number_of_hidden_layers может принимать одно из значений [1, 2, 3, 4].

Расширенные дискретные гиперпараметры также могут быть заданы с использованием распределения. Поддерживаются следующие распределения:
* `quniform(low, high, q)` — возвращает значение типа round(uniform(low, high) / q) * q.
* `qloguniform(low, high, q)` — возвращает значение типа round(exp(uniform(low, high)) / q) * q.
* `qnormal(mu, sigma, q)` — возвращает значение типа round(normal(mu, sigma) / q) * q.
* `qlognormal(mu, sigma, q)` — возвращает значение типа round(exp(normal(mu, sigma)) / q) * q.

#### <a name="continuous-hyperparameters"></a>Непрерывные гиперпараметры 
Непрерывные гиперпараметры могут быть указаны как распределение по непрерывному диапазону значений. Поддерживаются такие распределения:
* `uniform(low, high)` — возвращает значение, равномерно распределенное между верхней и нижней границами.
* `loguniform(low, high)` — возвращает значение, полученное в соответствии с exp(uniform(low, high)), так что логарифм возвращаемого значения равномерно распределен.
* `normal(mu, sigma)` — возвращает реальное значение, которое обычно распределяется со средним значением mu и стандартным отклонением sigma.
* `lognormal(mu, sigma)` — возвращает значение, полученное в соответствии с exp(normal(mu, sigma)), так что логарифм возвращаемого значения нормально распределен.

Ниже приведен пример определения пространства параметров:

```Python
    {    
        "learning_rate": normal(10, 3),
        "keep_probability": uniform(0.05, 0.1)
    }
```

В этом примере определяется пространство поиска с двумя параметрами — learning_rate и keep_probability. learning_rate будет иметь нормальное распределение со средним значением 10 и стандартным отклонением 3. keep_probability будет иметь равномерное распределение с минимальным значением 0,05 и максимальным значением 0,1.

### <a name="sampling-the-hyperparameter-space"></a>Выборка пространства гиперпараметров
Пользователь также указывает метод выборки параметров для использования в указанном определении пространства гиперпараметров. Служба "Машинное обучение Azure" поддерживает случайную выборку, решетчатую выборку и байесовскую выборку.

#### <a name="random-sampling"></a>Случайная выборка
В случайной выборке значения гиперпараметров выбираются случайным образом из определенного пространства поиска. Случайная выборка позволяет включать в пространство поиска как дискретные, так и непрерывные гиперпараметры. Например:

```Python
from azureml.train.hyperdrive import RandomParameterSampling
param_sampling = RandomParameterSampling( {
        "learning_rate": normal(10, 3),
        "keep_probability": uniform(0.05, 0.1),
        "batch_size": choice(16, 32, 64, 128)
    }
)
```

#### <a name="grid-sampling"></a>Решетчатая выборка
Решетчатая выборка выполняет простой решетчатый поиск по всем допустимым значениям в определенном пространстве поиска. Ее можно использовать только с гиперпараметрами, указанными с помощью `choice`. Например, следующее пространство имеет в общей сложности шесть выборок.

```Python
from azureml.train.hyperdrive import GridParameterSampling
param_sampling = GridParameterSampling( {
        "num_hidden_layers": choice(1, 2, 3),
        "batch_size": choice(16, 32)
    }
)
```

#### <a name="bayesian-sampling"></a>Байесовская выборка
Байесовская выборка основана на алгоритме Байесовской оптимизации и делает интеллектуальный выбор значений гиперпараметров для последующего отбора. Выборка выбирается на основе того, как выполнялись предыдущие выборки, так что новая выборка улучшает сообщаемую основную метрику.

При использовании байесовской выборки количество одновременных прогонов влияет на эффективность процесса настройки. Как правило, меньшее количество одновременных прогонов может привести к лучшей конвергенции выборки. Это связано с тем, что меньшая степень параллелизма увеличивает количество прогонов, которые выигрывают от ранее завершенных прогонов.

Байесовская выборка поддерживает в пространстве поиска только распределения `choice` и `uniform`. Например: 

```Python
from azureml.train.hyperdrive import BayesianParameterSampling
param_sampling = BayesianParameterSampling( {
        "learning_rate": uniform(0.05, 0.1),
        "batch_size": choice(16, 32, 64, 128)
    }
)
```

> [!NOTE]
> Байесовская выборка в настоящее время не поддерживает политику досрочного завершения (см. раздел[Указание политики досрочного завершения](#specify-an-early-termination-policy)). Если вы используете байесовскую выборку параметров, нужно установить для политики значение `None`. Если не указать политику завершения с байесовской выборкой, эффект будет такой же.
>
> ```Python
> early_termination_policy = None
> ```

## <a name="specify-a-primary-metric-to-optimize"></a>Указание основной метрики для оптимизации
При настройке гиперпараметров нужно указать основную метрику, которую необходимо оптимизировать в результате эксперимента с настройками гиперпараметров. Каждый обучающий прогон оценивается по этой основной метрике, и прогоны с низкой эффективностью (где основная метрика не соответствует критериям, установленным политикой раннего завершения) прекращаются. Помимо указания названия основной метрики также необходимо указать цель оптимизации — максимизировать или свести к минимуму основную метрику.
* `primary_metric_name`: имя основной метрики для оптимизации. Имя основной метрики должно точно соответствовать имени метрики, зарегистрированной в сценарии обучения. См. сведения в разделе [Ведение журнала метрик для настройки гиперпараметров](#log-metrics-for-hyperparameter-tuning).
* `primary_metric_goal`: это может быть `PrimaryMetricGoal.MAXIMIZE` или `PrimaryMetricGoal.MINIMIZE`. Это свойство определяет, что будет выполняться при оценке прогонов: максимизация или минимизация основной метрики. 

Например:
```Python
primary_metric_name="accuracy",
primary_metric_goal=PrimaryMetricGoal.MAXIMIZE
```
В этом случае прогоны оптимизируются, чтобы максимизировать точность.

### <a name="log-metrics-for-hyperparameter-tuning"></a>Ведение журнала метрик для настройки гиперпараметров
Чтобы использовать службу "Машинное обучение Azure" для настройки гиперпараметров, используемый для модели сценарий обучения должен будет сообщать о соответствующих метриках во время выполнения модели. Пользователь указывает основную метрику, которую служба должна использовать для оценки эффективности прогона, а сценарию обучения нужно будет регистрировать эту метрику. См. сведения в разделе [Указание метрики для оптимизации](#specify-a-primary-metric-to-optimize).

Используя приведенный ниже фрагмент кода, вы можете обновить сценарий обучения таким образом, чтобы он регистрировал метрику.

```Python
from azureml.core.run import Run
run_logger = Run.get_submitted_run()
run_logger.log("accuracy", float(val_accuracy))
```

В этом примере сценарий обучения вычисляет `val_accuracy` и записывает эту "точность", которая используется в качестве основной метрики. Разработчик модели должен определить, как часто сообщать об этой метрике.

## <a name="specify-an-early-termination-policy"></a>Указание политики досрочного завершения
При использовании службы "Машинное обучение Azure" для настройки гиперпараметров прогоны с низкой эффективностью автоматически завершаются досрочно. Это позволяет уменьшить потери ресурсов и использовать ресурсы для изучения других конфигураций параметров.

При использовании политики раннего завершения пользователь может настроить следующие параметры, которые управляют применением политики.
* `evaluation_interval`: частота применения политики. Каждый раз, когда сценарий обучения регистрирует основную метрику, это считается одним интервалом. Таким образом, `evaluation_interval` со значением 1 будет применять политику каждый раз, когда сценарий обучения сообщает основную метрику. Таким образом, `evaluation_interval` со значением 2 будет применять политику через раз, когда сценарий обучения сообщает основную метрику. Это необязательный параметр, и если он не указан, для `evaluation_interval` по умолчанию устанавливается значение 1.
* `delay_evaluation`: задерживает первую оценку политики для определенного количества интервалов. Это необязательный параметр, при указании которого все конфигурации выполняются в течение начального минимального количества интервалов, избегая преждевременного завершения обучающих прогонов. Если этот параметр указан, политика применяет каждое кратное значение evaluation_interval, которое больше или равно delay_evaluation.

Служба "Машинное обучение Azure" поддерживает следующие политики досрочного завершения.

### <a name="bandit-policy"></a>Политика Bandit
Политика Bandit — это политика завершения, основанная на факторе или количестве резерва времени и интервале оценки. Эта политика рано заканчивает любые прогоны, где основная метрика не находится в пределах указанного фактора или количества резерва времени в отношении обучающего прогона с самой высокой эффективностью. Эта политика принимает следующие параметры конфигурации:
* `slack_factor` или `slack_amount`: резерв времени, допустимый в отношении обучающего прогона с самой высокой эффективностью. `slack_factor` задает допустимый резерв времени как коэффициент. `slack_amount` указывает допустимый резерв времени как абсолютную величину, а не коэффициент.

    Например, рассмотрим политику Bandit, применяемую в интервале 10. Предположим, что наиболее эффективный прогон в интервале 10 сообщил основную метрику 0,8 с целью ее максимизации. Если политика была указана с использованием `slack_factor` 0,2, любые обучающие прогоны, лучшая метрика которых в интервале 10 меньше 0,66 (0,8/(1+`slack_factor`)), будут завершены. Если вместо этого политика была указана с использованием `slack_amount` 0,2, любые обучающие прогоны, лучшая метрика которых в интервале 10 меньше 0,6 (0,8 – `slack_amount`), будут завершены.
* `evaluation_interval`: частота применения политики (необязательный параметр).
* `delay_evaluation`: задерживает первую оценку политики для определенного количества интервалов (необязательный параметр).

Рассмотрим следующий пример.

```Python
from azureml.train.hyperdrive import BanditPolicy
early_termination_policy = BanditPolicy(slack_factor = 0.1, evaluation_interval=1, delay_evaluation=5)
```

В этом примере политика раннего завершения применяется в каждом интервале, когда указываются метрики, начиная с оценочного интервала 5. Любой прогон, лучшая метрика которого меньше (1/(1+0,1)) или соответствует 91 % от наилучшего прогона, будет завершен.

### <a name="median-stopping-policy"></a>Политика медианной остановки
Политика медианной остановки — это политика раннего завершения, основанная на использовании средних показателей основных метрик, сообщаемых в отчетах о прогонах. Эта политика вычисляет средние значения среди всех обучающих прогонов и завершает прогоны, эффективность которых хуже медианы средних показателей. Она принимает следующие параметры конфигурации:
* `evaluation_interval`: частота применения политики (необязательный параметр).
* `delay_evaluation`: задерживает первую оценку политики для определенного количества интервалов (необязательный параметр).

Рассмотрим следующий пример.

```Python
from azureml.train.hyperdrive import MedianStoppingPolicy
early_termination_policy = MedianStoppingPolicy(evaluation_interval=1, delay_evaluation=5)
```

В этом примере политика раннего завершения применяется в каждом интервале, начиная с оценочного интервала 5. Прогон будет завершен на интервале 5, если его лучшая основная метрика хуже, чем медиана средних показателей за интервалы 1:5 во всех обучающих прогонах.

### <a name="truncation-selection-policy"></a>Политика выбора усечения
Политика выбора усечения отменяет заданный процент прогонов с наихудшей эффективностью за каждый интервал оценки. Прогоны сравниваются в зависимости от их эффективности по основной метрике, и X % прогонов с наименьшей эффектностью завершаются. Эта политика принимает следующие параметры конфигурации:
* `truncation_percentage`: процент прогонов с наименьшей эффективностью, которые будут завершены в каждом интервале оценки. Это должно быть целое число от 1 до 99.
* `evaluation_interval`: частота применения политики (необязательный параметр).
* `delay_evaluation`: задерживает первую оценку политики для определенного количества интервалов (необязательный параметр).

Рассмотрим следующий пример.

```Python
from azureml.train.hyperdrive import TruncationSelectionPolicy
early_termination_policy = TruncationSelectionPolicy(evaluation_interval=1, truncation_percentage=20, delay_evaluation=5)
```

В этом примере политика раннего завершения применяется в каждом интервале, начиная с оценочного интервала 5. Прогон будет завершен в интервале 5, если по эффективности в этом интервале он находится в 20 % прогонов с наихудшей эффективностью в интервале 5.

### <a name="no-termination-policy"></a>Политика без завершения
Если вы хотите, чтобы все обучающие прогоны выполнялись полностью, используйте политику без завершения. Политика досрочного завершения выполняться не будет. Например: 

```Python
from azureml.train.hyperdrive import NoTerminationPolicy
early_termination_policy = NoTerminationPolicy()
```

### <a name="default-policy"></a>Политика по умолчанию
Если политика не указана, служба настройки гиперпараметров будет использовать политику медианной остановки с `evaluation_interval` 1 и `delay_evaluation` 5 по умолчанию. Это консервативные настройки, которые могут обеспечить экономию приблизительно 25–35 % без потерь по основной метрике (на основе наших оценочных данных).

## <a name="allocate-resources-for-hyperparameter-tuning"></a>Выделение ресурсов для настройки гиперпараметров
Вы можете управлять бюджетом ресурсов для своего эксперимента по настройке гиперпараметров, указав максимальное общее количество обучающих прогонов и при необходимости максимальную продолжительность эксперимента (в минутах). 
* `max_total_runs`: максимальное общее количество обучающих прогонов, которые будут созданы. Это верхняя граница. У нас может быть меньше прогонов, например, если пространство гиперпараметров ограничено и имеет меньше выборок. Это значение должно быть в диапазоне от 1 до 1000.
* `max_duration_minutes`: максимальная продолжительность эксперимента по настройке гиперпараметров в минутах. Это необязательный параметр, и если он присутствует, любые прогоны, которые выполняются по истечении этого времени, автоматически отменяются.

>[!NOTE] 
>Если указаны как `max_total_runs`, так и `max_duration_minutes`, эксперимент по настройке гиперпараметров прекращается, когда достигается первое из этих двух пороговых значений.

Кроме того, вы можете указать максимальное количество обучающих прогонов, которые будут выполняться одновременно во время поиска настроек гиперпараметров.
* `max_concurrent_runs`: это максимальное количество прогонов, выполняемых одновременно в любой момент. Если это значение не указано, все `max_total_runs` будут запущены параллельно. Если этот параметр указывается, его значение должно быть числом в диапазоне от 1 до 100.

>[!NOTE] 
>Количество параллельных прогонов зависит от ресурсов, доступных в заданном целевом объекте вычисления. Следовательно, вам нужно будет убедиться, что в целевом объекте вычисления доступны ресурсы для требуемого параллелизма.

Вы можете выделить ресурсы для настройки гиперпараметров, как показано в этом примере.
```Python
max_total_runs=20,
max_concurrent_runs=4
```
В этом случае эксперимент по настройке гиперпараметров будет использовать максимум 20 прогонов, одновременно выполняя 4 конфигурации.

## <a name="configure-your-hyperparameter-tuning-experiment"></a>Конфигурация эксперимента по настройке гиперпараметров
Вы можете настроить эксперимент, используя заданное пространство поиска гиперпаметров, политику раннего завершения, основную метрику и выделение ресурсов из приведенных выше разделов. Кроме того, вам нужно будет предоставить `estimator`, который будет вызываться с выборочными гиперпараметрами. `estimator` описывает выполняемый сценарий обучения, ресурсы на каждое задание (один или несколько GPU) и целевой объект вычисления. Так как параллелизм для вашего эксперимента по настройке гиперпараметров зависит от доступных ресурсов, вам нужно будет убедиться, что целевой объект вычисления, указанный в `estimator`, имеет достаточно ресурсов для желаемого параллелизма. (Дополнительные сведения об инструментах оценки см. в статье [Как обучать модели машинного обучения с помощью Машинного обучения Azure](how-to-train-ml-models.md)).

Ниже приведен пример того, как можно настроить эксперимент по настройке гиперпараметров.

```Python
from azureml.train.hyperdrive import HyperDriveRunConfig
hyperdrive_run_config = HyperDriveRunConfig(estimator=estimator,
                          hyperparameter_sampling=param_sampling, 
                          policy=early_termination_policy,
                          primary_metric_name="accuracy", 
                          primary_metric_goal=PrimaryMetricGoal.MAXIMIZE,
                          max_total_runs=100,
                          max_concurrent_runs=4)
```

## <a name="submit-your-hyperparameter-tuning-experiment"></a>Передача эксперимента по настройке гиперпараметров
После того как вы определили конфигурацию по настройке гиперпараметров, вы можете отправить эксперимент, используя эту конфигурацию:

```Python
from azureml.core.experiment import Experiment
experiment = Experiment(workspace, experiment_name)
hyperdrive_run = experiment.submit(hyperdrive_run_config)
```

Где `experiment_name` — это имя, назначаемое эксперименту по настройке гиперпараметров, а `workspace` — рабочее пространство, в котором нужно создать эксперимент (дополнительные сведения об экспериментах см. по [этой ссылке](/concept-azure-machine-learning-architecture.md)).

## <a name="visualize-your-hyperparameter-tuning-experiment"></a>Визуализация эксперимента по настройке гиперпараметров
Пакет SDK для Машинного обучения Azure предоставляет мини-приложение "Блокнот", которое можно использовать для визуализации процесса обучающих прогонов. Следующий фрагмент кода может быть использован для централизованной визуализации всех прогонов для настройки гиперпараметров.

```Python
from azureml.train.widgets import RunDetails
RunDetails(hyperdrive_run).show()
```

В результате отобразится таблица со сведениями об обучающих прогонах для каждой из конфигураций гиперпараметров. Например:

![Таблица настройки гиперпараметров](media/how-to-tune-hyperparameters/HyperparameterTuningTable.png)

Вы также можете визуализировать эффективность каждого прогона в ходе обучения. Например:

![График настройки гиперпараметров](media/how-to-tune-hyperparameters/HyperparameterTuningPlot.png)

Наконец, вы можете визуально идентифицировать соотношение между эффективностью и значениями отдельных гиперпараметров, используя график параллельных координат. Например: 

![параллельные координаты для настройки гиперпараметров](media/how-to-tune-hyperparameters/HyperparameterTuningParallelCoordinates.png)

Кроме того, вы можете визуализировать все прогоны для настройки гиперпараметров на веб-портале Azure. Дополнительные сведения о том, как просмотреть эксперимент на веб-портале, см. по [этой ссылке](/how-to-track-experiments.md/#view-the-experiment-in-the-web-portal). Например:

![портал настройки гиперпараметров](media/how-to-tune-hyperparameters/HyperparameterTuningPortal.png)

## <a name="find-the-configuration-that-resulted-in-the-best-performance"></a>Поиск конфигурации, которая обеспечила лучшую эффективность
Когда все прогоны для настройки гиперпараметров будут завершены, вы можете определить наилучшую конфигурацию и соответствующие значения гиперпараметров, используя следующий фрагмент кода.

```Python
best_run = hyperdrive_run.get_best_run_by_primary_metric()
best_run_metrics = best_run.get_metrics()
parameter_values = best_run.get_details()['runDefinition']['Arguments']

print('Best Run Id: ', best_run.id)
print('\n Accuracy:', best_run_metrics['accuracy'])
print('\n learning rate:',parameter_values[3])
print('\n keep probability:',parameter_values[5])
print('\n batch size:',parameter_values[7])
```

## <a name="sample-notebook"></a>Пример записной книжки
Перейдите к 
* `training/03.train-hyperparameter-tune-deploy-with-tensorflow/03.train-hyperparameter-tune-deploy-with-tensorflow.ipynb`, чтобы получить дополнительные сведения по настройке гиперпараметров для модели Tensorflow. 

Получите эту записную книжку:

[!INCLUDE [aml-clone-in-azure-notebook](../../../includes/aml-clone-for-examples.md)]

## <a name="next-steps"></a>Дополнительная информация
* [Руководство по отслеживанию эксперимента](how-to-track-experiments.md)
* [Развертывание обученной модели](how-to-deploy-and-where.md)
