---
title: Повышенная точность моделей компьютерного зрения и классификации в службе "Машинное обучение Azure"
description: Узнайте, как повысить точность классификации изображений с помощью компьютерного зрения, обнаружения объектов и моделей сходства изображений, используя пакет Машинного обучения Azure для компьютерного зрения.
services: machine-learning
ms.service: machine-learning
ms.component: core
ms.topic: conceptual
ms.reviewer: jmartens
ms.author: netahw
author: nhaiby
ms.date: 04/23/2018
ms.openlocfilehash: e134e1e544c51d6756d5021fef8c049fe7d8afb0
ms.sourcegitcommit: e221d1a2e0fb245610a6dd886e7e74c362f06467
ms.translationtype: HT
ms.contentlocale: ru-RU
ms.lasthandoff: 05/07/2018
ms.locfileid: "33783583"
---
# <a name="improve-the-accuracy-of-computer-vision-models"></a>Повышение точности модели компьютерного зрения

С помощью **пакета Машинного обучения Azure для компьютерного зрения** вы можете создавать и развертывать модели классификации изображений, обнаружения объектов и сходства изображений. Узнайте об этом пакете и его установке.

В этой статье вы узнаете, как выполнить тонкую настройку этих моделей для повышения их точности. 

## <a name="accuracy-of-image-classification-models"></a>Точность моделей классификации изображений

Пакет для компьютерного зрения позволяет добиться хороших результатов при работе с множеством различных наборов данных. Однако, как и для большинства проектов машинного обучения, для получения наилучших результатов при работе с новым набором данных требуется тщательная настройка параметров, а также следует рассмотреть различные проектные решения. В следующих разделах приведены рекомендации по повышению точности при работе с набором данных, то есть какие параметры наиболее перспективны с точки зрения оптимизации в первую очередь, какие значения для этих параметров следует установить и каких проблем следует избегать.

В общем, обучение модели глубокого обучения сопряжено с компромиссом между временем обучения и точностью модели. В пакете для компьютерного зрения предварительно установлены параметры по умолчанию (см. первую строку в таблице ниже), которые ориентированы на быструю скорость обучения, что обычно позволяет создавать модели с высокой точностью. Эта точность часто может быть дополнительно улучшена с использованием, например, более высокого разрешения изображений или более глубоких моделей, однако за счет увеличения времени обучения в 10 раз и более.

Рекомендуется сначала работать с параметрами по умолчанию, обучить модель, проверить результаты, корректировать реальные заметки по мере необходимости и только затем пробовать изменять параметры, замедляющие обучение (см. таблицу предлагаемых значений параметров ниже). Эти параметры рекомендуется знать, хотя технически это необязательно.


### <a name="best-practices-and-tips"></a>Советы и рекомендации

* Качество данных: обучающий и тестовый наборы должны иметь высокое качество. То есть изображения имеют правильные обозначения, удалены неоднозначные изображения (например, на которых плохо видно, что именно изображено: теннисный мяч или лимон), а атрибуты являются взаимоисключающими (то есть каждое изображение относится к одному атрибуту).

* Перед уточнением глубокой нейронной сети (DNN) классификатор SVM должен быть обучен с использованием предварительно подготовленной и фиксированной DNN в качестве характеризатора. Это поддерживается в пакете для компьютерного зрения и не требует большого количества времени для обучения, так как сама DNN не изменяется. Даже этот простой подход часто обеспечивает высокую точность и, следовательно, высокие базовые показатели. Следующим шагом будет уточнение DNN, которое должно повысить точность.

* Если нужный объект на изображении небольшой, то методы классификации изображений работают не лучшим образом. В таких случаях рекомендуется использовать подход обнаружения объектов, например Faster R-CNN пакета для компьютерного зрения на основе Tensorflow.

* Чем больше обучающих данных, тем лучше. Как правило, для каждого класса должно быть не менее 100 примеров, то есть 100 изображений собак, 100 изображений кошек и т. д. Обучение модели с меньшим количеством изображений возможно, но может не дать хороших результатов.

* Учебные изображения должны размещаться локально на компьютере с графическим процессором и находиться на накопителе SSD (а не на HDD). В противном случае задержки чтения изображений могут значительно снизить скорость обучения (вплоть до 100 раз).


### <a name="parameters-to-optimize"></a>Параметры для оптимизации

Поиск оптимальных значений этих параметров важен и часто может значительно повысить точность:
* Скорость обучения (`lr_per_mb`): возможно, самый важный параметр, который нужно задать правильно. Если точность обучения после уточнения DNN превышает ~5 %, то, скорее всего, скорость обучения слишком высока или количество эпох обучения слишком мало. Особенно в небольших наборах данных DNN имеет тенденцию переобучения в данных, однако на практике это приводит к созданию точных моделей в тестовой выборке. Обычно мы используем 15 эпох, где начальная скорость обучения уменьшается в два раза. Обучение с использованием большего количества эпох может в некоторых случаях повысить производительность.

* Разрешение входных данных (`image_dims`): разрешение по умолчанию составляет 224 x 224 пикселя. Использование более высокого разрешения изображений, например 500 x 500 или 1000 x 1000 пикселей, зачастую значительно повышает точность, но замедляет уточнение DNN. Пакету для компьютерного зрения требуется входное разрешение в виде кортежа (цветовые каналы, ширина и высота изображения), для примера (3, 224, 224), где число цветовых каналов должно иметь значение 3 (каналы "красный-зеленый-синий").

* Архитектура моделирования (`base_model_name`): попробуйте использовать более глубокие DNN, такие как ResNet-34 или ResNet-50, вместо стандартной модели ResNet-18 по умолчанию. Модель Resnet-50 не только глубже, но ее выходные данные предпоследнего слоя представляют собой 2048-битные данные с плавающей запятой (по сравнению с 512-битными данными с плавающей запятой в моделях ResNet-18 и ResNet 34). Это увеличение размерности может быть особенно полезным для сохранения фиксированной DNN и, вместо этого, обучения классификатора SVM.

* Размер мини-пакета (`mb_size`): большие размеры мини-пакетов приведут к ускорению времени обучения, но за счет увеличения потребления памяти со стороны DNN. Таким образом, при выборе более глубоких моделей (например, ResNet-50 по сравнению с ResNet-18) или более высокого разрешения (500 \* 500 пикселей и 224 \* 224 пикселя) обычно приходится уменьшать размер мини-пакетов, чтобы избежать ошибок недостаточного объема памяти. При изменении размера мини-пакетов часто требуется корректировка скорости обучения, как показано в таблице ниже.
* Частота отсева (`dropout_rate`) и регуляризатор L2 (`l2_reg_weight`): перенастройку DNN можно уменьшить с использованием коэффициента отсева 0,5 (по умолчанию 0,5 в пакете для компьютерного зрения) или более и путем увеличения веса регуляризатора (по умолчанию — 0,0005 в пакете для компьютерного зрения). Обратите внимание, что перенастройки DNN сложно, а часто невозможно избежать, особенно при работе с небольшими наборами данных.


### <a name="parameter-definitions"></a>Определения параметров

- **Скорость обучения**: размер шага, используемый во время обучения методом градиентного спуска. Если установлено слишком низкое значение, то обучение модели займет много эпох, если значение слишком высоко, в результате модель будет обучена недостаточно хорошо. Как правило, когда скорость обучения уменьшается после определенного количества эпох, используется расписание. Например, график обучения `[0.05]*7 + [0.005]*7 + [0.0005]` соответствует начальной скорости обучения 0,05 для первых семи эпох, за которой следует 10-кратное понижение скорости обучения 0,005 в течение еще семи эпох и, наконец, точная настройка модели для одной эпохи со 100-кратным уменьшением скорости обучения 0,0005.

- **Размер мини-пакета**: графические процессоры могут обрабатывать несколько изображений параллельно, чтобы ускорить вычисление. Эти параллельно обработанные изображения также называются мини-пакетами. Высокие размеры мини-пакетов приведут к ускорению времени обучения, но за счет увеличения потребления памяти со стороны DNN.

### <a name="recommended-parameter-values"></a>Рекомендуемые значения параметров

В приведенной ниже таблице представлены различные наборы параметров, которые позволяют создавать высокоточные модели для самых разных задач классификации изображений. Оптимальные параметры зависят от конкретного набора данных и используемого GPU, поэтому таблица должна рассматриваться только в качестве примера. После тестирования этих параметров попробуйте также использовать изображения с разрешением более 500 x 500 пикселей или более глубокие модели, такие как Resnet-101 или Resnet-152.

Параметры по умолчанию, заданные внутри пакета для компьютерного зрения, приведены в первой строке таблицы. Все остальные строки занимают больше времени обучения (указано в первом столбце), однако это приводит к повышению точности (см. второй столбец со средней точностью по трем внутренним наборам данных). Например, параметры в последней строке приводят к увеличению времени обучения в 5–15 раз при увеличении (усредненной) точности с 82,6 % до 92,8 % в трех внутренних тестовых наборах.

Для более глубоких моделей и более высокого входного разрешения требуется больший объем памяти DNN, и, следовательно, размер мини-пакетов должен быть уменьшен с увеличением сложности модели, чтобы избежать ошибок недостатка памяти. Как можно увидеть в приведенной ниже таблице, будет полезно уменьшить коэффициент обучения в два раза при уменьшении размера мини-пакетов во столько же раз. Возможно, потребуется дальнейшее уменьшение размера мини-пакетов при использовании графических процессоров с меньшим объемом памяти.

| Время обучения (приблизительная оценка) | Пример точности | Размер мини-пакета (*mb_size*) | Скорость обучения (*lr_per_mb*) | Разрешение изображения (*image_dims*) | Архитектура DNN (*base_model_name*) |
|------------- |:-------------:|:-------------:|:-----:|:-----:|:---:|
| 1 раз (базовая) | 82,6 % | 32 | [0,05]\*7 + [0,005]\*7 + [0,0005]  | (3, 224, 224) | ResNet18_ImageNet_CNTK |
| 2–5 раз    | 90,2 % | 16 | [0,025]\*7 + [0,0025]\*7 + [0,00025] | (3, 500 и 500) | ResNet18_ImageNet_CNTK |
| 2–5 раз    | 87,5 % | 16 | [0,025]\*7 + [0,0025]\*7 + [0,00025] | (3, 224, 224) | ResNet50_ImageNet_CNTK |
| 5–15 раз        | 92,8 % |  8 | [0,01]\*7 + [0,001]\*7 + [0,0001]  | (3, 500 и 500) | ResNet50_ImageNet_CNTK |


## <a name="next-steps"></a>Дополнительная информация

Дополнительные сведения о пакете обучения Azure для компьютерного зрения:
+ Справочная документация

+ Узнайте о [других пакетах Python для Машинного обучения Azure](reference-python-package-overview.md).