---
title: Запись данных с помощью пакета SDK для подготовки данных Машинного обучения Azure (Python)
description: Узнайте, как записывать данные с помощью пакета SDK для подготовки данных Машинного обучения Azure. Можно записать данные в любой точке потока данных, а также в файлы в любом из поддерживаемых расположений (локальная файловая система, хранилище BLOB-объектов Azure и Azure Data Lake Storage).
services: machine-learning
ms.service: machine-learning
ms.component: core
ms.topic: conceptual
ms.author: cforbe
author: cforbe
manager: cgronlun
ms.reviewer: jmartens
ms.date: 09/24/2018
ms.openlocfilehash: 81344d388fbba0db034b8adb06adab6797ec2ce1
ms.sourcegitcommit: 51a1476c85ca518a6d8b4cc35aed7a76b33e130f
ms.translationtype: HT
ms.contentlocale: ru-RU
ms.lasthandoff: 09/25/2018
ms.locfileid: "47166753"
---
# <a name="write-data-using-the-azure-machine-learning-data-prep-sdk"></a>Запись данных с помощью пакета SDK для подготовки данных Машинного обучения Azure
Можно записать данные в любой точке потока данных. Эти записи добавляются в качестве шагов к результирующему потоку данных и выполняются каждый раз, когда выполняется поток данных. Если разрешить параллельные операции записи, данные будут записываться в несколько файлов раздела.

Так как нет никаких ограничений по количеству шагов записи в конвейере, можно легко добавить дополнительные шаги записи, чтобы устранить неполадки или передать их для других конвейеров. 

Каждый раз, когда вы запускаете шаг записи, происходит полное извлечение данных в потоке данных. Например, три шага записи потока данных будут считывать и обрабатывать каждую запись в наборе данных три раза.

## <a name="supported-data-types-and-location"></a>Поддерживаемые типы данных и расположение

Поддерживаются следующие форматы файлов:
-   файлы с разделителями (CSV, TSV и т. д.);
-   файлы Parquet;

С помощью [пакета SDK для подготовки данных Машинного обучения Azure для Python](https://aka.ms/data-prep-sdk) можно записать данные в:
+ локальную файловую систему;
+ Хранилище больших двоичных объектов Azure
+ Хранилище Azure Data Lake.

## <a name="spark-considerations"></a>Рекомендации для Spark
Выполнение потока данных в Spark необходимо записывать в пустую папку. Попытка выполнить запись в существующую папку завершится ошибкой. Убедитесь, что папка целевого объекта пуста или использует другое целевое расположение для каждого запуска, иначе запись завершится ошибкой.

## <a name="monitoring-write-operations"></a>Мониторинг операций записи
Для вашего удобства после завершения записи создается отдельный файл с именем SUCCESS. Его наличие поможет определить, когда закончится запись в промежуточном режиме, без необходимости ожидать завершения всего конвейера.

## <a name="example-write-code"></a>Пример кода записи

В этом примере для начала загрузите данные в поток данных. Эти данные будут повторно использоваться в различных форматах.

```python
import azureml.dataprep as dprep
t = dprep.smart_read_file('./data/fixed_width_file.txt')
t = t.to_number('Column3')
t.head(10)
```   

Выходные данные примера:
|   |  Column1 |    Column2 | Column3 | Column4  |Column5   | Column6 | Column7 | Column8 | Column9 |
| -------- |  -------- | -------- | -------- |  -------- |  -------- |  -------- |  -------- |  -------- |  -------- |
| 0 |   10000,0 |   99999,0 |   None|       НЕТ|     НЕТ  |   ENRS    |NaN    |   NaN |   NaN|    
|   1|      10003,0 |   99999,0 |   None|       НЕТ|     НЕТ  |   ENSO|       NaN|        NaN |NaN|   
|   2|  10010,0|    99999,0|    None|   НЕТ| JN| ENJA|   70933,0|    –8667,0 |90,0|
|3| 10013,0|    99999,0|    None|   НЕТ| НЕТ| |   NaN|    NaN|    NaN|
|4.| 10014,0|    99999,0|    None|   НЕТ| НЕТ| ENSO|   59783,0|    5350,0| 500,0|
|5| 10015,0|    99999,0|    None|   НЕТ| НЕТ| ENBL|   61383,0|    5867,0| 3270,0|
|6| 10016,0 |99999,0|   None|   НЕТ| НЕТ|     |64850,0|   11233,0|    140,0|
|7| 10017,0|    99999,0|    None|   НЕТ| НЕТ| ENFR|   59933,0|    2417,0| 480,0|
|8| 10020,0|    99999,0|    None|   НЕТ| SV|     |80050,0|   16250,0|    80,0|
|9| 10030,0|    99999,0|    None|   НЕТ| SV|     |77000,0|   15500,0|    120,0|

### <a name="delimited-file-example"></a>Пример файла с разделителями

В этом разделе содержится пример использования функции `write_to_csv` для записи с помощью файла с разделителями.

```python
# Create a new data flow using `write_to_csv` 
write_t = t.write_to_csv(directory_path=dprep.LocalFileOutput('./test_out/'))

# Run the data flow to begin the write operation.
write_t.run_local()

written_files = dprep.read_csv('./test_out/part-*')
written_files.head(10)
```

Выходные данные примера:
|   |  Column1 |    Column2 | Column3 | Column4  |Column5   | Column6 | Column7 | Column8 | Column9 |
| -------- |  -------- | -------- | -------- |  -------- |  -------- |  -------- |  -------- |  -------- |  -------- |
| 0 |   10000,0 |   99999,0 |   ОШИБКА |       НЕТ|     НЕТ  |   ENRS    |ОШИБКА    |   ОШИБКА |   ОШИБКА|    
|   1|      10003,0 |   99999,0 |   ОШИБКА |       НЕТ|     НЕТ  |   ENSO|       ОШИБКА|        ОШИБКА |ОШИБКА|   
|   2|  10010,0|    99999,0|    ОШИБКА |   НЕТ| JN| ENJA|   70933,0|    –8667,0 |90,0|
|3| 10013,0|    99999,0|    ОШИБКА |   НЕТ| НЕТ| |   ОШИБКА|    ОШИБКА|    ОШИБКА|
|4.| 10014,0|    99999,0|    ОШИБКА |   НЕТ| НЕТ| ENSO|   59783,0|    5350,0| 500,0|
|5| 10015,0|    99999,0|    ОШИБКА |   НЕТ| НЕТ| ENBL|   61383,0|    5867,0| 3270,0|
|6| 10016,0 |99999,0|   ОШИБКА |   НЕТ| НЕТ|     |64850,0|   11233,0|    140,0|
|7| 10017,0|    99999,0|    ОШИБКА |   НЕТ| НЕТ| ENFR|   59933,0|    2417,0| 480,0|
|8| 10020,0|    99999,0|    ОШИБКА |   НЕТ| SV|     |80050,0|   16250,0|    80,0|
|9| 10030,0|    99999,0|    ОШИБКА |   НЕТ| SV|     |77000,0|   15500,0|    120,0|

В предыдущих выходных данных видно, что в числовых столбцах есть несколько ошибок из-за чисел, которые не были правильно проанализированы. При записи в CSV-файл эти значения null заменяются строкой "ОШИБКА" по умолчанию. 

Можно добавить параметры как часть вызова записи и указать строки, которые используются для представления значений null. Например: 

```python
write_t = t.write_to_csv(directory_path=dprep.LocalFileOutput('./test_out/'), 
                         error='BadData',
                         na='NA')
write_t.run_local()
written_files = dprep.read_csv('./test_out/part-*')
written_files.head(10)
```

Предыдущий код производит такие выходные данные:
|   |  Column1 |    Column2 | Column3 | Column4  |Column5   | Column6 | Column7 | Column8 | Column9 |
| -------- |  -------- | -------- | -------- |  -------- |  -------- |  -------- |  -------- |  -------- |  -------- |
| 0 |   10000,0 |   99999,0 |   BadData |       НЕТ|     НЕТ  |   ENRS    |BadData    |   BadData |   BadData|    
|   1|      10003,0 |   99999,0 |   BadData |       НЕТ|     НЕТ  |   ENSO|       BadData|        BadData |BadData|   
|   2|  10010,0|    99999,0|    BadData |   НЕТ| JN| ENJA|   70933,0|    –8667,0 |90,0|
|3| 10013,0|    99999,0|    BadData |   НЕТ| НЕТ| |   BadData|    BadData|    BadData|
|4.| 10014,0|    99999,0|    BadData |   НЕТ| НЕТ| ENSO|   59783,0|    5350,0| 500,0|
|5| 10015,0|    99999,0|    BadData |   НЕТ| НЕТ| ENBL|   61383,0|    5867,0| 3270,0|
|6| 10016,0 |99999,0|   BadData |   НЕТ| НЕТ|     |64850,0|   11233,0|    140,0|
|7| 10017,0|    99999,0|    BadData |   НЕТ| НЕТ| ENFR|   59933,0|    2417,0| 480,0|
|8| 10020,0|    99999,0|    BadData |   НЕТ| SV|     |80050,0|   16250,0|    80,0|
|9| 10030,0|    99999,0|    BadData |   НЕТ| SV|     |77000,0|   15500,0|    120,0|


### <a name="parquet-file-example"></a>Пример файла PARQUET

Так же как и `write_to_csv`, функция `write_to_parquet` возвращает новый поток данных с шагом записи Parquet, который выполняется при запуске потока данных.

```python
write_parquet_t = t.write_to_parquet(directory_path=dprep.LocalFileOutput('./test_parquet_out/'),
error='MiscreantData')
```

Затем вы можете запустить поток данных, чтобы начать операцию записи.

```
write_parquet_t.run_local()

written_parquet_files = dprep.read_parquet_file('./test_parquet_out/part-*')
written_parquet_files.head(10)
```

Предыдущий код производит такие выходные данные:
|   |  Column1 |    Column2 | Column3 | Column4  |Column5   | Column6 | Column7 | Column8 | Column9 |
| -------- |  -------- | -------- | -------- |  -------- |  -------- |  -------- |  -------- |  -------- |  -------- |
| 0 |   10000,0 |   99999,0 |   MiscreantData |       НЕТ|     НЕТ  |   ENRS    |MiscreantData    |   MiscreantData |   MiscreantData|    
|   1|      10003,0 |   99999,0 |   MiscreantData |       НЕТ|     НЕТ  |   ENSO|       MiscreantData|        MiscreantData |MiscreantData|   
|   2|  10010,0|    99999,0|    MiscreantData |   НЕТ| JN| ENJA|   70933,0|    –8667,0 |90,0|
|3| 10013,0|    99999,0|    MiscreantData |   НЕТ| НЕТ| |   MiscreantData|    MiscreantData|    MiscreantData|
|4.| 10014,0|    99999,0|    MiscreantData |   НЕТ| НЕТ| ENSO|   59783,0|    5350,0| 500,0|
|5| 10015,0|    99999,0|    MiscreantData |   НЕТ| НЕТ| ENBL|   61383,0|    5867,0| 3270,0|
|6| 10016,0 |99999,0|   MiscreantData |   НЕТ| НЕТ|     |64850,0|   11233,0|    140,0|
|7| 10017,0|    99999,0|    MiscreantData |   НЕТ| НЕТ| ENFR|   59933,0|    2417,0| 480,0|
|8| 10020,0|    99999,0|    MiscreantData |   НЕТ| SV|     |80050,0|   16250,0|    80,0|
|9| 10030,0|    99999,0|    MiscreantData |   НЕТ| SV|     |77000,0|   15500,0|    120,0|
