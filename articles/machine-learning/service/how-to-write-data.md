---
title: Запись данных с помощью пакета SDK для подготовки данных Машинного обучения Azure (Python)
description: Узнайте, как записывать данные с помощью пакета SDK для подготовки данных Машинного обучения Azure. Можно записать данные в любой точке потока данных, а также в файлы в любом из поддерживаемых расположений (локальная файловая система, хранилище BLOB-объектов Azure и Azure Data Lake Storage).
services: machine-learning
ms.service: machine-learning
ms.component: core
ms.topic: conceptual
ms.author: cforbe
author: cforbe
manager: cgronlun
ms.reviewer: jmartens
ms.date: 09/24/2018
ms.openlocfilehash: da5823473b7f69fa0a6c65d5ea7319bfd2e92720
ms.sourcegitcommit: 32d218f5bd74f1cd106f4248115985df631d0a8c
ms.translationtype: HT
ms.contentlocale: ru-RU
ms.lasthandoff: 09/24/2018
ms.locfileid: "46946771"
---
# <a name="write-data-with-the-azure-machine-learning-data-prep-sdk"></a>Запись данных с помощью пакета SDK для подготовки данных Машинного обучения Azure
Можно записать данные в любой точке потока данных. Эти записи добавляются в качестве шагов к результирующему потоку данных и выполняются каждый раз, когда выполняется поток данных. Так как нет никаких ограничений по количеству записей шагов в конвейере, несложно записать промежуточные результаты для устранения неполадок или передать их другим конвейерам. Важно отметить, что выполнение каждого шага записи приводит к полной операции извлечения данных в потоке данных. Например, три шага записи потока данных будут считывать и обрабатывать каждую запись в наборе данных три раза.

## <a name="writing-to-files"></a>Запись в файлы
С помощью [пакета SDK для подготовки данных Машинного обучения Azure](https://docs.microsoft.com/python/api/overview/azure/dataprep?view=azure-dataprep-py) можно записать данные в файлы в любом из поддерживаемых расположений (локальная файловая система, хранилище BLOB-объектов Azure и Azure Data Lake Storage). Если разрешить параллельные операции записи, данные будут записываться в несколько файлов раздела. После завершения записи также создается отдельный файл с именем SUCCESS. Это поможет определить, когда закончится запись в промежуточном режиме, без необходимости ожидать завершения всего конвейера.

Выполнение потока данных в Spark необходимо записывать в пустую папку. Попытка выполнить запись в существующую папку завершится сбоем. Убедитесь, что папка целевого объекта пуста или использует другое целевое расположение для каждого запуска, иначе запись завершится ошибкой.

Пакет SDK для подготовки данных Машинного обучения Azure поддерживает следующие форматы файлов:
-   файлы с разделителями (CSV, TSV и т. д.);
-   файлы Parquet;

В этом примере для начала загрузите данные в поток данных. Эти данные будут повторно использоваться в различных форматах.

```

import azureml.dataprep as dprep
t = dprep.smart_read_file('./data/fixed_width_file.txt')
t = t.to_number('Column3')
t.head(10)
```   

|   |  Column1 |    Column2 | Column3 | Column4  |Column5   | Column6 | Column7 | Column8 | Column9 |
| -------- |  -------- | -------- | -------- |  -------- |  -------- |  -------- |  -------- |  -------- |  -------- |
| 0 |   10000,0 |   99999,0 |   None|       НЕТ|     НЕТ  |   ENRS    |NaN    |   NaN |   NaN|    
|   1|      10003,0 |   99999,0 |   None|       НЕТ|     НЕТ  |   ENSO|       NaN|        NaN |NaN|   
|   2|  10010,0|    99999,0|    None|   НЕТ| JN| ENJA|   70933,0|    –8667,0 |90,0|
|3| 10013,0|    99999,0|    None|   НЕТ| НЕТ| |   NaN|    NaN|    NaN|
|4.| 10014,0|    99999,0|    None|   НЕТ| НЕТ| ENSO|   59783,0|    5350,0| 500,0|
|5| 10015,0|    99999,0|    None|   НЕТ| НЕТ| ENBL|   61383,0|    5867,0| 3270,0|
|6| 10016,0 |99999,0|   None|   НЕТ| НЕТ|     |64850,0|   11233,0|    140,0|
|7| 10017,0|    99999,0|    None|   НЕТ| НЕТ| ENFR|   59933,0|    2417,0| 480,0|
|8| 10020,0|    99999,0|    None|   НЕТ| SV|     |80050,0|   16250,0|    80,0|
|9| 10030,0|    99999,0|    None|   НЕТ| SV|     |77000,0|   15500,0|    120,0|

## <a name="delimited-files"></a>Файлы с разделителями
Следующая строка создает новый поток данных с шагом записи, но фактическая запись еще не происходит. Когда запущен поток данных, будет выполняться запись.

```
write_t = t.write_to_csv(directory_path=dprep.LocalFileOutput('./test_out/'))
```
Теперь запустите поток данных, который выполняет операции записи.
```
write_t.run_local()

written_files = dprep.read_csv('./test_out/part-*')
written_files.head(10)
```
|   |  Column1 |    Column2 | Column3 | Column4  |Column5   | Column6 | Column7 | Column8 | Column9 |
| -------- |  -------- | -------- | -------- |  -------- |  -------- |  -------- |  -------- |  -------- |  -------- |
| 0 |   10000,0 |   99999,0 |   ОШИБКА |       НЕТ|     НЕТ  |   ENRS    |ОШИБКА    |   ОШИБКА |   ОШИБКА|    
|   1|      10003,0 |   99999,0 |   ОШИБКА |       НЕТ|     НЕТ  |   ENSO|       ОШИБКА|        ОШИБКА |ОШИБКА|   
|   2|  10010,0|    99999,0|    ОШИБКА |   НЕТ| JN| ENJA|   70933,0|    –8667,0 |90,0|
|3| 10013,0|    99999,0|    ОШИБКА |   НЕТ| НЕТ| |   ОШИБКА|    ОШИБКА|    ОШИБКА|
|4.| 10014,0|    99999,0|    ОШИБКА |   НЕТ| НЕТ| ENSO|   59783,0|    5350,0| 500,0|
|5| 10015,0|    99999,0|    ОШИБКА |   НЕТ| НЕТ| ENBL|   61383,0|    5867,0| 3270,0|
|6| 10016,0 |99999,0|   ОШИБКА |   НЕТ| НЕТ|     |64850,0|   11233,0|    140,0|
|7| 10017,0|    99999,0|    ОШИБКА |   НЕТ| НЕТ| ENFR|   59933,0|    2417,0| 480,0|
|8| 10020,0|    99999,0|    ОШИБКА |   НЕТ| SV|     |80050,0|   16250,0|    80,0|
|9| 10030,0|    99999,0|    ОШИБКА |   НЕТ| SV|     |77000,0|   15500,0|    120,0|

Из-за чисел, которые не были правильно проанализированы, записанные данные имеют несколько ошибок в числовых столбцах. При записи в CSV-файл эти значения null заменяются строкой "ОШИБКА" по умолчанию. Можно добавить параметры как часть вызова записи и указать строки, которые используются для представления значений null.

```
write_t = t.write_to_csv(directory_path=dprep.LocalFileOutput('./test_out/'), 
                         error='BadData',
                         na='NA')
write_t.run_local()
written_files = dprep.read_csv('./test_out/part-*')
written_files.head(10)
```
|   |  Column1 |    Column2 | Column3 | Column4  |Column5   | Column6 | Column7 | Column8 | Column9 |
| -------- |  -------- | -------- | -------- |  -------- |  -------- |  -------- |  -------- |  -------- |  -------- |
| 0 |   10000,0 |   99999,0 |   BadData |       НЕТ|     НЕТ  |   ENRS    |BadData    |   BadData |   BadData|    
|   1|      10003,0 |   99999,0 |   BadData |       НЕТ|     НЕТ  |   ENSO|       BadData|        BadData |BadData|   
|   2|  10010,0|    99999,0|    BadData |   НЕТ| JN| ENJA|   70933,0|    –8667,0 |90,0|
|3| 10013,0|    99999,0|    BadData |   НЕТ| НЕТ| |   BadData|    BadData|    BadData|
|4.| 10014,0|    99999,0|    BadData |   НЕТ| НЕТ| ENSO|   59783,0|    5350,0| 500,0|
|5| 10015,0|    99999,0|    BadData |   НЕТ| НЕТ| ENBL|   61383,0|    5867,0| 3270,0|
|6| 10016,0 |99999,0|   BadData |   НЕТ| НЕТ|     |64850,0|   11233,0|    140,0|
|7| 10017,0|    99999,0|    BadData |   НЕТ| НЕТ| ENFR|   59933,0|    2417,0| 480,0|
|8| 10020,0|    99999,0|    BadData |   НЕТ| SV|     |80050,0|   16250,0|    80,0|
|9| 10030,0|    99999,0|    BadData |   НЕТ| SV|     |77000,0|   15500,0|    120,0|
## <a name="parquet-files"></a>файлы Parquet;

 Так же как и `write_to_csv`, функция `write_to_parquet` возвращает новый поток данных с шагом записи Parquet, который будет выполняться при запуске потока данных.

```
write_parquet_t = t.write_to_parquet(directory_path=dprep.LocalFileOutput('./test_parquet_out/'),
error='MiscreantData')
```
 Теперь запустите поток данных, который выполняет операции записи.

```
write_parquet_t.run_local()

written_parquet_files = dprep.read_parquet_file('./test_parquet_out/part-*')
written_parquet_files.head(10)
```
|   |  Column1 |    Column2 | Column3 | Column4  |Column5   | Column6 | Column7 | Column8 | Column9 |
| -------- |  -------- | -------- | -------- |  -------- |  -------- |  -------- |  -------- |  -------- |  -------- |
| 0 |   10000,0 |   99999,0 |   MiscreantData |       НЕТ|     НЕТ  |   ENRS    |MiscreantData    |   MiscreantData |   MiscreantData|    
|   1|      10003,0 |   99999,0 |   MiscreantData |       НЕТ|     НЕТ  |   ENSO|       MiscreantData|        MiscreantData |MiscreantData|   
|   2|  10010,0|    99999,0|    MiscreantData |   НЕТ| JN| ENJA|   70933,0|    –8667,0 |90,0|
|3| 10013,0|    99999,0|    MiscreantData |   НЕТ| НЕТ| |   MiscreantData|    MiscreantData|    MiscreantData|
|4.| 10014,0|    99999,0|    MiscreantData |   НЕТ| НЕТ| ENSO|   59783,0|    5350,0| 500,0|
|5| 10015,0|    99999,0|    MiscreantData |   НЕТ| НЕТ| ENBL|   61383,0|    5867,0| 3270,0|
|6| 10016,0 |99999,0|   MiscreantData |   НЕТ| НЕТ|     |64850,0|   11233,0|    140,0|
|7| 10017,0|    99999,0|    MiscreantData |   НЕТ| НЕТ| ENFR|   59933,0|    2417,0| 480,0|
|8| 10020,0|    99999,0|    MiscreantData |   НЕТ| SV|     |80050,0|   16250,0|    80,0|
|9| 10030,0|    99999,0|    MiscreantData |   НЕТ| SV|     |77000,0|   15500,0|    120,0|
