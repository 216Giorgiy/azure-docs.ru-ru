---
title: "Жизненный цикл процесса обработки и анализа данных группы | Документация Майкрософт"
description: "Этапы жизненного цикла и компоненты для структурирования проектов по обработке и анализу данных."
services: machine-learning
documentationcenter: 
author: bradsev
manager: jhubbard
editor: cgronlun
ms.assetid: b1f677bb-eef5-4acb-9b3b-8a5819fb0e78
ms.service: machine-learning
ms.workload: data-services
ms.tgt_pltfrm: na
ms.devlang: na
ms.topic: article
ms.date: 02/08/2017
ms.author: bradsev;hangzh;gokuma
translationtype: Human Translation
ms.sourcegitcommit: 1796f7a7cd174d7ed6582878d72c59995aac41cb
ms.openlocfilehash: 995ba0dc3ffd2bc78625db7d1176ca0d5e1611a0


---
# <a name="team-data-science-process-lifecycle"></a>Жизненный цикл процесса обработки и анализа данных группы
Процесс обработки и анализа данных группы (TDSP) выполняется в рамках рекомендуемого жизненного цикла, позволяя структурировать разработку проектов по обработке и анализу данных. Этот жизненный цикл представляет стандартные этапы выполнения проектов, от самого начала и до завершения. Если вы используете другой жизненный цикл обработки и анализа данных, например [CRISP-DM](https://wikipedia.org/wiki/Cross_Industry_Standard_Process_for_Data_Mining), [KDD](https://wikipedia.org/wiki/Data_mining#Process) или собственный корпоративный процесс, вы все равно можете использовать TDSP в нужном контексте разработки. 

Этот жизненный цикл предназначен для проектов обработки и анализа данных, которые входят в состав интеллектуальных приложений. Такие приложения развертывают модели машинного обучения или искусственного интеллекта для прогнозной аналитики. Также этот процесс будет полезен при работе с исследовательскими проектами обработки и анализа данных, а также проектами на основе ad-hoc-аналитики. Хотя в этих сценариях некоторые шаги могут быть ненужными.    

Ниже представлена схема **жизненного цикла TDSP**. 

![Жизненный цикл TDSP](./media/data-science-process-overview/tdsp-lifecycle.png) 

Жизненный цикл TDSP включает пять основных этапов, которые выполняются циклически. В частности, описаны такие возможности:

* **Анализ потребностей бизнеса**
* **Получение и анализ данных**
* **Моделирование**
* **Развертывание**
* **Приемка клиентом**

Для каждого этапа предоставляется следующая информация.

* **Цели** — определенные и детализированные задачи.
* **Как это сделать** — описание определенных задач с рекомендациями по их выполнению.
* **Артефакты** — конечные результаты и поддержка их реализации.

## <a name="1-business-understanding"></a>1. Коммерческий аспект.
### <a name="goals"></a>Цели
* Определяются **ключевые переменные** — они будут использоваться в качестве **целевых показателей модели**, а связанные с ними метрики позже помогут определить успешность проекта.
* Определяются релевантные **источники данных** — те, к которым уже есть доступ, или дополнительные при необходимости.

### <a name="how-to-do-it"></a>Как это сделать
На этом этапе нужно решить две основные задачи. 

* **Определение целей**. Совместно с клиентом и другими заинтересованными сторонами нужно проанализировать и определить бизнес-задачи. Сформулируйте вопросы, которые определяют бизнес-цели и которые можно решить с помощью методов обработки и анализа данных.
* **Определение источников данных**. Найдите релевантные данные, которые помогут ответить на вопросы, определяющие цели проекта.

#### <a name="11-define-objectives"></a>1.1 Определение целей
1. Основная задача этого этапа — определить ключевые **бизнес-переменные**, которые должен прогнозировать ваш анализ. Эти переменные называются **целевыми показателями модели**, а связанные с ними метрики позволяют определить успешность проекта. Примеры таких показателей представлены прогнозом объемов продаж или вероятностью того, что заказ окажется мошенническим.
2. Определите **целевые показатели модели**, создавая и уточняя острые вопросы: релевантные, конкретные и однозначные. Обработка и анализ данных — это работа с именами и числами для получения ответов на такие вопросы. "*Формулируя вопрос, представьте, что вы зададите его оракулу, который знает абсолютно все. Но ответить он вам может, только используя число или имя*". Дополнительные рекомендации можно найти в разделе **Ask a Sharp Question** (Как задать острый вопрос) записи блога [How to do Data Science](https://blogs.technet.microsoft.com/machinelearning/2016/03/28/how-to-do-data-science/) (Как выполнять обработку и анализ данных).   Обработка и анализ данных наряду с машинным обучением обычно применяются, чтобы отвечать на вопросы следующих пяти типов.
   * Сколько? (регрессия)
   * Какая категория? (классификация)
   * Какая группа? (кластеризация)
   * Является ли это странным? (обнаружение аномалий)
   * Какой вариант следует выбрать? (рекомендация)
3. Определите **команду проекта**, распределив роли и обязанности между его участниками. Разработайте обобщенный поэтапный план, который вы будете уточнять по мере получения дополнительных сведений.  
4. **Определите метрики успешности**. Например: спрогнозировать показатель оттока клиентов к моменту завершения 3-месячного проекта с точностью до X %, чтобы можно было составить рекламные предложения для минимизации оттока. Метрики должны соответствовать концепции **SMART**: 
   * **S**pecific (конкретные); 
   * **M**easurable (измеримые);
   * **A**chievable (достижимые); 
   * **R**elevant (релевантные); 
   * **T**ime-bound (с привязкой ко времени). 

#### <a name="12-identify-data-sources"></a>1.2 Определение источников данных
Определите источники данных, которые содержат известные примеры ответов на ваши острые вопросы. Вот что нужно искать.

* **Релевантные** данные для постановки вопроса. Есть ли у нас меры, описывающие целевой объект, или характеристики, имеющие к нему отношение?
* Данные, которые представляют **точную меру** целевых показателей модели или интересующую нас характеристику.

Например, редко встречаются системы, в которых для решения проблемы и достижения целей проекта собираются и регистрируются дополнительные типы данных. В этом случае вам нужно найти внешние источники данных или изменить систему для сбора новых данных.

### <a name="artifacts"></a>Артефакты
Ниже представлены некоторые примеры конечных результатов для этого этапа.

* [**Учредительный документ**](https://github.com/Azure/Azure-TDSP-ProjectTemplate/blob/master/Docs/Project/Charter.md). Стандартный шаблон предоставляется в определении структуры проекта TDSP. Это динамический документ, который обновляется в ходе выполнения проекта, когда появляются новые данные и изменяются бизнес-требования. Важно постоянно пересматривать этот документ, добавляя подробности по мере обнаружения данных. Работайте над обновлением вместе с клиентом и другими заинтересованными сторонами, четко объясняя им причины вносимых изменений.  
* [**Источники данных**](https://github.com/Azure/Azure-TDSP-ProjectTemplate/blob/master/Docs/DataReport/Data%20Defintion.md#raw-data-sources). Это часть отчета о данных, который входит в структуру проекта TDSP. Здесь описываются источники необработанных данных. На более поздних этапах вы добавите новые сведения, например скрипты для переноса данных в аналитическую среду.  
* [**Данные**](https://github.com/Azure/Azure-TDSP-ProjectTemplate/tree/master/Docs/DataDictionaries). Этот документ содержит описания и схемы (типы данных, сведения о правилах проверки, если они есть) для всех данных, которые используются для ответа на поставленный вопрос. Сюда входят также диаграммы или описания отношений между сущностями, если они существуют.

## <a name="2-data-acquisition-and-understanding"></a>2. Получение и анализ данных
### <a name="goals"></a>Цели
* Чистый набор данных высокого качества с понятными связями с целевыми переменными, размещенный в среде аналитики и готовый к моделированию.
* Готовая архитектура решения для конвейера данных, который будет регулярно обновлять и оценивать данные.

### <a name="how-to-do-it"></a>Как это сделать
На этом этапе нужно решить три основные задачи.

* **Прием данных** в целевую аналитическую среду.
* **Просмотр данных** для проверки того, позволяет ли качество данных ответить на поставленный вопрос. 
* **Настройка конвейера данных** для оценки новых или регулярно обновляемых данных.

#### <a name="21-ingest-the-data"></a>2.1 Прием данных
Выполните подготовку к перемещению данных из исходных расположений в целевые, где будут выполняться аналитические операции, например обучение и прогнозирование. Технические сведения и описание операций с использованием разных служб данных Azure см. в статье [Загрузка данных в среды хранения для аналитики](machine-learning-data-science-ingest-data.md). 

#### <a name="22-explore-the-data"></a>2.2 Просмотр данных
Прежде чем начинать обучение модели, нужно хорошо изучить имеющиеся данные. Наборы реальных данных часто характеризуются наличием шума и отсутствием нужных значений. Кроме того, такие данные бывают несогласованными. Чтобы оценить качество данных, можно использовать сводную информацию и визуализацию. Это снабдит вас информацией, необходимой для обработки данных в ходе подготовки к моделированию. Рекомендации по очистке данных см. в статье [Задачи по подготовке данных для расширенного машинного обучения](machine-learning-data-science-prepare-data.md). Часто этот процесс итеративный. 

Процесс TDSP включает автоматизированное средство [IDEAR](https://github.com/Azure/Azure-TDSP-Utilities/blob/master/DataScienceUtilities/DataReport-Utils), которое позволяет визуализировать данные и подготавливать сводные отчеты. Мы рекомендуем приступить к интерактивному изучению исходных данных с помощью IDEAR до написания кода. И только потом создавать пользовательский код для просмотра и визуализации данных. 

Когда вы будете удовлетворены качеством очищенных данных, переходите к анализу тенденций в данных. Таким образом вы сможете выбрать и подготовить прогнозную модель, соответствующую поставленной цели. Ищите свидетельства, подтверждающие наличие связи между данными и целями. А также убедитесь в том, что у вас достаточно информации для перехода к следующим шагам моделирования. Этот процесс также часто бывает итеративным. Возможно, вам понадобятся новые источники информации с более точными или релевантными данными, которые дополнят уже определенный набор данных.  

#### <a name="23-set-up-a-data-pipeline"></a>2.3 Настройка конвейера данных
Наряду с исходным процессом приема и очистки данных, как правило, требуется настроить еще и процесс оценки новых данных или их регулярного обновления в ходе обучения. Для этого можно настроить конвейер данных или рабочий процесс. Ниже приведен [пример](machine-learning-data-science-move-sql-azure-adf.md) по настройке конвейера в [фабрике данных Azure](https://azure.microsoft.com/services/data-factory/). На этом этапе создается архитектура решения для конвейера данных. Конвейер также разрабатывается параллельно со следующими этапами проекта обработки и анализа данных. Конвейер может использовать пакетную или потоковую (в том числе в режиме реального времени) передачу данных, либо гибридное решение в зависимости от бизнес-потребностей и ограничений существующих систем, с которыми это решение интегрируется. 

### <a name="artifacts"></a>Артефакты
Ниже представлены некоторые примеры конечных результатов для этого этапа.

* [**Отчет о качестве данных**](https://github.com/Azure/Azure-TDSP-ProjectTemplate/blob/master/Docs/DataReport/DataSummaryReport.md). Этот отчет будет содержать сводную информацию о данных, связи каждого атрибута с целевым объектом, ранжирование переменных и т. д. Средство [IDEAR](https://github.com/Azure/Azure-TDSP-Utilities/blob/master/DataScienceUtilities/DataReport-Utils) как часть TDSP может быстро создавать такой отчет по любому набору табличных данных, например CSV-файлу или реляционной таблице. 
* **Архитектура решения**. Это может быть схема или описание конвейера данных, используемого для оценки или прогнозирования на основе новых данных после построения модели. Также сюда входит конвейер для повторного обучения модели на основе новых данных. Документ хранится в этом [каталоге](https://github.com/Azure/Azure-TDSP-ProjectTemplate/tree/master/Docs/Project), если используется шаблон структуры каталогов TDSP.
* **Контрольная точка принятия решения**. Перед началом полномасштабного проектирования и создания модели стоит повторно оценить проект, чтобы определить, стоит ли он того, чтобы и дальше находится на этапе подготовки. Возможно, вы уже готовы продолжать, или вам нужны дополнительные данные, или от проекта пора отказаться из-за отсутствия данных, необходимых для получения ответа.

## <a name="3-modeling"></a>3. Моделирование
### <a name="goals"></a>Цели
* Оптимальные характеристики данных для модели машинного обучения.
* Информативная модель машинного обучения, которая наиболее точно прогнозирует целевой объект.
* Модель машинного обучения, пригодная для рабочей среды.

### <a name="how-to-do-it"></a>Как это сделать
На этом этапе нужно решить три основные задачи.

* **Проектирование признаков**. Создайте характеристики данных на основе необработанных данных, чтобы упростить обучение модели.
* **Обучение модели**. Найдите модель, которая наиболее точно отвечает на поставленный вопрос, сравнивая метрики успешности для моделей.
* Определите, будет ли модель **пригодной для рабочей среды**.

#### <a name="31-feature-engineering"></a>3.1 Проектирование признаков
Проектирование признаков включает учет, статистическую обработку и преобразование необработанных переменных для создания характеристик, используемых в анализе. Если вы хотите понять лежащие в основе своей модели механизмы, необходимо проанализировать связь между признаками и разобраться, как алгоритмы машинного обучения будут использовать эти признаки. На этом этапе требуется творческое сочетание опыта и информации, полученной на этапе анализа данных. Здесь важен баланс. Вам нужно найти и учесть информативные переменные, не создавая при этом лишние несвязанные переменные. Информативные переменные улучшают ваш результат, а несвязанные — добавляют в модель ненужный шум. При создании признаков нужно учитывать все новые данные, полученные во время оценки. Создание признаков может основываться только на тех данных, которые доступны во время оценки. Техническое руководство по проектированию признаков при использовании различных технологий данных Azure см. в статье [Реконструирование характеристик в процессе аналитики Кортаны](machine-learning-data-science-create-features.md). 

#### <a name="32-model-training"></a>3.2 Обучение модели
В зависимости от типа вопроса, на который вы ищете ответ, можно использовать разные алгоритмы моделирования. Инструкции по выбору алгоритма см. в статье [Выбор алгоритмов машинного обучения Microsoft Azure](machine-learning-algorithm-choice.md). Хотя эта статья посвящена службе машинного обучения Azure, содержащиеся рекомендации полезны и для других платформ машинного обучения. 

Процесс обучения модели включает следующие шаги: 

* Разделение входных данных для моделирования случайным образом на два набора данных: для обучения и для тестирования.
* Создайте модель с помощью набора данных для обучения.
* Оцените (по наборам данных для обучения и тестирования) несколько конкурирующих алгоритмов машинного обучения, а также связанных с ними параметров настройки (перебор параметров), которые определяют ответы на поставленный вопрос по имеющимся данным.
* Выясните, какое из решений наиболее точно отвечает на этот вопрос, сравнивая метрики успешности для альтернативных вариантов.

> [!NOTE]
> **Избегайте утечки данных**. Утечка данных, вызванная включением данных, внешних по отношению к обучающему набору данных, может привести к нереалистично высокой точности прогнозов модели или алгоритма машинного обучения. Именно риск утечки заставляет волноваться специалистов по обработке и анализу данных, когда полученные ими прогнозы являются слишком хорошими, чтобы быть правдой. Такие зависимости иногда очень трудно обнаружить. Чтобы избежать этого, часто нужно несколько раз повторить весь процесс: разработать набор данных для анализа, создать модель и оценить точность. 
> 
> 

Поэтому мы также предлагаем [средство автоматизированного моделирования и отчетности](https://github.com/Azure/Azure-TDSP-Utilities/blob/master/DataScienceUtilities/Modeling) как часть TDSP. Это средство может выполнить перебор нескольких алгоритмов и параметров для создания базовой модели. Оно также составит базовый отчет о моделировании, описывающий производительность для каждой комбинации моделей и параметров с указанием важности переменных. Этот процесс также является итеративным и может привести к дополнительному проектированию параметров. 

### <a name="artifacts"></a>Артефакты
На этом этапе создаются следующие артефакты.

* [**Наборы параметров**](https://github.com/Azure/Azure-TDSP-ProjectTemplate/blob/master/Docs/DataReport/Data%20Defintion.md#feature-sets). Параметры, разработанные для моделирования, описываются в разделе "Набор параметров" отчета об определении данных. Здесь есть указатели на код, создающий эти параметры, и описание самого процесса создания.
* [**Отчет о моделировании**](https://github.com/Azure/Azure-TDSP-ProjectTemplate/blob/master/Docs/Model/Model%201/Model%20Report.md). Для каждой проверенной модели создается стандартный отчет по указанному шаблону TDSP.
* **Контрольная точка принятия решения**. Оцените, достаточно ли хорошо работает модель, чтобы развернуть ее в рабочей системе. Здесь нужно ответить на такие вопросы.
  * Отвечает ли модель на поставленный вопрос по тестовым данным достаточно надежно? 
  * Не нужно ли рассмотреть альтернативные решения, например, собрать дополнительные данные, повторить этап проектирования признаков или проверить другие алгоритмы?

## <a name="4-deployment"></a>4. Развертывание
### <a name="goal"></a>Цель
* Модели и конвейер развертываются в производственную или близкую к ней среду для окончательного утверждения клиентом. 

### <a name="how-to-do-it"></a>Как это сделать
Основная задача, решаемая на этом этапе.

* **Ввод модели в эксплуатацию**. Разверните модель и конвейер в рабочую или близкую к ней среду, чтобы приложения могли к ней обращаться.

#### <a name="41-operationalize-a-model"></a>4.1 Ввод модели в эксплуатацию
Создав набор эффективно работающих моделей, можно ввести их в эксплуатацию для взаимодействия с другими приложениями. В зависимости от бизнес-требований прогнозы выполняются в режиме реального времени или в пакетном режиме. Модель готова к вводу в эксплуатацию, если она оснащена открытым API-интерфейсом, с которым без проблем могут взаимодействовать самые разные приложения, включая веб-сайты, электронные таблицы, панели мониторинга, бизнес-приложения и серверные приложения. Примеры ввода в эксплуатацию веб-службы машинного обучения Azure см. в статье [Развертывание веб-службы машинного обучения Azure](machine-learning-publish-a-machine-learning-web-service.md). Также мы рекомендуем встроить в производственную модель и развернутый конвейер средства телеметрии и мониторинга. Это позволит вам получать отчеты о состоянии системы и устранять неполадки.  

### <a name="artifacts"></a>Артефакты
* Панель мониторинга состояния работоспособности и ключевых метрик.
* Окончательный отчет о моделировании с информацией о развертывании.
* Документированная окончательная архитектура решения.

## <a name="5-customer-acceptance"></a>5. Приемка клиентом
### <a name="goal"></a>Цель
* **Завершите создание конечных результатов по проекту**. Убедитесь, что конвейер, модель и их развертывание в рабочей среде соответствуют задачам клиента.

### <a name="how-to-do-it"></a>Как это сделать
На этом этапе нужно решить три основные задачи.

* **Проверка системы**. Убедитесь, что развернутые модель и конвейер удовлетворяют требованиям клиента.
* **Передача проекта**. Передайте проект субъекту, который будет использовать систему в рабочей среде.

Клиент должен проверить, соответствует ли система его бизнес-требованиям и дает ли она ответы на поставленные вопросы с точностью, достаточной для развертывания в рабочей среде для использования клиентским приложением. Завершается подготовка и проверка документации. Составляется протокол передачи проекта субъекту, ответственному за эксплуатацию. Это может быть ИТ-отдел или команда обработки и анализа данных из клиентской организации либо представитель клиента, ответственный за эксплуатацию системы в рабочей среде. 

### <a name="artifacts"></a>Артефакты
Основной артефакт, создаваемый на последнем этапе процесса — это документ под названием [**Окончательный отчет по проекту**](https://github.com/Azure/Azure-TDSP-ProjectTemplate/blob/master/Docs/Project/Exit%20Report.md). В этот технический отчет входят все сведения о проекте, которые могут быть полезны для знакомства с системой и работы с ней. В рамках также предоставляется [шаблон](https://github.com/Azure/Azure-TDSP-ProjectTemplate/blob/master/Docs/Project/Exit%20Report.md), который можно использовать как есть или настроить в соответствии с потребностями клиента. 

## <a name="summary"></a>Сводка
[Жизненный цикл TDSP](http://aka.ms/datascienceprocess) моделируется как циклическая последовательность этапов. По сути это — руководство по выполнению задач, необходимых для работы с прогнозными моделями. Эти модели можно развертывать в рабочей среде и использовать для создания интеллектуальных приложений. Жизненный цикл этого процесса помогает развивать проект по анализу и обработке данных до четко определенной конечной цели, предусматривающей его применение. Разумеется, обработка и анализ данных — это исследовательская деятельность. Но если вы сможете доходчиво объяснить все ключевые моменты сотрудникам и клиентам с помощью хорошо определенного набора артефактов и стандартизированных шаблонов, вы сможете избежать недопонимания и существенно повысить вероятность успешной реализации сложного аналитического проекта.

## <a name="next-steps"></a>Дальнейшие действия
Также предоставляются полные пошаговые руководства, которые демонстрируют все этапы процесса для **конкретных сценариев** . Они перечислены с описаниями эскизов в статье [Пошаговые руководства по процессу обработки и анализа данных](data-science-process-walkthroughs.md) .




<!--HONumber=Feb17_HO2-->


