<properties
   pageTitle="Создание кластеров HDInsight с хранилищем озера данных Azure с помощью портала | Azure"
   description="Создание кластеров HDInsight для работы с хранилищем озера данных Azure с помощью портала Azure"
   services="data-lake-store,hdinsight" 
   documentationCenter=""
   authors="nitinme"
   manager="paulettm"
   editor="cgronlun"/>

<tags
   ms.service="data-lake-store"
   ms.devlang="na"
   ms.topic="article"
   ms.tgt_pltfrm="na"
   ms.workload="big-data"
   ms.date="08/29/2016"
   ms.author="nitinme"/>

# Создание кластера HDInsight с хранилищем озера данных с помощью портала Azure

> [AZURE.SELECTOR]
- [Использование портала](data-lake-store-hdinsight-hadoop-use-portal.md)
- [PowerShell](data-lake-store-hdinsight-hadoop-use-powershell.md)


Узнайте, как с помощью портала Azure создать кластер HDInsight (Hadoop, HBase, Spark или Storm) с доступом к хранилищу озера данных Azure. Важные сведения, которые следует учитывать при работе с данным выпуском.

* **В кластерах Spark (Linux) и Hadoop (Windows и Linux)** хранилище озера данных может использоваться только как дополнительная учетная запись хранения. Учетной записью хранения по умолчанию для таких кластеров по-прежнему будут BLOB-объекты хранилища Azure (WASB).

* **В кластерах Storm (Windows и Linux)** хранилище озера данных может использоваться для записи данных из топологии Storm. Хранилище озера данных также может использоваться для хранения справочных данных, которые затем можно будет прочитать с помощью топологии Storm. Дополнительные сведения см. в разделе [Использование хранилища озера данных в топологии Storm](#use-data-lake-store-in-a-storm-topology).

* **Для кластеров HBase (Windows и Linux)** Data Lake Store можно использовать как хранилище по умолчанию, а также как дополнительное хранилище. Дополнительные сведения см. в разделе [Использование хранилища озера данных с кластерами HBase](#use-data-lake-store-with-hbase-clusters).

> [AZURE.NOTE] Необходимо учитывать следующие важные замечания.
> 
> * Создание кластеров HDInsight с доступом к хранилищу озера данных доступно только при использовании HDInsight версии 3.2 и 3.4 (для кластеров Hadoop, HBase и Storm, как для Windows, так и для Linux). Для кластеров Spark в ОС Linux этот параметр доступен только для кластеров HDInsight 3.4.
>
> * Как упоминалось выше, хранилище озера данных доступно как хранилище по умолчанию для кластеров одних типов (HBase) и как дополнительное хранилище для кластеров других типов (Hadoop, Spark, Storm). Использование хранилища озера данных в качестве дополнительной учетной записи хранения не влияет на производительность или возможность выполнять чтение и запись в хранилище из кластера. В сценарии, при котором хранилище озера данных используется в качестве дополнительного хранилища, относящиеся к кластеру файлы (журналы и т. д.) записываются в хранилище по умолчанию (большие двоичные объекты Azure), а данные, которые необходимо обработать, могут храниться в учетной записи хранилища озера данных.


## Предварительные требования

Перед началом работы с этим учебником необходимо иметь следующее:

- **Подписка Azure.**. См. [Бесплатная пробная версия Azure](https://azure.microsoft.com/pricing/free-trial/).
- **Настройте свою подписку Azure** для использования общедоступной предварительной версии Data Lake Store. См. [инструкции](data-lake-store-get-started-portal.md#signup).
- **Учетная запись хранилища озера данных Azure**. Следуйте инструкциям в разделе [Приступая к работе с хранилищем озера данных Azure на портале Azure](data-lake-store-get-started-portal.md). После создания учетной записи выполните следующие задачи, чтобы передать некоторые примеры данных. Эти данные потребуются позже при выполнении заданий из кластера HDInsight для получения доступа к данным в хранилище озера данных.

	* [Создать папку в хранилище озера данных](data-lake-store-get-started-portal.md#createfolder).
	* [Передать файл в хранилище озера данных](data-lake-store-get-started-portal.md#uploaddata). Если у вас нет под рукой подходящих для этих целей данных, передайте папку **Ambulance Data** из [репозитория Git для озера данных Azure](https://github.com/Azure/usql/tree/master/Examples/Samples/Data/AmbulanceData).

## Учитесь быстрее с помощью видео?

Просмотрите следующие видео, чтобы понять, как подготовить кластеры HDInsight с доступом к хранилищу озера данных.

* [Создание кластера Azure HDInsight с доступом к хранилищу озера данных Azure.](https://mix.office.com/watch/l93xri2yhtp2)
* После настройки кластера [используйте сценарии Hive и Pig для доступа к данным в хранилище озера данных](https://mix.office.com/watch/1n9g5w0fiqv1q).

## Создание кластера Azure HDInsight с доступом к хранилищу озера данных Azure

В этом разделе мы создадим кластер HDInsight Hadoop, использующий хранилище озера данных в качестве дополнительного хранилища. В этом выпуске в кластере Hadoop хранилище озера данных может использоваться только как дополнительное хранилище кластера. Хранилищем по умолчанию по-прежнему будут большие двоичные объекты хранилища Azure (WASB). Поэтому мы сначала создадим учетную запись хранения и контейнеры хранилища, необходимые для кластера.

1. Перейдите на новый [портал Azure](https://portal.azure.com).

2. Выполните действия, описанные в разделе [Создание кластеров Hadoop в HDInsight](../hdinsight/hdinsight-provision-clusters.md#create-using-the-preview-portal), чтобы начать подготовку кластера HDInsight.

3. В колонке **Дополнительная настройка** щелкните **Источник данных**. В колонке **Источник данных** укажите данные учетной записи хранения и контейнера хранилища, в поле **Расположение** укажите **Восток США 2** и нажмите кнопку **Удостоверение кластера AAD**.

	![Добавление субъекта-службы в кластер HDInsight](./media/data-lake-store-hdinsight-hadoop-use-portal/hdi.adl.1.png "Добавление субъекта-службы в кластер HDInsight")

4. В колонке **Удостоверение кластера AAD** можно выбрать существующий субъект-службу или создать новый.

	* **Создание субъекта-службы.**

		* В колонке **Удостоверение кластера AAD** щелкните **Создать**, выберите **Субъект-служба**, а затем в колонке **Создание субъекта-службы** укажите параметры для создания субъекта-службы. В рамках этого процесса также создаются сертификат и приложение Azure Active Directory. Щелкните **Создать**.

			![Добавление субъекта-службы в кластер HDInsight](./media/data-lake-store-hdinsight-hadoop-use-portal/hdi.adl.2.png "Добавление субъекта-службы в кластер HDInsight")

		* В колонке **Удостоверение кластера AAD** щелкните **Управление доступом ADLS**. Откроется панель, на которой отображаются связанные с подпиской учетные записи Data Lake Store. Однако разрешения можно задать только для созданной вами учетной записи. Установите флажки для разрешений "ЧТЕНИЕ", "ЗАПИСЬ" и "ВЫПОЛНЕНИЕ" для учетной записи, которую нужно связать с кластером HDInsight, и нажмите кнопку **Сохранить разрешения**.

			![Добавление субъекта-службы в кластер HDInsight](./media/data-lake-store-hdinsight-hadoop-use-portal/hdi.adl.3.png "Добавление субъекта-службы в кластер HDInsight")

		* В колонке **Удостоверение кластера AAD** щелкните **Скачать сертификат**, чтобы скачать сертификат, связанный с субъектом-службой, которую вы создали. Это нужно, если требуется использовать один субъект-службу в будущем при создании дополнительных кластеров HDInsight. Нажмите кнопку **Выбрать**.

			![Добавление субъекта-службы в кластер HDInsight](./media/data-lake-store-hdinsight-hadoop-use-portal/hdi.adl.4.png "Добавление субъекта-службы в кластер HDInsight")


	* **Выбор существующего субъекта-службы**

		* В колонке **Удостоверение кластера AAD** щелкните **Использовать существующий**, выберите **Субъект-служба**, а затем в колонке **Выбор субъекта-службы** найдите существующую субъект-службу. Щелкните имя субъекта-службы, а затем нажмите кнопку **Выбрать**.

			![Добавление субъекта-службы в кластер HDInsight](./media/data-lake-store-hdinsight-hadoop-use-portal/hdi.adl.5.png "Добавление субъекта-службы в кластер HDInsight")

		* В колонке **Удостоверение кластера AAD** передайте связанный с выбранной субъектом-службой сертификат (PFX-файл) и введите пароль сертификата.

5. Щелкните **Управление доступом ADLS**, а затем выберите **Выбор разрешений для файла**.

	![Добавление субъекта-службы в кластер HDInsight](./media/data-lake-store-hdinsight-hadoop-use-portal/hdi.adl.5.existing.save.png "Добавление субъекта-службы в кластер HDInsight")

6. В колонке **Выбор разрешений для файла** в раскрывающемся списке **Учетная запись** выберите учетную запись Data Lake Store, которую хотите связать с кластером HDInsight. В колонке перечислены файлы и папки, доступные в выбранной учетной записи Data Lake Store.
 
	![Предоставление доступа к Data Lake Store](./media/data-lake-store-hdinsight-hadoop-use-portal/hdi-adl-permission-1.png "Предоставление доступа к Data Lake Store")

	После этого определите разрешения, которые будут предоставлены для выбранных файлов и папок. Для папок также укажите, применять ли разрешения только к папке или к папке и всем ее дочерним элементам. Для этого выберите соответствующее значение в раскрывающемся списке **Как применить**. Чтобы удалить разрешение, щелкните значок **удаления**.

	![Предоставление доступа к Data Lake Store](./media/data-lake-store-hdinsight-hadoop-use-portal/hdi-adl-permission-2.png "Предоставление доступа к Data Lake Store")

	Выполните те же действия со связанными файлами и папками из других учетных записей Data Lake Store. По завершении назначения разрешений нажмите кнопку **Выбрать** внизу колонки.

7. В колонке **Назначение выбранных разрешений** проверьте выбранные разрешения и нажмите кнопку **Запустить**, чтобы предоставить эти разрешения.

	![Предоставление доступа к Data Lake Store](./media/data-lake-store-hdinsight-hadoop-use-portal/hdi-adl-permission-3.png "Предоставление доступа к Data Lake Store")

	Ход выполнения отображается в столбце "Состояние". После успешного назначения всех разрешений нажмите кнопку **Готово**.

6. В колонках **Удостоверение кластера AAD** и **Источник данных** нажмите кнопку **Выбрать** и продолжите процесс создания кластера, как описано в статье [Создание кластеров под управлением Linux в HDInsight с помощью портала Azure](../hdinsight/hdinsight-hadoop-create-linux-clusters-portal.md).

7. После подготовки кластера убедитесь, что имя субъекта-службы связано с кластером HDInsight. Для этого в колонке кластера щелкните **Удостоверение кластера AAD**, чтобы просмотреть имя связанного субъекта-службы.

	![Добавление субъекта-службы в кластер HDInsight](./media/data-lake-store-hdinsight-hadoop-use-portal/hdi.adl.6.png "Добавление субъекта-службы в кластер HDInsight")

## Выполнение тестовых заданий в кластере HDInsight для использования хранилища озера данных Azure

После настройки кластера HDInsight выполните в нем тестовые задания, чтобы проверить, доступно ли ему хранилище озера данных Azure. Для этого выполним некоторые запросы hive, ориентированные на хранилища озера данных.

### Кластер Linux

1. Откройте колонку кластера, который вы подготовили, и нажмите кнопку **Панель мониторинга**. Откроется веб-интерфейс Ambari для кластера Linux. При открытии сайта Ambari вы получите запрос на проверку подлинности. Введите имя и пароль учетной записи администратора (по умолчанию), которые использовались при создании кластера.

	![Запуск панели мониторинга кластера](./media/data-lake-store-hdinsight-hadoop-use-portal/hdiadlcluster1.png "Запуск панели мониторинга кластера")

	Кроме того, можно открыть веб-интерфейс Ambari напрямую, открыв в браузере адрес https://CLUSTERNAME.azurehdinsight.net (замените **CLUSTERNAME** именем своего кластера HDInsight).

2. Откройте представление Hive. Выберите набор квадратов в меню страницы (рядом со ссылкой **Администрирование** и кнопкой в правой части страницы), чтобы открыть список доступных представлений. Выберите представление **Hive**.

	![Выбор представлений Ambari](./media/data-lake-store-hdinsight-hadoop-use-portal/selecthiveview.png)

3. Вы должны увидеть страницу, аналогичную показанной ниже:

	![Изображение страницы представления Hive с разделом редактора запросов](./media/data-lake-store-hdinsight-hadoop-use-portal/hiveview.png)

4. На странице в разделе **Редактор запросов** вставьте в лист следующую инструкцию HiveQL:

		CREATE EXTERNAL TABLE vehicles (str string) LOCATION 'adl://mydatalakestore.azuredatalakestore.net:443/mynewfolder'

5. Чтобы выполнить запрос, нажмите кнопку **Выполнить** в нижней части раздела **Редактор запросов**. Под окном **редактора запросов** появится раздел **Query Process Results** (Результаты обработки запроса), содержащий сведения о выполнении задания.

6. После выполнения запроса в разделе **Query Process Results** (Результаты обработки запроса) будут отображены результаты операции. Вкладка **Результаты** должна содержать указанные ниже сведения.

7. Используйте следующий запрос для проверки создания таблицы.

		SHOW TABLES;

	На вкладке **Результаты** должны отображаться следующие выходные данные:

		hivesampletable
		vehicles

	**vehicles** — таблица, которую вы создали ранее. **hivesampletable** является примером таблицы, которая доступна во всех кластерах HDInsight по умолчанию.

8. Можно также выполнить запрос для получения данных из таблицы **vehicles**.

		SELECT * FROM vehicles LIMIT 5;

### Кластер Windows

1. Откройте колонку кластера, который вы подготовили, и нажмите кнопку **Панель мониторинга**.

	![Запуск панели мониторинга кластера](./media/data-lake-store-hdinsight-hadoop-use-portal/hdiadlcluster1.png "Запуск панели мониторинга кластера")

	При появлении соответствующего запроса введите учетные данные администратора кластера.

2. Откроется консоль запроса Microsoft Azure HDInsight. Щелкните **Редактор Hive**.

	![Открытие редактора Hive](./media/data-lake-store-hdinsight-hadoop-use-portal/hdiadlcluster2.png "Открытие редактора Hive")

3. Введите следующий запрос в редакторе Hive и нажмите кнопку **Отправить**.

		CREATE EXTERNAL TABLE vehicles (str string) LOCATION 'adl://mydatalakestore.azuredatalakestore.net:443/mynewfolder'

	В этом запросе Hive мы создаем таблицу из данных, хранящихся в хранилище озера данных на `adl://mydatalakestore.azuredatalakestore.net:443/mynewfolder`. Это расположение содержит образец файла данных, загруженный ранее.

	Таблица **Сеанс задания** в нижней части показывает состояние задания, которое меняется от статуса **Инициализация** до статуса **Выполняется** и **Завершено**. Можно также щелкнуть **Просмотр подробных сведений** для просмотра дополнительных сведений о завершенном задании.

	![Создание таблицы](./media/data-lake-store-hdinsight-hadoop-use-portal/hdiadlcluster3.png "Создание таблицы")

4. Используйте следующий запрос для проверки создания таблицы.

		SHOW TABLES;

	Щелкните **Просмотреть сведения** для этого запроса. Будут показаны следующие выходные данные:

		hivesampletable
		vehicles

	**vehicles** — таблица, которую вы создали ранее. **hivesampletable** является примером таблицы, которая доступна во всех кластерах HDInsight по умолчанию.

5. Можно также выполнить запрос для получения данных из таблицы **vehicles**.

		SELECT * FROM vehicles LIMIT 5;


## Доступ к хранилищу озера данных с помощью команд HDFS

Настроив в кластере HDInsight параметры для работы с хранилищем озера данных, используйте для доступа к хранилищу команды оболочки HDFS.

### Кластер Linux

В этом разделе вы подключитесь к кластеру по SSH и выполните команды HDFS. Windows не предоставляет встроенный клиент SSH. Рекомендуется использовать **PuTTY**, который можно скачать по адресу: [http://www.chiark.greenend.org.uk/~sgtatham/putty/download.html](http://www.chiark.greenend.org.uk/~sgtatham/putty/download.html).

Дополнительные сведения об использовании PuTTY см. в статье [Использование SSH с Hadoop на основе Linux в HDInsight из Windows](../hdinsight/hdinsight-hadoop-linux-use-ssh-windows.md).

После подключения используйте следующую команду файловой системы HDFS для получения списка файлов в хранилище озера данных.

	hdfs dfs -ls adl://<Data Lake Store account name>.azuredatalakestore.net:443/

Эта команда должна показать файл, который вы ранее отправили в хранилище озера данных.

	15/09/17 21:41:15 INFO web.CaboWebHdfsFileSystem: Replacing original urlConnectionFactory with org.apache.hadoop.hdfs.web.URLConnectionFactory@21a728d6
	Found 1 items
	-rwxrwxrwx   0 NotSupportYet NotSupportYet     671388 2015-09-16 22:16 adl://mydatalakestore.azuredatalakestore.net:443/mynewfolder

С помощью команды `hdfs dfs -put` вы можете отправить в хранилище озера данных некоторые файлы, а затем с помощью команды `hdfs dfs -ls` проверить, успешно ли они передались.


### Кластер Windows

1. Перейдите на новый [портал Azure](https://portal.azure.com).

2. Последовательно щелкните **Обзор** и **Кластеры HDInsight**, а затем выберите созданный кластер HDInsight.

3. В колонке кластера нажмите кнопку **Удаленный рабочий стол**, а затем в колонке **Удаленный рабочий стол** щелкните **Подключиться**.

	![Удаленное подключение к кластеру HDI](./media/data-lake-store-hdinsight-hadoop-use-portal/ADL.HDI.PS.Remote.Desktop.png "Создание группы ресурсов Azure")

	При появлении соответствующего запроса введите учетные данные, которые вы указали для пользователя удаленного рабочего стола.

4. Во время удаленного сеанса запустите Windows PowerShell и, используя команды файловой системы HDFS, отобразите список файлов в хранилище озера данных Azure.

	 	hdfs dfs -ls adl://<Data Lake Store account name>.azuredatalakestore.net:443/

	Эта команда должна показать файл, который вы ранее отправили в хранилище озера данных.

		15/09/17 21:41:15 INFO web.CaboWebHdfsFileSystem: Replacing original urlConnectionFactory with org.apache.hadoop.hdfs.web.URLConnectionFactory@21a728d6
		Found 1 items
		-rwxrwxrwx   0 NotSupportYet NotSupportYet     671388 2015-09-16 22:16 adl://mydatalakestore.azuredatalakestore.net:443/mynewfolder

	С помощью команды `hdfs dfs -put` вы можете отправить в хранилище озера данных некоторые файлы, а затем с помощью команды `hdfs dfs -ls` проверить, успешно ли они передались.

## Использование хранилища озера данных с кластером Spark

В этом разделе описывается, как использовать записную книжку Jupyter с кластерами HDInsight Spark для выполнения задания, которое считывает данные из учетной записи хранилища озера данных, связанной с кластером HDInsight Spark, вместо учетной записи большого двоичного объекта службы хранилища Azure по умолчанию.

1. Скопируйте некоторые примеры данных из учетной записи хранения по умолчанию (WASB), связанной с кластером Spark, в учетную запись хранилища озера данных Azure, связанную с кластером. Для этого можно использовать [инструмент ADLCopy](http://aka.ms/downloadadlcopy). Скачайте и установите этот инструмент с помощью следующей ссылки.

2. Откройте командную строку и перейдите в каталог, в который установлено средство AdlCopy, обычно `%HOMEPATH%\Documents\adlcopy`.

3. Выполните следующую команду, чтобы скопировать заданный большой двоичный объект из контейнера-источника в хранилище озера данных:

		AdlCopy /source https://<source_account>.blob.core.windows.net/<source_container>/<blob name> /dest swebhdfs://<dest_adls_account>.azuredatalakestore.net/<dest_folder>/ /sourcekey <storage_account_key_for_storage_container>

	В целях этого учебника скопируйте пример файла данных **HVAC.csv**, расположенный в папке **/HdiSamples/HdiSamples/SensorSampleData/hvac/**, в учетную запись Azure Data Lake Store. Фрагмент кода должен иметь следующий вид.

		AdlCopy /Source https://mydatastore.blob.core.windows.net/mysparkcluster/HdiSamples/HdiSamples/SensorSampleData/hvac/HVAC.csv /dest swebhdfs://mydatalakestore.azuredatalakestore.net/hvac/ /sourcekey uJUfvD6cEvhfLoBae2yyQf8t9/BpbWZ4XoYj4kAS5Jf40pZaMNf0q6a8yqTxktwVgRED4vPHeh/50iS9atS5LQ==

	>[AZURE.WARNING] Убедитесь, что имена файлов и пути указаны в правильном регистре.

4. Вам будет предложено ввести учетные данные для подписки Azure, в которой расположена учетная запись Data Lake Store. Вы увидите результат, аналогичный приведенному ниже:

		Initializing Copy.
		Copy Started.
		100% data copied.
		Copy Completed. 1 file copied.

	Файл данных (**HVAC.csv**) будет скопирован в папку **/hvac** в учетной записи Data Lake Store.

4. На начальной панели [портала Azure](https://portal.azure.com/) щелкните элемент кластера Spark (если он закреплен на начальной панели). Кроме того, вы можете перейти к кластеру, выбрав пункты **Просмотреть все** и **Кластеры HDInsight**.

2. В колонке кластера Spark щелкните **Быстрые ссылки**, затем в колонке **Панель мониторинга кластера** выберите **Jupyter Notebook**. При появлении запроса введите учетные данные администратора для кластера.

	> [AZURE.NOTE] Также можно открыть Jupyter Notebook для своего кластера, открыв следующий URL-адрес в браузере. Замените __CLUSTERNAME__ именем кластера.
	>
	> `https://CLUSTERNAME.azurehdinsight.net/jupyter`

2. Создайте новую записную книжку. Щелкните **Создать**, а затем выберите **PySpark**.

	![Создание новой записной книжки Jupyter](./media/data-lake-store-hdinsight-hadoop-use-portal/hdispark.note.jupyter.createnotebook.png "Создание новой записной книжки Jupyter")

3. Будет создана и открыта записная книжка с именем **Untitled.pynb**.

4. Так как записная книжка была создана с помощью ядра PySpark, задавать контексты явно необязательно. Контексты Spark и Hive будут созданы автоматически при выполнении первой ячейки кода. Можно начать с импорта различных типов, необходимых для этого сценария. Для этого вставьте следующий фрагмент кода в ячейку и нажмите сочетание клавиш **SHIFT+ВВОД**.

		from pyspark.sql.types import *
		
	При каждом запуске задания в Jupyter в заголовке окна веб-браузера будет отображаться состояние **(Занято)**, а также название записной книжки. Кроме того, рядом с надписью **PySpark** в верхнем правом углу окна будет показан закрашенный кружок. После завершения задания этот значок изменится на кружок без заливки.

	 ![Состояние задания записной книжки Jupyter](./media/data-lake-store-hdinsight-hadoop-use-portal/hdispark.jupyter.job.status.png "Состояние задания записной книжки Jupyter")

4. Загрузите пример данных во временную таблицу с помощью файла **HVAC.csv**, скопированного в учетную запись Data Lake Store. Получить доступ к данным в учетной записи хранилища озера данных можно с помощью следующего шаблона URL-адреса.

		adl://<data_lake_store_name>.azuredatalakestore.net/<path_to_file>

	Вставьте приведенный ниже код в пустую ячейку, замените **MYDATALAKESTORE** именем учетной записи Data Lake Store и нажмите клавиши **SHIFT+ВВОД**. Этот пример кода регистрирует данные во временной таблице с именем **hvac**.

		# Load the data
		hvacText = sc.textFile("adl://MYDATALAKESTORE.azuredatalakestore.net/hvac/HVAC.csv")
		
		# Create the schema
		hvacSchema = StructType([StructField("date", StringType(), False),StructField("time", StringType(), False),StructField("targettemp", IntegerType(), False),StructField("actualtemp", IntegerType(), False),StructField("buildingID", StringType(), False)])
		
		# Parse the data in hvacText
		hvac = hvacText.map(lambda s: s.split(",")).filter(lambda s: s[0] != "Date").map(lambda s:(str(s[0]), str(s[1]), int(s[2]), int(s[3]), str(s[6]) ))
		
		# Create a data frame
		hvacdf = sqlContext.createDataFrame(hvac,hvacSchema)
		
		# Register the data fram as a table to run queries against
		hvacdf.registerTempTable("hvac")

5. Так как вы используете ядро PySpark, вы можете отправить SQL-запрос непосредственно к временной таблице **hvac**, которую вы только что создали с помощью волшебного слова `%%sql`. Дополнительные сведения о волшебном слове `%%sql`, а также других волшебных словах, доступных в ядре PySpark, см. в статье [Ядра, доступные для использования записными книжками Jupyter с кластерами Spark в HDInsight (Linux)](hdinsight-apache-spark-jupyter-notebook-kernels.md#why-should-i-use-the-new-kernels).
		
		%%sql
		SELECT buildingID, (targettemp - actualtemp) AS temp_diff, date FROM hvac WHERE date = "6/1/13"

5. После успешного выполнения задания по умолчанию будет показаны следующие табличные данные.

 	![Табличные выходные данные для результата запроса](./media/data-lake-store-hdinsight-hadoop-use-portal/tabular.output.png "Табличные выходные данные для результата запроса")

	Результаты также можно просмотреть и в других визуализациях. Например, диаграмма областей для тех же выходных данных будет выглядеть следующим образом.

	![Диаграмма областей для результата запроса](./media/data-lake-store-hdinsight-hadoop-use-portal/area.output.png "Диаграмма областей для результата запроса")


6. Завершив работу с приложением, следует закрыть записную книжку, чтобы освободить ресурсы. Для этого в записной книжке в меню **Файл** выберите пункт **Закрыть и остановить**. Это завершит работу записной книжки и закроет ее.

## Использование хранилища озера данных в топологии Storm

Хранилище озера данных можно использовать для записи данных из топологии Storm. Инструкции по реализации этого сценария см. в статье [Использование хранилища озера данных Azure с помощью Apache Storm в HDInsight](../hdinsight/hdinsight-storm-write-data-lake-store.md).

## Использование хранилища озера данных с кластерами HBase

С кластерами HBase хранилище озера данных можно использовать как хранилище по умолчанию, а также как дополнительное хранилище. Для этого выполните следующие действия:

1.  В колонке **Источник данных** в разделе **Расположение данных HBase** выберите **Data Lake Store**.
2.  Выберите имя хранилища озера данных, которое вы хотите использовать, или создайте новое.
3.  Наконец, укажите **корневую папку HBase** в Data Lake Store. Если у учетной записи хранилища озера данных нет корневой папки, создайте новую.

	![HBase с хранилищем озера данных](./media/data-lake-store-hdinsight-hadoop-use-portal/hbase-data-lake-store.png "Создание группы ресурсов Azure")

### Рекомендации по использованию хранилища озера данных в качестве хранилища по умолчанию для кластеров HBase

* Одну и ту же учетную запись хранилища озера данных можно использовать для нескольких кластеров HBase. Тем не менее **корневая папка HBase** (шаг 4 на снимке экрана выше) должна быть уникальной для каждого кластера. Вы **не должны** использовать одну и ту же корневую папку для двух различных кластеров HBase.
* Несмотря на то, что в качестве хранилища по умолчанию используется учетная запись хранилища озера данных, файлы журнала кластера HBase по-прежнему хранятся в хранилище BLOB-объектов Azure (WASB), связанном с кластером. Это выделено прямоугольником синего цвета на снимке экрана выше.



## Дополнительные материалы

* [PowerShell: создание кластера HDInsight для работы с хранилищем озера данных](data-lake-store-hdinsight-hadoop-use-powershell.md)

[makecert]: https://msdn.microsoft.com/library/windows/desktop/ff548309(v=vs.85).aspx
[pvk2pfx]: https://msdn.microsoft.com/library/windows/desktop/ff550672(v=vs.85).aspx

<!---HONumber=AcomDC_0831_2016-->