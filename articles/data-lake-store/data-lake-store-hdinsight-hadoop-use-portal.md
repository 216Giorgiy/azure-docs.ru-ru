<properties 
   pageTitle="Создание кластеров HDInsight Hadoop с хранилищем озера данных Azure с помощью портала | Azure" 
   description="Создание кластеров HDInsight Hadoop для работы с хранилищем озера данных Azure с помощью портала Azure" 
   services="data-lake-store" 
   documentationCenter="" 
   authors="nitinme" 
   manager="paulettm" 
   editor="cgronlun"/>
 
<tags
   ms.service="data-lake-store"
   ms.devlang="na"
   ms.topic="article"
   ms.tgt_pltfrm="na"
   ms.workload="big-data" 
   ms.date="01/20/2016"
   ms.author="nitinme"/>

# Создание кластера HDInsight с хранилищем озера данных с помощью портала Azure

> [AZURE.SELECTOR]
- [Using Portal](data-lake-store-hdinsight-hadoop-use-portal.md)
- [Using PowerShell](data-lake-store-hdinsight-hadoop-use-powershell.md)


Узнайте, как с помощью портала Azure создать кластер HDInsight (Hadoop, HBase или Storm) с доступом к хранилищу озера данных Azure. Важные сведения, которые следует учитывать при работе с данным выпуском.

* **В кластерах Hadoop (Windows и Linux)** хранилище озера данных может использоваться только как дополнительная учетная запись хранения. Учетной записью хранения по умолчанию для таких кластеров по-прежнему будут BLOB-объекты хранилища Azure (WASB).

* **В кластерах Storm (Windows и Linux)** хранилище озера данных может использоваться для записи данных из топологии Storm. Хранилище озера данных также может использоваться для хранения справочных данных, которые затем можно будет прочитать с помощью топологии Storm.

* **Для кластеров HBase (Windows и Linux)** хранилище озера данных можно использовать как хранилище по умолчанию или дополнительное хранилище.


В этой статье мы подготовим кластер Hadoop, в котором хранилище озера данных будет дополнительным хранилищем. Настройка в HDInsight хранилища озера данных с помощью портала Azure состоит из нескольких этапов.

* Создание кластера HDInsight с проверкой подлинности в субъекте-службе Azure Active Directory
* Настройка доступа к хранилищу озера данных с помощью одного субъекта-службы
* Выполнение тестового задания в кластере

## Предварительные требования

Перед началом работы с этим учебником необходимо иметь следующее:

- **Подписка Azure.**. См. [Бесплатная пробная версия Azure](https://azure.microsoft.com/pricing/free-trial/).
- **Включите свою подписку Azure** для общедоступной предварительной версии хранилища озера данных. См. [инструкции](data-lake-store-get-started-portal.md#signup).


## Создание кластера HDInsight с проверкой подлинности в субъекте-службе Azure Active Directory

В этом разделе мы создадим кластер HDInsight Hadoop, использующий хранилище озера данных в качестве дополнительного хранилища. В этом выпуске в кластере Hadoop хранилище озера данных может использоваться только как дополнительное хранилище кластера. Хранилищем по умолчанию по-прежнему будут большие двоичные объекты хранилища Azure (WASB). Поэтому мы сначала создадим учетную запись хранения и контейнеры хранилища, необходимые для кластера.

1. Перейдите на новый [портал Azure](https://portal.azure.com).

2. Выполните действия, описанные в разделе [Создание кластеров Hadoop в HDInsight](../hdinsight/hdinsight-provision-clusters.md#create-using-the-preview-portal), чтобы начать подготовку кластера HDInsight.
 
3. В колонке **Дополнительная настройка** щелкните **Источник данных**. В колонке **Источник данных** укажите данные учетной записи хранения и контейнера хранилища, в поле **Расположение** укажите **Восток США 2** и нажмите кнопку **Удостоверение кластера AAD**.

	![Добавление субъекта-службы в кластер HDInsight](./media/data-lake-store-hdinsight-hadoop-use-portal/hdi.adl.1.png "Добавление субъекта-службы в кластер HDInsight")

4. В колонке **Удостоверение кластера AAD** можно выбрать существующий субъект-службу или создать новый.
	
	* **Создание субъекта-службы**. В колонке **Удостоверение кластера AAD** щелкните **Создать**. Щелкните **Субъект-служба**, а затем в колонке **Создание субъекта-службы** укажите значения для создания нового субъекта-службы. В рамках этого процесса также создаются сертификат и приложение Azure Active Directory. Щелкните **Создать**.

		![Добавление субъекта-службы в кластер HDInsight](./media/data-lake-store-hdinsight-hadoop-use-portal/hdi.adl.4.png "Добавление субъекта-службы в кластер HDInsight")

		В колонке **Удостоверение кластера AAD** щелкните **Выбрать**, чтобы продолжить работу с субъектом-службой, который будет создан.

		![Добавление субъекта-службы в кластер HDInsight](./media/data-lake-store-hdinsight-hadoop-use-portal/hdi.adl.5.png "Добавление субъекта-службы в кластер HDInsight")


	* **Выбор существующего субъекта-службы**. В колонке **Удостоверение кластера AAD** щелкните **Использовать существующий**. Нажмите кнопку **Субъект-служба**, а затем в колонке **Выбор субъекта-службы** найдите существующий субъект-службу. Щелкните имя субъекта-службы, а затем нажмите кнопку **Выбрать**.

		![Добавление субъекта-службы в кластер HDInsight](./media/data-lake-store-hdinsight-hadoop-use-portal/hdi.adl.2.png "Добавление субъекта-службы в кластер HDInsight")

		В колонке **Удостоверение кластера AAD** отправьте сертификат (PFX), который был создан ранее, и введите пароль, использованный для создания сертификата. Нажмите кнопку **Выбрать**. На этом завершается настройка Azure Active Directory для кластера HDInsight.

		![Добавление субъекта-службы в кластер HDInsight](./media/data-lake-store-hdinsight-hadoop-use-portal/hdi.adl.3.png "Добавление субъекта-службы в кластер HDInsight")

6. Щелкните **Выбрать** в колонке **Источник данных** и продолжите подготовку кластера, как описано в разделе [Создание кластеров Hadoop в HDInsight](../hdinsight/hdinsight-provision-clusters.md#create-using-the-preview-portal).

7. После подготовки кластера убедитесь, что имя субъекта-службы связано с кластером HDInsight. Для этого в колонке кластера выберите **Параметры**, щелкните **Удостоверение кластера AAD**, и вы увидите имя связанного субъекта-службы.

	![Добавление субъекта-службы в кластер HDInsight](./media/data-lake-store-hdinsight-hadoop-use-portal/hdi.adl.6.png "Добавление субъекта-службы в кластер HDInsight")

## <a name="acl"></a>Настройка субъекта-службы для доступа к файловой системе хранилища озера данных

1. Перейдите на новый [портал Azure](https://portal.azure.com).

2. Если у вас нет учетной записи хранения озера данных, создайте ее. Следуйте инструкциям в разделе [Приступая к работе с хранилищем озера данных Azure на портале Azure](data-lake-store-get-started-portal.md).

	При наличии учетной записи хранения озера данных в левой области щелкните **Обзор**, щелкните **Хранилище озера данных** и затем щелкните имя учетной записи, к которой требуется предоставить доступ.

	Выполните следующие задачи в вашей учетной записи хранения озера данных.

	* [Создать папку в хранилище озера данных](data-lake-store-get-started-portal.md#createfolder).
	* [Передать файл в хранилище озера данных](data-lake-store-get-started-portal.md#uploaddata). Если у вас нет под рукой подходящих для этих целей данных, передайте папку **Ambulance Data** из [репозитория Git для озера данных Azure](https://github.com/MicrosoftBigData/usql/tree/master/Examples/Samples/Data/AmbulanceData).

	Позже мы используем загруженные файлы при проверке работы учетной записи хранения озера данных с кластером HDInsight.

3. В колонке хранилища озера данных выберите **Обозреватель данных**.

	![Обозреватель данных](./media/data-lake-store-hdinsight-hadoop-use-portal/adl.start.data.explorer.png "Обозреватель данных")

4. В колонке **Обозреватель данных** щелкните корень учетной записи, а затем в колонке вашей учетной записи щелкните значок **доступа**.

	![Настройка списков управления доступом в файловой системе озера данных](./media/data-lake-store-hdinsight-hadoop-use-portal/adl.acl.1.png "Настройка списков управления доступом в файловой системе озера данных")

5. В колонке **Доступ** перечислены стандартные и пользовательские варианты доступа, уже назначенные корню. Щелкните значок **Добавить** для добавления списков управления доступом пользовательского уровня и включения субъекта-службы, созданного ранее.

	![Перечисление стандартных и пользовательских сценариев доступа](./media/data-lake-store-hdinsight-hadoop-use-portal/adl.acl.2.png "Перечисление стандартных и пользовательских сценариев доступа")

6. Щелкните значок **Добавить**, чтобы открыть колонку **Добавить пользовательский доступ**. В этой колонке щелкните **Выбор пользователя или группы**, а затем в колонке **Выбор пользователя или группы** найдите субъект-службу, созданный ранее в Azure Active Directory. Имя созданного ранее субъекта-службы — **HDIADL**. Щелкните имя субъекта-службы и нажмите кнопку **Выбрать**.

	![Добавление группы](./media/data-lake-store-hdinsight-hadoop-use-portal/adl.acl.3.png "Добавление группы")

7. Щелкните **Выбрать разрешения**, выберите разрешения, которые вы хотите назначить субъекту-службе, и нажмите кнопку **ОК**.

	![Назначение разрешений для группы](./media/data-lake-store-hdinsight-hadoop-use-portal/adl.acl.4.png "Назначение разрешений для группы")

8. В колонке **Добавить пользовательский доступ** щелкните **ОК**. Теперь добавленная группа с соответствующими разрешениями отобразится в колонке **Доступ**.

	![Назначение разрешений для группы](./media/data-lake-store-hdinsight-hadoop-use-portal/adl.acl.5.png "Назначение разрешений для группы")

7. При необходимости можно также изменить права доступа уже после добавления субъекта-службы. Снимите или установите флажок для каждого типа разрешений (чтение, запись, выполнение) в зависимости от того, нужно ли удалить или назначить разрешение. Щелкните **Сохранить**, чтобы сохранить изменения, или **Отменить** для их отмены.



## Выполнение тестовых заданий в кластере HDInsight для использования хранилища озера данных Azure

После настройки кластера HDInsight выполните в нем тестовые задания, чтобы проверить, доступно ли ему хранилище озера данных Azure. Для этого выполним некоторые запросы hive, ориентированные на хранилища озера данных.

### Кластер Linux

1. Откройте колонку кластера, который вы подготовили, и нажмите кнопку **Панель мониторинга**. Откроется веб-интерфейс Ambari для кластера Linux. При открытии сайта Ambari вы получите запрос на проверку подлинности. Введите имя и пароль учетной записи администратора (по умолчанию), которые использовались при создании кластера.

	![Запуск панели мониторинга кластера](./media/data-lake-store-hdinsight-hadoop-use-portal/hdiadlcluster1.png "Запуск панели мониторинга кластера")

	Также можно открыть веб-интерфейс Ambari напрямую, открыв в браузере адрес https://CLUSTERNAME.azurehdinsight.net (замените **CLUSTERNAME** на имя своего кластера HDInsight).

2. Откройте представление Hive. Выберите набор квадратов в меню страницы (рядом со ссылкой **Администрирование** и кнопкой в правой части страницы), чтобы открыть список доступных представлений. Выберите представление **Hive**.

	![Выбор представлений Ambari](./media/data-lake-store-hdinsight-hadoop-use-portal/selecthiveview.png)

3. Вы должны увидеть страницу, аналогичную показанной ниже:

	![Изображение страницы представления Hive с разделом редактора запросов](./media/data-lake-store-hdinsight-hadoop-use-portal/hiveview.png)

4. На странице в разделе **Редактор запросов** вставьте в рабочий лист следующие инструкции HiveQL:

		CREATE EXTERNAL TABLE vehicles (str string) LOCATION 'adl://mydatalakestore.azuredatalakestore.net:443/mynewfolder'

5. Чтобы выполнить запрос, нажмите кнопку **Выполнить** в нижней части окна **Редактор запросов**. Под окном **Редактор запросов** появится раздел **Результаты обработки запроса**, содержащий сведения о выполнении задания.

6. После окончания выполнения запроса в разделе **Результаты обработки запроса** будут отображены результаты операции. Вкладка **Результаты** должна содержать указанные ниже сведения.

7. Используйте следующий запрос для проверки создания таблицы.

		SHOW TABLES;

	На вкладке **Результаты** должны отображаться следующие сведения:

		hivesampletable
		vehicles

	**vehicles** — таблица, которую вы создали ранее. **hivesampletable** является примером таблицы, которая доступна во всех кластерах HDInsight по умолчанию.

8. Также можно выполнить запрос для получения данных из таблицы **vehicles**.

		SELECT * FROM vehicles LIMIT 5;

### Кластер Windows

1. Откройте колонку кластера, который вы подготовили, и нажмите кнопку **Панель мониторинга**.

	![Запуск панели мониторинга кластера](./media/data-lake-store-hdinsight-hadoop-use-portal/hdiadlcluster1.png "Запуск панели мониторинга кластера")

	При появлении соответствующего запроса введите учетные данные администратора кластера.

2. Откроется консоль запроса Microsoft Azure HDInsight. Щелкните **Редактор Hive**.

	![Открытие редактора Hive](./media/data-lake-store-hdinsight-hadoop-use-portal/hdiadlcluster2.png "Открытие редактора Hive")

3. Введите следующий запрос в редакторе Hive и нажмите кнопку **Отправить**.

		CREATE EXTERNAL TABLE vehicles (str string) LOCATION 'adl://mydatalakestore.azuredatalakestore.net:443/mynewfolder'

	В этом запросе Hive мы создаем таблицу из данных, хранящихся в хранилище озера данных на `adl://mydatalakestore.azuredatalakestore.net:443/mynewfolder`. Это расположение содержит образец файла данных, загруженный ранее.

	Таблица **Сеанс задания** в нижней части показывает состояние задания, которое меняется от статуса **Инициализация** до статуса **Выполняется** и **Завершено**. Можно также щелкнуть **Просмотр подробных сведений** для просмотра дополнительных сведений о завершенном задании.

	![Создание таблицы](./media/data-lake-store-hdinsight-hadoop-use-portal/hdiadlcluster3.png "Создание таблицы")

4. Используйте следующий запрос для проверки создания таблицы.

		SHOW TABLES;

	Щелкните **Просмотр подробных сведений** для этого запроса. Должны отобразиться следующие выходные данные:

		hivesampletable
		vehicles

	**vehicles** — таблица, которую вы создали ранее. **hivesampletable** является примером таблицы, которая доступна во всех кластерах HDInsight по умолчанию.

5. Также можно выполнить запрос для получения данных из таблицы **vehicles**.

		SELECT * FROM vehicles LIMIT 5;


## Доступ к хранилищу озера данных с помощью команд HDFS

Настроив в кластере HDInsight параметры для работы с хранилищем озера данных, используйте для доступа к хранилищу команды оболочки HDFS.

### Кластер Linux

В этом разделе вы подключитесь к кластеру по SSH и выполните команды HDFS. Windows не предоставляет встроенный клиент SSH. Рекомендуется использовать **PuTTY**, который можно скачать по адресу: [http://www.chiark.greenend.org.uk/~sgtatham/putty/download.html](http://www.chiark.greenend.org.uk/~sgtatham/putty/download.html).

Дополнительные сведения об использовании PuTTY см. в разделе [Использование SSH с Hadoop на основе Linux в HDInsight из Windows ](../hdinsight/hdinsight-hadoop-linux-use-ssh-windows.md).

После подключения используйте следующую команду файловой системы HDFS для получения списка файлов в хранилище озера данных.

	hdfs dfs -ls adl://<Data Lake Store account name>.azuredatalakestore.net:443/

Эта команда должна показать файл, который вы ранее отправили в хранилище озера данных.

	15/09/17 21:41:15 INFO web.CaboWebHdfsFileSystem: Replacing original urlConnectionFactory with org.apache.hadoop.hdfs.web.URLConnectionFactory@21a728d6
	Found 1 items
	-rwxrwxrwx   0 NotSupportYet NotSupportYet     671388 2015-09-16 22:16 adl://mydatalakestore.azuredatalakestore.net:443/mynewfolder

С помощью команды `hdfs dfs -put` вы можете отправить в хранилище озера данных некоторые файлы, а затем с помощью команды `hdfs dfs -ls` проверить, успешно ли они передались.


### Кластер Windows

1. Перейдите на новый [портал Azure](https://portal.azure.com).

2. Последовательно щелкните **Обзор** и **Кластеры HDInsight**, а затем выберите созданный кластер HDInsight.

3. В колонке кластера нажмите кнопку **Удаленный рабочий стол**, а затем в колонке **Удаленный рабочий стол** щелкните **Подключиться**.

	![Удаленное подключение к кластеру HDI](./media/data-lake-store-hdinsight-hadoop-use-portal/ADL.HDI.PS.Remote.Desktop.png "Создание группы ресурсов Azure")

	При появлении соответствующего запроса введите учетные данные, которые вы указали для пользователя удаленного рабочего стола.

4. Во время удаленного сеанса запустите Windows PowerShell и, используя команды файловой системы HDFS, отобразите список файлов в хранилище озера данных Azure.

	 	hdfs dfs -ls adl://<Data Lake Store account name>.azuredatalakestore.net:443/

	Эта команда должна показать файл, который вы ранее отправили в хранилище озера данных.

		15/09/17 21:41:15 INFO web.CaboWebHdfsFileSystem: Replacing original urlConnectionFactory with org.apache.hadoop.hdfs.web.URLConnectionFactory@21a728d6
		Found 1 items
		-rwxrwxrwx   0 NotSupportYet NotSupportYet     671388 2015-09-16 22:16 adl://mydatalakestore.azuredatalakestore.net:443/mynewfolder

	С помощью команды `hdfs dfs -put` вы можете отправить в хранилище озера данных некоторые файлы, а затем с помощью команды `hdfs dfs -ls` проверить, успешно ли они передались.

## Вопросы подготовки кластера HBase, который использует хранилище озера данных в качестве хранилища по умолчанию

Для кластеров HBase можно использовать учетные записи хранения озера данных в качестве хранилища по умолчанию. Если вы решили сделать это, чтобы успешно подготовить кластер, субъект-служба, связанный с кластером, **должен** иметь доступ к учетной записи хранения озера данных. Это можно проверить двумя способами:

* **При использовании существующего субъекта-службы** перед началом подготовки кластера необходимо убедиться, что субъект-служба добавлен в список управления доступом на корневом уровне файловой системы хранилища озера данных.
* Если в рамках подготовки кластера **выбрано создание нового субъекта-службы**, в самом начале подготовки кластера необходимо добавить созданный субъект-службу в корневой уровень файловой системы хранилища озера данных. Если этого не сделать, кластер будет подготовлен, но не сможет запустить службы HBase. Чтобы обойти эту проблему, необходимо затем добавить субъект-службу в список управления доступом учетной записи хранения озера данных и перезапустить службы HBase с помощью веб-интерфейса Ambari.

Инструкции по добавлению субъекта-службы в файловую систему хранилища озера данных см. в разделе [Настройка субъекта-службы для доступа к файловой системе хранилища озера данных](#acl).

## Использование хранилища озера данных в топологии Storm

Хранилище озера данных можно использовать для записи данных из топологии Storm. Инструкции по реализации этого сценария см. в разделе [Использование хранилища озера данных Azure с Apache Storm в HDInsight](../hdinsight/hdinsight-storm-write-data-lake-store.md).

## См. также

* [PowerShell: создание кластера HDInsight для работы с хранилищем озера данных](data-lake-store-hdinsight-hadoop-use-powershell.md)

[makecert]: https://msdn.microsoft.com/library/windows/desktop/ff548309(v=vs.85).aspx
[pvk2pfx]: https://msdn.microsoft.com/library/windows/desktop/ff550672(v=vs.85).aspx

<!---HONumber=AcomDC_0121_2016-->