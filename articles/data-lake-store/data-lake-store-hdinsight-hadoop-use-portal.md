<properties 
   pageTitle="Создание кластеров HDInsight Hadoop с хранилищем озера данных Azure с помощью портала | Azure" 
   description="Создание кластеров HDInsight Hadoop для работы с хранилищем озера данных Azure с помощью портала Azure" 
   services="data-lake-store" 
   documentationCenter="" 
   authors="nitinme" 
   manager="paulettm" 
   editor="cgronlun"/>
 
<tags
   ms.service="data-lake-store"
   ms.devlang="na"
   ms.topic="article"
   ms.tgt_pltfrm="na"
   ms.workload="big-data" 
   ms.date="02/03/2016"
   ms.author="nitinme"/>

# Создание кластера HDInsight с хранилищем озера данных с помощью портала Azure

> [AZURE.SELECTOR]
- [Using Portal](data-lake-store-hdinsight-hadoop-use-portal.md)
- [Using PowerShell](data-lake-store-hdinsight-hadoop-use-powershell.md)


Узнайте, как с помощью портала Azure создать кластер HDInsight (Hadoop, HBase или Storm) с доступом к хранилищу озера данных Azure. Важные сведения, которые следует учитывать при работе с данным выпуском.

* **В кластерах Hadoop (Windows и Linux)** хранилище озера данных может использоваться только как дополнительная учетная запись хранения. Учетной записью хранения по умолчанию для таких кластеров по-прежнему будут BLOB-объекты хранилища Azure (WASB).

* **В кластерах Storm (Windows и Linux)** хранилище озера данных может использоваться для записи данных из топологии Storm. Хранилище озера данных также может использоваться для хранения справочных данных, которые затем можно будет прочитать с помощью топологии Storm.

* **Для кластеров HBase (Windows и Linux)** хранилище озера данных можно использовать как хранилище по умолчанию или дополнительное хранилище. Создание кластеров HBase с доступом к хранилищу озера данных доступно только при использовании HDI версии 3.1 и 3.2 (для Windows) или HDI версии 3.2 (для Linux).


## Предварительные требования

Перед началом работы с этим учебником необходимо иметь следующее:

- **Подписка Azure.**. См. [Бесплатная пробная версия Azure](https://azure.microsoft.com/pricing/free-trial/).
- **Включите свою подписку Azure** для общедоступной предварительной версии хранилища озера данных. См. [инструкции](data-lake-store-get-started-portal.md#signup).
- **Учетная запись хранилища озера данных Azure**. Следуйте инструкциям в разделе [Приступая к работе с хранилищем озера данных Azure на портале Azure](data-lake-store-get-started-portal.md). После создания учетной записи выполните следующие задачи, чтобы передать некоторые примеры данных. Эти данные потребуются позже при выполнении заданий из кластера HDInsight для получения доступа к данным в хранилище озера данных. 

	* [Создать папку в хранилище озера данных](data-lake-store-get-started-portal.md#createfolder).
	* [Передача файла в хранилище озера данных](data-lake-store-get-started-portal.md#uploaddata). Если у вас нет под рукой подходящих для этих целей данных, передайте папку **Ambulance Data** из [репозитория Git для озера данных Azure](https://github.com/Azure/usql/tree/master/Examples/Samples/Data/AmbulanceData).


## Создание кластера Azure HDInsight с доступом к хранилищу озера данных Azure

В этом разделе мы создадим кластер HDInsight Hadoop, использующий хранилище озера данных в качестве дополнительного хранилища. В этом выпуске в кластере Hadoop хранилище озера данных может использоваться только как дополнительное хранилище кластера. Хранилищем по умолчанию по-прежнему будут большие двоичные объекты хранилища Azure (WASB). Поэтому мы сначала создадим учетную запись хранения и контейнеры хранилища, необходимые для кластера.

1. Перейдите на новый [портал Azure](https://portal.azure.com).

2. Выполните действия, описанные в разделе [Создание кластеров Hadoop в HDInsight](../hdinsight/hdinsight-provision-clusters.md#create-using-the-preview-portal), чтобы начать подготовку кластера HDInsight.
 
3. В колонке **Дополнительная настройка** щелкните **Источник данных**. В колонке **Источник данных** укажите данные учетной записи хранения и контейнера хранилища, в поле **Расположение** укажите **Восток США 2** и нажмите кнопку **Удостоверение кластера AAD**.

	![Добавление субъекта-службы в кластер HDInsight](./media/data-lake-store-hdinsight-hadoop-use-portal/hdi.adl.1.png "Добавление субъекта-службы в кластер HDInsight")

4. В колонке **Удостоверение кластера AAD** можно выбрать существующий субъект-службу или создать новый.
	
	* **Создание субъекта-службы**.
	
		* В колонке **Удостоверение кластера AAD** щелкните **Создать**, выберите **Субъект-служба**, а затем в колонке **Создание субъекта-службы** укажите значения для создания нового субъекта-службы. В рамках этого процесса также создаются сертификат и приложение Azure Active Directory. Щелкните **Создать**.

			![Добавление субъекта-службы в кластер HDInsight](./media/data-lake-store-hdinsight-hadoop-use-portal/hdi.adl.2.png "Добавление субъекта-службы в кластер HDInsight")

		* В колонке **Удостоверение кластера AAD** щелкните **Управление доступом ADLS**. Откроется панель, на которой отображаются связанные с подпиской учетные записи хранилища озера данных. Однако разрешения можно задать только для созданной вами учетной записи. Установите флажки для разрешений "ЧТЕНИЕ", "ЗАПИСЬ" и "ВЫПОЛНЕНИЕ" для учетной записи, которую нужно связать с кластером HDInsight, и нажмите кнопку **Сохранить разрешения**.

			![Добавление субъекта-службы в кластер HDInsight](./media/data-lake-store-hdinsight-hadoop-use-portal/hdi.adl.3.png "Добавление субъекта-службы в кластер HDInsight")

		* В колонке **Удостоверение кластера AAD** щелкните **Загрузить сертификат**, чтобы скачать связанный с субъектом-службой сертификат, который вы создали. Это нужно, если требуется использовать один субъект-службу в будущем при создании дополнительных кластеров HDInsight. Нажмите кнопку **Выбрать**.

			![Добавление субъекта-службы в кластер HDInsight](./media/data-lake-store-hdinsight-hadoop-use-portal/hdi.adl.4.png "Добавление субъекта-службы в кластер HDInsight")


	* **Выбор существующего субъекта-службы**.

		* В колонке **Удостоверение кластера AAD** щелкните **Использовать существующий**, выберите **Субъект-служба**, а затем в колонке **Выбор субъекта-службы** найдите существующий субъект-службу. Щелкните имя субъекта-службы, а затем нажмите кнопку **Выбрать**.

			![Добавление субъекта-службы в кластер HDInsight](./media/data-lake-store-hdinsight-hadoop-use-portal/hdi.adl.5.png "Добавление субъекта-службы в кластер HDInsight")

		* В колонке **Удостоверение кластера AAD** передайте связанный с выбранным субъектом-службой сертификат (PFX) и введите соответствующий пароль.
		
		* Щелкните **Управление доступом ADLS**. Откроется панель, на которой отображаются связанные с подпиской учетные записи хранилища озера данных. Однако разрешения можно задать только для созданной вами учетной записи. Установите флажки для разрешений "ЧТЕНИЕ", "ЗАПИСЬ" и "ВЫПОЛНЕНИЕ" для учетной записи, которую нужно связать с кластером HDInsight, и нажмите кнопку **Сохранить разрешения**.

			![Добавление субъекта-службы в кластер HDInsight](./media/data-lake-store-hdinsight-hadoop-use-portal/hdi.adl.5.existing.save.png "Добавление субъекта-службы в кластер HDInsight")

		* Нажмите кнопку **Сохранить разрешения**, а затем — **Выбрать**.

6. Щелкните **Выбрать** в колонке **Источник данных** и продолжите подготовку кластера, как описано в разделе [Создание кластеров Hadoop в HDInsight](../hdinsight/hdinsight-provision-clusters.md#create-using-the-preview-portal).

7. После подготовки кластера убедитесь, что имя субъекта-службы связано с кластером HDInsight. Для этого в колонке кластера выберите **Параметры**, щелкните **Удостоверение кластера AAD**, и вы увидите имя связанного субъекта-службы.

	![Добавление субъекта-службы в кластер HDInsight](./media/data-lake-store-hdinsight-hadoop-use-portal/hdi.adl.6.png "Добавление субъекта-службы в кластер HDInsight")

## Выполнение тестовых заданий в кластере HDInsight для использования хранилища озера данных Azure

После настройки кластера HDInsight выполните в нем тестовые задания, чтобы проверить, доступно ли ему хранилище озера данных Azure. Для этого выполним некоторые запросы hive, ориентированные на хранилища озера данных.

### Кластер Linux

1. Откройте колонку кластера, который вы подготовили, и нажмите кнопку **Панель мониторинга**. Откроется веб-интерфейс Ambari для кластера Linux. При открытии сайта Ambari вы получите запрос на проверку подлинности. Введите имя и пароль учетной записи администратора (по умолчанию), которые использовались при создании кластера.

	![Запуск панели мониторинга кластера](./media/data-lake-store-hdinsight-hadoop-use-portal/hdiadlcluster1.png "Запуск панели мониторинга кластера")

	Кроме того, можно открыть веб-интерфейс Ambari напрямую, открыв в браузере адрес https://CLUSTERNAME.azurehdinsight.net (замените **CLUSTERNAME** именем своего кластера HDInsight).

2. Откройте представление Hive. Выберите набор квадратов в меню страницы (рядом со ссылкой **Администрирование** и кнопкой в правой части страницы), чтобы открыть список доступных представлений. Выберите представление **Hive**.

	![Выбор представлений Ambari](./media/data-lake-store-hdinsight-hadoop-use-portal/selecthiveview.png)

3. Вы должны увидеть страницу, аналогичную показанной ниже:

	![Изображение страницы представления Hive с разделом редактора запросов](./media/data-lake-store-hdinsight-hadoop-use-portal/hiveview.png)

4. На странице в разделе **Редактор запросов** вставьте в рабочий лист следующие инструкции HiveQL:

		CREATE EXTERNAL TABLE vehicles (str string) LOCATION 'adl://mydatalakestore.azuredatalakestore.net:443/mynewfolder'

5. Чтобы выполнить запрос, нажмите кнопку **Выполнить** в нижней части окна **редактора запросов**. Под окном **редактора запросов** появится раздел **Результаты обработки запроса**, содержащий сведения о выполнении задания.

6. После выполнения запроса в разделе **Результаты обработки запроса** будут отображены результаты операции. Вкладка **Результаты** должна содержать указанные ниже сведения.

7. Используйте следующий запрос для проверки создания таблицы.

		SHOW TABLES;

	На вкладке **Результаты** должны отображаться следующие выходные данные:

		hivesampletable
		vehicles

	**vehicles** — таблица, которую вы создали ранее. **hivesampletable** является примером таблицы, которая доступна во всех кластерах HDInsight по умолчанию.

8. Можно также выполнить запрос для получения данных из таблицы **vehicles**.

		SELECT * FROM vehicles LIMIT 5;

### Кластер Windows

1. Откройте колонку кластера, который вы подготовили, и нажмите кнопку **Панель мониторинга**.

	![Запуск панели мониторинга кластера](./media/data-lake-store-hdinsight-hadoop-use-portal/hdiadlcluster1.png "Запуск панели мониторинга кластера")

	При появлении соответствующего запроса введите учетные данные администратора кластера.

2. Откроется консоль запроса Microsoft Azure HDInsight. Щелкните **Редактор Hive**.

	![Открытие редактора Hive](./media/data-lake-store-hdinsight-hadoop-use-portal/hdiadlcluster2.png "Открытие редактора Hive")

3. Введите следующий запрос в редакторе Hive и нажмите кнопку **Отправить**.

		CREATE EXTERNAL TABLE vehicles (str string) LOCATION 'adl://mydatalakestore.azuredatalakestore.net:443/mynewfolder'

	В этом запросе Hive мы создаем таблицу из данных, хранящихся в хранилище озера данных на `adl://mydatalakestore.azuredatalakestore.net:443/mynewfolder`. Это расположение содержит образец файла данных, загруженный ранее.

	Таблица **Сеанс задания** в нижней части показывает состояние задания, которое меняется от статуса **Инициализация** до статуса **Выполняется** и **Завершено**. Можно также щелкнуть **Просмотр подробных сведений** для просмотра дополнительных сведений о завершенном задании.

	![Создание таблицы](./media/data-lake-store-hdinsight-hadoop-use-portal/hdiadlcluster3.png "Создание таблицы")

4. Используйте следующий запрос для проверки создания таблицы.

		SHOW TABLES;

	Щелкните **Просмотр подробных сведений** для этого запроса. Должны отобразиться следующие выходные данные:

		hivesampletable
		vehicles

	**vehicles** — таблица, которую вы создали ранее. **hivesampletable** является примером таблицы, которая доступна во всех кластерах HDInsight по умолчанию.

5. Можно также выполнить запрос для получения данных из таблицы **vehicles**.

		SELECT * FROM vehicles LIMIT 5;


## Доступ к хранилищу озера данных с помощью команд HDFS

Настроив в кластере HDInsight параметры для работы с хранилищем озера данных, используйте для доступа к хранилищу команды оболочки HDFS.

### Кластер Linux

В этом разделе вы подключитесь к кластеру по SSH и выполните команды HDFS. Windows не предоставляет встроенный клиент SSH. Рекомендуется использовать **PuTTY**, который можно скачать по адресу: [http://www.chiark.greenend.org.uk/~sgtatham/putty/download.html](http://www.chiark.greenend.org.uk/~sgtatham/putty/download.html).

Дополнительные сведения об использовании PuTTY см. в статье [Использование SSH с Hadoop на основе Linux в HDInsight из Windows ](../hdinsight/hdinsight-hadoop-linux-use-ssh-windows.md).

После подключения используйте следующую команду файловой системы HDFS для получения списка файлов в хранилище озера данных.

	hdfs dfs -ls adl://<Data Lake Store account name>.azuredatalakestore.net:443/

Эта команда должна показать файл, который вы ранее отправили в хранилище озера данных.

	15/09/17 21:41:15 INFO web.CaboWebHdfsFileSystem: Replacing original urlConnectionFactory with org.apache.hadoop.hdfs.web.URLConnectionFactory@21a728d6
	Found 1 items
	-rwxrwxrwx   0 NotSupportYet NotSupportYet     671388 2015-09-16 22:16 adl://mydatalakestore.azuredatalakestore.net:443/mynewfolder

С помощью команды `hdfs dfs -put` вы можете отправить в хранилище озера данных некоторые файлы, а затем с помощью команды `hdfs dfs -ls` проверить, успешно ли они передались.


### Кластер Windows

1. Перейдите на новый [портал Azure](https://portal.azure.com).

2. Последовательно щелкните **Обзор** и **Кластеры HDInsight**, а затем выберите созданный кластер HDInsight.

3. В колонке кластера нажмите кнопку **Удаленный рабочий стол**, а затем в колонке **Удаленный рабочий стол** щелкните **Подключиться**.

	![Удаленное подключение к кластеру HDI](./media/data-lake-store-hdinsight-hadoop-use-portal/ADL.HDI.PS.Remote.Desktop.png "Создание группы ресурсов Azure")

	При появлении соответствующего запроса введите учетные данные, которые вы указали для пользователя удаленного рабочего стола.

4. Во время удаленного сеанса запустите Windows PowerShell и, используя команды файловой системы HDFS, отобразите список файлов в хранилище озера данных Azure.

	 	hdfs dfs -ls adl://<Data Lake Store account name>.azuredatalakestore.net:443/

	Эта команда должна показать файл, который вы ранее отправили в хранилище озера данных.

		15/09/17 21:41:15 INFO web.CaboWebHdfsFileSystem: Replacing original urlConnectionFactory with org.apache.hadoop.hdfs.web.URLConnectionFactory@21a728d6
		Found 1 items
		-rwxrwxrwx   0 NotSupportYet NotSupportYet     671388 2015-09-16 22:16 adl://mydatalakestore.azuredatalakestore.net:443/mynewfolder

	С помощью команды `hdfs dfs -put` вы можете отправить в хранилище озера данных некоторые файлы, а затем с помощью команды `hdfs dfs -ls` проверить, успешно ли они передались.


## Использование хранилища озера данных в топологии Storm

Хранилище озера данных можно использовать для записи данных из топологии Storm. Инструкции по реализации этого сценария см. в статье [Использование хранилища озера данных Azure с Apache Storm в HDInsight](../hdinsight/hdinsight-storm-write-data-lake-store.md).

## См. также

* [PowerShell: создание кластера HDInsight для работы с хранилищем озера данных](data-lake-store-hdinsight-hadoop-use-powershell.md)

[makecert]: https://msdn.microsoft.com/library/windows/desktop/ff548309(v=vs.85).aspx
[pvk2pfx]: https://msdn.microsoft.com/library/windows/desktop/ff550672(v=vs.85).aspx

<!---HONumber=AcomDC_0204_2016-->