---
title: "Рекомендации по настройке производительности Azure Data Lake Store | Документация Майкрософт"
description: "Рекомендации по настройке производительности Azure Data Lake Store"
services: data-lake-store
documentationcenter: 
author: nitinme
manager: jhubbard
editor: cgronlun
ms.assetid: ebde7b9f-2e51-4d43-b7ab-566417221335
ms.service: data-lake-store
ms.devlang: na
ms.topic: article
ms.tgt_pltfrm: na
ms.workload: big-data
ms.date: 12/02/2016
ms.author: nitinme
translationtype: Human Translation
ms.sourcegitcommit: af11866fc812cd8a375557b7bf9df5cdc9bba610
ms.openlocfilehash: f0d0c05c08ce198e2702c76ad35b348107c664c7


---
# <a name="performance-tuning-guidance-for-azure-data-lake-store"></a>Рекомендации по настройке производительности Azure Data Lake Store

В этой статье приводятся рекомендации по настройке наиболее оптимальной производительности при записи данных в Azure Data Lake Store или чтении данных из него. Эта статья призвана помочь пользователям освоиться с параметрами, которые можно настроить для часто используемых средств отправки или скачивания данных и рабочих нагрузок для анализа данных. Настройка в этом руководстве специально предназначена для ресурсоемких рабочих нагрузок с большими объемами данных, считываемых из Data Lake Store и записываемых в него.

## <a name="prerequisites"></a>Предварительные требования

* **Подписка Azure**. Ознакомьтесь с [бесплатной пробной версией Azure](https://azure.microsoft.com/pricing/free-trial/).
* **Учетная запись Azure Data Lake Store.** Инструкции по созданию учетной записи см. в статье [Начало работы с Azure Data Lake Store с помощью портала Azure](data-lake-store-get-started-portal.md).
* **Кластер Azure HDInsight** с доступом к учетной записи Data Lake Store. См. статью [Создание кластера HDInsight с Data Lake Store с помощью портала Azure](data-lake-store-hdinsight-hadoop-use-portal.md). Убедитесь, что вы включили удаленный рабочий стол для кластера.


## <a name="guidelines-for-data-ingestion-tools"></a>Рекомендации для средств приема данных

В этом разделе содержатся общие рекомендации по повышению производительности при копировании или перемещении в Data Lake Store. Здесь мы рассмотрим факторы, ограничивающие производительность, и способы преодоления этих ограничений. Ниже приведены некоторые рекомендации, которые следует учесть.

* **Источник данных.** Есть множество ограничений, обусловленных расположением источника данных. Пропускная способность может быть узким местом, если источник данных находится на диске с медленными шпинделями или в удаленном хранилище с низкой пропускной способностью. SSD, предпочтительно на локальном диске, обеспечивают наилучшую производительность из-за более высокой пропускной способности диска.

* **Сеть.** Если источник данных находится на виртуальных машинах, необходимо наличие сетевого подключения между виртуальными машинами и Data Lake Store. Используйте виртуальные машины с сетевыми картами максимального размера, чтобы обеспечить большую пропускную способность сети.

* **Межрегиональное копирование.** Межрегиональные операции ввода-вывода данных, например запуск средства приема данных на виртуальной машине в восточной части США 2 для записи данных в учетную запись Data Lake Store в центральной части США, характеризуются большими расходами на сетевые ресурсы. При копировании данных между регионами наблюдается снижение производительности. Для улучшения пропускной способности сети мы рекомендуем использовать задания приема данных на виртуальных машинах в том же регионе, где расположена целевая учетная запись Data Lake Store.                                                                                                                                        

* **Кластер.** При запуске заданий приема данных через кластер HDInsight (например, DistCp) мы рекомендуем использовать для кластера виртуальные машины серии D, так как в них предоставлен больший объем памяти. Большее количество ядер также поможет увеличить пропускную способность.                                                                                                                                                                                                                                                                                                            

* **Параллелизм потоков.** При использовании кластера HDInsight для копирования данных из контейнера хранилища применяются ограничения на количество параллельных потоков, используемых в зависимости от размера вашего кластера, размера контейнера и параметров потока. Один из самых важных способов улучшить производительность в Data Lake Store — увеличить значение параллелизма. Чтобы повысить пропускную способность, необходимо задать для параметра параллелизма максимальное значение. В следующей таблице перечислены параметры для каждого метода приема, который можно настроить для обеспечения обработки большего количества параллельных потоков. Воспользуйтесь ссылками в таблице, чтобы перейти к статьям, в которых описывается, как использовать средство для приема данных в Data Lake Store, а также настроить производительность средства для обеспечения максимальной пропускной способности.

    | Средство               | Параметр параллелизма                                                                |
    |--------------------|------------------------------------------------------------------------------------|
    | [PowerShell](data-lake-store-get-started-powershell.md)       | PerFileThreadCount, ConcurrentFileCount |
    | [AdlCopy](data-lake-store-copy-data-azure-storage-blob.md)    | Единицы измерения Azure Data Lake Analytics         |
    | [DistCp](data-lake-store-copy-data-wasb-distcp.md)            | -m (mapper)                             |
    | [Фабрика данных Azure](../data-factory/data-factory-azure-datalake-connector.md)| parallelCopies                          |
    | [Sqoop](data-lake-store-data-transfer-sql-sqoop.md)           | fs.azure.block.size, -m (mapper)        |


## <a name="guidelines-while-working-with-hdinsight-workloads"></a>Рекомендации по работе с рабочими нагрузками HDInsight

Во время выполнения аналитических рабочих нагрузок для работы с данными в Data Lake Store мы рекомендуем использовать версию кластера HDInsight 3.5 для обеспечения высокой производительности Data Lake Store. Если во время вашего задания выполняется большое количество операций ввода-вывода, некоторые параметры можно настроить для повышения производительности. Например, если задание состоит преимущественно из операций чтения или записи, повысить производительность можно, увеличив значение параметра параллелизма для операций ввода-вывода в Azure Data Lake Store и из него.

Производительность Azure Data Lake Store можно лучше всего оптимизировать при максимальном значении для параллельной обработки. Есть несколько основных способов повышения параллелизма для заданий с большим количеством операций ввода-вывода.

1. **Запустите большее число вычислительных контейнеров YARN.** Наличие дополнительных контейнеров увеличит параллелизм для операций ввода-вывода, таким образом задействуя возможности Data Lake Store.

    Например, предположим, что в вашем кластере HDInsight 2 узла D3v2. На каждом узле D3v2 доступно 12 ГБ памяти YARN, поэтому на 2 компьютерах D3v2 будет доступно 24 ГБ памяти YARN. Предположим также, что для размеров контейнера YARN установлено значение 6 ГБ. Это означает, что у вас есть 4 контейнера по 6 ГБ. Таким образом, вы можете параллельно выполнять 4 задачи. Для повышения параллелизма можно уменьшить размер контейнеров до 3 ГБ, в результате чего у вас будет 8 контейнеров по 3 ГБ. Таким образом, вы можете параллельно выполнять 8 задач. Это показано на схеме ниже.

    ![Производительность Data Lake Store](./media/data-lake-store-performance-tuning-guidance/image-1.png)

    Нас часто спрашивают, можно ли уменьшить размер контейнера до 1 ГБ памяти, чтобы получить 24 контейнера для повышения параллелизма. Это зависит от того, необходимо ли для выполнения задачи 3 ГБ памяти или достаточно 1 ГБ.  Вы можете выполнять простую операцию в контейнере, для которой требуется всего 1 ГБ памяти, либо сложную операцию, для которой может потребоваться 3 ГБ памяти.  Если слишком сильно уменьшить размер контейнера, можно получить исключение из-за нехватки памяти.  В этом случае следует увеличить размер контейнеров.  Помимо памяти, на параллелизм также может повлиять количество виртуальных ядер.

    ![Производительность Data Lake Store](./media/data-lake-store-performance-tuning-guidance/image-2.png)

2. **Увеличьте объем памяти в кластере, чтобы увеличить параллелизм.** Увеличить объем памяти в кластере можно, увеличив размер кластера или выбрав тип виртуальной машины с большим объемом памяти. Это увеличит объем доступной памяти YARN, и вы сможете создать дополнительные контейнеры, чтобы повысить параллелизм.  

    Например, предположим, что в вашем кластере HDInsight есть один узел D3v2 с 12 ГБ памяти YARN и контейнеры по 3 ГБ.  Масштабируйте кластер до 2 узлов D3v2, чтобы увеличить объем памяти YARN до 24 ГБ.  Это увеличит значение параллелизма с 4 до 8.

    ![Производительность Data Lake Store](./media/data-lake-store-performance-tuning-guidance/image-3.png)

3. **Выполните запуск, задав для числа задач значение параллелизма.** Размер контейнера уже настроен для получения максимального объема параллелизма. Теперь следует задать число задач для использования всех этих контейнеров. В каждой рабочей нагрузке для всех задач есть разные имена.

    Кроме того, вы можете обратить внимание на размер задания. Если размер задания большой, каждой задаче придется обрабатывать большой объем данных. Возможно, понадобится использовать дополнительные задачи, чтобы каждая задача не обрабатывала слишком большой объем данных.

    К примеру, предположим, что у вас 6 контейнеров. В качестве отправной точки для наших задач необходимо задать значение 6. Можно поэкспериментировать с количеством задач, чтобы увидеть, улучшится ли производительность. Задание большего количества задач не увеличивает параллелизм. Если установить для задач значение больше 6, задача не будет выполняться до следующей волны. Если установить для задач значение меньше 6, параллелизм не будет использоваться полностью.

    У всех рабочих нагрузок разные параметры для установки количества задач. В следующей таблице представлены некоторые из них.

    | Рабочая нагрузка               | Параметры для настройки задач                                                         |
    |--------------------|------------------------------------------------------------------------------------|
    | [Spark в HDInsight](data-lake-store-performance-tuning-spark.md)       | <ul><li>Num-executors</li><li>Executor-memory</li><li>Executor-cores</li></ul> |
    | [Hive в HDInsight](data-lake-store-performance-tuning-hive.md)    | hive.tez.container.size         |
    | [MapReduce в HDInsight](data-lake-store-performance-tuning-mapreduce.md)            | <ul><li>Mapreduce.map.memory</li><li>Mapreduce.job.maps</li><li>Mapreduce.reduce.memory</li><li>Mapreduce.job.reduces</li></ul> |
    | [Storm в HDInsight](data-lake-store-performance-tuning-storm.md)| <ul><li>Количество рабочих процессов</li><li>Количество экземпляров исполнителей воронки</li><li>Количество экземпляров исполнителей сита </li><li>Количество задач воронки</li><li>Количество задач сита</li></ul>|

## <a name="see-also"></a>Дополнительные материалы
* [Обзор хранилища озера данных Azure](data-lake-store-overview.md)
* [Начало работы с аналитикой озера данных Azure](../data-lake-analytics/data-lake-analytics-get-started-portal.md)



<!--HONumber=Jan17_HO3-->


