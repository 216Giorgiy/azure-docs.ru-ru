---
title: Рекомендации по использованию Azure Data Lake Store | Документация Майкрософт
description: Ознакомьтесь с рекомендациями по приему и безопасности данных, а также по производительности, связанные с использованием Azure Data Lake Store.
services: data-lake-store
documentationcenter: ''
author: sachinsbigdata
manager: jhubbard
editor: cgronlun
ms.service: data-lake-store
ms.devlang: na
ms.topic: article
ms.tgt_pltfrm: na
ms.workload: big-data
ms.date: 03/02/2018
ms.author: sachins
ms.openlocfilehash: 7493c10407bfe83bdc7277c49dae1a7e9d7c39f2
ms.sourcegitcommit: 9cdd83256b82e664bd36991d78f87ea1e56827cd
ms.translationtype: HT
ms.contentlocale: ru-RU
ms.lasthandoff: 04/16/2018
---
# <a name="best-practices-for-using-azure-data-lake-store"></a>Рекомендации по использованию Azure Data Lake Store
Из этой статьи вы узнаете о лучших методиках и рекомендациях, связанных с работой с Azure Data Lake Store. В этом руководстве приводятся сведения о безопасности, производительности, отказоустойчивости и мониторинге для Data Lake Store. До появления Data Lake Store работать с большими данными в таких службах, как Azure HDInsight, было достаточно сложно. Нужно было сегментировать данные в нескольких учетных записях хранения больших двоичных объектов, чтобы обеспечить хранение петабайтовых файлов и оптимальную производительность в этом масштабе. С Data Lake Store большинство жестких ограничений размера и производительности исчезли. Тем не менее в этой статье рассматриваются некоторые методики по обеспечению высокой производительности при работе с Data Lake Store. 

## <a name="security-considerations"></a>Вопросы безопасности

Azure Data Lake Store предлагает элементы управления доступом POSIX и подробный аудит для пользователей, групп и субъектов-служб Azure Active Directory (Azure AD). Эти элементы управления доступом можно настроить для имеющихся файлов и папок. Их также можно использовать для создания значений по умолчанию, которые можно применить к новым файлам или папкам. Если для имеющихся папок и дочерних объектов установлены разрешения, их нужно рекурсивно распространить на каждый объект. При наличии большого количества файлов распространение разрешений может занять много времени. Затраченное время может варьироваться между 30–50 объектами, обрабатываемыми за секунду. Следовательно, необходимо соответствующим образом упорядочить структуру папок и создать группы пользователей. В противном случае это может вызвать непредвиденные задержки и проблемы при работе с данными. 

Предположим, у вас есть папка, содержащая 100 000 дочерних объектов. Если взять нижнюю границу — 30 объектов, обрабатываемых за секунду, то обновление разрешения для всей папки может занять час. Дополнительные сведения о списках управления доступом Data Lake Store см. в статье [Контроль доступа в Azure Data Lake Store](data-lake-store-access-control.md). Для повышения производительности при рекурсивном назначении списков управления доступом можно использовать программу командной строки Azure Data Lake. Программа создает несколько потоков и рекурсивную навигационную логику для быстрого применения списков ACL к миллионам файлов. Она доступна для Linux и Windows, а [документацию](https://github.com/Azure/data-lake-adlstool) и [файлы для скачивания](http://aka.ms/adlstool-download) можно найти на сайте GitHub. Такие улучшения производительности можно включить собственными средствами, написанными с использованием пакетов SDK для Data Lake Store для [.NET](data-lake-store-data-operations-net-sdk.md) и [Java](data-lake-store-get-started-java-sdk.md).

### <a name="use-security-groups-versus-individual-users"></a>Сравнение использования групп безопасности и отдельных пользователей 

При работе с большими данными в Data Lake Store субъект-служба, скорее всего, будет использоваться для предоставления службам, таким как Azure HDInsight, разрешения работать с данными. Однако встречаются случаи, когда доступ к данным также необходимо предоставить отдельным пользователям. В таких случаях нужно использовать группы безопасности Azure Active Directory вместо назначения отдельных пользователей папкам и файлам. 

Когда группе безопасности назначены разрешения, для добавления или удаления пользователей из группы не требуются какие-либо обновления Data Lake Store. Так вы не превысите ограничение в [32 списка ACL (списки для доступа и списки по умолчанию)](../azure-subscription-service-limits.md#data-lake-store-limits). Сюда входят четыре списка ACL типа POSIX, которые всегда связаны со всеми файлами и папками: [пользователь-владелец](data-lake-store-access-control.md#the-owning-user), [группа-владелец](data-lake-store-access-control.md#the-owning-group), [маска](data-lake-store-access-control.md#the-mask-and-effective-permissions)и др.

### <a name="security-for-groups"></a>Безопасность для групп 

Как уже отмечалось, когда пользователям нужен доступ к Data Lake Store, лучше всего использовать группы безопасности Azure Active Directory. Мы рекомендуем начать с таких групп, как **ReadOnlyUsers**, **WriteAccessUsers** и **FullAccessUsers**, на корневом уровне учетной записи, а также назначить отдельные группы для основных подпапок. Если есть другие ожидаемые группы пользователей, которые нужно будет добавить позже, но они еще не определены, можно рассмотреть создание пустых групп безопасности с доступом к определенным папкам. Использование группы безопасности — гарантия того, что вам позже не потребуется длительное время обработки для назначения новых разрешений тысячам файлов. 

### <a name="security-for-service-principals"></a>Безопасность для субъектов-служб 

Субъекты-службы Azure Active Directory обычно используются такими службами, как Azure HDInsight, для доступа к данным в Data Lake Store. В зависимости от требований к доступности нескольких рабочих нагрузок стоит рассмотреть обеспечение безопасности внутри организации и за ее пределами. Для многих клиентов может быть достаточно одного субъекта-службы Azure Active Directory, и ему можно назначить полный набор прав в корневой папке Data Lake Store. Другим клиентам может потребоваться несколько кластеров с разными субъектами-службами, где у одного кластера будет полный доступ к данным, а у другого — только доступ на чтение. Как и в случае с группами безопасности, можно рассмотреть возможность создания субъекта-службы для каждого ожидаемого сценария (чтения, записи, расширенного), когда учетная запись Data Lake Store будет создана. 

### <a name="enable-the-data-lake-store-firewall-with-azure-service-access"></a>Включение брандмауэра Data Lake Store с доступом к службе Azure 

Data Lake Store поддерживает возможность включения брандмауэра и предоставления доступа только службам Azure, что рекомендуется для меньшего вектора атаки в случае внешних вторжений. Брандмауэр можно включить для учетной записи Data Lake Store на портале Azure, выбрав **Брандмауэр** > **Включить брандмауэр (Вкл.)** > **Allow access to Azure services** (Разрешить доступ службам Azure).  

![Параметры брандмауэра в Data Lake Store](./media/data-lake-store-best-practices/data-lake-store-firewall-setting.png "Параметры брандмауэра в Data Lake Store")

После включения брандмауэра доступ к Data Lake Store возможен только для служб Azure, таких как HDInsight, фабрика данных, хранилище данных SQL и т. д. Из-за внутреннего преобразования сетевых адресов, используемого Azure, брандмауэр Data Lake Store не поддерживает ограничение для конкретных служб по IP-адресу и предназначается только для ограничения по конечным точкам за пределами Azure, например в локальной среде. 

## <a name="performance-and-scale-considerations"></a>Рекомендации по производительности и масштабируемости

Одна из самых мощных функций Data Lake Store заключается в устранении жестких ограничений пропускной способности данных. Благодаря этому клиенты могут увеличивать размер данных и расширять соответствующие требования к производительности без необходимости сегментировать данные. Одна из наиболее важных рекомендаций по оптимизации производительности Data Lake Store связана с параллелизмом.

### <a name="improve-throughput-with-parallelism"></a>Повышение пропускной способности при параллелизме 

Оптимальную пропускную способность чтения и записи можно получить при использовании 8–12 потоков на ядро. Это объясняется блокировкой операций чтения и записи в одном потоке, а большее количество потоков могут обеспечить более высокий параллелизм на виртуальной машине. Для обеспечения работоспособности уровней и повышения параллелизма необходимо отслеживать использование ЦП виртуальной машины.   

### <a name="avoid-small-file-sizes"></a>Не используйте файлы небольшого размера

Разрешения и аудит POSIX в Data Lake Store сопровождаются накладными расходами, которые становятся очевидными при работе со множеством файлов небольшого размера. Лучше всего упаковать данные в файлы большего размера, а не записывать тысячи или миллионы небольших файлов в Data Lake Store. Использование файлов большего размера предоставляет следующие преимущества:

* снижение числа проверок подлинности для большого количества файлов;
* уменьшение числа подключений к открытым файлам;
* более быстрые копирование или репликация;
* меньшее количество файлов для обработки при обновлении разрешений POSIX в Data Lake Store. 

В зависимости от того, какие службы и рабочие нагрузки используют данные, оптимальный диапазон для размера файлов — от 256 МБ до 1 ГБ, в идеале — не менее 100 МБ или не более 2 ГБ. Если файлы нельзя упаковать с учетом размеров при размещении в Data Lake Store, можно использовать отдельное задание сжатия, которое объединит эти файлы в более крупные по размеру. Дополнительные сведения и рекомендации по размерам файлов и упорядочивании данных в Data Lake Store см. в разделе [Структура набора данных](data-lake-store-performance-tuning-guidance.md#structure-your-data-set). 

### <a name="large-file-sizes-and-potential-performance-impact"></a>Файлы больших размеров и возможное влияние на производительность 

Хотя Data Lake Store поддерживает файлы больших размеров — до петабайт, для обеспечения оптимальной производительности и в зависимости от процесса, считывающего данные, превышение в среднем 2 ГБ не рекомендуется. Например, при использовании операции **Distcp** для копирования данных между расположениями или разными учетными записями хранения, файлы представляют собой самый нижний уровень детализации, используемый для определения задач сопоставления. Итак, если вы копируете 10 файлов по 1 ТБ каждый, выделяется не более 10 модулей сопоставления. Кроме того, если у вас много файлов с назначенными модулями сопоставления, эти модули изначально работают параллельно для перемещения файлов больших размеров. Тем не менее, когда задание начинает завершаться, доступными остаются всего несколько модулей сопоставления и может даже остаться только один модуль, назначенный файлу большого размера. Корпорация Майкрософт оптимизировала Distcp для решения этой проблемы в будущих версиях Hadoop.  

Также стоит обратить внимание на использование Azure Data Lake Analytics с Data Lake Store. В зависимости от обработки, выполняемой средством извлечения, может ухудшиться производительность некоторых файлов размером свыше 2 ГБ, которые нельзя разделить (например, XML-, JSON-файлы). В случаях, когда файлы можно разделить с помощью средства извлечения (например, CSV-файлы), файлы больших размеров являются оптимальными.

### <a name="capacity-plan-for-your-workload"></a>Планирование емкости для рабочей нагрузки 

Azure Data Lake Store устраняет жесткие ограничения регулирования операций ввода-вывода, установленные в учетных записях хранения больших двоичных объектов. Тем не менее по-прежнему применяются некоторые нестрогие ограничения, которые стоит учитывать. Ограничения регулирования входящего и исходящего трафика по умолчанию удовлетворяют потребностям большинства сценариев. Если для вашей рабочей нагрузки нужно увеличить ограничения, мы рекомендуем обратиться в службу поддержки Майкрософт. Кроме того, ознакомьтесь с ограничениями на этапе работы в экспериментальной среде, чтобы не достичь ограничений регулирования операций ввода-вывода при использовании в рабочей среде. В противном случае вам придется ждать некоторое время, пока сотрудник службы поддержки Майкрософт не увеличит ограничения вручную. При регулировании операций ввода-вывода Azure Data Lake Store возвращает код ошибки 429, и в идеале должна быть выполнена повторная попытка с использованием соответствующей политики экспоненциального откладывания. 

### <a name="optimize-writes-with-the-data-lake-store-driver-buffer"></a>Оптимизация операций записи с помощью буфера драйвера Data Lake Store 

Чтобы оптимизировать производительность и уменьшить количество операций ввода-вывода в секунду при записи в Data Lake Store из Hadoop, выполните операции записи размером как можно ближе к размеру буфера драйвера Data Lake Store. Старайтесь не превышать размер буфера перед очисткой, например при потоковой передаче с помощью рабочих нагрузок потоковой передачи Spark или Apache Storm. При записи в Data Lake Store из HDInsight или Hadoop важно знать, что в Data Lake Store есть драйвер с буфером размером 4 МБ. Как и многие драйверы файловой системы, этот буфер можно вручную очистить до достижения размера 4 МБ. Если этого не сделать, его содержимое будет перенесено в хранилище, если следующая операция записи превышает максимальный размер буфера. По возможности нужно избегать переполнения или недостаточного заполнения буфера при синхронизации или переносе содержимого по количеству или временному окну.

## <a name="resiliency-considerations"></a>Рекомендации по обеспечению устойчивости 

При разработке системы с Data Lake Store или любой облачной службой нужно учесть требования к доступности и способы реагирования на возможные прерывания обслуживания. Проблему можно локализовать на уровне конкретного экземпляра или даже всего региона, поэтому важно учесть все в комплексе. В зависимости от соглашений об уровне обслуживания в отношении **целевого времени восстановления** и **целевой точки восстановления** для вашей рабочей нагрузки, можно выбрать более или менее агрессивную стратегию для обеспечения высокой доступности и аварийного восстановления.

### <a name="high-availability-and-disaster-recovery"></a>Высокий уровень доступности и аварийное восстановление 

Высокий уровень доступности (HA) и аварийное восстановление (DR) иногда можно сочетать, хотя связанные стратегии немного отличаются, особенно при работе с данными. Data Lake Store уже обрабатывает 3-кратную репликацию в фоновом режиме, чтобы защитить оборудование от локальных сбоев. Но так как отсутствует встроенная репликация по регионам, вам нужно выполнить ее самостоятельно. Составляя план для обеспечения высокого уровня доступности, в случае прерывания работы службы нужно как можно быстрее предоставить для рабочей нагрузки доступ к последним данным, выполнив переключение на отдельно реплицированный экземпляр в локальной среде или новом регионе.  

В стратегии аварийного восстановления, чтобы подготовиться к маловероятному событию катастрофического отказа региона, также важно реплицировать данные в другой регион. Эти данные изначально должны быть такими же, как и реплицированные данные для обеспечения высокого уровня доступности. Тем не менее стоит также рассмотреть требования для таких пограничных случаев, как повреждение данных, когда может понадобиться создать периодические моментальные снимки, чтобы вернуться к ним. В зависимости от важности и размера данных рассмотрите возможность развертывания разностных моментальных снимков с интервалом времени 1, 6 и 24 часа в локальном или дополнительном хранилище в соответствии с допусками риска. 

Для обеспечения устойчивости данных в Data Lake Store рекомендуется выполнить георепликацию данных в отдельный регион с частотой, которая удовлетворяет вашим требованиям к высокой доступности и аварийному восстановлению, в идеале — каждый час. Эта частота репликации минимизирует массивные перемещения данных с возможными конкурирующими требованиями к пропускной способности в отношении основной системы и требованиями к оптимальной целевой точке восстановления (RPO). Кроме того, стоит подумать, каким образом приложение, использующее Data Lake Store, автоматически выполнит отработку отказа в дополнительную учетную запись на основе мониторинга триггеров или количества попыток, завершившихся сбоем, или по крайней мере отправит уведомление администраторам для устранения неполадок вручную. Имейте в виду, что есть компромисс — выполнить отработку отказа, а не ждать, когда служба снова станет работоспособной. Если репликация не закончена, отработка отказа может привести к потере данных, несогласованности или сложному слиянию данных. 

Ниже приводятся три оптимальных варианта организации репликации между учетными записями Data Lake Store и основные различия между ними.


|  |Distcp  |Фабрика данных Azure  |AdlCopy  |
|---------|---------|---------|---------|
|**Ограничения масштабирования**     | Ограничивается рабочими узлами        | Ограничивается максимальным количеством единиц перемещения облачных данных        | Ограничивается единицами аналитики        |
|**Поддержка копирования изменений**     |   Yes      | Нет          | Нет          |
|**Встроенная оркестрация**     |  Отсутствует (используйте Oozie Airflow или задания Cron)       | Yes        | Отсутствует (используйте службу автоматизации Azure или планировщик задач Windows)         |
|**Поддерживаемые файловые системы**     | ADL, HDFS, WASB, S3, GS, CFS        |Много. Дополнительные сведения см. в статье [Копирование данных в хранилище BLOB-объектов Azure и обратно с помощью фабрики данных Azure](../data-factory/connector-azure-blob-storage.md).         | ADL в ADL, WASB в ADL (только в одном регионе)        |
|**Поддержка ОС**     |Любая ОС, где выполняется Hadoop         | Недоступно          | Windows 10         |
   

### <a name="use-distcp-for-data-movement-between-two-locations"></a>Использование программы Distcp для перемещения данных между двумя расположениями 

Distcp, сокращение от "распределенное копирование", представляет собой программу командной строки Linux, которая входит в состав Hadoop, и обеспечивает распределенное перемещение данных между двумя расположениями. Этими расположениями могут быть Data Lake Store, HDFS, WASB или S3. В программе используются задания MapReduce в кластере Hadoop (например, HDInsight) для масштабирования на всех узлах. Distcp считается самым быстрым способом перемещения больших данных без специальных устройств сетевого сжатия. Это средство также позволяет обновлять разностные данные между двумя расположениями, обрабатывать автоматические повторные попытки, а также применять динамическое масштабирование к вычислениям. Этот подход невероятно эффективен, когда, например, речь идет о реплицировании таблиц Hive и Spark, которые могут содержать много файлов больших размеров в одном каталоге, и вы хотите копировать только измененные данные. Именно поэтому Distcp является наиболее рекомендуемым инструментом для копирования данных между хранилищами больших данных. 

Задания копирования могут запустить рабочие процессы Apache Oozie, использующие триггеры частоты или данных, а также задания Cron в Linux. Для интенсивных задач репликации рекомендуется развернуть отдельный кластер HDInsight Hadoop, который можно настроить и масштабировать специально для заданий копирования. Таким образом задания копирования и критические задания не будут влиять на работу друг друга. При выполнении репликации с достаточно широким интервалом кластер может прекращать работу между выполнением каждого задания. При выполнении отработки отказа в дополнительный регион в этом регионе нужно развернуть другой кластер для репликации новых данных обратно в основную учетную запись Data Lake Store, когда она снова станет рабочей. Примеры использования Distcp см. в статье [Использование Distcp для копирования данных между BLOB-объектами и хранилищем озера данных](data-lake-store-copy-data-wasb-distcp.md).

### <a name="use-azure-data-factory-to-schedule-copy-jobs"></a>Использование фабрики данных Azure для планирования заданий копирования 

Фабрику данных Azure можно также использовать для планирования заданий копирования с помощью **действия копирования**, а также настроить с определенной частотой через **мастер копирования**. Имейте в виду, что для фабрики данных Azure есть ограничение единиц перемещения облачных данных (DMU) и в конечном итоге ограничение пропускной способности или вычислительной мощности рабочих нагрузок с большими данными. Кроме того, фабрика данных Azure в настоящее время не предлагает обновления разностных данных между учетными записями Data Lake Store, поэтому для таких папок, как таблицы Hive, требуется полная копия для репликации. Дополнительные сведения о копировании с помощью фабрики данных см. в статье [Руководство по настройке производительности действия копирования](../data-factory/v1/data-factory-copy-activity-performance.md). 

### <a name="adlcopy"></a>AdlCopy

AdlCopy — это программа командной строки Windows, которая позволяет копировать данные между двумя учетными записями Data Lake Store только в одном регионе. Средство AdlCopy предоставляет вариант изолированного использования или возможность использовать учетную запись Azure Data Lake Analytics для выполнения задания копирования. Хотя изначально это средство было создано для копирования по запросу, а не для надежной репликации, оно обеспечивает еще один вариант выполнения распределенного копирования между учетными записями Data Lake Store в одном регионе. Для обеспечения надежности рекомендуется использовать службу Data Lake Analytics уровня "Премиум" для любой нагрузки в рабочей среде. Изолированная версия может возвращать ответы о занятости службы и включает ограниченные масштабируемость и мониторинг. 

Как и в случае с Distcp, AdlCopy нужно управлять с помощью службы автоматизации Azure или планировщика задач Windows. Как и в случае с фабрикой данных, AdlCopy не поддерживает копирование только обновленных файлов. Он повторно копирует и перезаписывает имеющиеся файлы. Дополнительные сведения и примеры использования AdlCopy см. в статье [Копирование данных из больших двоичных объектов хранилища Azure в хранилище озера данных](data-lake-store-copy-data-azure-storage-blob.md).

## <a name="monitoring-considerations"></a>Рекомендации по мониторингу 

Data Lake Store предоставляет подробные журналы диагностики и возможность аудита, а также некоторые базовые метрики на портале Azure в разделе учетной записи Data Lake Store и в Azure Monitor. Сведения о доступности Data Lake Store отображаются на портале Azure. Однако эта метрика обновляется каждые семь минут, и ее нельзя запросить через общедоступный API-интерфейс. Чтобы получить самое актуальное состояние доступности учетной записи Data Lake Store, нужно запустить собственные искусственные тесты для проверки доступности. Обновление других метрик, например общего использования хранилища, запросов на чтение и запись, а также показателей входящего и исходящего трафика, может занять до 24 часов. Таким образом, более актуальные метрики нужно получить самостоятельно с помощью программ командной строки Hadoop или путем агрегирования сведений журналов. Самый быстрый способ получить самые актуальные сведения об использовании хранилища — запустить команду HDFS ниже с узла кластера Hadoop (например, головного узла):   

    hdfs dfs -du -s -h adl://<adls_account_name>.azuredatalakestore.net:443/

### <a name="export-data-lake-store-diagnostics"></a>Экспорт сведений диагностики Data Lake Store 

Один из самых быстрых способов получить доступ к журналам с возможностью поиска из Data Lake Store — включить доставку журналов в **Log Analytics** в колонке **Диагностика** для учетной записи Data Lake Store. Это обеспечит немедленный доступ к входящим журналам с фильтрами времени и содержимого, а также параметрам оповещения (электронная почта или веб-перехватчик), которые запускаются с интервалом в 15 минут. Дополнительные сведения см. в статье [Доступ к журналам диагностики Azure Data Lake Store](data-lake-store-diagnostic-logs.md). 

Чтобы получать оповещения в режиме реального времени и получить больший контроль над размещением журналов, журналы можно экспортировать в Azure EventHub, где содержимое можно проанализировать отдельно или с учетом временного окна для отправки уведомлений в режиме реального времени в очередь. Отдельное приложение, например [приложение логики](../connectors/connectors-create-api-azure-event-hubs.md), может затем использовать эти оповещения и передавать их в соответствующий канал, а также отправлять метрики в средства мониторинга, такие как NewRelic, Datadog или AppDynamics. Кроме того, если вы используете сторонний инструмент, такой как ElasticSearch, вы можете экспортировать журналы в хранилище BLOB-объектов и использовать [подключаемый модуль Azure Logstash](https://github.com/Azure/azure-diagnostics-tools/tree/master/Logstash/logstash-input-azureblob) для использования данных в стеке Elasticsearch, Kibana и Logstash (ELK).

### <a name="turn-on-debug-level-logging-in-hdinsight"></a>Включение ведения журнала на уровне отладки в HDInsight 

Если доставка журналов Data Lake Store отключена, Azure HDInsight также предоставляет возможность включить [ведение журнала на стороне клиента для Data Lake Store](data-lake-store-performance-tuning-mapreduce.md) через log4j. Нужно задать свойство ниже в **Ambari** > **YARN** > **Конфигурация** > **Advanced yarn-log4j configurations** (Расширенные конфигурации yarn-log4j): 

    log4j.logger.com.microsoft.azure.datalake.store=DEBUG 

После установки этого свойства и перезагрузки узлов данные диагностики Data Lake Store начнут записываться в журналы YARN на узлах (/tmp/<user>/yarn.log), и вы сможете отслеживать важные данные, такие как ошибки или регулирование (код ошибки HTTP 429). Эти сведения также можно отследить в Log Analytics или при отправке журналов в колонку [Диагностика](data-lake-store-diagnostic-logs.md) в учетной записи Data Lake Store. Рекомендуется включить хотя бы ведение журнала на стороне клиента или использовать параметр доставки журнала с помощью Data Lake Store для обеспечения оперативной видимости и упрощенной отладки.

### <a name="run-synthetic-transactions"></a>Запуск искусственных транзакций 

В настоящее время метрика доступности службы для Data Lake Store на портале Azure имеет 7-минутное окно обновления. Кроме того, ее нельзя запросить с помощью общедоступного API-интерфейса. Таким образом, рекомендуется создать базовое приложение, которое выполняет искусственные транзакции в Data Lake Store, обеспечивающее доступность до минуты. Например, можно создать приложение WebJob, приложение логики или приложение-функции Azure для чтения, создания и обновления в Data Lake Store и отправки результатов в ваше решение мониторинга. Эти операции могут выполняться во временной папке, а затем удаляться после теста, который может запускаться каждые 30–60 секунд в зависимости от требований.

## <a name="directory-layout-considerations"></a>Рекомендации в отношении структуры каталога

При размещении данных в Data Lake важно заранее спланировать структуру данных, чтобы можно было эффективно использовать безопасность, секционирование и обработку. Многие из рекомендаций ниже можно использовать в Azure Data Lake Store, хранилище BLOB-объектов или HDFS. Каждая рабочая нагрузка включает разные требования к способу использования данных. Ниже приводятся некоторые общие шаблоны, которые следует учесть при работе с пакетными сценариями и Центром Интернета вещей.

### <a name="iot-structure"></a>Структура Центра Интернета вещей 

В рабочих нагрузках Центра Интернета вещей большое количество данных может размещаться в хранилище данных, которое охватывает множество продуктов, устройств, организаций и клиентов. Важно заранее спланировать структуру каталога для организации, обеспечения безопасности и эффективной обработки данных для нисходящих потребителей. Ниже приведен общий шаблон, который стоит рассмотреть. 

    {Region}/{SubjectMatter(s)}/{yyyy}/{mm}/{dd}/{hh}/ 

Например, каталог размещения телеметрии для авиационного двигателя в Великобритании может выглядеть так: 

    UK/Planes/BA1293/Engine1/2017/08/11/12/ 

Есть важная причина размещения даты в конце структуры папки. Если вы хотите заблокировать определенные регионы и типы данных для пользователей или групп, это можно легко сделать с помощью разрешений POSIX. В противном случае, если возникла необходимость ограничить определенную группу безопасности — предоставить возможность просматривать только данные Великобритании или определенных самолетов с датой в начале структуры папки — потребуется отдельное разрешение для нескольких папок в папке, создаваемой каждый час. Кроме того, при наличии структуры даты в начале количество папок будет экспоненциально увеличиваться с течением времени.

### <a name="batch-jobs-structure"></a>Структура пакетных заданий 

На высоком уровне широко используемым подходом в пакетной обработке является размещение данных во вложенной папке. Как только данные будут обработаны, поместите новые данные во внешнюю папку для использования нисходящими процессами. Эта структура каталогов иногда наблюдается в случае заданий, требующих обработки отдельных файлов и не требующих массовой параллельной обработки больших наборов данных. Как и структура Центра Интернета вещей, рекомендованная выше, оптимальная структура каталога включает папки на родительском уровне для региона и прочего (например, организации, продукта или производителя). Эта структура помогает обеспечить безопасность данных в организации и оптимизировать управление данными в рабочих нагрузках. Кроме того, рассмотрите дату и время в структуре, чтобы обеспечить лучшую организацию, отфильтрованные поисковые запросы, безопасность и автоматизацию в процессе обработки. Уровень детализации структуры даты определяется интервалом, с которым данные загружаются или обрабатываются, например ежечасно, ежедневно или даже ежемесячно. 

Иногда обработка файлов завершается сбоем из-за повреждения данных или непредвиденных форматов. В таких случаях в структуре каталога целесообразно использовать папку **/bad**, чтобы перемещать в нее файлы для дальнейшей проверки. Пакетное задание также может обрабатывать отчет или уведомление об этих *недопустимых* файлах для устранения проблем вручную. Рассмотрите следующую структуру: 

    {Region}/{SubjectMatter(s)}/In/{yyyy}/{mm}/{dd}/{hh}/ 
    {Region}/{SubjectMatter(s)}/Out/{yyyy}/{mm}/{dd}/{hh}/ 
    {Region}/{SubjectMatter(s)}/Bad/{yyyy}/{mm}/{dd}/{hh}/ 

Например, маркетинговая фирма ежедневно получает извлечения данных клиентских обновлений от своих клиентов в Северной Америке. Она может выглядеть, как приведенный ниже фрагмент кода, перед обработкой и после нее: 

    NA/Extracts/ACMEPaperCo/In/2017/08/14/updates_08142017.csv 
    NA/Extracts/ACMEPaperCo/Out/2017/08/14/processed_updates_08142017.csv 
 
В общем случае пакетных данных, обрабатываемых непосредственно в таких базах данных, как Hive или традиционных базах данных SQL, нет необходимости в папке **/in** или **/out**, так как результаты уже выводятся в отдельную папку для таблицы Hive или внешней базы данных. Например, ежедневные извлечения данных от клиентов будут размещаться в их соответствующих папках, а при управлении с помощью фабрики данных Azure, Apache Oozie или Apache Airflow будет ежедневно выполняться задание Hive или Spark для обработки и записи данных в таблицу Hive.

## <a name="next-steps"></a>Дополнительная информация     

* [Обзор Azure Data Lake Store](data-lake-store-overview.md) 
* [Контроль доступа в Azure Data Lake Store](data-lake-store-access-control.md) 
* [Обеспечение безопасности в хранилище озера данных Azure](data-lake-store-security-overview.md)
* [Настройка Azure Data Lake Store для повышения производительности](data-lake-store-performance-tuning-guidance.md)
* [Рекомендации по настройке производительности для Spark в HDInsight и Azure Data Lake Store](data-lake-store-performance-tuning-spark.md)
* [Рекомендации по настройке производительности Hive в HDInsight и Azure Data Lake Store](data-lake-store-performance-tuning-hive.md)
* [Data Orchestration using Azure Data Factory for Azure Data Lake Store (Оркестрация данных с помощью фабрики данных Azure для хранилища озера данных Azure)](https://mix.office.com/watch/1oa7le7t2u4ka)
* [Создание кластеров HDInsight, использующих Data Lake Store, с помощью портала Azure](data-lake-store-hdinsight-hadoop-use-portal.md) 
