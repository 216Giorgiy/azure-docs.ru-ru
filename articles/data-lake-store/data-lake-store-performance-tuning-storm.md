---
title: "Рекомендации по настройке производительности для Storm в Azure Data Lake Store | Документация Майкрософт"
description: "Рекомендации по настройке производительности для Storm в Azure Data Lake Store"
services: data-lake-store
documentationcenter: 
author: stewu
manager: amitkul
editor: stewu
ms.assetid: ebde7b9f-2e51-4d43-b7ab-566417221335
ms.service: data-lake-store
ms.devlang: na
ms.topic: article
ms.tgt_pltfrm: na
ms.workload: big-data
ms.date: 12/19/2016
ms.author: stewu
translationtype: Human Translation
ms.sourcegitcommit: 518d586a921926874cd959587ad2730ad346df71
ms.openlocfilehash: cae3f0192d6b0e6204ede4c1855b731a2ffa4ae1


---
# <a name="performance-tuning-guidance-for-storm-on-hdinsight-and-azure-data-lake-store"></a>Рекомендации по настройке производительности для Storm в HDInsight и Azure Data Lake Store

Существует несколько факторов, которые необходимо учитывать при настройке производительности для топологии Storm.  Важно понять характеристики работы, выполняемой элементами spout и bolt (в случае, когда работа связана с интенсивными рабочими нагрузками ввода-вывода или активным использованием памяти).

## <a name="prerequisites"></a>Предварительные требования 

* **Подписка Azure**. Ознакомьтесь с [бесплатной пробной версией Azure](https://azure.microsoft.com/pricing/free-trial/). 
* **Учетная запись Azure Data Lake Store.** Инструкции по созданию учетной записи см. в статье [Начало работы с Azure Data Lake Store с помощью портала Azure](data-lake-store-get-started-portal.md). 
* **Кластер Azure HDInsight** с доступом к учетной записи Data Lake Store. См. статью [Создание кластера HDInsight с Data Lake Store с помощью портала Azure](data-lake-store-hdinsight-hadoop-use-portal.md). Убедитесь, что вы включили удаленный рабочий стол для кластера. 
* **Запущенный кластер Storm в Azure Data Lake Store.**  Дополнительные сведения см. в статье [Основные сведения об Apache Storm в службе HDInsight. Аналитика в реальном времени для Hadoop](https://docs.microsoft.com/en-us/azure/hdinsight/hdinsight-storm-overview). 
* **Рекомендации по настройке производительности в Azure Data Lake Store**.  См. [рекомендации по настройке производительности для Azure Data Lake Store](https://docs.microsoft.com/en-us/azure/data-lake-store/data-lake-store-performance-tuning-guidance).  

**Настройка параллелизма топологии**

Повысить производительность можно путем увеличения степени параллелизма операций ввода-вывода в и из Azure Data Lake Store.  
Топология Storm имеет набор конфигураций, которые определяют параллелизм:
* Количество рабочих процессов. Рабочие роли равномерно распределяются между виртуальными машинами.
* Количество экземпляров исполнителей воронки
* Количество экземпляров исполнителей сита
* Количество задач воронки
* количество задач элемента bolt.

Например, в кластере с 4 виртуальными машинами и 4 рабочими процессами есть 32 исполнителя элемента spout и 32 задачи элемента spout, 256 исполнителей элемента bolt и 512 задач элемента bolt.

Каждый супервизор, являющийся рабочим узлом, будет иметь один рабочий процесс виртуальной машины Java, который будет управлять 4 потоками spout и 64 потоками bolt. Внутри каждого потока задачи выполняются последовательно. В указанной выше конфигурации каждый поток spout будет иметь одну задачу, а каждый поток bolt — 2 задачи.

Ниже приведены различные компоненты для Storm и их влияние на итоговый уровень параллелизма.
* Головной узел (называемый в Storm Nimbus) используется для отправки заданий и управления ими. Эти узлы не оказывают влияния на степень параллелизма.
* Узел супервизора в Azure HDInsight соответствует виртуальной машине Azure рабочего узла.
* Рабочие задачи — это процессы Storm, выполняемые на виртуальных машинах. Каждая рабочая задача соответствует экземпляру виртуальной машины Java. Storm распределяет указанное число рабочих процессов между рабочими узлами максимально равномерно.
* Экземпляры исполнителей spout и bolt. Каждый экземпляр исполнителя соответствует потоку, который выполняется в рабочих процессах (на виртуальных машинах Java).
* Задачи Storm. Это логические задачи, которые выполняет каждый из потоков. Это не меняет уровень параллелизма, поэтому следует оценить, нужны ли вам несколько задач на каждый исполнитель.

## <a name="guidance"></a>Руководство

Чтобы достичь высокой производительности при работе с Azure Data Lake, можно сделать следующее.
* Объедините маленькие добавления в пакеты большего размера (в идеале по 4 МБ).
* Выполняйте максимально возможное количество одновременных запросов. Так как каждый поток элементов bolt блокирует возможность чтения, необходимо от 8 до 12 потоков на каждое ядро, что позволит эффективно использовать сетевой адаптер и ЦП.  Крупная виртуальная машина позволяет выполнять большее число параллельных запросов.  

## <a name="example"></a>Пример

Предположим, что у вас есть кластер из 8 рабочих узлов с виртуальной машиной D13v2 Azure.  Виртуальная машина D13v2 имеет 8 ядер, поэтому на 8 рабочих узлов приходится 64 ядра.

Предположим, что мы запускаем 8 потоков элементов bolt на ядро. Так как у нас есть 64 ядра, мы получаем 512 экземпляров исполнителей элемента bolt (т. е. потоков). Например, мы начинаем с одной виртуальной машины Java на каждую виртуальную машину и в основном используем параллелизм потоков внутри виртуальной машины Java для достижения параллелизма. Это означает, что нам нужно 8 рабочих задач (по одной на каждую виртуальную машину Azure) и 512 исполнителей элемента bolt. При такой конфигурации Storm попытается распределить рабочие процессы равномерно между рабочими узлами (так называемыми контрольными узлами), предоставляя каждому рабочему узлу одну виртуальную машину Java. Дальше Storm попытается распределить исполнители равномерно между контрольными узлами, предоставляя каждому узлу (т. е. виртуальной машине Java) по 8 потоков.

## <a name="further-tuning"></a>Дополнительные настройки
После построения базовой топологии можно решить, нужно ли настроить какие-либо из следующих параметров.
* **Число виртуальных машин Java на каждый рабочий узел.** При наличии большой структуры данных (например, таблицы подстановки), размещенной в памяти, каждой виртуальной машине Java требуется отдельная копия. При наличии меньшего числа виртуальных машин Java можно использовать структуру нескольких потоков. Для операций ввода-вывода элементов bolt количество виртуальных машин Java не так влияет на производительность, как число потоков на этих машинах. Для простоты рекомендуется использовать одну виртуальную машину Java для каждой рабочей роли. Количество, которое необходимо настроить, следует оценить исходя из того, что делает элемент bolt или какая обработка приложения требуется.
* **Количество исполнителей spout.** Так как в данном примере для записи в Azure Data Lake используются элементы bolt, количество элементов spout не связано непосредственно с производительностью элементов bolt. В зависимости от объема обработки или операций ввода-вывода в элементе spout для повышения производительности может понадобиться настроить эти элементы. В крайнем случае убедитесь, что имеется достаточно элементов spout, чтобы элементы bolt были заняты. То есть скорость вывода элементов spout должна соответствовать пропускной способности элементов bolt. Фактическая конфигурация будет зависеть от элемента spout и выходит за рамки данной статьи.
* **Число задач.** Каждый элемент bolt выполняется как один поток. Дополнительные задачи для каждого элемента bolt не обеспечивают дополнительный уровень параллелизма. Они могут обеспечить преимущество только в том случае, если на процесс подтверждения кортежа затрачивается большая часть времени выполнения элемента bolt. Рекомендуется группировать несколько кортежей в одно крупное добавление перед отправкой подтверждения от элемента bolt. В большинстве случаев несколько задач не дают дополнительных преимуществ.
* **Локальное группирование или группирование в случайном порядке.** При включении этого параметра кортежи отправляются в элементы bolt в одном рабочем процессе. Это уменьшает межпроцессное взаимодействие и количество сетевых вызовов. Мы рекомендуем использовать этот параметр для большинства топологий.

Рекомендуем начать с базового сценария и протестировать его, используя свои данные, чтобы настроить упомянутые выше параметры для достижения оптимальной производительности.

## <a name="tuning-the-spout"></a>Настройка элемента spout

**Время ожидания кортежа**

topology.message.timeout.sec — этот параметр определяет количество времени, в течение которого сообщение завершается и получает подтверждение, до того как начнет считаться завершившимся сбоем.

**Максимальный объем памяти для каждого рабочего процесса**

Worker.childopts — этот параметр позволяет указать дополнительные параметры командной строки для рабочих ролей Java. Наиболее часто используемый здесь параметр — XmX, который определяет максимальный объем памяти, выделенный для кучи виртуальных машин Java.

**Максимальное время ожидания элемента spout**

Topology.max.spout.Pending — эта конфигурация определяет число активных кортежей (еще не подтвержденных на всех узлах в топологии) для каждого потока элемента spout в любой момент времени.

Целесообразно оценить размер каждого кортежа и разобраться, сколько памяти выделяется для потока spout. Общий выделенный для потока объем памяти, разделенный на это значение, обозначит верхнюю границу параметра максимального времени ожидания элемента spout.

## <a name="tuning-the-bolt"></a>Настройка элемента bolt
При записи в ADLS рекомендуется назначить для политики размера синхронизации (буфер на стороне клиента) в 4 МБ.  Очистка или операция hsync() выполняется только в том случае, если размер буфера превышает это значение.  Драйвер ADLS на виртуальных машинах рабочих ролей автоматически выполняет эту буферизацию, если пользователь явно не выполняет операцию hsync().

По умолчанию bolt Storm в Azure Data Lake Store имеет параметр политики размера синхронизации (fileBufferSize), который можно использовать для настройки этого параметра.

В топологиях с интенсивным выполнением операций ввода-вывода для каждого потока bolt рекомендуется выполнять запись в отдельный файл и установить политику смены файлов (fileRotationSize).  Когда файл достигает определенного размера, поток автоматически очищается и выполняется запись в новый файл.  Рекомендуемый размер для смены составляет 1 ГБ.

**Когда подтверждать.** В Storm элемент spout держится за кортеж, пока он явным образом не подтверждается элементом bolt.  Если кортеж прочитан элементом bolt, но еще не подтвержден, это означает, что нет гарантии того, что элемент bolt сохранился в серверной части Azure Data Lake Store.  После подтверждения кортежа элемент bolt гарантированно сохраняет элемент spout и может удалить исходные данные из любого источника, откуда он считывает данные.  

**Обеспечение максимальной производительности в ADLS.** Для элемента bolt рекомендуется записывать в буфер 4 МБ данных кортежа, а затем записывать их в серверную часть ADLS как одну запись размером 4 МБ. После успешной записи данных в хранилище (путем вызова hflush()) элемент bolt может отправить подтверждение данных обратно элементу spout. Это выполняет приведенный здесь пример элемента bolt. Также допускается содержание большего количество кортежей, прежде чем будет выполнен вызов hflush() и кортежи подтвердятся. Однако это увеличивает число активных кортежей, которые должен удерживать элемент spout. Таким образом увеличивается объем памяти, необходимый для каждой виртуальной машины Java.

Приложениям может потребоваться выполнять подтверждение чаще (при размере данных меньше 4 МБ) по другим причинам, не связанным с производительностью. Это может повлиять на пропускную способность операций ввода-вывода к внутренней части хранилища, поэтому клиент должен тщательно оценить этот компромисс с точки зрения производительности операций ввода-вывода для элемента bolt.

Если скорости поступления кортежей не достаточно и буфер на 4 МБ заполняется долго, это можно исправить несколькими способами.
* Уменьшите количество элементов bolt, чтобы заполнялось меньше буферов на 4 МБ.
* Включите политику на основе времени или политику на основе количества, в которой операция hflush() запускается каждые x сбросов или каждые y миллисекунд, а уже накопленные кортежи подтверждаются.

Обратите внимание, что пропускная способность в этом случае будет меньше, хотя при низкой скорости событий максимальная пропускная способность не самое главное.  Описанные выше инструкции по устранению проблем позволят сократить общее время, необходимое кортежу для передачи в хранилище, что может быть важным, если требуется конвейер, работающий в режиме реального времени, несмотря на низкую скорость событий.  Обратите внимание, что в случае низкой скорости входящего кортежа можно также настроить параметр topology.message.timeout_secs таким образом, чтобы кортежи не простаивали, пока они буферизуются или обрабатываются.

## <a name="interpreting-storm-ui"></a>Интерпретация пользовательского интерфейса Storm  
Выполнение топологии можно отслеживать в пользовательском интерфейсе Storm. Ниже приведены основные параметры, на которые необходимо обратить внимание.

* **Общая задержка выполнения процесса** — это среднее время, за которое один кортеж отправляется элементом spout, обрабатывается элементом bolt и подтверждается.

* **Общая задержка обработки элемента bolt** — это среднее время, проведенное кортежем в элементе bolt до получения подтверждения.

* **Общая задержка обработки элемента bolt** — это среднее время, затраченное элементом bolt в методе execute.

* **Число сбоев** — это число кортежей, которые не удалось полностью обработать, прежде чем истекло время их ожидания.

* **Емкость** — это мера занятости вашей системы. Если это значение равно 1, элементы bolt работают с максимально возможной скоростью. Если это значение меньше 1, необходимо увеличить параллелизм. Если значение больше, уменьшите параллелизм.

## <a name="common-troubleshooting-scenarios"></a>Общие сценарии устранения неисправностей
* **Истекает время ожидания большого количество кортежей** — просмотрите каждый узел в топологии, чтобы определить, где находится узкое место. Наиболее распространенной причиной этого является неспособность элементов bolt справиться с элементами spout, что приводит к переполнению внутренних буферов кортежами, ожидающими обработки. Попробуйте увеличить значение времени ожидания или уменьшить максимальное время ожидания элемента spout.

* **Высокая общая задержка выполнения процесса при низкой задержке обработки элемента bolt** — в этом случае, возможно, кортежи обрабатываются недостаточно быстро. Убедитесь, что имеется достаточное количество элементов bolt типа acker. Второй вариант — кортежи ожидают в очереди слишком долго, прежде чем элементы bolt начинают их обрабатывать. Уменьшите максимальное время ожидания элемента spout.

* **Высокая задержка выполнения элемента bolt** — это означает, что метод execute() элемента bolt выполняется слишком долго. Оптимизируйте код или обратите внимание на поведение очистки записей и на размер блоков записи.

## <a name="limitation"></a>Ограничения 
Регулирование ADLS. Если вы превысили ограничения пропускной способности, предоставляемой ADLS, начнут происходить сбои задач. Это можно заметить, отслеживая ошибки регулирования в журналах задач.  Вы можете уменьшить параллелизм, увеличив размер контейнера.  Если для обработки задания требуется больший параллелизм, свяжитесь с нами.   
Чтобы проверить, применяется ли для вас регулирование, включите ведение журнала отладки на стороне клиента. Вот как это сделать.

1. Выберите в Ambari следующее: Storm > Config > Advanced storm-worker-log4j.  Изменение &lt;root level="info"&gt; на &lt;root level="debug"&gt;.  Перезапустите все узлы и службы, чтобы изменения конфигурации вступили в силу.
2. Отслеживайте журналы топологии рабочих узлов Storm (в разделе /var/log/storm/worker-artifacts/&lt;TopologyName&gt;/&lt;port&gt;/worker.log) на случай возникновения исключений регулирования ADLS.

## <a name="additional-tuning"></a>Дополнительная настройка
Сведения о дополнительных настройках производительности Storm см. в этом [блоге](https://blogs.msdn.microsoft.com/shanyu/2015/05/14/performance-tuning-for-hdinsight-storm-and-microsoft-azure-eventhubs/).

## <a name="examples-to-run"></a>Примеры выполнения кода
Ознакомьтесь с этим примером на [GitHub](https://github.com/hdinsight/storm-performance-automation).



<!--HONumber=Feb17_HO2-->


