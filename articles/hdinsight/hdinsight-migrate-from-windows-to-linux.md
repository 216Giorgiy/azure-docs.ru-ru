---
title: "Миграция из кластера HDInsight под управлением Windows на кластер HDInsight под управлением Linux | Документация Майкрософт"
description: "Узнайте, как выполнить миграцию из кластера HDInsight под управлением Windows на кластер HDInsight под управлением Linux."
services: hdinsight
documentationcenter: 
author: Blackmist
manager: jhubbard
editor: cgronlun
ms.assetid: ff35be59-bae3-42fd-9edc-77f0041bab93
ms.service: hdinsight
ms.devlang: na
ms.topic: article
ms.tgt_pltfrm: na
ms.workload: big-data
ms.date: 01/13/2017
ms.author: larryfr
translationtype: Human Translation
ms.sourcegitcommit: a4d30ffc0a5c5ef9fe7bb892d17f0859ff27f569
ms.openlocfilehash: bf6ef38ba28d11d7894a30115174582903f84580
ms.lasthandoff: 03/02/2017


---
# <a name="migrate-from-a-windows-based-hdinsight-cluster-to-a-linux-based-cluster"></a>Миграция из кластера HDInsight под управлением Windows на кластер под управлением Linux
Хотя HDInsight на основе Windows упрощает использование Hadoop в облаке, вам может потребоваться перейти на кластер под управлением Linux. Например, чтобы воспользоваться преимуществами инструментов и технологий на основе Linux, которые необходимы для вашего решения. Многие компоненты в экосистеме Hadoop разрабатываются в системах под управлением Linux, и они могут быть недоступны в HDInsight под управлением Windows. Кроме того, во многих книгах, видеороликах и других учебных материалах предполагается, что при работе с Hadoop вы используете Linux.

Этот документ содержит сведения о различиях между HDInsight в Windows и Linux и руководство по миграции существующих рабочих нагрузок на кластер под управлением Linux.

> [!NOTE]
> В кластерах HDInsight в качестве операционной системы узлов используется Ubuntu Long Term Support (LTS). Сведения о версии Ubuntu с поддержкой HDInsight, а также другие сведения об управлении версиями компонента см. в описании [версий компонента HDInsight](hdinsight-component-versioning.md).

## <a name="migration-tasks"></a>Задачи миграции
Общий рабочий процесс для миграции выглядит следующим образом.

![Схема рабочего процесса миграции](./media/hdinsight-migrate-from-windows-to-linux/workflow.png)

1. Прочитайте каждый раздел этого документа, чтобы понять, какие изменения могут потребоваться для миграции существующего рабочего процесса, заданий и т. д. на кластер под управлением Linux.
2. Создайте кластер под управлением Linux как среду тестирования и контроля качества. Дополнительные сведения о создании кластера под управлением Linux см. в статье [Создание кластеров под управлением Linux в HDInsight](hdinsight-hadoop-provision-linux-clusters.md).
3. Скопируйте в новую среду существующие задания, источники данных и приемники.
4. Выполните проверочное тестирование, чтобы убедиться, что задания должным образом работают новом кластере.

Убедившись, что все работает правильно, запланируйте время простоя для миграции. Во время этого простоя выполните следующие действия.

1. Создайте резервную копию всех временных данных, хранящихся локально на узлах кластера. Например, к ним могут относиться данные, которые хранятся непосредственно на головном узле.
2. Удалите кластер под управлением Windows.
3. Создайте кластер под управлением Linux, используя то же хранилище данных по умолчанию, которое использовалось кластером под управлением Windows. Новый кластер может продолжить работу с существующими рабочими данными.
4. Импортируйте все временные данные из резервной копии.
5. Запустите задания и продолжите обработку с помощью нового кластера.

### <a name="copy-data-to-the-test-environment"></a>Копирование данных в среду тестирования
Существует множество методов для копирования данных и заданий. В этом разделе рассматриваются два простейших метода перемещения файлов непосредственно в кластер тестирования.

#### <a name="hdfs-dfs-copy"></a>Копирование с помощью команды HDFS DFS

Чтобы скопировать данные из рабочего кластера в тестовый кластер, выполните приведенные ниже действия. Для их выполнения используется служебная программа `hdfs dfs`, которая входит в состав HDInsight.

1. Определите учетную запись хранения и контейнер по умолчанию для существующего кластера. В следующем примере для извлечения этой информации используется PowerShell.

    ```powershell
    $clusterName="Your existing HDInsight cluster name"
    $clusterInfo = Get-AzureRmHDInsightCluster -ClusterName $clusterName
    write-host "Storage account name: $clusterInfo.DefaultStorageAccount.split('.')[0]"
    write-host "Default container: $clusterInfo.DefaultStorageContainer"
    ```

2. Чтобы создать среду тестирования, выполните действия, описанные в документе "Создание кластеров под управлением Linux в HDInsight". Остановитесь перед созданием кластера и вместо этого выберите **Необязательная конфигурация**.
3. В колонке "Необязательная конфигурация" выберите **Связанные учетные записи хранения**.
4. Выберите **Добавить ключ к хранилищу данных**и при появлении запроса выберите учетную запись хранения, которая была определена с помощью сценария PowerShell на шаге 1. Щелкните **Выбрать** на каждой колонке. Наконец, создайте кластер.
5. После создания кластера подключитесь к нему с помощью протокола **SSH**. Если вы не знакомы с использованием SSH c HDInsight, ознакомьтесь с одним из следующих документов:

   * [Использование SSH с HDInsight (Hadoop) в PuTTY на базе Windows](hdinsight-hadoop-linux-use-ssh-windows.md)
   * [Использование SSH с HDInsight (Hadoop) из Bash на платформе Windows 10, Linux, Unix или OS X](hdinsight-hadoop-linux-use-ssh-unix.md)

6. В сеансе SSH используйте следующую команду для копирования файлов из связанной учетной записи хранения в новую учетную запись хранения по умолчанию. Замените CONTAINER данными контейнера, возвращенными PowerShell. Замените __ACCOUNT__ именем учетной записи. Замените путь к данным на путь к файлу данных.

        hdfs dfs -cp wasbs://CONTAINER@ACCOUNT.blob.core.windows.net/path/to/old/data /path/to/new/location

    > [!NOTE]
    > Если структура каталогов, которая содержит данные, не существует в тестовой среде, ее можно создать с помощью следующей команды.

        hdfs dfs -mkdir -p /new/path/to/create

    При указании параметра `-p` будут созданы все каталоги в пути.

#### <a name="direct-copy-between-azure-storage-blobs"></a>Прямое копирование между большими двоичными объектами хранилища Azure
При желании также можно использовать командлет Azure PowerShell `Start-AzureStorageBlobCopy`, чтобы скопировать большие двоичные объекты между учетными записями хранения вне HDInsight. Дополнительные сведения см. в разделе "Управление большими двоичными объектами Azure" статьи "Использование Azure PowerShell с хранилищем Azure".

## <a name="client-side-technologies"></a>Технологии на стороне клиента
В общем случае клиентские технологии, такие как [командлеты Azure PowerShell](/powershell/azureps-cmdlets-docs), [Azure CLI](../xplat-cli-install.md) или [пакет SDK .NET для Hadoop](https://hadoopsdk.codeplex.com/), продолжат работать точно так же в кластерах под управлением Linux, так как они используют интерфейсы REST API, которые одинаковы для обоих типов ОС кластеров.

## <a name="server-side-technologies"></a>Технологии на стороне сервера
В следующей таблице приведены рекомендации по миграции серверных компонентов, которые являются специфичными для Windows.

| Если вы используете эту технологию... | Выполните это действие... |
| --- | --- |
| **PowerShell** (сценарии на стороне сервера, включая действия сценариев, используемые во время создания кластера) |Перепишите эти сценарии как скрипты Bash. Сведения о действиях сценариев см. в разделах [Настройка кластеров HDInsight под управлением Linux с помощью действия сценария](hdinsight-hadoop-customize-cluster-linux.md) и [Разработка действий сценариев с помощью HDInsight](hdinsight-hadoop-script-actions-linux.md). |
| **Azure CLI** (сценарии на стороне сервера) |Хотя интерфейс командной строки Azure доступен в Linux, он не предустановлен на головных узлах кластера HDInsight. Если он необходим для создания сценариев на стороне сервера, обратитесь к разделу [Установка Azure CLI](../xplat-cli-install.md) для получения сведений об установке Azure CLI на платформах под управлением Linux. |
| **Компоненты .NET** |.NET не поддерживается полностью в кластерах HDInsight под управлением Linux. В кластерах Storm в HDInsight под управлением Linux, созданных после 28 октября 2016 года, предусмотрена поддержка топологий Storm на C# при помощи платформы SCP.NET. Дополнительная поддержка .NET будет добавлена в будущих обновлениях. |
| **Компоненты Win32 или другая технология, которая существует только для Windows** |Точные действия зависят от компонента или технологии. Возможно, вам удастся найти версию, которая совместима с Linux; возможно, потребуется найти альтернативное решение или переписать этот компонент. |

## <a name="cluster-creation"></a>Создание кластера
В этом разделе приведены сведения о различиях при создании кластера.

### <a name="ssh-user"></a>Пользователь SSH
Кластеры HDInsight под управлением Linux используют протокол **Secure Shell (SSH)** для предоставления удаленного доступа к узлам кластера. В отличие от удаленного рабочего стола для кластеров Windows, большинство клиентов SSH предоставляет не графический пользовательский интерфейс, а командную строку, которая позволяет выполнять команды в кластере. Некоторые клиенты (например, [MobaXterm](http://mobaxterm.mobatek.net/)) в дополнение к удаленной командной строке предоставляют графический проводник файловой системы.

Во время создания кластера необходимо указать имя пользователя SSH и **пароль** или **сертификат открытого ключа** для аутентификации.

Мы рекомендуем использовать сертификат открытого ключа, так как он более безопасен по сравнению с паролем. При использовании сертификата создается пара подписанных ключей (открытый и закрытый), после чего открытый ключ указывается при создании кластера. При подключении к серверу с помощью SSH проверка подлинности подключения выполняется с помощью закрытого ключа на клиентском компьютере.

Дополнительные сведения об использовании SSH с HDInsight см. в следующих статьях:

* [Использование SSH с HDInsight из клиентов Windows](hdinsight-hadoop-linux-use-ssh-windows.md)
* [Использование SSH с HDInsight из клиентов Linux, Unix и OS X](hdinsight-hadoop-linux-use-ssh-unix.md)

### <a name="cluster-customization"></a>Настройка кластера
**Действия сценария**, используемые в кластерах под управлением Linux, должны быть записаны в сценарий Bash. Действия сценариев можно использовать не только во время создания кластера, но и для настройки после запуска кластера (для кластеров под управлением Linux). Дополнительные сведения см. в разделах [Настройка кластеров HDInsight под управлением Linux с помощью действия сценария](hdinsight-hadoop-customize-cluster-linux.md) и [Разработка действий сценариев с помощью HDInsight](hdinsight-hadoop-script-actions-linux.md).

Еще одна возможность настройки — **начальная загрузка**. Для кластеров Windows эта функция позволяет указать расположение дополнительных библиотек для использования с Hive. После создания кластера эти библиотеки автоматически становятся доступными для Hive без необходимости использования `ADD JAR`.

Для кластеров под управлением Linux функция начальной загрузки не предоставляет такой возможности. Вместо этого используйте действие сценария, указанное в статье [Добавление библиотек Hive во время создания кластера HDInsight](hdinsight-hadoop-add-hive-libraries.md).

### <a name="virtual-networks"></a>Виртуальные сети
Кластеры HDInsight под управлением Windows работают только с классическими виртуальными сетями, а для кластеров HDInsight под управлением Linux требуются виртуальные сети Resource Manager. Если в классической виртуальной сети имеются ресурсы, к которым должен подключаться кластер HDInsight под управлением Linux, обратитесь к разделу [Подключение классических виртуальных сетей к новым виртуальным сетям](../vpn-gateway/vpn-gateway-connect-different-deployment-models-portal.md).

Дополнительные сведения о требованиях к конфигурации при использовании виртуальных сетей Azure в HDInsight см. в статье [Расширение возможностей HDInsight с помощью виртуальной сети Azure](hdinsight-extend-hadoop-virtual-network.md).

## <a name="management-and-monitoring"></a>Управление и мониторинг
Многие веб-интерфейсы, которыми вы могли пользоваться в HDInsight под управлением Windows, например журнал заданий или пользовательский интерфейс Yarn, доступны в Ambari. Кроме того, представление Hive Ambari позволяет выполнять запросы Hive с помощью веб-браузера. Пользовательский веб-интерфейс Ambari доступен в кластерах HDInsight на платформе Linux по адресу: https://CLUSTERNAME.azurehdinsight.net.

Дополнительные сведения о работе с Ambari см. в следующих документах:

* [Веб-интерфейс Ambari](hdinsight-hadoop-manage-ambari.md)
* [Ambari REST API](hdinsight-hadoop-manage-ambari-rest-api.md)

### <a name="ambari-alerts"></a>Предупреждения Ambari
Ambari имеет систему предупреждений, которые могут сообщить вам о возможных проблемах с кластером. Предупреждения выделяются красным или желтым цветом в веб-интерфейсе Ambari. Их также можно получить с помощью интерфейса API REST.

> [!IMPORTANT]
> Предупреждения Ambari указывают на то, что проблема *возможна*, а не на то, что она уже *присутствует*. Например, может появиться предупреждение о том, что сервер HiveServer2 недоступен. При этом вы можете обратиться к нему обычным образом.
>
> Многие предупреждения реализованы в качестве запросов к службе и ожидают ответа в течение определенного промежутка времени. Поэтому предупреждение не обязательно означает, что служба не работает — оно означает лишь то, что служба не возвратила результаты в течение ожидаемого интервала времени.

В общем случае перед выполнением каких-либо действий с оповещением следует оценить, появлялось ли оно в течение продолжительного периода времени или отражает проблемы в работе пользователей, о которых уже сообщалось.

## <a name="file-system-locations"></a>Структура файловой системы
Для кластеров под управлением Linux структура файловой системы отличается от кластеров HDInsight под управлением Windows. Используйте следующую таблицу для поиска часто используемых файлов.

| Необходимо найти... | Это находится в папке... |
| --- | --- |
| Конфигурация |`/etc`. Например, `/etc/hadoop/conf/core-site.xml` |
| Файлы журналов |`/var/logs` |
| Платформа данных Hortonworks Data Platform (HDP) |`/usr/hdp`. Здесь расположены два каталога — каталог с текущей версией HDP и каталог `current`. Каталог `current` содержит символьные ссылки на файлы и папки, размещенные в каталоге номера версии. Каталог `current` предоставляется для удобного доступа к файлам HDP, так как при обновлении версии HDP номер версии меняется. |
| hadoop-streaming.jar |`/usr/hdp/current/hadoop-mapreduce-client/hadoop-streaming.jar` |

В общем случае, если вам известно имя файла, можно выполнить следующую команду в сеансе SSH, чтобы определить путь к файлу:

    find / -name FILENAME 2>/dev/null

В имени файла также можно использовать подстановочные знаки. Например, `find / -name *streaming*.jar 2>/dev/null` возвращает путь ко всем JAR-файлам, содержащим слово streaming в имени файла.

## <a name="hive-pig-and-mapreduce"></a>Hive, Pig и MapReduce

Рабочие нагрузки Pig и MapReduce на кластерах под управлением Linux очень похожи. Единственное отличие заключается в подключении к головным узлам кластера. Дополнительные сведения см. в следующих документах:

* [Использование Pig с SSH](hdinsight-hadoop-use-pig-ssh.md)
* [Использование MapReduce с SSH](hdinsight-hadoop-use-mapreduce-ssh.md)

### <a name="hive"></a>Hive
Следующая схема содержит рекомендации по переносу рабочих нагрузок Hive.

| В кластерах под управлением Windows я пользуюсь... | В кластерах под управлением Linux... |
| --- | --- |
| **редактор Hive;** |[используйте представление Hive в Ambari](hdinsight-hadoop-use-hive-ambari-view.md) |
| `set hive.execution.engine=tez;` для включения Tez. |Tez — ядро выполнения по умолчанию для кластеров под управлением Linux, поэтому инструкция set больше не требуется. |
| CMD-файлами или сценариями на сервере, вызываемыми как часть задания Hive |используйте скрипты Bash |
| `hive` из удаленного рабочего стола. |используйте [Beeline](hdinsight-hadoop-use-hive-beeline.md) или [Hive из сеанса SSH](hdinsight-hadoop-use-hive-ssh.md). |

## <a name="storm"></a>Storm
| В кластерах под управлением Windows я пользуюсь... | В кластерах под управлением Linux... |
| --- | --- |
| Панель мониторинга Storm |Панель мониторинга Storm недоступна. Сведения об отправке топологий приведены в разделе [Развертывание и управление топологиями Storm в HDInsight под управлением Linux](hdinsight-storm-deploy-monitor-topology-linux.md) . |
| Пользовательский интерфейс Storm |Пользовательский интерфейс Storm доступен по адресу https://<имя_кластера>.azurehdinsight.net/stormui. |
| Visual Studio для создания, развертывания и управления C# или гибридными топологиями |Visual Studio можно использовать для создания, развертывания и управления топологиями C# (SCP.NET) или гибридными топологиями в кластерах Storm в HDInsight под управлением Linux, созданных после 28 октября 2016 года. |

## <a name="hbase"></a>HBase
На кластерах под управлением Linux родительским Z-узлом для HBase является `/hbase-unsecure`. Задайте это значение в конфигурации для всех клиентских приложений Java, которые используют собственный API Java для HBase.

Пример клиента, который устанавливает это значение, см. в разделе [Использование Maven для сборки приложений Java, которые используют HBase с HDInsight (Hadoop)](hdinsight-hbase-build-java-maven.md).

## <a name="spark"></a>Spark
Кластеры Spark были доступны в кластерах Windows на этапе предварительной версии. Общедоступная версия Spark доступна только в кластерах Linux. Способа миграции кластера Spark под управлением Windows в предварительной версии в кластер Spark под управлением Linux основной версии не существует.

## <a name="known-issues"></a>Известные проблемы
### <a name="azure-data-factory-custom-net-activities"></a>Пользовательские действия .NET фабрики данных Azure
Пользовательские действия .NET фабрики данных Azure в настоящее время не поддерживаются в кластерах HDInsight под управлением Linux. Вместо этого следует использовать один из следующих методов для реализации пользовательских действий в рамках конвейера ADF.

* Выполните действия .NET в пуле пакетной службы Azure. Ознакомьтесь с разделом "Использование связанной пакетной службы Azure" статьи [Использование настраиваемых действий в конвейере фабрики данных Azure](../data-factory/data-factory-use-custom-activities.md).
* Реализуйте действие как действие MapReduce. Дополнительные сведения см. в разделе [Вызов программы MapReduce из фабрики данных](../data-factory/data-factory-map-reduce.md).

### <a name="line-endings"></a>Символы конца строки
Как правило, в качестве символов конца строки в Windows используется CRLF, а в Linux — LF. Если вы формируете или ожидаете получить данные с символами конца строки CRLF, может потребоваться изменить производителей или потребителей данных для работы с символами конца строки LF.

Например, при выполнении запроса к HDInsight с использованием Azure PowerShell в кластере под управлением Windows будут возвращены данные с символами конца строки CRLF. Тот же запрос к кластеру под управлением Linux возвратит данные с символами конца строки LF. Вы должны проверить, вызывает ли это ошибки в работе решения, прежде чем переходить на кластер под управлением Linux.

Если у вас есть сценарии, выполняемые непосредственно на узлах кластера Linux, следует всегда использовать символы конца строки LF. Если использовать CRLF, могут возникнуть ошибки при выполнении сценариев в кластере под управлением Linux.

Если вы знаете, что в сценариях нет строк, содержащих символы CR, можно выполнить массовую замену символов конца строк с помощью одного из следующих методов:

* **При наличии сценариев, которые планируется передать в кластер**, используйте следующие инструкции PowerShell для замены символов конца строк с CRLF на LF перед отправкой сценариев в кластер.

      $original_file ='c:\path\to\script.py'
      $text = [IO.File]::ReadAllText($original_file) -replace "`r`n", "`n"
      [IO.File]::WriteAllText($original_file, $text)
* **При наличии сценариев, которые уже находятся в хранилище кластера**, для изменения сценария можно использовать следующую команду в сеансе SSH в кластерах под управлением Linux.

      hdfs dfs -get wasbs:///path/to/script.py oldscript.py
      tr -d '\r' < oldscript.py > script.py
      hdfs dfs -put -f script.py wasbs:///path/to/script.py

## <a name="next-steps"></a>Дальнейшие действия
* [Узнайте, как создавать кластеры HDInsight под управлением Linux](hdinsight-hadoop-provision-linux-clusters.md)
* [Подключитесь к кластеру под управлением Linux с помощью SSH из клиента Windows](hdinsight-hadoop-linux-use-ssh-windows.md)
* [Подключитесь к кластеру под управлением Linux с помощью SSH из клиента Linux, Unix или Mac](hdinsight-hadoop-linux-use-ssh-unix.md)
* [Выполняйте управление кластером под управлением Linux с помощью Ambari](hdinsight-hadoop-manage-ambari.md)

