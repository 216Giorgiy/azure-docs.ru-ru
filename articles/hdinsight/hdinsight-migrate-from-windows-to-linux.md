---
title: "Миграция из кластера HDInsight под управлением Windows на кластер HDInsight под управлением Linux | Документация Майкрософт"
description: "Узнайте, как выполнить миграцию из кластера HDInsight под управлением Windows на кластер HDInsight под управлением Linux."
services: hdinsight
documentationcenter: 
author: Blackmist
manager: jhubbard
editor: cgronlun
ms.assetid: ff35be59-bae3-42fd-9edc-77f0041bab93
ms.service: hdinsight
ms.devlang: na
ms.topic: article
ms.tgt_pltfrm: na
ms.workload: big-data
ms.date: 10/28/2016
ms.author: larryfr
translationtype: Human Translation
ms.sourcegitcommit: 8a7ca492d846f274019eb228fc027defac0aa390
ms.openlocfilehash: ae954da8c71e6fcc67941919851ea67b825c54d0


---
# <a name="migrate-from-a-windows-based-hdinsight-cluster-to-a-linux-based-cluster"></a>Миграция из кластера HDInsight под управлением Windows на кластер под управлением Linux
Хотя кластер HDInsight под управлением Windows позволяет удобно использовать Hadoop в облаке, вы можете обнаружить, что вам необходим кластер под управлением Linux, чтобы воспользоваться средствами и технологиями, которые необходимы для вашего решения. Многие компоненты в экосистеме Hadoop разрабатываются в системах под управлением Linux, а некоторые могут быть и вовсе недоступны в HDInsight под управлением Windows. Кроме того, во многих книгах, видеороликах и других учебных материалах предполагается, что при работе с Hadoop вы используете Linux.

Этот документ содержит сведения о различиях между HDInsight в Windows и Linux и руководство по миграции существующих рабочих нагрузок на кластер под управлением Linux.

> [!NOTE]
> В кластерах HDInsight в качестве операционной системы для узлов в кластере используется Ubuntu Long Term Support (LTS). Сведения о версии Ubuntu с поддержкой HDInsight, а также другие сведения об управлении версиями компонента см. в описании [версий компонента HDInsight](hdinsight-component-versioning.md).

## <a name="migration-tasks"></a>Задачи миграции
Общий рабочий процесс для миграции выглядит следующим образом.

![Схема рабочего процесса миграции](./media/hdinsight-migrate-from-windows-to-linux/workflow.png)

1. Прочитайте каждый раздел этого документа, чтобы понять, какие изменения могут потребоваться для миграции существующего рабочего процесса, заданий и т. д. на кластер под управлением Linux.
2. Создайте кластер под управлением Linux как среду тестирования и контроля качества. Дополнительные сведения о создании кластера под управлением Linux см. в статье [Создание кластеров под управлением Linux в HDInsight](hdinsight-hadoop-provision-linux-clusters.md).
3. Скопируйте существующие задания, источники данных и приемники в новую среду. Дополнительные сведения см. в разделе "Копирование данных в среду тестирования".
4. Выполните проверочное тестирование, чтобы убедиться, что задания должным образом работают новом кластере.

Убедившись, что все работает правильно, запланируйте время простоя для миграции. Во время этого простоя выполните следующие действия.

1. Создайте резервную копию всех временных данных, хранящихся локально на узлах кластера. Например, к ним могут относиться данные, которые хранятся непосредственно на головном узле.
2. Удалите кластер под управлением Windows.
3. Создайте кластер под управлением Linux, используя то же хранилище данных по умолчанию, которое использовалось кластером под управлением Windows. Это позволит новому кластеру продолжить работу с существующими рабочими данными.
4. Импортируйте все временные данные из резервной копии.
5. Запустите задания и продолжите обработку с помощью нового кластера.

### <a name="copy-data-to-the-test-environment"></a>Копирование данных в среду тестирования
Существует множество методов для копирования данных и заданий. В этом разделе рассматриваются два простейших метода перемещения файлов непосредственно в кластер тестирования.

#### <a name="hdfs-dfs-copy"></a>Копирование с помощью команды HDFS DFS
С помощью команды HDFS Hadoop можно скопировать данные из хранилища для существующего рабочего кластера непосредственного в хранилище нового кластера тестирования. Для этого выполните следующие действия.

1. Определите учетную запись хранения и контейнер по умолчанию для существующего кластера. Это можно сделать с помощью следующего сценария Azure PowerShell.

    ```powershell
    $clusterName="Your existing HDInsight cluster name"
    $clusterInfo = Get-AzureRmHDInsightCluster -ClusterName $clusterName
    write-host "Storage account name: $clusterInfo.DefaultStorageAccount.split('.')[0]"
    write-host "Default container: $clusterInfo.DefaultStorageContainer"
    ```

2. Выполните действия, описанные в документе "Создание кластеров под управлением Linux в HDInsight", чтобы создать новую среду тестирования. Остановитесь перед созданием кластера и вместо этого выберите **Необязательная конфигурация**.
3. В колонке "Необязательная конфигурация" выберите **Связанные учетные записи хранения**.
4. Выберите **Добавить ключ к хранилищу данных**и при появлении запроса выберите учетную запись хранения, которая была определена с помощью сценария PowerShell на шаге 1. Щелкните **Выбрать** на каждой колонке, чтобы закрыть ее. Наконец, создайте кластер.
5. После создания кластера подключитесь к нему с помощью протокола **SSH**. Если вы не знакомы с использованием SSH c HDInsight, обратитесь к одной из следующих статей.

   * [Использование SSH с HDInsight под управлением Linux из клиентов Windows](hdinsight-hadoop-linux-use-ssh-windows.md)
   * [Использование SSH с HDInsight под управлением Linux из клиентов Linux, Unix и Mac](hdinsight-hadoop-linux-use-ssh-unix.md)
6. В сеансе SSH используйте следующую команду для копирования файлов из связанной учетной записи хранения в новую учетную запись хранения по умолчанию. Замените CONTAINER и ACCOUNT на контейнер и учетную запись, которые были определены с помощью сценария PowerShell на шаге 1. Замените путь к данным на путь к файлу данных.

        hdfs dfs -cp wasbs://CONTAINER@ACCOUNT.blob.core.windows.net/path/to/old/data /path/to/new/location

    > [!NOTE]
    > Если структура каталогов, которая содержит данные, не существует в тестовой среде, ее можно создать с помощью следующей команды.

        hdfs dfs -mkdir -p /new/path/to/create

    При указании параметра `-p` будут созданы все каталоги в пути.

#### <a name="direct-copy-between-azure-storage-blobs"></a>Прямое копирование между большими двоичными объектами хранилища Azure
При желании также можно использовать командлет Azure PowerShell `Start-AzureStorageBlobCopy`, чтобы скопировать большие двоичные объекты между учетными записями хранения вне HDInsight. Дополнительные сведения см. в разделе "Управление большими двоичными объектами Azure" статьи "Использование Azure PowerShell с хранилищем Azure".

## <a name="client-side-technologies"></a>Технологии на стороне клиента
В общем случае клиентские технологии, такие как [командлеты Azure PowerShell](/powershell/azureps-cmdlets-docs), [Azure CLI](../xplat-cli-install.md) или [пакет SDK .NET для Hadoop](https://hadoopsdk.codeplex.com/), продолжат работать точно так же в кластерах под управлением Linux, так как они используют интерфейсы REST API, которые одинаковы для обоих типов ОС кластеров.

## <a name="server-side-technologies"></a>Технологии на стороне сервера
В следующей таблице приведены рекомендации по миграции серверных компонентов, которые являются специфичными для Windows.

| Если вы используете эту технологию... | Выполните это действие... |
| --- | --- |
| **PowerShell** (сценарии на стороне сервера, включая действия сценариев, используемые во время создания кластера) |Перепишите эти сценарии как скрипты Bash. Сведения о действиях сценариев см. в разделах [Настройка кластеров HDInsight под управлением Linux с помощью действия сценария](hdinsight-hadoop-customize-cluster-linux.md) и [Разработка действий сценариев с помощью HDInsight](hdinsight-hadoop-script-actions-linux.md). |
| **Azure CLI** (сценарии на стороне сервера) |Хотя интерфейс командной строки Azure доступен в Linux, он не предустановлен на головных узлах кластера HDInsight. Если он необходим для создания сценариев на стороне сервера, обратитесь к разделу [Установка Azure CLI](../xplat-cli-install.md) для получения сведений об установке Azure CLI на платформах под управлением Linux. |
| **Компоненты .NET** |.NET не поддерживается полностью в кластерах HDInsight под управлением Linux. В кластерах Storm в HDInsight под управлением Linux, созданных после 28 октября 2017 года, предусмотрена поддержка топологий Storm на C# при помощи платформы SCP.NET. Дополнительная поддержка .NET будет добавлена в будущих обновлениях. |
| **Компоненты Win32 или другая технология, которая существует только для Windows** |Точные действия зависят от компонента или технологии. Возможно, вам удастся найти версию, которая совместима с Linux; возможно, потребуется найти альтернативное решение или переписать этот компонент. |

## <a name="cluster-creation"></a>Создание кластера
В этом разделе приведены сведения о различиях при создании кластера.

### <a name="ssh-user"></a>Пользователь SSH
Кластеры HDInsight под управлением Linux используют протокол **Secure Shell (SSH)** для предоставления удаленного доступа к узлам кластера. В отличие от удаленного рабочего стола для кластеров Windows, большинство клиентов SSH предоставляют не графический пользовательский интерфейс, а командную строку, которая позволяет выполнять команды в кластере. Некоторые клиенты (например, [MobaXterm](http://mobaxterm.mobatek.net/)) в дополнение к удаленной командной строке предоставляют графический проводник файловой системы.

Во время создания кластера необходимо указать имя пользователя SSH и **пароль** или **сертификат открытого ключа** для аутентификации.

Мы рекомендуем использовать сертификат открытого ключа, так как он более безопасен по сравнению с паролем. При использовании сертификата создается пара подписанных ключей (открытый и закрытый), после чего открытый ключ указывается при создании кластера. При подключении к серверу с помощью SSH проверка подлинности подключения выполняется с помощью закрытого ключа на клиентском компьютере.

Дополнительные сведения об использовании SSH с HDInsight см. в следующих статьях:

* [Использование SSH с HDInsight из клиентов Windows](hdinsight-hadoop-linux-use-ssh-windows.md)
* [Использование SSH с HDInsight из клиентов Linux, Unix и OS X](hdinsight-hadoop-linux-use-ssh-unix.md)

### <a name="cluster-customization"></a>Настройка кластера
**Действия сценария**, используемые в кластерах под управлением Linux, должны быть записаны в сценарий Bash. Действия сценариев можно использовать не только во время создания кластера, но и для настройки после запуска кластера (для кластеров под управлением Linux). Дополнительные сведения см. в разделах [Настройка кластеров HDInsight под управлением Linux с помощью действия сценария](hdinsight-hadoop-customize-cluster-linux.md) и [Разработка действий сценариев с помощью HDInsight](hdinsight-hadoop-script-actions-linux.md).

Еще одна возможность настройки — **начальная загрузка**. Для кластеров Windows она позволяет указать расположение дополнительных библиотек для использования с Hive. После создания кластера эти библиотеки автоматически становятся доступными для Hive без необходимости использования `ADD JAR`.

Для кластеров под управлением Linux начальная загрузка не предоставляет такой возможности. Вместо этого используйте действие сценария, указанное в статье [Добавление библиотек Hive во время создания кластера HDInsight](hdinsight-hadoop-add-hive-libraries.md).

### <a name="virtual-networks"></a>Виртуальные сети
Кластеры HDInsight под управлением Windows работают только с классическими виртуальными сетями, а для кластеров HDInsight под управлением Linux требуются виртуальные сети Resource Manager. Если в классической виртуальной сети имеются ресурсы, к которым должен подключаться кластер HDInsight под управлением Linux, обратитесь к разделу [Подключение классических виртуальных сетей к новым виртуальным сетям](../vpn-gateway/vpn-gateway-connect-different-deployment-models-portal.md).

Дополнительные сведения о требованиях к конфигурации при использовании виртуальных сетей Azure в HDInsight см. в статье [Расширение возможностей HDInsight с помощью виртуальной сети Azure](hdinsight-extend-hadoop-virtual-network.md).

## <a name="management-and-monitoring"></a>Управление и мониторинг
Многие веб-интерфейсы, которыми вы могли пользоваться в HDInsight под управлением Windows, например журнал заданий или пользовательский интерфейс Yarn, доступны в Ambari. Кроме того, представление Hive Ambari позволяет выполнять запросы Hive с помощью веб-браузера. Пользовательский веб-интерфейс Ambari доступен в кластерах HDInsight на платформе Linux по адресу: https://<имя_кластера>.azurehdinsight.net.

Дополнительные сведения о работе с Ambari см. в следующих документах:

* [Веб-интерфейс Ambari](hdinsight-hadoop-manage-ambari.md)
* [Ambari REST API](hdinsight-hadoop-manage-ambari-rest-api.md)

### <a name="ambari-alerts"></a>Предупреждения Ambari
Ambari имеет систему предупреждений, которые могут сообщить вам о возможных проблемах с кластером. Предупреждения выделяются красным или желтым цветом в веб-интерфейсе Ambari. Их также можно получить с помощью интерфейса API REST.

> [!IMPORTANT]
> Предупреждения Ambari указывают на то, что проблема *возможна*, а не на то, что она уже *присутствует*. Например, может появиться предупреждение о том, что сервер HiveServer2 недоступен. При этом вы можете обратиться к нему обычным образом.
>
> Многие предупреждения реализованы в качестве запросов к службе и ожидают ответа в течение определенного промежутка времени. Поэтому предупреждение не обязательно означает, что служба не работает — оно означает лишь то, что служба не возвратила результаты в течение ожидаемого интервала времени.

В общем случае перед выполнением каких-либо действий с предупреждением следует оценить, появлялось ли оно в течение продолжительного периода времени и отражает ли проблемы в кластерах, о которых уже сообщалось.

## <a name="file-system-locations"></a>Структура файловой системы
Для кластеров под управлением Linux структура файловой системы отличается от кластеров HDInsight под управлением Windows. Используйте следующую таблицу для поиска часто используемых файлов.

| Необходимо найти... | Это находится в папке... |
| --- | --- |
| Конфигурация |`/etc`. Например, `/etc/hadoop/conf/core-site.xml` |
| Файлы журналов |`/var/logs` |
| Платформа данных Hortonworks Data Platform (HDP) |`/usr/hdp`. Здесь расположены два каталога — каталог с текущей версией HDP (например, `2.2.9.1-1`) и каталог `current`. Каталог `current` содержит символические ссылки на файлы и каталоги, расположенные в каталоге с номером версии. Это позволяет удобно обращаться к файлам HDP, так как номер версии будет изменяться при обновлении HDP. |
| hadoop-streaming.jar |`/usr/hdp/current/hadoop-mapreduce-client/hadoop-streaming.jar` |

В общем случае, если вам известно имя файла, можно выполнить следующую команду в сеансе SSH, чтобы определить путь к файлу:

    find / -name FILENAME 2>/dev/null

В имени файла также можно использовать подстановочные знаки. Например, `find / -name *streaming*.jar 2>/dev/null` возвращает путь ко всем JAR-файлам, содержащим слово "streaming" в имени файла.

## <a name="hive-pig-and-mapreduce"></a>Hive, Pig и MapReduce
Рабочие нагрузки Pig и MapReduce очень похожи на рабочие нагрузки в кластерах под управлением Linux. Основное отличие заключается в том, что если в Windows для подключения к кластеру и запуска заданий используется удаленный рабочий стол, то в Linux для этого используется SSH.

* [Использование Pig с SSH](hdinsight-hadoop-use-pig-ssh.md)
* [Использование MapReduce с SSH](hdinsight-hadoop-use-mapreduce-ssh.md)

### <a name="hive"></a>Hive
Следующая схема содержит рекомендации по переносу рабочих нагрузок Hive.

| В кластерах под управлением Windows я пользуюсь... | В кластерах под управлением Linux... |
| --- | --- |
| **редактор Hive;** |[используйте представление Hive в Ambari](hdinsight-hadoop-use-hive-ambari-view.md) |
| `set hive.execution.engine=tez;` для включения Tez. |Tez — ядро выполнения по умолчанию для кластеров под управлением Linux, поэтому инструкция set больше не требуется. |
| CMD-файлами или сценариями на сервере, вызываемыми как часть задания Hive |используйте скрипты Bash |
| `hive` из удаленного рабочего стола. |используйте [Beeline](hdinsight-hadoop-use-hive-beeline.md) или [Hive из сеанса SSH](hdinsight-hadoop-use-hive-ssh.md). |

## <a name="storm"></a>Storm
| В кластерах под управлением Windows я пользуюсь... | В кластерах под управлением Linux... |
| --- | --- |
| Панель мониторинга Storm |Панель мониторинга Storm недоступна. Сведения об отправке топологий приведены в разделе [Развертывание и управление топологиями Storm в HDInsight под управлением Linux](hdinsight-storm-deploy-monitor-topology-linux.md) . |
| Пользовательский интерфейс Storm |Пользовательский интерфейс Storm доступен по адресу https://<имя_кластера>.azurehdinsight.net/stormui. |
| Visual Studio для создания, развертывания и управления C# или гибридными топологиями |Visual Studio можно использовать для создания, развертывания и управления топологиями C# (SCP.NET) или гибридными топологиями в кластерах Storm в HDInsight под управлением Linux, созданных после 28 октября 2017 года. |

## <a name="hbase"></a>HBase
На кластерах под управлением Linux родительским Z-узлом для HBase является `/hbase-unsecure`. Его необходимо установить в конфигурации для всех клиентских приложений Java, которые используют нативный API Java для HBase.

Пример клиента, который устанавливает это значение, см. в разделе [Использование Maven для сборки приложений Java, которые используют HBase с HDInsight (Hadoop)](hdinsight-hbase-build-java-maven.md).

## <a name="spark"></a>Spark
Кластеры Spark были доступны в кластерах Windows в предварительной версии. Однако в основной версии Spark доступен только для кластеров под управлением Linux. Способа миграции кластера Spark под управлением Windows в предварительной версии в кластер Spark под управлением Linux основной версии не существует.

## <a name="known-issues"></a>Известные проблемы
### <a name="azure-data-factory-custom-net-activities"></a>Пользовательские действия .NET фабрики данных Azure
Пользовательские действия .NET фабрики данных Azure в настоящее время не поддерживаются в кластерах HDInsight под управлением Linux. Вместо этого следует использовать один из следующих методов для реализации пользовательских действий в рамках конвейера ADF.

* Выполните действия .NET в пуле пакетной службы Azure. Ознакомьтесь с разделом "Использование связанной пакетной службы Azure" статьи [Использование настраиваемых действий в конвейере фабрики данных Azure](../data-factory/data-factory-use-custom-activities.md).
* Реализуйте действие как действие MapReduce. Дополнительные сведения см. в разделе [Вызов программы MapReduce из фабрики данных](../data-factory/data-factory-map-reduce.md).

### <a name="line-endings"></a>Символы конца строки
Как правило, в качестве символов конца строки в Windows используется CRLF, а в Linux — LF. Если вы формируете или ожидаете получить данные с символами конца строки CRLF, может потребоваться изменить производителей или потребителей данных для работы с символами конца строки LF.

Например, при выполнении запроса к HDInsight с использованием Azure PowerShell в кластере под управлением Windows будут возвращены данные с символами конца строки CRLF. Тот же запрос в кластере под управлением Linux возвратит данные с символами конца строки LF. Во многих случаях это не имеет значения для потребителя данных, однако этот вопрос необходимо изучить перед миграцией на кластер под управлением Linux.

Если имеются сценарии, которые будут выполняться непосредственно на узлах кластера Linux (например сценарий Python, используемый с Hive, или задание MapReduce), следует всегда использовать LF в качестве символов конца строки. Если использовать CRLF, могут возникнуть ошибки при выполнении сценариев в кластере под управлением Linux.

Если вы знаете, что в сценариях нет строк, содержащих символы CR, можно выполнить массовую замену символов конца строк с помощью одного из следующих методов:

* **При наличии сценариев, которые планируется передать в кластер**, используйте следующие инструкции PowerShell для замены символов конца строк с CRLF на LF перед отправкой сценариев в кластер.

      $original_file ='c:\path\to\script.py'
      $text = [IO.File]::ReadAllText($original_file) -replace "`r`n", "`n"
      [IO.File]::WriteAllText($original_file, $text)
* **При наличии сценариев, которые уже находятся в хранилище кластера**, для изменения сценария можно использовать следующую команду в сеансе SSH в кластерах под управлением Linux.

      hdfs dfs -get wasbs:///path/to/script.py oldscript.py
      tr -d '\r' < oldscript.py > script.py
      hdfs dfs -put -f script.py wasbs:///path/to/script.py

## <a name="next-steps"></a>Дальнейшие действия
* [Узнайте, как создавать кластеры HDInsight под управлением Linux](hdinsight-hadoop-provision-linux-clusters.md)
* [Подключитесь к кластеру под управлением Linux с помощью SSH из клиента Windows](hdinsight-hadoop-linux-use-ssh-windows.md)
* [Подключитесь к кластеру под управлением Linux с помощью SSH из клиента Linux, Unix или Mac](hdinsight-hadoop-linux-use-ssh-unix.md)
* [Выполняйте управление кластером под управлением Linux с помощью Ambari](hdinsight-hadoop-manage-ambari.md)



<!--HONumber=Dec16_HO2-->


