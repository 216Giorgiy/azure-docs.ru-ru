---
title: "Основные сведения об Apache Storm в службе HDInsight | Документация Майкрософт"
description: "Введение в Apache Storm в службе HDInsight."
services: hdinsight
documentationcenter: 
author: Blackmist
manager: jhubbard
editor: cgronlun
tags: azure-portal
ms.assetid: 72d54080-1e48-4a5e-aa50-cce4ffc85077
ms.service: hdinsight
ms.devlang: na
ms.topic: get-started-article
ms.tgt_pltfrm: na
ms.workload: big-data
ms.date: 01/11/2017
ms.author: larryfr
translationtype: Human Translation
ms.sourcegitcommit: 24d86e17a063164c31c312685c0742ec4a5c2f1b
ms.openlocfilehash: 354292f51d07bff00e7a6811e4d1d7beb7844920
ms.lasthandoff: 03/11/2017


---
# <a name="introduction-to-apache-storm-on-hdinsight-real-time-analytics-for-hadoop"></a>Основные сведения об Apache Storm в службе HDInsight. Аналитика в реальном времени для Hadoop

Apache Storm в службе HDInsight позволяет создавать в Azure распределенные решения для анализа данных в реальном времени.

Apache Storm — это распределенная отказоустойчивая вычислительная система с открытым исходным кодом, предназначенная для обработки данных в реальном времени с использованием Hadoop. Решения Storm могут также обеспечить гарантированную обработку данных и возможность воспроизвести те данные, которые не прошли удачную обработку в первый раз.

## <a name="why-use-storm-on-hdinsight"></a>Преимущества Apache Storm в HDInsight

Apache Storm в HDInsight представляет собой управляемый кластер, интегрированный в среду Azure. Storm и другие компоненты Hadoop в HDInsight работают на базе платформы HDP (Hortonworks Data Platform), а кластер — на базе операционной системы Ubuntu (дистрибутив Linux). Такая конфигурация обеспечивает совместимость этой платформы с популярными средствами и службами в экосистеме Hadoop.

> [!IMPORTANT]
> Linux — это единственная операционная система, используемая для работы с HDInsight 3.4 или более поздних версий. См. дополнительные сведения о [нерекомендуемых версиях HDInsight в Windows](hdinsight-component-versioning.md#hdi-version-32-and-33-nearing-deprecation-date).

Использование Apache Storm в HDInsight обеспечивает следующие преимущества:

* Решение выполняется как управляемая служба с доступностью на уровне 99,9 %, гарантируемой в рамках соглашения об уровне обслуживания.

* Простая настройка с помощью скриптов во время или после создания кластера. Дополнительные сведения см. в статье [Настройка кластеров HDInsight под управлением Linux с помощью действия сценария](hdinsight-hadoop-customize-cluster-linux.md).

* Выбор языка программирования: компоненты Storm можно написать на различных языках, таких как **Java**, **C#** и **Python**.
  
  * Интеграция Visual Studio с HDInsight для разработки, администрирования и отслеживания топологий C#. Дополнительные сведения см. в статье [Разработка топологий для Apache Storm в HDInsight на C# с помощью средств Hadoop для Visual Studio](hdinsight-storm-develop-csharp-visual-studio-topology.md).

  * Поддержка Java-интерфейса **Trident**. Этот интерфейс позволяет создавать топологии Storm, поддерживающие обработку сообщений в рамках подхода "только один раз", сохраняемость "транзакционных" хранилищ данных, а также набор распространенных операций Stream Analytics.

* Простое масштабирование кластера (добавление или удаление рабочих узлов), не влияющее на выполняющиеся топологии Storm.

* Интеграция со следующими службами Azure:
  
    * Концентраторы событий
    * Виртуальная сеть
    * База данных SQL
    * Хранилище Azure
    * DocumentDB.
  
  * Безопасное объединений возможностей нескольких кластеров HDInsight с помощью виртуальной сети Azure для создания конвейеров аналитики на основе кластеров HDInsight, HBase или Hadoop.

Список компаний, использующих Apache Storm в качестве решения для анализа данных в реальном времени, см. в статье [Companies Using Apache Storm](https://storm.apache.org/documentation/Powered-By.html) (Компании, использующие Apache Storm).

Сведения для начала работы с системой Storm см. в статье [Начало работы со Storm в HDInsight][gettingstarted].

### <a name="ease-of-creation"></a>Простота создания

Новый кластер Storm в HDInsight можно подготовить за считанные минуты. Просто укажите имя кластера, размер, учетную запись администратора и учетную запись хранения, и служба Azure создаст кластер с примерами топологий и веб-сайтом панели мониторинга.

> [!NOTE]
> Кластеры Storm также можно подготавливать к работе с помощью [Azure CLI](../xplat-cli-install.md) или [Azure PowerShell](/powershell/azureps-cmdlets-docs).

В течение 15 минут после отправки запроса у вас будет новый работающий кластер Storm, полностью готовый для первого конвейера аналитики в реальном времени.

### <a name="ease-of-use"></a>Простота использования

* __Подключение Secure Shell.__ Головные узлы кластера HDInsight доступны через Интернет по протоколу SSH. SSH позволяет выполнять команды непосредственно в кластере.

  Дополнительные сведения см. в статье [Использование SSH с Hadoop на основе Linux в HDInsight из Linux, Unix или OS X](hdinsight-hadoop-linux-use-ssh-unix.md).

* __Веб-подключение.__ Кластеры HDInsight предоставляют веб-интерфейс Ambari. Он позволяет легко отслеживать, настраивать и администрировать службы в кластере. Storm в HDInsight также предоставляет пользовательский интерфейс Storm, который позволяет отслеживать и контролировать выполнение топологий Storm из браузера.

  См. дополнительные сведения об [управлении HDInsight с помощью веб-интерфейса Ambari](hdinsight-hadoop-manage-ambari.md), а также о [мониторинге и управлении с помощью пользовательского интерфейса Storm](hdinsight-storm-deploy-monitor-topology-linux.md#monitor-and-manage-using-the-storm-ui).

* __Azure PowerShell и CLI.__ Обе эти служебные программы командной строки можно использовать для работы с HDInsight и другими службами Azure из клиентской системы.

* __Интеграция с Visual Studio.__ Средства Data Lake для Visual Studio включают шаблоны проектов для создания топологий C# Storm, а также средства для мониторинга Storm в HDInsight. Эти решения позволяют создавать, развертывать, отслеживать и администрировать топологии C# из среды Visual Studio.

  Дополнительные сведения см. в статье [Разработка топологий для Apache Storm в HDInsight на C# с помощью средств Hadoop для Visual Studio](hdinsight-storm-develop-csharp-visual-studio-topology.md).

* __Интеграция с другими службами Azure__

  * Для разработки на основе __Java__ корпорация Майкрософт использует имеющиеся компоненты Storm, обеспечивая интеграцию с другими службами Azure, где это возможно. В некоторых случаях может потребоваться компонент или решение для определенной службы.

    * __Azure Data Lake Store.__ Топологии на основе Java могут обращаться к хранилищу Data Lake Store с помощью элемента bolt Storm-HDFS с использованием схемы URI `adl://`. Дополнительные сведения об этом элементе см. на примере [использования Azure Data Lake Store и Apache Storm в HDInsight](https://docs.microsoft.com/en-us/azure/hdinsight/hdinsight-storm-write-data-lake-store).

    * __Служба хранилища Azure__ (при использовании в качестве хранилища для HDInsight). Топологии на основе Java могут обращаться к службе хранилища Azure с помощью элемента bolt Storm-HDFS со схемой URI `wasb://`.

    * __Концентраторы событий Azure.__ Поддерживают возможность доступа с помощью компонентов EventHubSpout и EventHubBolt, предоставляемых корпорацией Майкрософт. Эти компоненты написаны на языке Java. Они предоставляются в виде отдельного JAR-файла.

    Дополнительные сведения о разработке решений на языке Java см. в статье [Разработка топологий на основе Java для базовых приложений подсчета слов с помощью Apache Storm и Maven в HDInsight](hdinsight-storm-develop-java-topology.md).

  * Для разработки на основе __C#__ обычно можно использовать пакет SDK .NET для службы Azure. В некоторых случаях для работы пакета SDK может требоваться поддержка платформ, которые недоступны в Linux (ОС узла для HDInsight 3.4 и более поздних версий). В этом случае можно использовать компоненты Java, предоставляемые решением C#.

    * Примеры использования __базы данных SQL__, __DocumentDB__, __концентратора событий__ и __HBase__ включены как шаблоны в средства Azure Data Lake для Visual Studio. Дополнительные сведения см. в статье [Разработка топологий для Apache Storm в HDInsight на C# с помощью средств Hadoop для Visual Studio](hdinsight-storm-develop-csharp-visual-studio-topology.md).

    * __Концентраторы событий Azure.__ Ознакомиться с использованием компонентов Java из решения C# можно на примере [обработки событий из концентраторов событий Azure с помощью Storm в HDInsight (C#)](hdinsight-storm-develop-csharp-event-hub-topology.md).

    Дополнительные сведения о создании решений на основе C# см. в статье [Разработка топологий для Apache Storm в HDInsight на C# с помощью средств Hadoop для Visual Studio](hdinsight-storm-develop-csharp-visual-studio-topology.md).

### <a name="reliability"></a>Надежность

Система Apache Storm гарантирует, что каждое входящее сообщение будет полностью обработано даже в том случае, когда анализ данных распределен между сотнями узлов.

Функциональные возможности **узла Nimbus** схожи с возможностями службы Hadoop JobTracker. Через **Zookeeper** этот узел назначает задачи другим узлам в кластере. Узлы Zookeeper обеспечивают координацию кластера и упрощают взаимодействие между узлом Nimbus и процессом **контролера** на рабочих узлах. Если один узел обработки выходит из строя, узел Nimbus узнает об этом и назначает задачу и связанные данные другому узлу.

По умолчанию для Apache Storm используется только один узел Nimbus, но кластер Storm в HDInsight работает на двух. При сбое основного узла кластер HDInsight переключится на дополнительный на время восстановления основного узла.

![Схема с контролерами и компонентами Nimbus и Zookeeper](./media/hdinsight-storm-overview/nimbus.png)

### <a name="scale"></a>Масштаб

Количество узлов указывается во время создания кластера. Тем не менее рабочая нагрузка может меняться, и тогда возникает необходимость увеличить или уменьшить размер кластера. Все кластеры HDInsight позволяют изменять количество узлов в кластере даже во время обработки данных.

> [!NOTE]
> Чтобы воспользоваться преимуществами новых узлов, добавленных с помощью масштабирования, необходимо повторно сбалансировать топологии, запущенные до увеличения размера кластера.

### <a name="support"></a>Поддержка

Для кластеров Storm в HDInsight круглосуточно действует полная поддержка корпоративного уровня. Коме того, для кластеров Storm в HDInsight заявлена гарантированная доступность в течение 99,9 % времени. Это означает, что мы гарантируем возможность подключения к кластеру извне в течение как минимум 99,9 % времени.

## <a name="common-use-cases-for-real-time-analytics"></a>Распространенные варианты использования аналитики в реальном времени

Ниже приведены несколько распространенных ситуаций, в которых вам может помочь кластер Apache Storm в HDInsight. Сценарии из реальной жизни см. в статье о том, [как компании используют Storm](https://storm.apache.org/documentation/Powered-By.html).

* Интернет вещей.
* Обнаружение мошенничества.
* Социальная аналитика.
* Извлечение, преобразование и загрузка.
* Мониторинг сетей.
* Поиск
* Взаимодействие через мобильные устройства.

## <a name="how-is-data-in-hdinsight-storm-processed"></a>Как происходит обработка данных в HDInsight Storm

Apache Storm работает с **топологиями** , а не задания MapReduce, с которыми вы, вероятно, знакомы по HDInsight или Hadoop. Кластер Storm в HDInsight имеет два типа узлов: головные узлы, на которых работает **Nimbus**, и рабочие узлы, на которых работает **контролер**.

* **Nimbus.** Как и служба JobTracker в Hadoop, этот узел отвечает за распределение кода в кластере, назначение задач виртуальным машинам и отслеживание сбоев. Служба HDInsight имеет два узла Nimbus, поэтому в кластере Storm в HDInsight нет единой точки отказа.
* **Контролер.** Контролер для каждого рабочего узла, отвечающий за начало и остановку **рабочих процессов** на узле.
* **Рабочий процесс.** Выполняет подмножество **топологии**. Выполняемая топология распределяется по многим рабочим процессам кластера.
* **Топология.** Определяет граф вычислений, которые обрабатывают **потоки** данных. В отличие от заданий MapReduce топология выполняется до тех пор, пока ее остановят.
* **Поток.** Несвязанный набор **кортежей**. Потоки создаются со стороны **воронок** и **сит** и направляются в **сита**.
* **Кортеж.** Именованный список динамически вводимых значений.
* **Воронка.** Потребляет данные из источника данных и отправляет один или несколько **потоков**.
  
  > [!NOTE]
  > Зачастую данные считываются из очереди (например, из Kafka или концентраторов событий Azure). Очередь отвечает за сохраняемость данных в случае сбоя.

* **Сито.** Принимает **потоки**, выполняет обработку **кортежей** и может отправлять **потоки**. Сито также отвечает за запись данных во внешние хранилища, такие как HDInsight, HBase, хранилища очередей, BLOB-объектов и другие хранилища данных.
* **Apache Thrift.** Программная платформа для разработки масштабируемых служб на разных языках. Она позволяет собирать службы, работающие переключаясь между языками C++, Java, Python, PHP, Ruby, Erlang, Perl, Haskell, C#, Cocoa, JavaScript, Node.js, Smalltalk и др.

Дополнительные сведения о компонентах Storm см. в [руководстве по Storm][apachetutorial] на сайте apache.org.

## <a name="what-programming-languages-can-i-use"></a>Использование языков программирования

### <a name="c35"></a>C&#35;

Средства Data Lake для Visual Studio позволяют разработчикам .NET проектировать и реализовывать топологии на языке C#. Вы также можете создавать гибридные топологии, в которых используются компоненты Java и C#.

Дополнительные сведения см. в статье [Разработка топологий для Apache Storm в HDInsight на C# с помощью средств Hadoop для Visual Studio](hdinsight-storm-develop-csharp-visual-studio-topology.md).

### <a name="java"></a>Java

Большинство примеров Java, с которыми вам доведется иметь дело, создаются с использованием либо только Java, либо Trident. Trident — это высокоуровневая абстракция, которая облегчает такие операции, как объединение, агрегирование, группирование, фильтрация. Тем не менее Trident работает с пакетами кортежей, тогда как решение, созданное только на языке Java, будет обрабатывать в потоке по одному кортежу за раз.

Дополнительные сведения о Trident см. в [руководстве по Trident](https://storm.apache.org/documentation/Trident-tutorial.html) на сайте apache.org.

Примеры топологий Java и Trident можно найти в [списке примеров топологий Storm](hdinsight-storm-example-topology.md) или в примерах storm-starter в вашем кластере HDInsight.

Примеры storm-starter расположены в каталоге **/usr/hdp/current/storm-client/contrib/storm-starter** кластера HDInsight.

### <a name="python"></a>Python

Пример использования компонентов Python см. в статье [Разработка топологий Apache Storm с помощью Python в HDInsight](hdinsight-storm-develop-python-topology.md).

## <a name="what-are-some-common-development-patterns"></a>Некоторые типичные шаблоны разработки

### <a name="guaranteed-message-processing"></a>Гарантированная обработка сообщений

Storm может обеспечить различные уровни гарантированной обработки сообщений. Например, простое приложение Storm гарантирует как минимум одну обработку, в то время как Trident может гарантировать ровно одну обработку.

Дополнительные сведения см. в статье о [гарантированной обработке данных](https://storm.apache.org/about/guarantees-data-processing.html) на сайте apache.org.

### <a name="ibasicbolt"></a>IBasicBolt

Шаблон чтения входного кортежа, выдающий значение 0 или больше, а затем непосредственно в конце метод execute, запрашивающий подтверждение входного кортежа, является типичным. Storm обеспечивает интерфейс [IBasicBolt](https://storm.apache.org/apidocs/backtype/storm/topology/IBasicBolt.html) для автоматизации этого шаблона.

### <a name="joins"></a>Соединения

Объединение потоков данных отличается в разных приложениях. Например, вы можете объединять все кортежи с нескольких потоков в один новый поток или объединять только пакеты кортежей для отдельного окна. В любом случае, объединение может завершиться с помощью [fieldsGrouping](http://javadox.com/org.apache.storm/storm-core/0.9.1-incubating/backtype/storm/topology/InputDeclarer.html#fieldsGrouping%28java.lang.String,%20backtype.storm.tuple.Fields%29), который является способом определения того, как кортежи перенаправляются к bolts.

В приведенном ниже примере Java используется fieldsGrouping для перенаправления кортежей из компонентов "1", "2" и "3" в сито **MyJoiner** .

    builder.setBolt("join", new MyJoiner(), parallelism) .fieldsGrouping("1", new Fields("joinfield1", "joinfield2")) .fieldsGrouping("2", new Fields("joinfield1", "joinfield2")) .fieldsGrouping("3", new Fields("joinfield1", "joinfield2"));

### <a name="batching"></a>Пакетная обработка

Storm предоставляет внутренний временной механизм (или временной кортеж), который можно использовать для отправки одного пакета каждые X секунд.

Пример использования временного кортежа из компонента на C# см. здесь: [PartialBoltCount.cs](https://github.com/hdinsight/hdinsight-storm-examples/blob/3b2c960549cac122e8874931df4801f0934fffa7/EventCountExample/EventCountTopology/src/main/java/com/microsoft/hdinsight/storm/examples/PartialCountBolt.java).

Если вы пользуетесь Trident, он основан на обработке потоков кортежей.

### <a name="caching"></a>Caching

Для ускорения обработки часто используется кэширование в памяти, при котором в памяти сохраняются часто используемые ресурсы. Так как топология распределяется между несколькими узлами и несколькими процессами в пределах одного узла, вы можете использовать [fieldsGrouping](http://javadox.com/org.apache.storm/storm-core/0.9.1-incubating/backtype/storm/topology/InputDeclarer.html#fieldsGrouping%28java.lang.String,%20backtype.storm.tuple.Fields%29). `fieldsGrouping` гарантирует, что кортежи, содержащие поля, используемые для поиска в кэше, всегда перенаправляются к одному и тому же процессу. Эта функция группирования избавит от дублирования записей кэша в процессах.

### <a name="streaming-top-n"></a>Максимальное количество потоков (top N)

Когда ваша топология зависит от расчета значения "Топ N", это значение нужно рассчитывать параллельно, а затем объединять результат расчетов в глобальное значение. Это можно сделать с помощью [fieldsGrouping](http://javadox.com/org.apache.storm/storm-core/0.9.1-incubating/backtype/storm/topology/InputDeclarer.html#fieldsGrouping%28java.lang.String,%20backtype.storm.tuple.Fields%29), направив отдельные поля в параллельную обработку, а затем — в сито, которое определяет глобальное значение "Топ N".

Для расчета значения "Топ N" смотрите следующий пример [RollingTopWords](https://github.com/nathanmarz/storm-starter/blob/master/src/jvm/storm/starter/RollingTopWords.java).

## <a name="what-type-of-logging-does-storm-use"></a>Тип ведения журналов в Storm

Storm использует Apache Log4j для записи информации в журнал. По умолчанию в журнал записывается большой объем данных, и разобраться в этой информации может быть трудно. Чтобы управлять ведением журналов, включите файл конфигурации ведения журналов в топологию Storm.

Пример топологии, в котором показано, как настроить ведение журнала, см. в примере Storm в HDInsight в статье [Разработка топологий на основе Java для базовых приложений подсчета слов с помощью Apache Storm и Maven в HDInsight](hdinsight-storm-develop-java-topology.md).

## <a name="next-steps"></a>Дальнейшие действия

Ниже приведены статьи, в которых можно найти дополнительные сведения о решениях для анализа данных в реальном времени с помощью Apache Storm в HDInsight.

* [Начало работы с кластером Storm в HDInsight][gettingstarted]
* [Примеры топологий для Storm в HDInsight](hdinsight-storm-example-topology.md)

[stormtrident]: https://storm.apache.org/documentation/Trident-API-Overview.html
[samoa]: http://yahooeng.tumblr.com/post/65453012905/introducing-samoa-an-open-source-platform-for-mining
[apachetutorial]: https://storm.apache.org/documentation/Tutorial.html
[gettingstarted]: hdinsight-apache-storm-tutorial-get-started-linux.md

