<properties
	pageTitle="Разработка действий сценариев с помощью HDInsight | Microsoft Azure"
	description="Дополнительные сведения о настройке кластеров Hadoop с помощью действия скрипта."
	services="hdinsight"
	documentationCenter=""
	tags="azure-portal"
	authors="mumian"
	manager="paulettm"
	editor="cgronlun"/>

<tags
	ms.service="hdinsight"
	ms.workload="big-data"
	ms.tgt_pltfrm="na"
	ms.devlang="na"
	ms.topic="article"
	ms.date="02/04/2016"
	ms.author="jgao"/>

# Разработка скриптов действия сценария для HDInsight

Узнайте, как разрабатывать скрипты действия сценария для HDInsight. Дополнительную информацию о скриптах действия сценария см. в статье [Настройка кластеров HDInsight с помощью действия сценария](hdinsight-hadoop-customize-cluster.md). В качестве аналогичной статьи для кластера HDInsight под управлением Linux см. [Разработка скриптов действия сценария для HDInsight](hdinsight-hadoop-script-actions-linux.md).

Действие сценария можно использовать для установки дополнительного программного обеспечения, работающего в кластере Hadoop, или для изменения конфигурации приложений, установленных в кластере. Действия сценариев — это сценарии, выполняемые на узлах кластера во время развертывания кластеров HDInsight. Они будут выполнены, как только узлы в кластере завершат конфигурацию HDInsight. Действие сценария выполняется из учетной записи с правами системного администратора и предоставляет права полного доступа к узлам кластера. Для каждого кластера можно задать ряд действий сценария, которые будут выполнены в указанном порядке.

> [AZURE.NOTE] Если появляется следующее сообщение об ошибке:
> 
>     System.Management.Automation.CommandNotFoundException; ExceptionMessage : The term 'Save-HDIFile' is not recognized as the name of a cmdlet, function, script file, or operable program. Check the spelling of the name, or if a path was included, verify that the path is correct and try again.
> Это означает, что вы не включили вспомогательные методы. См. [Вспомогательные методы для пользовательских скриптов](hdinsight-hadoop-script-actions.md#helper-methods-for-custom-scripts).

## Примеры сценариев

Для создания кластеров HDInsight в операционной системе Windows действием сценария является сценарий Azure PowerShell. Ниже приведен пример сценария для настройки файлов конфигурации сайта:

	param (
	    [parameter(Mandatory)][string] $ConfigFileName,
	    [parameter(Mandatory)][string] $Name,
	    [parameter(Mandatory)][string] $Value,
	    [parameter()][string] $Description
	)

	if (!$Description) {
	    $Description = ""
	}

	$hdiConfigFiles = @{
	    "hive-site.xml" = "$env:HIVE_HOME\conf\hive-site.xml";
	    "core-site.xml" = "$env:HADOOP_HOME\etc\hadoop\core-site.xml";
	    "hdfs-site.xml" = "$env:HADOOP_HOME\etc\hadoop\hdfs-site.xml";
	    "mapred-site.xml" = "$env:HADOOP_HOME\etc\hadoop\mapred-site.xml";
	    "yarn-site.xml" = "$env:HADOOP_HOME\etc\hadoop\yarn-site.xml"
	}

	if (!($hdiConfigFiles[$ConfigFileName])) {
	    Write-HDILog "Unable to configure $ConfigFileName because it is not part of the HDI configuration files."
	    return
	}

	[xml]$configFile = Get-Content $hdiConfigFiles[$ConfigFileName]

	$existingproperty = $configFile.configuration.property | where {$_.Name -eq $Name}

	if ($existingproperty) {
	    $existingproperty.Value = $Value
	    $existingproperty.Description = $Description
	} else {
	    $newproperty = @($configFile.configuration.property)[0].Clone()
	    $newproperty.Name = $Name
	    $newproperty.Value = $Value
	    $newproperty.Description = $Description
	    $configFile.configuration.AppendChild($newproperty)
	}

	$configFile.Save($hdiConfigFiles[$ConfigFileName])

	Write-HDILog "$configFileName has been configured."

Сценарий принимает четыре параметра: имя файла конфигурации, свойство, которое вы хотите изменить, значение, которое вы хотите установить, и описание. Например:

	hive-site.xml hive.metastore.client.socket.timeout 90 

Эти параметры установят для значения hive.metastore.client.socket.timeout величину 90 в файле hive-site.xml. Значение по умолчанию составляет 60 секунд.

Этот пример сценария также доступен по ссылке [https://hditutorialdata.blob.core.windows.net/customizecluster/editSiteConfig.ps1](https://hditutorialdata.blob.core.windows.net/customizecluster/editSiteConfig.ps1).

HDInsight предоставляет несколько скриптов для установки дополнительных компонентов в кластерах HDInsight:

Имя | Скрипт
----- | -----
**Установка Spark** | https://hdiconfigactions.blob.core.windows.net/sparkconfigactionv03/spark-installer-v03.ps1. См. статью [Установка и использование Spark в кластерах HDInsight][hdinsight-install-spark].
**Установка R** | https://hdiconfigactions.blob.core.windows.net/rconfigactionv02/r-installer-v02.ps1. См. статью [Установка и использование R в кластерах HDInsight][hdinsight-r-scripts].
**Установка Solr** | https://hdiconfigactions.blob.core.windows.net/solrconfigactionv01/solr-installer-v01.ps1. См. статью [Установка и использование Solr в кластерах HDInsight](hdinsight-hadoop-solr-install.md).
— **Установка Giraph** | https://hdiconfigactions.blob.core.windows.net/giraphconfigactionv01/giraph-installer-v01.ps1. См. статью [Установка и использование Giraph в кластерах HDInsight](hdinsight-hadoop-giraph-install.md).

Действие сценария можно развернуть из портала Azure, из пакета SDK для HDInsight .NET или Azure PowerShell. Дополнительную информацию см. в разделе [Настройка кластеров HDInsight с помощью действия сценария][hdinsight-cluster-customize].

> [AZURE.NOTE] Примеры сценариев работают только с кластером HDInsight версии 3.1 или более поздней. Дополнительную информацию о версиях кластера HDInsight см. в статье [Новые возможности версий кластеров Hadoop, предоставляемых HDInsight](../hdinsight-component-versioning/).





## Вспомогательные методы для пользовательских скриптов

Вспомогательные методы действий скриптов представляют собой служебные программы, которые можно использовать при создании пользовательских скриптов. Они определяются на странице [https://hdiconfigactions.blob.core.windows.net/configactionmodulev05/HDInsightUtilities-v05.psm1](https://hdiconfigactions.blob.core.windows.net/configactionmodulev05/HDInsightUtilities-v05.psm1) и могут быть включены в скрипты с помощью следующей команды.

    # Download config action module from a well-known directory.
	$CONFIGACTIONURI = "https://hdiconfigactions.blob.core.windows.net/configactionmodulev05/HDInsightUtilities-v05.psm1";
	$CONFIGACTIONMODULE = "C:\apps\dist\HDInsightUtilities.psm1";
	$webclient = New-Object System.Net.WebClient;
	$webclient.DownloadFile($CONFIGACTIONURI, $CONFIGACTIONMODULE);
	
	# (TIP) Import config action helper method module to make writing config action easy.
	if (Test-Path ($CONFIGACTIONMODULE))
	{ 
		Import-Module $CONFIGACTIONMODULE;
	} 
	else
	{
		Write-Output "Failed to load HDInsightUtilities module, exiting ...";
		exit;
	}

Ниже приведены вспомогательные методы, предоставляемые этим скриптом.

Вспомогательный метод | Описание
-------------- | -----------
**Save-HDIFile** | Скачивает файл с указанным универсальным идентификатором ресурса в расположение на локальном диске, который сопоставлен с узлом виртуальной машины Azure, назначенным данному кластеру.
**Expand-HDIZippedFile** | Распаковывает ZIP-файл.
**Invoke-HDICmdScript** | Запускает сценарий из cmd.exe.
**Write-HDILog** | Записывает выходные данные пользовательского сценария, используемого для действия сценария.
**Get-Services** | Получает список служб, запущенных на том компьютере, где выполняется сценарий.
**Get-Service** | Используя имя определенной службы в качестве входных данных, получает подробную информацию об этой службе (имя службы, идентификатор процесса, состояние и т. п.) на том компьютере, где выполняется сценарий.
**Get-HDIServices** | Получает список служб HDInsight, запущенных на том компьютере, где выполняется сценарий.
**Get-HDIService** | Используя имя определенной службы HDInsight в качестве входных данных, получает подробную информацию об этой службе (имя службы, идентификатор процесса, состояние и т. п.) на том компьютере, где выполняется сценарий.
**Get-ServicesRunning** | Получает список служб, запущенных на том компьютере, где выполняется сценарий.
**Get-ServiceRunning** | Проверяет, запущена ли служба с определенным именем на том компьютере, где выполняется сценарий.
**Get-HDIServicesRunning** | Получает список служб HDInsight, запущенных на том компьютере, где выполняется сценарий.
**Get-HDIServiceRunning** | Проверяет, запущена ли служба HDInsight с определенным именем на том компьютере, где выполняется сценарий.
**Get-HDIHadoopVersion** | Получает версию Hadoop, установленную на том компьютере, где выполняется сценарий.
**Test-IsHDIHeadNode** | Проверяет, является ли тот компьютер, где выполняется сценарий, головным узлом.
**Test-IsActiveHDIHeadNode** | Проверяет, является ли тот компьютер, где выполняется сценарий, активным головным узлом.
**Test-IsHDIDataNode** | Проверяет, является ли тот компьютер, где выполняется сценарий, узлом данных.
**Edit-HDIConfigFile** | Изменяет файлы конфигурации hive-site.xml, core-site.xml, hdfs-site.xml, mapred-site.xml и yarn-site.xml.


## Рекомендации по разработке скриптов

При разработке пользовательского скрипта для кластера HDInsight следует иметь в виду некоторые рекомендации.

- Проверка версии Hadoop

	Только HDInsight версии 3.1 (Hadoop 2.4) и выше поддерживает использование действия скрипта для установки пользовательских компонентов в кластере. В пользовательском сценарии необходимо использовать вспомогательный метод **Get-HDIHadoopVersion** для проверки версии Hadoop, и только затем продолжить выполнение других задач в сценарии.


- Стабильные ссылки на ресурсы скрипта

	Пользователям следует убедиться, что все скрипты и другие артефакты, используемые при настройке кластера, доступны в период существования кластера и версии этих файлов не изменялись на протяжении данного периода. Эти ресурсы необходимы, если требуется восстановить узлы в кластере из образа. Мы советуем скачивать и архивировать все материалы в учетную запись хранения, управляемую пользователем. Это может быть учетная запись хранения по умолчанию или любые дополнительные учетные записи хранения, указанные во время развертывания настроенного кластера. К примеру, в приведенных в документации примерах настроенного кластера Spark и R мы создали локальную копию ресурсов в этой учетной записи хранения: https://hdiconfigactions.blob.core.windows.net/.


- Обеспечение идемпотентности сценария настройки кластера

	Нужно допускать, что потребуется восстановить из образа узлы кластера HDInsight в период существования этого кластера. Скрипт настройки кластера выполняется при каждом восстановлении кластера из образа. Этот сценарий должен быть рассчитан на идемпотентность. Имеется в виду, что при восстановлении из образа сценарий должен обеспечивать возврат кластера к тем настройкам, которые были заданы для него во время первого запуска сценария после изначального создания этого кластера. Например, если пользовательский сценарий во время своего первого запуска установил приложение в папку D:\\AppLocation, то при каждом последующем запуске и восстановлении из образа сценарий должен проверить, существует ли приложение в папке D:\\AppLocation, и только после этого переходить к следующим шагам.


- Установка пользовательских компонентов в оптимальное расположение

	Если узлы кластера восстанавливаются из образа, диск ресурсов C:\\ и системный диск D:\\ могут быть переформатированы, что приведет к потере находящихся на них данных и приложений. Это также может произойти, если узел виртуальной машины Azure, являющийся частью кластера, выходит из строя и заменяется новым узлом. Компоненты можно установить на диске D:\\ или в папке C:\\apps на кластере. Все расположения на диске C:\\ зарезервированы. Укажите расположение, где должны устанавливаться приложения или библиотеки в рамках скрипта настройки кластера.


- Обеспечение высокого уровня доступности кластера

	В целях обеспечения высокой доступности HDInsight имеет активно-пассивную архитектуру, в которой один головной узел находится в активном режиме (где выполняются службы HDInsight), а другой головной узел находится в режиме ожидания (на нем службы HDInsight не запущены). Узлы переключаются между активным и пассивным режимами в случае сбоев в службах службы HDInsight. Если с помощью действия сценария на обоих головных узлах устанавливаются службы для обеспечения высокой доступности, следует помнить о том, что механизм отработки отказа HDInsight не сможет автоматически выполнить отработку отказа для этих установленных пользователем служб. Поэтому службы HDInsight, установленные пользователем на головных узлах, к которым предъявляется требование высокой доступности, должны иметь собственный механизм отработки отказа в режиме "активный — пассивный" или работать в режиме "активный — активный".

	Команда действия сценария HDInsight выполняется на обоих головных узлах, если роль головного узла указана в качестве значения параметра *ClusterRoleCollection* (см. раздел [Как запустить действие сценария](#runScriptAction) ниже). Поэтому при разработке пользовательского скрипта убедитесь, что в скрипте учтены эти особенности установки. Не следует создавать проблемы, устанавливая и запуская на обоих головных узлах одинаковые службы, которые в итоге будут конкурировать друг с другом. Обратите внимание, что при восстановлении из образа данные будут утеряны, поэтому необходимо, чтобы программное обеспечение, установленное через действие сценария, было устойчивым к таким сбоям. Приложения должны быть рассчитаны на работу с высокодоступными данными, распределенными на множестве узлов. Обратите внимание, что как минимум пятая часть узлов в кластере может быть восстановлена из образа одновременно.


- Настройка пользовательских компонентов для использования хранилища больших двоичных объектов Azure

	Конфигурация по умолчанию для пользовательских компонентов, устанавливаемых на узлах кластера, может предполагать использование хранилища распределенной файловой системы Hadoop (HDFS). Следует изменить конфигурацию, чтобы в ней использовалось хранилище больших двоичных объектов Azure. При восстановлении кластера из образа файловая система HDFS форматируется, в результате чего будут потеряны все хранящиеся в ней данные. В случае использования хранилища больших двоичных объектов Azure эти данные будут сохранены.

## Общие варианты использования

В этом разделе содержится руководство по реализации некоторых общих вариантов использования, которые могут понадобиться при написании пользовательского сценария.

### Настройка переменных среды

Часто при разработке действий сценария необходимо задавать переменные среды. Например, наиболее вероятный сценарий — скачивание двоичного файла с внешнего сайта, установка этого файла в кластер и добавление его расположения в переменную среду PATH. В следующем фрагменте кода показано, как задавать переменные среды в пользовательском сценарии.

	Write-HDILog "Starting environment variable setting at: $(Get-Date)";
	[Environment]::SetEnvironmentVariable('MDS_RUNNER_CUSTOM_CLUSTER', 'true', 'Machine');

Этот оператор задает для переменной среды **MDS\_RUNNER\_CUSTOM\_CLUSTER** значение true, а также задает область действия этой переменной в рамках компьютера. В некоторых случаях крайне важно, чтобы переменные среды были заданы в соответствующей области — в рамках компьютера или пользовательской области. Дополнительную информацию о настройке переменных среды см. [здесь][1].

### Доступ к расположениям, в которых хранятся пользовательские сценарии

Сценарии для настройки кластера должны находиться в учетной записи хранения по умолчанию для кластера или в доступном только для чтения контейнере другой учетной записи хранения. Если сценарий получает доступ к ресурсам в другом расположении, это расположение должно быть общедоступным (или по крайней мере открытым только для чтения). Например, вам может потребоваться получить доступ к файлу и сохранить его с помощью команды SaveFile HDI.

	Save-HDIFile -SrcUri 'https://somestorageaccount.blob.core.windows.net/somecontainer/some-file.jar' -DestFile 'C:\apps\dist\hadoop-2.4.0.2.1.9.0-2196\share\hadoop\mapreduce\some-file.jar'

В этом примере необходимо убедиться, что контейнер somecontainer в учетной записи хранения somestorageaccount является общедоступным. В противном случае сценарий выдаст исключение "Не найдено" и прекратит работу.

### Передача параметров командлету Add-AzureRmHDInsightScriptAction

Чтобы передать несколько параметров командлету Add-AzureRmHDInsightScriptAction, необходимо отформатировать строковое значение, которое содержит все параметры для данного сценария. Например:

	"-CertifcateUri wasb:///abc.pfx -CertificatePassword 123456 -InstallFolderName MyFolder"
 
или

	$parameters = '-Parameters "{0};{1};{2}"' -f $CertificateName,$certUriWithSasToken,$CertificatePassword


### Вызов исключения при сбое развертывания кластера

Если вы хотите получать точные уведомления о том, что настройки кластера не сработали надлежащим образом, необходимо вызвать исключение и отменить создание кластера. Например, может потребоваться обработка файла, если он существует, или обработка ошибки, если файл не существует. Это обеспечит корректное завершение сценария и точное оповещение о состоянии кластера. В следующем фрагменте кода показано, как этого достичь:

	If(Test-Path($SomePath)) {
		#Process file in some way
	} else {
		# File does not exist; handle error case
		# Print error message
	exit
	}

В этом фрагменте кода, если файл не существовал, это приведет к состоянию, когда скрипт фактически завершает свою работу после выдачи сообщения об ошибке, а кластер переходит в рабочее состояние при условии, что процесс настройки кластера был завершен "успешно". Если вы хотите получать уведомления о том, что настройка кластера завершилась неудачно из-за отсутствия файла, то более правильным действием будет выдача исключения и остановка этапа настройки кластера. Для этого необходимо использовать следующий образец фрагмента кода.

	If(Test-Path($SomePath)) {
		#Process file in some way
	} else {
		# File does not exist; handle error case
		# Print error message
	throw
	}


## Контрольный список для развертывания действия сценария
Ниже приведены шаги, которые использовались при подготовке к развертыванию этих скриптов.

1. Поместите файлы, содержащие пользовательские скрипты, в месте, доступном из узлов кластера во время развертывания. Это может быть любая из используемых по умолчанию или дополнительных учетных записей хранения, указанных во время развертывания кластера, или другой общедоступный контейнер хранилища.
2. Добавьте проверки в скрипты, чтобы гарантировать, что они выполняются идемпотентно, а значит, скрипт сможет многократно выполняться на одном и том же узле.
3. Используйте командлет Azure PowerShell **Write-Output** для вывода в STDOUT и STDERR. Не используйте **Write-Host**.
4. Используйте папку для временных файлов, например $env: TEMP, чтобы сохранить скачанный файл, используемый сценариями. После выполнения сценариев очистите эту папку.
5. Устанавливайте пользовательское программное обеспечения только на диске D:\\ или в папке C:\\apps. Не следует производить установку в другие расположения на диске C:, так как они зарезервированы. Обратите внимание, что установка файлов на диске C: вне папки C:\\apps может привести к сбою установки во время восстановления узла из образа.
6. В случае изменений параметров на уровне операционной системы или файлов конфигурации службы Hadoop может потребоваться перезапуск служб HDInsight. За счет этого службы HDInsight смогут автоматически установить любые параметры уровня операционной системы, например заданные в сценариях переменные среды.



## Проверка пользовательского сценария с использованием эмулятора HDInsight

Самый простой способ проверить пользовательский сценарий перед использованием его в команде действия сценария HDInsight — запустить его в эмуляторе HDInsight. Вы можете установить эмулятор HDInsight локально или в виртуальной машине Windows Server 2012 R2 с технологией Azure "инфраструктура как услуга" (IaaS) либо установить его на локальном компьютере и проверить, правильно ли работает сценарий. Помните, что виртуальная машина Windows Server 2012 R2 — это та же виртуальная машина, которую HDInsight использует для узлов.

В этом разделе описаны процедуры локального использования эмулятора HDInsight для проведения тестирования, однако в виртуальной машине тестирование проводится аналогичным образом.

**Установка эмулятора HDInsight**. Для выполнения действия сценария на локальном компьютере нужно установить эмулятор HDInsight. Указания по его установке см. в статье [Приступая к работе с эмулятором HDInsight](../hdinsight-get-started-emulator/).

**Задание политики выполнения для Azure PowerShell**. Откройте Azure PowerShell и выполните (с правами администратора) следующую команду, чтобы задать политику выполнения *LocalMachine* и *Unrestricted*:

	Set-ExecutionPolicy Unrestricted –Scope LocalMachine

Эта политика должна быть неограниченной, так как скрипты не подписаны.

**Скачивание действия сценария**, который требуется выполнить, в локальное расположение. Следующие примеры сценариев доступны в следующих расположениях:

* **Spark**. https://hdiconfigactions.blob.core.windows.net/sparkconfigactionv02/spark-installer-v02.ps1
* **R**. https://hdiconfigactions.blob.core.windows.net/rconfigactionv02/r-installer-v02.ps1
* **Solr**. https://hdiconfigactions.blob.core.windows.net/solrconfigactionv01/solr-installer-v01.ps1
* **Giraph**. https://hdiconfigactions.blob.core.windows.net/giraphconfigactionv01/giraph-installer-v01.ps1

**Запуск действия сценария**. Откройте новое окно Azure PowerShell в режиме администратора и запустите сценарий установки Spark или R из локального расположения, где он был сохранен.

**Примеры использования**. При использовании кластеров Spark и R в эмуляторе HDInsight могут отсутствовать необходимые файлы данных. Поэтому необходимо передать соответствующие TXT-файлы, содержащие данные пути, в HDFS, а затем использовать этот путь для получения доступа к данным. Например:

	val file = sc.textFile("/example/data/gutenberg/davinci.txt")


Обратите внимание, что в некоторых случаях пользовательский скрипт может фактически зависеть от компонентов HDInsight, таких как идентификация активности определенных служб Hadoop. В этом случае необходимо проверить пользовательские скрипты, развернув их на фактическом кластере HDInsight.


## Отладка пользовательских сценариев

Журналы ошибок сценария хранятся вместе с другими выходными данными в учетной записи хранения по умолчанию, заданной для кластера при его создании. Журналы хранятся в таблице с именем *u<\\cluster-name-fragment><\\time-stamp>setuplog*. Это сводные журналы, содержащие записи из всех узлов (рабочих и главного), на которых выполняется сценарий в кластере. Для проверки журналов удобно воспользоваться инструментами HDInsight для Visual Studio. Для установки инструментов см. статью [Приступая к работе с инструментами Hadoop в Visual Studio для HDInsight](hdinsight-hadoop-visual-studio-tools-get-started.md#install-hdinsight-tools-for-visual-studio).

**Для проверки журнала с помощью Visual Studio**

1. Откройте Visual Studio.
2. Щелкните **Представление**, а затем щелкните **Обозреватель сервера**.
3. Щелкните правой кнопкой мыши на Azure, выберите "Подключение к **подписке Microsoft Azure**", а затем введите учетные данные.
4. Разверните **Хранилище**, затем разверните узлы учетной записи хранения Azure, используемой в качестве файловой системы по умолчанию, разверните **Таблицы**, а затем дважды щелкните имя таблицы.


Вы также можете осуществить удаленный доступ к узлам кластера для просмотра STDOUT и STDERR для пользовательских сценариев. Журналы на каждом узле относятся только к данному конкретному узлу и хранятся в **C:\\HDInsightLogs\\DeploymentAgent.log**. В эти файлы журналов записываются все выходные данные пользовательского скрипта. Фрагмент журнала для действия сценария Spark выглядит следующим образом:

	Microsoft.Hadoop.Deployment.Engine.CustomPowershellScriptCommand; Details : BEGIN: Invoking powershell script https://configactions.blob.core.windows.net/sparkconfigactions/spark-installer.ps1.;
	Version : 2.1.0.0;
	ActivityId : 739e61f5-aa22-4254-aafc-9faf56fc2692;
	AzureVMName : HEADNODE0;
	IsException : False;
	ExceptionType : ;
	ExceptionMessage : ;
	InnerExceptionType : ;
	InnerExceptionMessage : ;
	Exception : ;
	...

	Starting Spark installation at: 09/04/2014 21:46:02 Done with Spark installation at: 09/04/2014 21:46:38;

	Version : 2.1.0.0;
	ActivityId : 739e61f5-aa22-4254-aafc-9faf56fc2692;
	AzureVMName : HEADNODE0;
	IsException : False;
	ExceptionType : ;
	ExceptionMessage : ;
	InnerExceptionType : ;
	InnerExceptionMessage : ;
	Exception : ;
	...

	Microsoft.Hadoop.Deployment.Engine.CustomPowershellScriptCommand;
	Details : END: Invoking powershell script https://configactions.blob.core.windows.net/sparkconfigactions/spark-installer.ps1.;
	Version : 2.1.0.0;
	ActivityId : 739e61f5-aa22-4254-aafc-9faf56fc2692;
	AzureVMName : HEADNODE0;
	IsException : False;
	ExceptionType : ;
	ExceptionMessage : ;
	InnerExceptionType : ;
	InnerExceptionMessage : ;
	Exception : ;


Из данных журнала следует, что действие скрипта Spark было выполнено на виртуальной машине с именем HEADNODE0 и во время выполнения исключения не возникали.

В случае сбоя при выполнении, в файле журнала будут содержаться выходные данные со сведениями о нем. Информация в этих журналах может быть полезной при отладке сценария.


## См. также

- [Настройка кластеров HDInsight с помощью действия сценария][hdinsight-cluster-customize]
- [Установка и использование Spark в кластерах HDInsight][hdinsight-install-spark]
- [Установка и использование R в кластерах HDInsight][hdinsight-r-scripts]
- [Установка и использование Solr в кластерах HDInsight](hdinsight-hadoop-solr-install.md).
- [Установка и использование Giraph в кластерах HDInsight](hdinsight-hadoop-giraph-install.md).

[hdinsight-provision]: ../hdinsight-provision-clusters/
[hdinsight-cluster-customize]: ../hdinsight-hadoop-customize-cluster
[hdinsight-install-spark]: ../hdinsight-hadoop-spark-install/
[hdinsight-r-scripts]: ../hdinsight-hadoop-r-scripts/
[powershell-install-configure]: ../install-configure-powershell/

<!--Reference links in article-->
[1]: https://msdn.microsoft.com/library/96xafkes(v=vs.110).aspx

<!---HONumber=AcomDC_0211_2016-->