---
title: "Советы по использованию Hadoop в HDInsight на платформе Linux | Документация Майкрософт"
description: "Советы по использованию кластеров HDInsight (Hadoop) на базе Linux в привычной среде Linux, выполняемой в облаке Azure."
services: hdinsight
documentationcenter: 
author: Blackmist
manager: jhubbard
editor: cgronlun
tags: azure-portal
ms.assetid: c41c611c-5798-4c14-81cc-bed1e26b5609
ms.service: hdinsight
ms.devlang: na
ms.topic: article
ms.tgt_pltfrm: na
ms.workload: big-data
ms.date: 11/28/2016
ms.author: larryfr
translationtype: Human Translation
ms.sourcegitcommit: 854df55045d4d9a062ade3905b9be1daad0a7d8c
ms.openlocfilehash: 3ce0444427ba10e7247aec500017ea4bae3af161


---
# <a name="information-about-using-hdinsight-on-linux"></a>Сведения об использовании HDInsight в Linux

Кластеры Azure HDInsight под управлением Linux предоставляют Hadoop в привычной среде Linux, выполняемой в облаке Azure. Для большинства задач они должны работать так же, как и любые другие установки Hadoop в Linux. В этом документе рассматриваются определенные отличия, которые при этом следует учитывать.

## <a name="prerequisites"></a>Предварительные требования

При выполнении многих действий, описанных в этом документе, используются следующие служебные программы, которые может потребоваться установить в системе:

* [cURL](https://curl.haxx.se/) — используется для взаимодействия с веб-службами;
* [jq](https://stedolan.github.io/jq/) — используется для анализа документов JSON.
* [Azure CLI 2.0](https://docs.microsoft.com/cli/azure/install-az-cli2) (предварительная версия) используется для удаленного управления службами Azure.

## <a name="users"></a>Пользователи

Если кластер HDInsight не [присоединен к домену](hdinsight-domain-joined-introduction.md), его нужно рассматривать как **однопользовательскую** систему. В кластере создается отдельная учетная запись пользователя SSH с разрешениями уровня администратора. Можно создать и дополнительные учетные записи SSH, но им также предоставляются права администратора для доступа к кластеру.

Присоединенный к домену кластер HDInsight обеспечивает поддержку нескольких пользователей, а также более детализированные параметры разрешений и ролей. Дополнительные сведения см. в статье [Manage Domain-joined HDInsight clusters](hdinsight-domain-joined-manage.md) (Управление присоединенными к домену кластерами HDInsight).

## <a name="domain-names"></a>Имена доменов

При подключении к кластеру из Интернета следует использовать полное доменное имя (FQDN) **&lt;имя_кластера>.azurehdinsight.net** или (только для SSH) **&lt;имя_кластера_ssh>.azurehdinsight.net**.

На внутреннем уровне каждый узел в кластере имеет имя, назначаемое при конфигурации кластера. Чтобы найти имена кластеров, посетите страницу **Узлы** пользовательского веб-интерфейса Ambari или воспользуйтесь следующей командой, чтобы вернуть список узлов из REST API Ambari.

    curl -u admin:PASSWORD -G "https://CLUSTERNAME.azurehdinsight.net/api/v1/clusters/CLUSTERNAME/hosts" | jq '.items[].Hosts.host_name'

Замените параметр **PASSWORD** паролем учетной записи администратора, а **CLUSTERNAME** — именем своего кластера. Возвращает документ JSON, который содержит список узлов в кластере, а затем jq извлекает значение элемента `host_name` для каждого узла в кластере.

Если требуется найти имя узла для конкретной службы, можно запросить Ambari для этого компонента. Например, чтобы найти узлы для узла имен HDFS, воспользуйтесь следующей командой.

    curl -u admin:PASSWORD -G "https://CLUSTERNAME.azurehdinsight.net/api/v1/clusters/CLUSTERNAME/services/HDFS/components/NAMENODE" | jq '.host_components[].HostRoles.host_name'

Это возвращает документ JSON с описанием службы, а затем jq извлекает только значение `host_name` для узлов.

## <a name="remote-access-to-services"></a>Удаленный доступ к службам

* **Ambari (Интернет)** — https://&lt;имя_кластера>.azurehdinsight.net.

    Выполните аутентификацию, а затем войдите в Ambari. Используйте для этого имя пользователя и пароль администратора кластера.

    При аутентификации используется открытый текст. Всегда используйте протокол HTTPS, чтобы обеспечить безопасное подключение.

    > [!IMPORTANT]
    > Хотя Ambari для кластера доступен напрямую через Интернет, некоторые функциональные возможности зависят от доступа к узлам по внутреннему доменному имени, используемому в кластере. Так как это внутреннее доменное имя, а не общедоступное, вы получите ошибку "сервер не найден", если попытаетесь получить доступ к некоторым функциям сервера через Интернет.
    >
    > Чтобы получить доступ ко всем функциям веб-интерфейса Ambari, используйте туннелирование SSH для проксирования веб-трафика на головной узел кластера. Дополнительные сведения см. в статье [Использование туннелирования SSH для доступа к веб-интерфейсу Ambari, JobHistory, NameNode, Oozie и другим веб-интерфейсам](hdinsight-linux-ambari-ssh-tunnel.md).

* **Ambari (REST)** —https://&lt;имя_кластера>.azurehdinsight.net/ambari.

    > [!NOTE]
    > Выполните аутентификацию, используя имя пользователя и пароль администратора кластера.
    >
    > При аутентификации используется открытый текст. Всегда используйте протокол HTTPS, чтобы обеспечить безопасное подключение.

* **WebHCat (Templeton)** —https://&lt;имя_кластера>.azurehdinsight.net/templeton.

    > [!NOTE]
    > Выполните аутентификацию, используя имя пользователя и пароль администратора кластера.
    >
    > При аутентификации используется открытый текст. Всегда используйте протокол HTTPS, чтобы обеспечить безопасное подключение.

* **SSH** - &lt;имя_кластера>-ssh.azurehdinsight.net через порт 22 или 23. Для подключения к основному головному узлу используется порт 22, а для подключения к дополнительному — порт 23. Дополнительные сведения о головных узлах см. в статье [Доступность и надежность кластеров Hadoop в HDInsight](hdinsight-high-availability-linux.md).

    > [!NOTE]
    > Доступ к головным узлам кластера можно получить только по протоколу SSH с клиентского компьютера. После подключения с головного узла можно получить доступ к рабочим узлам по протоколу SSH.

## <a name="file-locations"></a>Местоположения файлов

Связанные с Hadoop файлы можно найти на узлах кластера в папке `/usr/hdp`. Этот каталог содержит следующие подкаталоги:

* **2.2.4.9-1.** Имя этого каталога соответствует версии платформы данных Hortonworks, используемой в HDInsight, поэтому номер в кластере может отличаться от указанного здесь.
* **current.** Этот каталог содержит ссылки на каталоги в каталоге **2.2.4.9-1** и существует для того, чтобы не приходилось вводить номер версии (который может измениться) каждый раз, когда нужно получить доступ к файлу.

Примеры данных и JAR-файлы можно найти в распределенной файловой системе Hadoop (HDFS) или в хранилище BLOB-объектов Azure в папке /example или wasbs:///example.

## <a name="hdfs-azure-blob-storage-and-storage-best-practices"></a>Рекомендации при работе с распределенной файловой системой Hadoop, хранилищем больших двоичных объектов Azure, а также рекомендации по использованию хранилища

В большинстве дистрибутив Hadoop распределенная файловая система Hadoop реализуется на базе локального хранилища на компьютерах в кластере. Несмотря на эффективность, в случае облачного решения с почасовой или поминутной платой за вычислительные ресурсы такой подход может оказаться весьма затратным.

HDInsight использует хранилище больших двоичных объектов Azure как хранилище по умолчанию, что дает следующие преимущества:

* недорогое долговременное хранение;
* доступность из внешних служб, например веб-сайтов, служебных программ для отправки или скачивания файлов, пакетов SDK для различных языков и веб-браузеров.

Поскольку это хранилище по умолчанию для HDInsight, в большинстве случаев его можно использовать без какой-либо специальной подготовки. Например, следующая команда отображает список файлов в папке **/example/data** , которая хранится в хранилище больших двоичных объектов Azure:

    hdfs dfs -ls /example/data

Возможно, для некоторых команд нужно будет указать, что вы используете хранилище больших двоичных объектов. Для этого можно добавить к команде префикс **wasb://** или **wasbs://**.

HDInsight также позволяет связать несколько учетных записей хранилища больших двоичных объектов с кластером. Для доступа к данным из учетной записи хранилища BLOB-объектов, отличной от заданной по умолчанию, можно использовать формат **wasbs://&lt;container-name>@&lt;имя_учетной_записи>.blob.core.windows.net/**. Например, ниже будет перечислено содержимое каталога **/example/data** для указанного контейнера и учетной записи хранилища больших двоичных объектов.

    hdfs dfs -ls wasbs://mycontainer@mystorage.blob.core.windows.net/example/data

### <a name="what-blob-storage-is-the-cluster-using"></a>Какие хранилища больших двоичных объектов используются в кластере

При создании кластера вы выбираете существующие учетную запись хранения Azure и контейнер, или можете создать новые. Если вы забудете, что именно выбрали, то сможете найти используемые по умолчанию учетную запись хранения и контейнер с помощью интерфейса API REST Ambari.

1. Для получения информации о конфигурации HDFS используйте команду curl и выполните фильтрацию с помощью [jq](https://stedolan.github.io/jq/):

        curl -u admin:PASSWORD -G "https://CLUSTERNAME.azurehdinsight.net/api/v1/clusters/CLUSTERNAME/configurations/service_config_versions?service_name=HDFS&service_config_version=1" | jq '.items[].configurations[].properties["fs.defaultFS"] | select(. != null)'

    > [!NOTE]
    > Эта команда возвращает первую конфигурацию, применяемую к серверу (`service_config_version=1`), который будет содержать эти сведения. Чтобы получить значение, которое было изменено после создания кластера, может потребоваться перечислить версии конфигурации и получить последнюю из них.

    В результате возвращается значение, аналогичное приведенному ниже, где **CONTAINER** — это контейнер по умолчанию, а **ACCOUNTNAME** — имя учетной записи хранения Azure.

        wasbs://CONTAINER@ACCOUNTNAME.blob.core.windows.net

2. Для получения уникального идентификатора для учетной записи хранения воспользуйтесь следующей командой. В следующей команде замените **ACCOUNTNAME** именем учетной записи хранения, полученным из Ambari.

        az storage account list --query "[?name=='ACCOUNTNAME'].id --out list

3. Для получения ключа для учетной записи хранения воспользуйтесь следующей командой. Замените **STORAGEID** идентификатором учетной записи хранения.

        az storage account keys list --ids STORAGEID --out list

    Эта команда возвращает первичный ключ для учетной записи.

Сведения о хранилище также можно найти на портале Azure.

1. На [портале Azure](https://portal.azure.com/)выберите свой кластер HDInsight.
2. В разделе **Основное** выберите **Все параметры**.
3. В разделе **Параметры** выберите **Ключи к хранилищу Azure**.
4. В разделе **Ключи к хранилищу Azure** выберите одну из перечисленных учетных записей хранения. Отобразится информация о выбранной учетной записи хранения.
5. Щелкните значок ключа. Отобразятся ключи для этой учетной записи хранения.

### <a name="how-do-i-access-blob-storage"></a>Как получить доступ к хранилищу больших двоичных объектов

Получить доступ к большим двоичным объектам можно не только с помощью команды Hadoop из кластера, но и множеством других способов:

* [Azure CLI 2.0](https://docs.microsoft.com/cli/azure/install-az-cli2) — это набор команд интерфейса командной строки для работы с Azure. После установки используйте команду `az storage` для получения информации по использованию хранилища, а команду `az storage blob` — для получения информации о больших двоичных объектах.
* [blobxfer.py](https://github.com/Azure/azure-batch-samples/tree/master/Python/Storage)— cценарий Python для работы с большими двоичными объектами в хранилище Azure.
* Различные пакеты SDK:

    * [Java](https://github.com/Azure/azure-sdk-for-java)
    * [Node.js](https://github.com/Azure/azure-sdk-for-node)
    * [PHP](https://github.com/Azure/azure-sdk-for-php)
    * [Python](https://github.com/Azure/azure-sdk-for-python)
    * [Ruby](https://github.com/Azure/azure-sdk-for-ruby)
    * [.NET](https://github.com/Azure/azure-sdk-for-net)
    * [REST API службы хранилища](https://msdn.microsoft.com/library/azure/dd135733.aspx)

## <a name="a-namescalingascaling-your-cluster"></a><a name="scaling"></a>Масштабирование кластера

Масштабирование кластера позволяет вам изменить число узлов данных в кластере, который работает в Azure HDInsight. При этом не требуется удалять и повторно создавать кластер.

Операции масштабирования можно выполнять параллельно с другими заданиями и процессами, выполняющимися в кластере.

Масштабирование влияет на разные типы кластеров по-разному:

* **Hadoop.** При уменьшении количества узлов в кластере некоторые службы в нем перезапускаются. Это может привести к сбою всех выполняющихся и ожидающих заданий при завершении операции масштабирования. После завершения операции вы можете повторно отправить задания.
* **HBase.** В течение нескольких минут после завершения операции масштабирования автоматически выполняется балансировка нагрузки на региональные серверы. Чтобы вручную распределить нагрузку между региональными серверами, выполните следующие действия.

    1. Подключитесь к кластеру HDInsight по протоколу SSH. Дополнительные сведения об использовании SSH с HDInsight см. в следующих статьях:

        * [Использование SSH с HDInsight в Linux, Unix и Mac OS X](hdinsight-hadoop-linux-use-ssh-unix.md)
        * [Использование SSH с Hadoop на основе Linux в HDInsight из Windows](hdinsight-hadoop-linux-use-ssh-windows.md)

    2. Чтобы запустить оболочку HBase, используйте следующую команду:

            hbase shell
    
    3. После загрузки оболочки HBase запустите балансировку нагрузки между региональными серверами вручную, используя следующую команду:

            balancer

* **Storm.** После завершения операции масштабирования следует запустить повторную балансировку для всех запущенных топологий Storm. Это позволяет настроить параметры параллелизма для топологий на основе нового количества узлов в кластере. Чтобы повторно выполнить балансировку выполняющихся топологий, используйте один из следующих вариантов.

    * **SSH.** Подключитесь к серверу и запустите балансировку для топологии, используя следующую команду.

            storm rebalance TOPOLOGYNAME

        Можно также указать параметры для переопределения подсказок параллелизма, изначально предоставляемых топологией. Например, `storm rebalance mytopology -n 5 -e blue-spout=3 -e yellow-bolt=10` перенастроит топологию с учетом 5 рабочих процессов, 3 исполнителей для компонента blue-spout и 10 исполнителей для компонента yellow-bolt.

    * **Пользовательский интерфейс Storm.** Чтобы запустить балансировку для топологии из интерфейса Storm, выполните следующие действия.

        1. Откройте в веб-браузере страницу с адресом **https://CLUSTERNAME.azurehdinsight.net/stormui**, где CLUSTERNAME — имя вашего кластера Storm. При появлении запроса введите имя администратора кластера HDInsight (admin) и пароль, указанный при создании кластера.
        2. Выберите топологию, для которой нужно выполнить повторную балансировку, и нажмите кнопку **Перераспределить**. Введите задержку перед выполнением операции перебалансировки.

Подробные сведения о масштабировании кластера HDInsight см. в следующих статьях.

* [Управление кластерами Hadoop в HDInsight с помощью портала Azure](hdinsight-administer-use-portal-linux.md#scale-clusters)
* [Управление кластерами Hadoop в HDInsight с помощью интерфейса командной строки (CLI) Azure](hdinsight-administer-use-command-line.md#scale-clusters)

## <a name="how-do-i-install-hue-or-other-hadoop-component"></a>Как установить Hue (или другой компонент Hadoop)?

HDInsight — управляемая служба. Это означает, что при возникновении проблемы Azure может автоматически удалить и повторно подготовить узлы в кластере. Поэтому не рекомендуется вручную устанавливать компоненты непосредственно на узлах кластера. При необходимости установить указанные ниже компоненты используйте [действия скрипта HDInsight](hdinsight-hadoop-customize-cluster.md).

* Служба или веб-сайт, например Spark или Hue.
* Компонент, для которого необходимо изменить конфигурацию на нескольких узлах кластера. Например, обязательная переменная среды, создание каталога ведения журналов или создание файла конфигурации.

Действия сценариев — это сценарии Bash, которые выполняются при подготовке кластера и которые можно использовать для установки и настройки дополнительных компонентов в кластере. Доступны примеры скриптов для установки следующих компонентов:

* [Hue](hdinsight-hadoop-hue-linux.md)
* [Giraph](hdinsight-hadoop-giraph-install-linux.md)
* [Solr](hdinsight-hadoop-solr-install-linux.md)

Сведения о разработке собственных действий скриптов см. в статье [Разработка действий сценариев с помощью HDInsight](hdinsight-hadoop-script-actions-linux.md).

### <a name="jar-files"></a>JAR-файлы

Некоторые технологии Hadoop предоставляются в автономных JAR-файлах, которые содержат функции, используемые в рамках задания MapReduce или из Pig и Hive. Несмотря на то что их можно установить с помощью действий сценариев, зачастую они не требуют установки. После подготовки можно просто отправить их в кластер для непосредственного использования. Если вы хотите, чтобы компонент не исчез при повторном создании образа кластера, можно сохранить JAR-файл в WASB.

Например, если необходимо использовать последнюю версию [DataFu](http://datafu.incubator.apache.org/), можно скачать JAR-файл, содержащий проект, и отправить его в кластер HDInsight. Далее следуйте инструкциям в документации для DataFu по использованию его в Pig или Hive.

> [!IMPORTANT]
> Некоторые компоненты, представляющие собой автономные JAR-файлы, предоставляются вместе с HDInsight, но не в пути. Если вам необходим определенный компонент, можно выполнить его поиск в кластере.
>
> ```find / -name *componentname*.jar 2>/dev/null```
>
> В результате выполнения этой команды будут возвращены пути к соответствующим JAR-файлам.

Если кластер уже содержит версию компонента в виде автономного JAR-файла, но вам необходимо использовать другую версию, вы можете отправить новую версию компонента в кластер и попробовать использовать его в ваших заданиях.

> [!WARNING]
> Компоненты, предоставляемые вместе с кластером HDInsight, поддерживаются в полном объеме. Техническая поддержка Майкрософт поможет вам выявить и решить проблемы, связанные с этими компонентами.
>
> Настраиваемые компоненты получают ограниченную коммерчески оправданную поддержку, способствующую дальнейшей диагностике проблемы. В результате проблема может быть устранена, либо вас могут попросить воспользоваться доступными каналами по технологиям с открытым исходным кодом, чтобы связаться с экспертами в данной области. Можно использовать ряд сайтов сообществ, например [форум MSDN по HDInsight](https://social.msdn.microsoft.com/Forums/azure/en-US/home?forum=hdinsight) или [http://stackoverflow.com](http://stackoverflow.com). Кроме того, проекты Apache можно просмотреть на соответствующих сайтах по адресу [http://apache.org](http://apache.org), например для [Hadoop](http://hadoop.apache.org/) и [Spark](http://spark.apache.org/).

## <a name="next-steps"></a>Дальнейшие действия

* [Миграция из кластера HDInsight под управлением Windows в кластер HDInsight под управлением Linux](hdinsight-migrate-from-windows-to-linux.md)
* [Использование Hive с HDInsight](hdinsight-use-hive.md)
* [Использование Pig с HDInsight](hdinsight-use-pig.md)
* [Использование заданий MapReduce с HDInsight](hdinsight-use-mapreduce.md)



<!--HONumber=Dec16_HO1-->


