<properties
   pageTitle="Советы по использованию Hadoop в HDInsight на платформе Linux | Microsoft Azure"
   description="Советы по использованию кластеров HDInsight (Hadoop) на базе Linux в привычной среде Linux, выполняемой в облаке Azure."
   services="hdinsight"
   documentationCenter=""
   authors="Blackmist"
   manager="paulettm"
   editor="cgronlun"
	tags="azure-portal"/>

<tags
   ms.service="hdinsight"
   ms.devlang="na"
   ms.topic="article"
   ms.tgt_pltfrm="na"
   ms.workload="big-data"
   ms.date="08/12/2015"
   ms.author="larryfr"/>

# Сведения об использовании HDInsight в Linux

Кластеры Azure HDInsight под управлением Linux предоставляют Hadoop в привычной среде Linux, выполняемой в облаке Azure. Для большинства задач они должны работать так же, как и любые другие установки Hadoop в Linux. В этом документе рассматриваются определенные отличия, которые при этом следует учитывать.

## Имена доменов

При подключении к кластеру следует использовать полное доменное имя (FQDN) **&lt;имя\_кластера>.azurehdinsight.net** или (только для SSH) **&lt;имя\_кластера>.aurehdinsight.net**.

## Удаленный доступ к службам

* **Ambari (веб-версия)** — https://&lt;clustername>.azurehdinsight.net

	Выполните аутентификацию, а затем войдите в Ambari. Используйте для этого имя пользователя и пароль администратора кластера.

	При аутентификации используется открытый текст. Всегда используйте протокол HTTPS, чтобы обеспечить безопасное подключение.

	> [AZURE.IMPORTANT]Хотя Ambari для кластера доступен напрямую через Интернет, некоторые функциональные возможности зависят от доступа к узлам по внутреннему доменному имени, используемому в кластере. Так как это внутреннее доменное имя, а не общедоступное, вы получите ошибку "сервер не найден", если попытаетесь получить доступ к некоторым функциям сервера через Интернет.
	>
	> Чтобы получить доступ ко всем функциям веб-интерфейса Ambari, используйте туннелирование SSH для проксирования веб-трафика на головной узел кластера. Дополнительные сведения см. в статье [Использование туннелирования SSH для доступа к веб-интерфейсу Ambari, ResourceManager, JobHistory, NameNode, Oozie и другим веб-интерфейсам](hdinsight-linux-ambari-ssh-tunnel.md).

* **Ambari (REST)** — https://&lt;clustername>.azurehdinsight.net/ambari

	> [AZURE.NOTE]Выполните аутентификацию, используя имя пользователя и пароль администратора кластера.
	>
	> При аутентификации используется открытый текст. Всегда используйте протокол HTTPS, чтобы обеспечить безопасное подключение.

* **WebHCat (Templeton)** — https://&lt;clustername>.azurehdinsight.net/templeton

	> [AZURE.NOTE]Выполните аутентификацию, используя имя пользователя и пароль администратора кластера.
	>
	> При аутентификации используется открытый текст. Всегда используйте протокол HTTPS, чтобы обеспечить безопасное подключение.

* **SSH** — &lt;имя\_кластера>-ssh.azurehdinsight.net через порт 22 или 23. Для подключения к headnode0 используется порт 22, а для подключения к headnode1 — порт 23. Дополнительные сведения о головных узлах см. в статье [Доступность и надежность кластеров Hadoop в HDInsight](hdinsight-high-availability-linux.md).

	> [AZURE.NOTE]Доступ к головным узлам кластера можно получить только по протоколу SSH с клиентского компьютера. После подключения с головного узла можно получить доступ к рабочим узлам по протоколу SSH.

## Местоположения файлов

Связанные с Hadoop файлы можно найти на узлах кластера в папке `/usr/hdp`. Этот каталог содержит следующие подкаталоги:

* __2.2.4.9-1__. Имя этого каталога соответствует версии платформы данных Hortonworks, используемой в HDInsight, поэтому номер в кластере может отличаться от указанного здесь.
* __Current__. Этот каталог содержит ссылки на каталоги в каталоге __2.2.4.9-1__ и существует для того, чтобы не приходилось вводить номер версии (который может измениться) каждый раз, когда нужно получить доступ к файлу.

Примеры данных и JAR-файлы можно найти в распределенной файловой системе Hadoop или в хранилище больших двоичных объектов Azure в папке /example или wasb:///example.

## Рекомендации при работе с распределенной файловой системой Hadoop, хранилищем больших двоичных объектов Azure, а также рекомендации по использованию хранилища

В большинстве дистрибутив Hadoop распределенная файловая система Hadoop реализуется на базе локального хранилища на компьютерах в кластере. Несмотря на эффективность, в случае облачного решения с почасовой платой за вычислительные ресурсы такой подход может оказаться весьма затратным.

HDInsight использует хранилище больших двоичных объектов Azure как хранилище по умолчанию, что дает следующие преимущества:

* недорогое долговременное хранение;

* доступность из внешних служб, например веб-сайтов, служебных программ для отправки или скачивания файлов, пакетов SDK для различных языков и веб-браузеров.

Поскольку это хранилище по умолчанию для HDInsight, в большинстве случаев его можно использовать без какой-либо специальной подготовки. Например, следующая команда отображает список файлов в папке **/example/data**, которая хранится в хранилище больших двоичных объектов Azure:

	hadoop fs -ls /example/data

Возможно, для некоторых команд нужно будет указать, что вы используете хранилище больших двоичных объектов. Для этого можно добавить к команде префикс ****WASB://**.

HDInsight также позволяет связать несколько учетных записей хранилища больших двоичных объектов с кластером. Для доступа к данным из учетной записи хранилища больших двоичных объектов, отличной от заданной по умолчанию, можно использовать формат **WASB://&lt;container-name>@&lt;имя\_учетной\_записи>.blob.core.windows.net/**. Например, ниже будет перечислено содержимое каталога **/example/data** для указанного контейнера и учетной записи хранилища больших двоичных объектов.

	hadoop fs -ls wasb://mycontainer@mystorage.blob.core.windows.net/example/data

### Какие хранилища больших двоичных объектов используются в кластере

При создании кластера вы выбираете существующие учетную запись хранения Azure и контейнер, или можете создать новые. Если вы забудете, что именно выбрали, то сможете найти используемые по умолчанию учетную запись хранения и контейнер с помощью интерфейса API REST Ambari.

1. Для получения информации о конфигурации HDFS используйте следующую команду:

        curl -u admin:PASSWORD -G "https://CLUSTERNAME.azurehdinsight.net/api/v1/clusters/CLUSTERNAME/configurations/service_config_versions?service_name=HDFS&service_config_version=1"

2. В возвращенных данных JSON найдите запись `fs.defaultFS`. В ней содержатся контейнер по умолчанию и имя учетной записи хранения в формате, аналогичному следующему:

        wasb://CONTAINTERNAME@STORAGEACCOUNTNAME.blob.core.windows.net

	> [AZURE.TIP]Если вы установили [jq](http://stedolan.github.io/jq/), следующее можно использовать только для возврата записи `fs.defaultFS`:
	>
	> `curl -u admin:PASSWORD -G "https://CLUSTERNAME.azurehdinsight.net/api/v1/clusters/CLUSTERNAME/configurations/service_config_versions?service_name=HDFS&service_config_version=1" | jq '.items[].configurations[].properties["fs.defaultFS"] | select(. != null)'`

3. Чтобы найти ключ, используемый для проверки подлинности учетной записи хранения, или найти все вторичные учетные записи хранения, связанные с кластером, используйте следующую команду:

		curl -u admin:PASSWORD -G "https://CLUSTERNAME.azurehdinsight.net/api/v1/clusters/CLUSTERNAME/configurations/service_config_versions?service_name=HDFS&service_config_version=1"

4. В возвращенных данных JSON найдите запись, которая начинается с `fs.azure.account.key`. Остаток имени записи является именем учетной записи хранения. Например, `fs.azure.account.key.mystorage.blob.core.windows.net`. Значение, хранящееся в этой записи, является ключом, используемым для проверки подлинности учетной записи хранения.

	> [AZURE.TIP]Если вы установили [jq](http://stedolan.github.io/jq/), вы можете использовать следующую команду, чтобы вернуть список ключей и значений:
	>
	> `curl -u admin:PASSWORD -G "https://CLUSTERNAME.azurehdinsight.net/api/v1/clusters/CLUSTERNAME/configurations/service_config_versions?service_name=HDFS&service_config_version=1" | jq '.items[].configurations[].properties as $in | $in | keys[] | select(. | contains("fs.azure.account.key.")) as $item | $item | ltrimstr("fs.azure.account.key.") | { storage_account: ., storage_account_key: $in[$item] }'`

Сведения о хранении также можно найти на портале предварительной версии Azure.

1. На [портале предварительной версии Azure](https://portal.azure.com/) выберите свой кластер HDInsight.

2. В разделе __Основные сведения__ нажмите кнопку __Все параметры__.

3. В разделе __Параметры__ выберите __Ключи к хранилищу Azure__.

4. В разделе __Ключи к хранилищу Azure__ выберите одну из перечисленных учетных записей хранения. Отобразится информация о выбранной учетной записи хранения.

5. Щелкните значок ключа. Отобразятся ключи для этой учетной записи хранения.

### Как получить доступ к хранилищу больших двоичных объектов

Получить доступ к большим двоичным объектам можно не только с помощью команды Hadoop из кластера, но и множеством других способов:

* [CLI Azure для Mac, Linux и Windows](../xplat-cli.md) — это набор кроссплатформенных команд для работы с Azure. После установки используйте команду `azure storage` для получения информации по использованию хранилища, а команду `azure blob` — для получения информации о больших двоичных объектах.

* [blobxfer.py](https://github.com/Azure/azure-batch-samples/tree/master/Python/Storage) — cценарий Python для работы с большими двоичными объектами в хранилище Azure.

* Различные пакеты SDK:

	* [Java](https://github.com/Azure/azure-sdk-for-java)

	* [Node.js](https://github.com/Azure/azure-sdk-for-node)

	* [PHP](https://github.com/Azure/azure-sdk-for-php)

	* [Python](https://github.com/Azure/azure-sdk-for-python)

	* [Ruby](https://github.com/Azure/azure-sdk-for-ruby)

	* [.NET](https://github.com/Azure/azure-sdk-for-net)

* [REST API службы хранилища](https://msdn.microsoft.com/library/azure/dd135733.aspx)

##<a name="scaling"></a>Масштабирование кластера

Масштабирование кластера позволяет вам изменить число узлов данных в кластере, который работает в Azure HDInsight. При этом не требуется удалять и повторно создавать кластер.

Операции масштабирования можно выполнять параллельно с другими заданиями и процессами, выполняющимися в кластере.

Масштабирование влияет на разные типы кластеров по-разному:

* __Hadoop__. При уменьшении количества узлов в кластере некоторые службы в нем перезапускаются. Это может привести к сбою всех выполняющихся и ожидающих заданий при завершении операции масштабирования. После завершения операции вы можете повторно отправить задания.

* __HBase__. В течение нескольких минут после завершения операции масштабирования автоматически выполняется балансировка нагрузки на региональные серверы. Чтобы вручную распределить нагрузку между региональными серверами, выполните следующие действия.

	1. Подключитесь к кластеру HDInsight по протоколу SSH. Дополнительные сведения об использовании SSH с HDInsight см. в следующих статьях:

		* [Использование SSH с HDInsight в Linux, Unix и Mac OS X](hdinsight-hadoop-linux-use-ssh-unix.md)

		* [Использование SSH с HDInsight в Windows](hdinsight-hadoop-linux-use-ssh-windows.md)

	1. Чтобы запустить оболочку HBase, используйте следующую команду:

			hbase shell

	2. После загрузки оболочки HBase запустите балансировку нагрузки между региональными серверами вручную, используя следующую команду:

			balancer

* __Storm__. После завершения операции масштабирования следует запустить повторную балансировку для всех запущенных топологий Storm. Это позволяет настроить параметры параллелизма для топологий на основе нового количества узлов в кластере. Чтобы повторно выполнить балансировку выполняющихся топологий, используйте один из следующих вариантов.

	* __SSH__. Подключитесь к серверу и запустите балансировку для топологии, используя следующую команду:

			storm rebalance TOPOLOGYNAME

		Можно также указать параметры для переопределения подсказок параллелизма, изначально предоставляемых топологией. Например, `storm rebalance mytopology -n 5 -e blue-spout=3 -e yellow-bolt=10` перенастроит топологию с учетом 5 рабочих процессов, 3 исполнителей для компонента blue-spout и 10 исполнителей для компонента yellow-bolt.

	* __Пользовательский интерфейс Storm__. Чтобы запустить балансировку для топологии из интерфейса Storm, выполните следующие действия.

		1. [Создайте туннель SSH в кластер и откройте веб-интерфейс Ambari](hdinsight-linux-ambari-ssh-tunnel.md).

		2. В списке служб в левой части страницы выберите __Storm__. Затем выберите элемент __Пользовательский интерфейс Storm__ в меню __Быстрые ссылки__.

			![Запись "Пользовательский интерфейс Storm" в меню "Быстрые ссылки"](./media/hdinsight-hadoop-linux-information/ambari-storm.png)

			Отобразится веб-интерфейс Storm:

			![пользовательский интерфейс storm](./media/hdinsight-hadoop-linux-information/storm-ui.png)

		3. Выберите топологию, для которой нужно выполнить повторную балансировку, и нажмите кнопку __Перераспределить__. Введите задержку перед выполнением операции перебалансировки.

Подробные сведения о масштабировании кластера HDInsight см. в следующих статьях.

* [Управление кластерами Hadoop в HDInsight с помощью портала предварительной версии Azure](hdinsight-administer-use-portal-linux.md#scaling)

* [Управление кластерами Hadoop в HDInsight с помощью Azure PowerShell](hdinsight-administer-use-command-line.md#scaling)

## Как установить Hue (или другой компонент Hadoop)?

HDInsight — управляемая служба. Это означает, что при возникновении проблемы Azure может автоматически удалить и повторно подготовить узлы в кластере. Поэтому не рекомендуется вручную устанавливать компоненты непосредственно на узлах кластера. При необходимости установить указанные ниже компоненты используйте [действия сценариев HDInsight](hdinsight-hadoop-customize-cluster.md).

* Служба или веб-сайт, например Spark или Hue.
* Компонент, для которого необходимо изменить конфигурацию на нескольких узлах кластера. Например, обязательная переменная среды, создание каталога ведения журналов или создание файла конфигурации.

Действия сценариев — это сценарии Bash, которые выполняются при подготовке кластера и которые можно использовать для установки и настройки дополнительных компонентов в кластере. Доступны примеры скриптов для установки следующих компонентов:

* [Hue](hdinsight-hadoop-hue-linux.md)
* [Giraph](hdinsight-hadoop-giraph-install-linux.md)
* [R](hdinsight-hadoop-r-scripts-linux.md)
* [Solr](hdinsight-hadoop-solr-install-linux.md)
* [Spark](hdinsight-hadoop-spark-install-linux.md)

Сведения о разработке собственных действий сценариев см. в статье [Разработка действий сценариев с помощью HDInsight](hdinsight-hadoop-script-actions-linux.md).

###JAR-файлы

Некоторые технологии Hadoop предоставляются в автономных JAR-файлах, которые содержат функции, используемые в рамках задания MapReduce или из Pig и Hive. Несмотря на то что их можно установить с помощью действий сценариев, зачастую они не требуют установки. После подготовки можно просто отправить их в кластер для непосредственного использования. Если вы хотите, чтобы компонент не исчез при повторном создании образа кластера, можно сохранить JAR-файл в WASB.

Например, если необходимо использовать последнюю версию [DataFu](http://datafu.incubator.apache.org/), можно скачать JAR-файл, содержащий проект, и отправить его в кластер HDInsight. Далее следуйте инструкциям в документации для DataFu по использованию его в Pig или Hive.

> [AZURE.IMPORTANT]Некоторые компоненты, представляющие собой автономные JAR-файлы, предоставляются вместе с HDInsight, но не в пути. Если вам необходим определенный компонент, можно выполнить его поиск в кластере.
>
> ```find / -name *componentname*.jar 2>/dev/null```
>
> В результате выполнения этой команды будут возвращены пути к соответствующим JAR-файлам.

Если кластер уже содержит версию компонента в виде автономного JAR-файла, но вам необходимо использовать другую версию, вы можете отправить новую версию компонента в кластер и попробовать использовать его в ваших заданиях.

> [AZURE.WARNING]Компоненты, предоставляемые вместе с кластером HDInsight, поддерживаются в полном объеме. Техническая поддержка Майкрософт поможет вам выявить и решить проблемы, связанные с этими компонентами.
>
> Настраиваемые компоненты получают ограниченную коммерчески оправданную поддержку, способствующую дальнейшей диагностике проблемы. В результате проблема может быть устранена, либо вас могут попросить воспользоваться доступными каналами по технологиям с открытым исходным кодом, чтобы связаться с экспертами в данной области. Можно использовать сайты сообществ, например [форум MSDN по HDInsight](https://social.msdn.microsoft.com/Forums/azure/ru-RU/home?forum=hdinsight) и [http://stackoverflow.com](http://stackoverflow.com). Кроме того, для проектов Apache есть соответствующие сайты по-адресу [http://apache.org](http://apache.org), например для [Hadoop](http://hadoop.apache.org/) и [Spark](http://spark.apache.org/).

## Дальнейшие действия

* [Использование Hive с HDInsight](hdinsight-use-hive.md)
* [Использование Pig с HDInsight](hdinsight-use-pig.md)
* [Использование заданий MapReduce с HDInsight](hdinsight-use-mapreduce.md)

<!---HONumber=Sept15_HO4-->