---
title: "Советы по использованию Hadoop в HDInsight на платформе Linux в Azure | Документация Майкрософт"
description: "Советы по использованию кластеров HDInsight (Hadoop) на базе Linux в привычной среде Linux, выполняемой в облаке Azure."
services: hdinsight
documentationcenter: 
author: Blackmist
manager: jhubbard
editor: cgronlun
tags: azure-portal
ms.assetid: c41c611c-5798-4c14-81cc-bed1e26b5609
ms.service: hdinsight
ms.custom: hdinsightactive
ms.devlang: na
ms.topic: article
ms.tgt_pltfrm: na
ms.workload: big-data
ms.date: 10/04/2017
ms.author: larryfr
ms.openlocfilehash: 29f245fdeaadd6f95755f7fd7564dfa7f6b2981f
ms.sourcegitcommit: 6699c77dcbd5f8a1a2f21fba3d0a0005ac9ed6b7
ms.translationtype: HT
ms.contentlocale: ru-RU
ms.lasthandoff: 10/11/2017
---
# <a name="information-about-using-hdinsight-on-linux"></a>Сведения об использовании HDInsight в Linux

Кластеры Azure HDInsight предоставляют Hadoop в привычной среде Linux, выполняемой в облаке Azure. Для большинства задач они должны работать так же, как и любые другие установки Hadoop в Linux. В этом документе рассматриваются определенные отличия, которые при этом следует учитывать.

> [!IMPORTANT]
> Linux — это единственная операционная система, используемая для работы с HDInsight 3.4 или более поздних версий. Дополнительные сведения см. в разделе [Приближается дата прекращения сопровождения HDI версии 3.3](hdinsight-component-versioning.md#hdinsight-windows-retirement).

## <a name="prerequisites"></a>Предварительные требования

При выполнении многих действий, описанных в этом документе, используются следующие служебные программы, которые может потребоваться установить в системе:

* [cURL](https://curl.haxx.se/) — используется для взаимодействия с веб-службами;
* [jq](https://stedolan.github.io/jq/) — используется для анализа документов JSON.
* [Azure CLI 2.0](https://docs.microsoft.com/cli/azure/install-az-cli2) (предварительная версия) используется для удаленного управления службами Azure.

## <a name="users"></a>Пользователи

Если кластер HDInsight не [присоединен к домену](hdinsight-domain-joined-introduction.md), его нужно рассматривать как **однопользовательскую** систему. В кластере создается отдельная учетная запись пользователя SSH с разрешениями уровня администратора. Можно создать и дополнительные учетные записи SSH, но им также предоставляются права администратора для доступа к кластеру.

Присоединенный к домену кластер HDInsight поддерживает несколько пользователей, а также более детализированные параметры разрешений и ролей. Дополнительные сведения см. в статье [Manage Domain-joined HDInsight clusters](hdinsight-domain-joined-manage.md) (Управление присоединенными к домену кластерами HDInsight).

## <a name="domain-names"></a>Имена доменов

При подключении к кластеру из Интернета следует использовать полное доменное имя (FQDN) **&lt;имя_кластера>.azurehdinsight.net** или (только для SSH) **&lt;имя_кластера_ssh>.azurehdinsight.net**.

На внутреннем уровне каждый узел в кластере имеет имя, назначаемое при конфигурации кластера. Имена кластеров вы найдете на странице **Hosts** (Узлы) в веб-интерфейсе Ambari. Список узлов можно также получить через интерфейс REST API Ambari следующим образом:

    curl -u admin -G "https://CLUSTERNAME.azurehdinsight.net/api/v1/clusters/CLUSTERNAME/hosts" | jq '.items[].Hosts.host_name'

Замените **CLUSTERNAME** именем кластера. При появлении запроса введите пароль для учетной записи администратора. Эта команда возвращает документ JSON, который содержит список узлов в кластере. Программа jq извлекает значение элемента `host_name` для каждого узла.

Если требуется найти имя узла для конкретной службы, можно запросить Ambari для этого компонента. Например, чтобы найти узлы для узла имен HDFS, выполните следующую команду:

    curl -u admin -G "https://CLUSTERNAME.azurehdinsight.net/api/v1/clusters/CLUSTERNAME/services/HDFS/components/NAMENODE" | jq '.host_components[].HostRoles.host_name'

Эта команда возвращает документ JSON с описанием службы, а затем программа jq извлекает только значения `host_name` для всех узлов.

## <a name="remote-access-to-services"></a>Удаленный доступ к службам

* **Ambari (Интернет)** — https://&lt;имя_кластера>.azurehdinsight.net.

    Выполните аутентификацию, а затем войдите в Ambari.

    При аутентификации используется открытый текст. Всегда используйте протокол HTTPS, чтобы обеспечить безопасное подключение.

    > [!IMPORTANT]
    > Некоторые веб-интерфейсы, предоставляемые через узлы Ambari, используют внутреннее доменное имя. Внутренние доменные имена не доступны из Интернета. Вы можете получать ошибку "сервер не найден" при обращении к некоторым функциям через Интернет.
    >
    > Чтобы получить доступ ко всем функциям веб-интерфейса Ambari, используйте туннелирование SSH для проксирования веб-трафика на головной узел кластера. Дополнительные сведения см. в статье [Использование туннелирования SSH для доступа к веб-интерфейсу Ambari, JobHistory, NameNode, Oozie и другим веб-интерфейсам](hdinsight-linux-ambari-ssh-tunnel.md).

* **Ambari (REST)** —https://&lt;имя_кластера>.azurehdinsight.net/ambari.

    > [!NOTE]
    > Выполните аутентификацию, используя имя пользователя и пароль администратора кластера.
    >
    > При аутентификации используется открытый текст. Всегда используйте протокол HTTPS, чтобы обеспечить безопасное подключение.

* **WebHCat (Templeton)** —https://&lt;имя_кластера>.azurehdinsight.net/templeton.

    > [!NOTE]
    > Выполните аутентификацию, используя имя пользователя и пароль администратора кластера.
    >
    > При аутентификации используется открытый текст. Всегда используйте протокол HTTPS, чтобы обеспечить безопасное подключение.

* **SSH** - &lt;имя_кластера>-ssh.azurehdinsight.net через порт 22 или 23. Для подключения к основному головному узлу используется порт 22, а для подключения к дополнительному — порт 23. Дополнительные сведения о головных узлах см. в статье [Доступность и надежность кластеров Hadoop в HDInsight](hdinsight-high-availability-linux.md).

    > [!NOTE]
    > Доступ к головным узлам кластера можно получить только по протоколу SSH с клиентского компьютера. После подключения с головного узла можно получить доступ к рабочим узлам по протоколу SSH.

## <a name="file-locations"></a>Местоположения файлов

Связанные с Hadoop файлы можно найти на узлах кластера в папке `/usr/hdp`. Этот каталог содержит следующие подкаталоги:

* **2.2.4.9-1** — именем каталога является версия платформы данных Hortonworks, используемая HDInsight. Это число для вашего кластера может отличаться от указанного здесь.
* **current** — этот каталог содержит ссылки на подкаталоги в каталоге **2.2.4.9-1**. Он позволяет вам не запоминать номер версии.

Примеры данных и JAR-файлы можно найти в распределенной файловой системе Hadoop в папках `/example` и `/HdiSamples`.

## <a name="hdfs-azure-storage-and-data-lake-store"></a>HDFS, служба хранилища Azure и Data Lake Store

В большинстве дистрибутив Hadoop распределенная файловая система Hadoop реализуется на базе локального хранилища на компьютерах в кластере. Использование локального хранилища в случае облачного решения с почасовой или поминутной платой за вычислительные ресурсы может оказаться весьма затратным.

В качестве хранилища по умолчанию HDInsight использует большие двоичные объекты в службе хранилища Azure или Azure Data Lake Store. Эти службы предоставляют следующие преимущества:

* недорогое долговременное хранение;
* доступность из внешних служб, например веб-сайтов, служебных программ для отправки или скачивания файлов, пакетов SDK для различных языков и веб-браузеров.

> [!WARNING]
> HDInsight поддерживает только учетные записи хранения Azure __общего назначения__. Учетные записи __хранилища BLOB-объектов__ сейчас не поддерживаются.

Учетная запись хранения Azure может содержать до 4,75 ТБ, хотя размер отдельных больших двоичных объектов (то есть файлов с точки зрения HDInsight) не должен превышать 195 ГБ. Хранилище Azure Data Lake Store может динамически увеличиваться и вмещать несколько триллионов файлов, размер любого из которых может быть более петабайта. Подробные сведения см. в [статье о больших двоичных объектах](https://docs.microsoft.com/rest/api/storageservices/understanding-block-blobs--append-blobs--and-page-blobs) и в описании [Data Lake Store](https://azure.microsoft.com/services/data-lake-store/).

Если вы используете службу хранилища Azure или Data Lake Store, для доступа к данным не требуется никаких специальных действий в HDInsight. Например, следующая команда отображает список файлов в папке `/example/data`, даже если она хранится в службе хранилища Azure или в Data Lake Store:

    hdfs dfs -ls /example/data

### <a name="uri-and-scheme"></a>Схема и URI

Некоторые команды требуют при доступе к файлу указывать схему в составе URI. Например, схема обязательна для компонента Storm-HDFS. Если вы используете нестандартное хранилище (добавленное в кластер как дополнительное хранилище), необходимо всегда включать схему в состав URI.

При использовании __службы хранилища Azure__ выберите одну из следующих схем URI:

* `wasb:///`: хранилище по умолчанию без шифрования обмена данными.

* `wasbs:///`: хранилище по умолчанию с шифрованием обмена данными.  Схема wasbs поддерживается только в HDInsight начиная с версии 3.6.

* `wasb://<container-name>@<account-name>.blob.core.windows.net/`: при взаимодействии с учетной записью хранения, кроме используемой по умолчанию. Например, используется для дополнительной учетной записи хранения или при доступе к данным в общедоступной учетной записи хранения.

При использовании __Data Lake Store__ выберите одну из следующих схем URI:

* `adl:///`: доступ к хранилищу Data Lake Store, используемому по умолчанию для кластера.

* `adl://<storage-name>.azuredatalakestore.net/`: используется при взаимодействии с Data Lake Store, отличным от используемого по умолчанию. Также применяется для доступа к данным вне корневого каталога вашего кластера HDInsight.

> [!IMPORTANT]
> Если в качестве хранилища по умолчанию для HDInsight используется Data Lake Store, необходимо указать путь внутри хранилища, который будет корневым каталогом для хранилища HDInsight. По умолчанию используется путь `/clusters/<cluster-name>/`.
>
> Если для доступа к данным используется `/` или `adl:///`, доступны только те данные, которые расположены в корневом каталоге кластера (например, `/clusters/<cluster-name>/`). Чтобы получить доступ ко всему хранилищу, используйте формат `adl://<storage-name>.azuredatalakestore.net/`.

### <a name="what-storage-is-the-cluster-using"></a>Какие хранилища используются в кластере

С помощью Ambari можно узнать конфигурацию хранилища, используемого по умолчанию для кластера. Для получения информации о конфигурации HDFS используйте команду curl и выполните фильтрацию с помощью [jq](https://stedolan.github.io/jq/):

```curl -u admin -G "https://CLUSTERNAME.azurehdinsight.net/api/v1/clusters/CLUSTERNAME/configurations/service_config_versions?service_name=HDFS&service_config_version=1" | jq '.items[].configurations[].properties["fs.defaultFS"] | select(. != null)'```

> [!NOTE]
> Эта команда возвращает первую конфигурацию, применяемую к серверу (`service_config_version=1`), которая содержит эти сведения. Может потребоваться перечислить все версии конфигурации, чтобы найти последнюю.

Эта команда возвращает значение, похожее на следующие URI:

* `wasb://<container-name>@<account-name>.blob.core.windows.net`, если используется учетная запись хранения Azure.

    Имя учетной записи — это имя вашей учетной записи хранения Azure. Имя контейнера — это контейнер больших двоичных объектов, который является корнем системы хранения данных кластера.

* `adl://home`, если используется Azure Data Lake Store. Чтобы получить имя Data Lake Store, используйте следующий вызов REST:

    ```curl -u admin -G "https://CLUSTERNAME.azurehdinsight.net/api/v1/clusters/CLUSTERNAME/configurations/service_config_versions?service_name=HDFS&service_config_version=1" | jq '.items[].configurations[].properties["dfs.adls.home.hostname"] | select(. != null)'```

    Эта команда возвращает следующее имя узла: `<data-lake-store-account-name>.azuredatalakestore.net`.

    Чтобы получить каталог хранилища, назначенный корневым для HDInsight, используйте следующий вызов REST:

    ```curl -u admin -G "https://CLUSTERNAME.azurehdinsight.net/api/v1/clusters/CLUSTERNAME/configurations/service_config_versions?service_name=HDFS&service_config_version=1" | jq '.items[].configurations[].properties["dfs.adls.home.mountpoint"] | select(. != null)'```

    Эта команда возвращает путь в следующем формате: `/clusters/<hdinsight-cluster-name>/`.

Сведения о хранилище также можно найти на портале Azure, сделав следующее:

1. На [портале Azure](https://portal.azure.com/) выберите свой кластер HDInsight.

2. В разделе **Свойства** выберите **Учетные записи хранения**. Отобразится информация о хранилище для кластера.

### <a name="how-do-i-access-files-from-outside-hdinsight"></a>Доступ к файлам за пределами HDInsight

Для доступа к данным из-за пределов кластера HDInsight есть несколько методов. Ниже приводятся ссылки на служебные программы и пакеты SDK, которые можно использовать для работы с данными.

Если вы используете __службу хранилища Azure__, для получения данных используйте следующие способы.

* [Azure CLI 2.0](https://docs.microsoft.com/cli/azure/install-az-cli2) — это набор команд интерфейса командной строки для работы с Azure. После установки используйте команду `az storage` для получения информации по использованию хранилища, а команду `az storage blob` — для получения информации о больших двоичных объектах.
* [blobxfer.py](https://github.com/Azure/azure-batch-samples/tree/master/Python/Storage)— cценарий Python для работы с большими двоичными объектами в хранилище Azure.
* Различные пакеты SDK:

    * [Java](https://github.com/Azure/azure-sdk-for-java)
    * [Node.js](https://github.com/Azure/azure-sdk-for-node)
    * [PHP](https://github.com/Azure/azure-sdk-for-php)
    * [Python](https://github.com/Azure/azure-sdk-for-python)
    * [Ruby](https://github.com/Azure/azure-sdk-for-ruby)
    * [.NET](https://github.com/Azure/azure-sdk-for-net)
    * [REST API службы хранилища](https://msdn.microsoft.com/library/azure/dd135733.aspx)

Если вы используете __Azure Data Lake Store__, для получения данных используйте следующие способы:

* [веб-браузер](../data-lake-store/data-lake-store-get-started-portal.md);
* [PowerShell](../data-lake-store/data-lake-store-get-started-powershell.md)
* [Azure CLI 2.0](../data-lake-store/data-lake-store-get-started-cli-2.0.md)
* [REST API WebHDFS](../data-lake-store/data-lake-store-get-started-rest-api.md);
* [средства Data Lake для Visual Studio](https://www.microsoft.com/download/details.aspx?id=49504);
* [.NET](../data-lake-store/data-lake-store-get-started-net-sdk.md)
* [Java](../data-lake-store/data-lake-store-get-started-java-sdk.md)
* [Python](../data-lake-store/data-lake-store-get-started-python.md)

## <a name="scaling"></a>Масштабирование кластера

Масштабирование кластера позволяет динамически изменить число узлов данных в кластере. Операции масштабирования можно выполнять параллельно с другими заданиями и процессами, выполняющимися в кластере.

Масштабирование влияет на разные типы кластеров по-разному:

* **Hadoop.** При уменьшении количества узлов в кластере некоторые службы в нем перезапускаются. Это может привести к сбою выполняющихся и ожидающих заданий при завершении операции масштабирования. После завершения операции вы можете повторно отправить задания.
* **HBase.** В течение нескольких минут после завершения операции масштабирования автоматически выполняется балансировка нагрузки на региональные серверы. Чтобы вручную распределить нагрузку между региональными серверами, выполните следующие действия.

    1. Подключитесь к кластеру HDInsight по протоколу SSH. Дополнительные сведения см. в статье [Использование SSH с Hadoop на основе Linux в HDInsight из Linux, Unix или OS X](hdinsight-hadoop-linux-use-ssh-unix.md).

    2. Чтобы запустить оболочку HBase, используйте следующую команду:

            hbase shell

    3. После загрузки оболочки HBase запустите балансировку нагрузки между региональными серверами вручную, используя следующую команду:

            balancer

* **Storm.** После завершения операции масштабирования следует запустить повторную балансировку для всех запущенных топологий Storm. Она позволяет настроить параметры параллелизма для топологий на основе нового количества узлов в кластере. Чтобы повторно выполнить балансировку выполняющихся топологий, используйте один из следующих вариантов.

    * **SSH.** Подключитесь к серверу и запустите балансировку для топологии, используя следующую команду.

            storm rebalance TOPOLOGYNAME

        Можно также указать параметры для переопределения подсказок параллелизма, изначально предоставляемых топологией. Например, команда `storm rebalance mytopology -n 5 -e blue-spout=3 -e yellow-bolt=10` перенастроит топологию следующим образом: 5 рабочих процессов, 3 исполнителя для компонента blue-spout и 10 исполнителей для компонента yellow-bolt.

    * **Пользовательский интерфейс Storm.** Чтобы запустить балансировку для топологии из интерфейса Storm, выполните следующие действия.

        1. Откройте в веб-браузере страницу с адресом **https://CLUSTERNAME.azurehdinsight.net/stormui**, где CLUSTERNAME — имя вашего кластера Storm. При появлении запроса введите имя администратора кластера HDInsight (admin) и пароль, указанный при создании кластера.
        2. Выберите топологию, для которой нужно выполнить повторную балансировку, и нажмите кнопку **Перераспределить**. Введите задержку перед выполнением операции перебалансировки.

Подробные сведения о масштабировании кластера HDInsight см. в следующих статьях.

* [Управление кластерами Hadoop в HDInsight с помощью портала Azure](hdinsight-administer-use-portal-linux.md#scale-clusters)
* [Управление кластерами Hadoop в HDInsight с помощью интерфейса командной строки (CLI) Azure](hdinsight-administer-use-command-line.md#scale-clusters)

## <a name="how-do-i-install-hue-or-other-hadoop-component"></a>Как установить Hue (или другой компонент Hadoop)?

HDInsight является управляемой службой. В случае обнаружения проблем с кластером Azure может удалить неисправный узел и создать новый для его замены. Если вы вручную установили какие-либо компоненты на кластер, они не сохраняются при выполнении этой операции. Вместо этого используйте [действия скрипта HDInsight](hdinsight-hadoop-customize-cluster.md). Действие скрипта может использоваться для внесения следующих изменений:

* Установка и настройка службы или веб-сайта.
* Установка и настройка компонента, для которого необходимо изменить конфигурацию на нескольких узлах кластера.

Действия сценариев — это сценарии Bash. Они выполняются при создании кластера, и их можно использовать для установки и настройки дополнительных компонентов. Доступны примеры скриптов для установки следующих компонентов:

* [Giraph](hdinsight-hadoop-giraph-install-linux.md)
* [Solr](hdinsight-hadoop-solr-install-linux.md)

Сведения о разработке собственных действий скриптов см. в статье [Разработка действий сценариев с помощью HDInsight](hdinsight-hadoop-script-actions-linux.md).

### <a name="jar-files"></a>JAR-файлы

Некоторые технологии Hadoop предоставляются в автономных JAR-файлах, которые содержат функции, используемые в рамках задания MapReduce, либо из Pig или Hive. Они часто не требуют какой-либо настройки и могут передаваться в кластер после его создания для непосредственного использования. Если вы хотите, чтобы компонент не исчез при повторном создании образа кластера, можно сохранить JAR-файл в хранилище по умолчанию для кластера (WASB или ADL).

Например, если необходимо использовать последнюю версию [DataFu](http://datafu.incubator.apache.org/), можно скачать JAR-файл, содержащий проект, и отправить его в кластер HDInsight. Далее следуйте инструкциям в документации для DataFu по использованию его в Pig или Hive.

> [!IMPORTANT]
> Некоторые компоненты, представляющие собой автономные JAR-файлы, предоставляются вместе с HDInsight, но не в пути. Если вам необходим определенный компонент, можно выполнить его поиск в кластере.
>
> ```find / -name *componentname*.jar 2>/dev/null```
>
> Эта команда возвращает путь к соответствующим JAR-файлам.

Чтобы использовать другую версию компонента, отправьте нужную версию и используйте ее в заданиях.

> [!WARNING]
> Компоненты, предоставляемые вместе с кластером HDInsight, поддерживаются в полном объеме. Служба технической поддержки Майкрософт помогает выявить и решить проблемы, связанные с этими компонентами.
>
> Настраиваемые компоненты получают ограниченную коммерчески оправданную поддержку, способствующую дальнейшей диагностике проблемы. В результате проблема может быть устранена, либо вас могут попросить воспользоваться доступными каналами по технологиям с открытым исходным кодом, чтобы связаться с экспертами в данной области. Можно использовать ряд сайтов сообществ, например [форум MSDN по HDInsight](https://social.msdn.microsoft.com/Forums/azure/en-US/home?forum=hdinsight) или [http://stackoverflow.com](http://stackoverflow.com). Кроме того, проекты Apache можно просмотреть на соответствующих сайтах по адресу [http://apache.org](http://apache.org), например для [Hadoop](http://hadoop.apache.org/) и [Spark](http://spark.apache.org/).

## <a name="next-steps"></a>Дальнейшие действия

* [Миграция из кластера HDInsight под управлением Windows в кластер HDInsight под управлением Linux](hdinsight-migrate-from-windows-to-linux.md)
* [Использование Hive с HDInsight](hdinsight-use-hive.md)
* [Использование Pig с HDInsight](hdinsight-use-pig.md)
* [Использование заданий MapReduce с HDInsight](hdinsight-use-mapreduce.md)
