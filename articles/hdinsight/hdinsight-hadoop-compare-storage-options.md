---
title: Сравнение вариантов хранения для использования с кластерами Azure HDInsight
description: Предоставляет обзор типов хранилища и того, как они работают с Azure HDInsight.
services: hdinsight,storage
author: hrasheed-msft
ms.author: hrasheed
ms.reviewer: jasonh
ms.service: hdinsight
ms.topic: conceptual
ms.date: 02/04/2019
ms.openlocfilehash: 7f113587dfabd66461a9bcfbde18a0178c6608f0
ms.sourcegitcommit: 3aa0fbfdde618656d66edf7e469e543c2aa29a57
ms.translationtype: HT
ms.contentlocale: ru-RU
ms.lasthandoff: 02/05/2019
ms.locfileid: "55733551"
---
# <a name="compare-storage-options-for-use-with-azure-hdinsight-clusters"></a>Сравнение вариантов хранения для использования с кластерами Azure HDInsight

Пользователям Azure HDInsight доступны несколько различных вариантов хранения при создании кластеров HDInsight:

* Хранилище Azure Data Lake Gen2
* Хранилище Azure
* Хранилище Azure Data Lake Gen1

В этой статье предоставлен обзор различных типов хранилища и их уникальных функций.

## <a name="use-azure-data-lake-storage-gen2-with-apache-hadoop-in-azure-hdinsight"></a>Использование Azure Data Lake Storage 2-го поколения с Apache Hadoop в Azure HDInsight

Дополнительные сведения об Azure Data Lake Storage 2-го поколения см. в [этой статье](../storage/blobs/data-lake-storage-introduction.md).

В Azure Data Lake Store 2-го поколения реализованы основные возможности Azure Data Lake Storage 1-го поколения, такие как совместимая с Hadoop файловая система, Azure Active Directory и списки управления доступом на основе POSIX, и интегрированы в хранилище BLOB-объектов Azure. Эта комбинация обеспечивает производительность Azure Data Lake Storage 1-го поколения в сочетании с распределением по уровням хранилища BLOB-объектов и возможностью управлять жизненным циклом данных.

### <a name="core-functionality-of-azure-data-lake-storage-gen2"></a>Основные функциональные возможности Azure Data Lake Storage 2-го поколения

* Доступ, совместимый с Hadoop. Хранилище Azure Data Lake Storage 2-го поколения позволяет получать доступ к данным и управлять ими так же, как и в распределенной файловой системе Hadoop (HDFS). Во всех средах Apache Hadoop, в том числе Azure HDInsight и Azure Databricks, доступен драйвер файловой системы больших двоичных объектов, который позволяет получать доступ к хранимым данным в Data Lake Storage 2-го поколения.

* Супермножество разрешений POSIX. Модель безопасности Data Lake 2-го поколения поддерживает разрешения ACL и POSIX, а также некоторую дополнительную детализацию, относящуюся к Data Lake Storage 2-го поколения. Параметры можно настроить с помощью средств администрирования или платформ, таких как Apache Hive и Apache Spark.

* Экономичность. Data Lake Storage 2-го поколения обеспечивает недорогостоящие транзакции и емкость хранилища. Такие функции, как жизненный цикл хранилища BLOB-объектов Azure, помогают снизить затраты, регулируя тарифные ставки при перемещении данных в течение жизненного цикла.

* Поддержка средств, платформ и приложений хранилища BLOB-объектов. Хранилище Data Lake Storage 2-го поколения поддерживает множество средств, платформ и приложений хранилища BLOB-объектов.

* Оптимизированный драйвер. Драйвер ABFS оптимизирован специально для аналитики больших данных. Соответствующие интерфейсы REST API подключены через конечную точку dfs — dfs.core.windows.net.

### <a name="whats-new-about-azure-data-lake-storage-gen-2"></a>Новые возможности Azure Data Lake Storage 2-го поколения

#### <a name="managed-identities-for-secure-file-access"></a>Управляемые удостоверения для безопасного доступа к файлам

Azure HDInsight использует управляемые удостоверения, чтобы защитить доступ к кластеру файлов в Azure Data Lake Storage 2-го поколения. Управляемые удостоверения — это функция Azure Active Directory, которая предоставляет службы Azure с набором автоматически управляемых учетных данных. Эти учетные данные можно использовать для аутентификации в любой службе, которая поддерживает аутентификацию AD. Для управляемых удостоверений не требуется хранить учетные данные в коде или файлах конфигурации.

Дополнительные сведения см. в разделе [Что такое управляемые удостоверения для ресурсов Azure](../active-directory/managed-identities-azure-resources/overview.md).

#### <a name="azure-blob-filesystem-abfs-driver"></a>Драйвер файловой системы BLOB-объектов (ABFS)

Приложения Apache Hadoop изначально рассчитаны на чтение и запись данных из локального дискового хранилища. Драйвер файловой системы Hadoop, такой как ABFS, позволяет приложениям Hadoop работать с облачным хранилищем за счет эмуляции регулярных операций файловой системы Hadoop. Затем драйвер преобразует полученные из приложения команды в операции, чтобы их поддерживала фактическая платформа облачного хранения.

Ранее драйвер файловой системы Hadoop преобразовывал все операции файловой системы в вызовы REST API службы хранилища Azure на стороне клиента, а затем вызывал REST API. Это преобразование на стороне клиента привело к нескольким вызовам REST API на одну операцию файловой системы, например переименование файла. В ABFS определенная логика файловой системы Hadoop перемещена со стороны клиента на сторону сервера. Теперь API Azure Data Lake Storage 2-го поколения выполняется параллельно с API больших двоичных объектов. Такая миграция повышает производительность, так как теперь общие операции файловой системы Hadoop выполняются с помощью одного вызова REST API.

Дополнительные сведения см. в [The Azure Blob Filesystem driver (ABFS): A dedicated Azure Storage driver for Hadoop](../storage/blobs/data-lake-storage-abfs-driver.md) (Драйвер файловой системы BLOB-объектов Azure (ABFS) — выделенный драйвер службы хранилища Azure Storage для Hadoop).

#### <a name="azure-data-lake-storage-gen-2-uri-scheme"></a>Схема URI Azure Data Lake Storage 2-го поколения

Azure Data Lake Storage 2-го поколения использует схему URI для доступа к файлам в службе хранилища Azure из HDInsight:

`abfs[s]://<FILE_SYSTEM_NAME>@<ACCOUNT_NAME>.dfs.core.windows.net/<PATH>`

Эта схема URI предоставляет как доступ с использованием SSL-шифрования с префиксом `abfss://`, так и незашифрованный доступ с префиксом `abfs://`. Мы рекомендуем использовать `abfss` всегда, когда это возможно, даже при обращении к данным, которые хранятся в том же регионе Azure.

`<FILE_SYSTEM_NAME>` идентифицирует путь к файловой системе Data Lake Storage 2-го поколения.

`<ACCOUNT_NAME>` определяет имя учетной записи службы хранилища Azure. Обязательно использовать полное доменное имя (FQDN).

`<PATH>` — это имя пути к файлу или каталогу HDFS.

Если значения для `<FILE_SYSTEM_NAME>` и `<ACCOUNT_NAME>` не указаны, используется файловая система по умолчанию. Для файлов в файловой системе по умолчанию можно использовать относительный или абсолютный путь. Например, для ссылки на файл `hadoop-mapreduce-examples.jar`, который поставляется с кластерами HDInsight, можно использовать один из приведенных ниже вариантов:

```
abfss://myfilesystempath@myaccount.dfs.core.windows.net/example/jars/hadoop-mapreduce-examples.jar
abfss:///example/jars/hadoop-mapreduce-examples.jar /example/jars/hadoop-mapreduce-examples.jar
```

> [!Note]
> В кластерах HDInsight версий 2.1 и 1.6 файл называется `hadoop-examples.jar`. При работе с файлами вне HDInsight большинство программ не распознают формат ABFS и вместо этого ожидают формат базового пути, например `example/jars/hadoop-mapreduce-examples.jar`.

Дополнительные сведения см. в статье [Use the Azure Data Lake Storage Gen2 URI](../storage/blobs/data-lake-storage-introduction-abfs-uri.md) (Использование универсального кода ресурса в Azure Data Lake Storage 2-го поколения).

## <a name="use-azure-storage"></a>Использование Службы хранилища Azure

Служба хранилища Azure — это надежное, универсальное решение, которое полностью интегрируется с HDInsight. HDInsight может использовать контейнер больших двоичных объектов в службе хранилища Azure в качестве файловой системы по умолчанию для кластера. С помощью интерфейса распределенной файловой системы Hadoop все компоненты HDInsight могут напрямую взаимодействовать со структурированными или неструктурированными данными, хранимыми в виде больших двоичных объектов.

> [!WARNING]  
> При создании учетной записи хранения Azure доступно несколько параметров. Следующая таблица содержит сведения о параметрах, поддерживаемых для HDInsight.

| Тип учетной записи хранения | Поддерживаемые службы | Поддерживаемые уровни производительности | Поддерживаемые уровни доступа |
|----------------------|--------------------|-----------------------------|------------------------|
| Общего назначения версии 2   | BLOB-объект               | Стандартная                    | Горячий, холодный или архивный*    |
| Общего назначения версии 1   | BLOB-объект               | Стандартная                    | Недоступно                    |
| Хранилище BLOB-объектов         | BLOB-объект               | Стандартная                    | Горячий, холодный или архивный*    |

Применяемый по умолчанию контейнер больших двоичных объектов не рекомендуется использовать для хранения бизнес-данных. Чтобы сократить затраты на хранение, контейнер больших двоичных объектов по умолчанию рекомендуется удалять после каждого использования. Контейнер по умолчанию содержит журналы приложений и системный журнал. Обязательно извлеките эти журналы перед удалением контейнера.

Использование одного контейнера больших двоичных объектов в качестве файловой системы по умолчанию для нескольких кластеров не поддерживается.
 
 > [!NOTE]  
 > Архивный уровень доступа — это автономный уровень с задержкой извлечения в несколько часов, который не рекомендуется использовать вместе с HDInsight. Дополнительные сведения см. в разделе [Архивный уровень доступа](../storage/blobs/storage-blob-storage-tiers.md#archive-access-tier).

### <a name="hdinsight-storage-architecture"></a>Архитектура хранилища HDInsight
Следующая схема является абстрактным представлением архитектуры хранилища HDInsight с использованием службы хранилища Azure.

![Кластеры Hadoop используют API HDFS для доступа к структурированным и неструктурированным данным и их хранения в хранилище BLOB-объектов.](./media/hdinsight-hadoop-compare-storage-options/HDI.WASB.Arch.png "Архитектура хранилища HDInsight")

HDInsight предоставляет доступ к распределенной файловой системе, которая локально присоединена к вычислительным узлам. Доступ к этой файловой системе может осуществляться с использованием полного универсального кода ресурса (URI), например:

    hdfs://<namenodehost>/<path>

Кроме того, HDInsight позволяет получить доступ к данным, содержащимся в службе хранилища Azure. Синтаксис:

    wasb[s]://<containername>@<accountname>.blob.core.windows.net/<path>

Ниже приведены некоторые рекомендации для использования учетной записи хранения Azure с кластерами HDInsight.

* **Контейнеры в учетных записях хранения, подключенных к кластеру.** Так как имя учетной записи и ключ связываются с кластером во время создания, вы получаете полный доступ к большим двоичным объектам в этих контейнерах.

* **Общедоступные контейнеры или общедоступные большие двоичные объекты в учетных записях хранения, не подключенных к кластеру.** У вас есть разрешение только для чтения к большим двоичным объектам в контейнерах.
  
  > [!NOTE]  
  > Общедоступные контейнеры позволяют получить список всех доступных в этом контейнере BLOB-объектов, а также метаданные контейнера. Общедоступные BLOB-объекты позволяют получить доступ к BLOB-объектам только при условии, что вам известен точный URL-адрес. Дополнительные сведения см. в статье [Управление анонимным доступом на чтение к контейнерам и большим двоичным объектам](../storage/blobs/storage-manage-access-to-resources.md).

* **Частные контейнеры в учетных записях хранения, не подключенных к кластеру.** Вы не можете получить доступ к большим двоичным объектам в контейнерах, если не определите учетную запись хранения при отправке заданий WebHCat. Это объясняется далее в статье.

Определенные на этапе создания учетные записи хранения и их ключи хранятся в файле %HADOOP_HOME%/conf/core-site.xml на узлах кластера. По умолчанию HDInsight будет использовать учетные записи хранения, описанные в файле core-site.xml. Этот параметр можно изменить с помощью [Apache Ambari](./hdinsight-hadoop-manage-ambari.md).

Множество заданий WebHCat, включая Apache Hive, MapReduce, потоковую передачу Apache Hadoop и Apache Pig, могут переносить описание учетных записей хранения и метаданные вместе с ними. (В настоящее время эта функция работает для Pig с учетными записями хранения, но не с метаданными). Дополнительные сведения см. в разделе [Использование кластера HDInsight с дополнительными учетными записями хранения и метахранилищами](https://social.technet.microsoft.com/wiki/contents/articles/23256.using-an-hdinsight-cluster-with-alternate-storage-accounts-and-metastores.aspx).

Большие двоичные объекты могут использоваться для хранения как структурированных, так и неструктурированных данных. В контейнерах больших двоичных объектов данные хранятся в виде пар "ключ — значение" и отсутствует иерархия каталогов. Тем не менее, в имени ключа может использоваться знак косой черты "/", чтобы оно выглядело так, будто файл хранится в структуре каталогов. Например, ключ большого двоичного объекта может выглядеть следующим образом: `input/log1.txt`. На самом деле никакого каталога `input` не существует, но из-за наличия знака косой черты "/" имя ключа выглядит как путь к файлу.

### <a id="benefits"></a>Преимущества службы хранилища Azure
Предполагаемые рабочие затраты из-за отсутствия совмещенных вычислительных ресурсов и ресурсов хранения снижаются за счет того, что создание вычислительных кластеров происходит в непосредственной близости от ресурсов учетных записей хранения в регионе Azure, в котором высокоскоростная сеть обеспечивает вычислительным узлам эффективный доступ к данным в службе хранилища Azure.

Ниже перечислены некоторые преимущества, связанные с хранением данных в службе хранилища Azure (вместо HDFS).

* **Повторное использование данных и общий доступ.** Данные в файловой системе HDFS расположены в вычислительном кластере. Только приложения, имеющие доступ к вычислительному кластеру, могут использовать данные через API HDFS. Доступ к данным в службе хранилища Azure может осуществляться через интерфейсы API HDFS или через интерфейсы REST API хранилища BLOB-объектов. Таким образом, для создания и использования данных можно применять больший набор приложений (включая другие кластеры HDInsight) и средств.
* **Архивация данных.** Хранение данных в службе хранилища Azure позволяет безопасно (без потери пользовательских данных) удалять используемые для расчетов кластеры HDInsight.
* **Затраты на хранение данных.** Хранение данных в файловой системе DFS в долгосрочной перспективе является более затратным, чем хранение данных в службе хранилища Azure, так как стоимость вычислительного кластера превышает стоимость службы хранилища Azure. Кроме того, так как данные не требуется повторно загружать при создании каждого вычислительного кластера, вы экономите также на загрузке данных.
* **Гибкое горизонтальное масштабирование.** Хотя HDFS и представляет собой масштабируемую файловую систему, масштаб определяется количеством узлов, создаваемых для кластера. Изменение масштаба может оказаться более сложным процессом, чем использование гибких возможностей масштабирования службы хранилища Azure, которые вы получаете автоматически.
* **Георепликация.** Доступна функция георепликации для вашей службы хранилища Azure. Хотя это обеспечивает возможность географического восстановления и избыточность данных, переход в расположение геореплицированных данных при отработке отказа заметно сказывается на производительности, что может привести к дополнительным затратам. Поэтому мы рекомендуем взвешенно подходить к выбору георепликации и выбирать ее только в том случае, если ценность данных окупит дополнительные затраты.

Определенные задания и пакеты MapReduce могут создавать промежуточные результаты, которые нет нужды хранить в службе хранилища Azure. В таком случае можно выбрать хранение данных в локальной системе HDFS. На деле HDInsight использует DFS для некоторых таких промежуточных результатов в заданиях Hive и других процессах.

> [!NOTE]  
> Большинство команд HDFS (например, `ls`, `copyFromLocal` и `mkdir`) по-прежнему работают правильно. В службе хранилища Azure будет отличаться поведение только тех команд, которые относятся к стандартной реализации HDFS (под названием DFS), например `fschk` и `dfsadmin`.

## <a name="use-azure-data-lake-storage-gen1"></a>Использование Azure Data Lake Storage 1-го поколения

### <a name="overview"></a>Обзор

Дополнительные сведения об Azure Data Lake Storage 1-го поколения см. в [этой статье](../data-lake-store/data-lake-store-overview.md).

Azure Data Lake Storage 1-го поколения — это крупномасштабный репозиторий корпоративного уровня для рабочих нагрузок анализа больших данных. Azure Data Lake позволяет сохранять данные с любым размером, типом и скоростью приема в одном месте для эксплуатационной и исследовательской аналитики.

Data Lake Storage 1-го поколения доступно из Hadoop (имеется в кластере HDInsight) с помощью интерфейсов REST API, совместимых с WebHDFS. Оно разработано для анализа сохраненных данных и адаптировано к различным сценариям анализа данных. По умолчанию оно включает все возможности корпоративного уровня — безопасность, управляемость, масштабируемость, надежность и доступность — необходимые для реальных задач предприятия.

![Azure Data Lake Storage](./media/hdinsight-hadoop-compare-storage-options/data-lake-store-concept.png "Архитектура хранилища HDInsight")

Ниже перечислены некоторые основные возможности Data Lake Storage 1-го поколения.

#### <a name="built-for-hadoop"></a>Поддержка Hadoop

Data Lake Storage 1-го поколения имеет файловую систему Apache Hadoop, которая совместима с распределенной файловой системой Hadoop и поддерживает экосистему Hadoop.  Существующие приложения и службы HDInsight, использующие API-интерфейс WebHDFS, могут легко интегрироваться с Data Lake Storage 1-го поколения. Data Lake Storage 1-го поколения также предоставляет для приложений интерфейс REST, совместимый с WebHDFS.

Данные, хранящиеся в Data Lake Storage 1-го поколения, можно легко анализировать с помощью аналитических платформ Hadoop, таких как MapReduce или Hive. Для прямого доступа к данным, хранящимся в Data Lake Storage 1-го поколения, можно подготовить и настроить кластеры Microsoft Azure HDInsight.

#### <a name="unlimited-storage-petabyte-files"></a>Неограниченное пространство хранения, файлы петабайтного размера

Data Lake Storage 1-го поколения предоставляет неограниченное пространство и подходит для хранения разнообразных данных для анализа. В нем нет никаких ограничений на размер учетной записи, размер файла или объем данных, которые могут храниться в озере данных. Отдельные файлы могут иметь размер от килобайта до петабайтов, благодаря чему хранилище подходит для хранения данных любого типа. Надежность хранения данных обеспечивается созданием нескольких копий, кроме того, нет никаких ограничений на продолжительность хранения данных в озере данных.

#### <a name="performance-tuned-for-big-data-analytics"></a>Настройки производительности для анализа больших данных

Data Lake Storage 1-го поколения предназначено для работы в крупномасштабных аналитических системах, где требуется высокая пропускная способность для запроса и анализа больших объемов данных. В озере данных фрагменты файлов распределяются по нескольким отдельным серверам хранилища. Это повышает пропускную способность при параллельном чтении файла для проведения анализа данных.

#### <a name="enterprise-ready-highly-available-and-secure"></a>Готовность к использованию на предприятии: Высокая доступность и надежность

Data Lake Storage 1-го поколения обладает доступностью и надежностью, соответствующими отраслевым стандартам. Надежность хранения данных обеспечивается созданием избыточных копий для защиты от любых непредвиденных сбоев. Предприятия могут использовать Data Lake Storage 1-го поколения в своих решениях как важную часть существующей платформы данных.

Data Lake Storage 1-го поколения также обеспечивает безопасность корпоративного уровня для сохраненных данных. Дополнительные сведения см. в статье о [защите данных в Data Lake Storage 1-го поколения](#DataLakeStoreSecurity).

#### <a name="all-data"></a>Любые данные

Data Lake Storage 1-го поколения может хранить любые данные в собственном формате, как есть, без необходимости предварительного преобразования. Data Lake Storage 1-го поколения не требует определять схему перед загрузкой данных. Интерпретацию данных и определение схемы осуществляет конкретная аналитическая платформа во время анализа. Возможность хранения файлов произвольных форматов и размера позволяет обрабатывать в Data Lake Storage 1-го поколения структурированные, полуструктурированные и неструктурированные данные.

В Data Lake Storage 1-го поколения хранятся контейнеры для данных — папки и файлы. Операции с хранимыми данными осуществляются через пакеты SDK, портал Azure и Azure PowerShell. Используя эти интерфейсы и соответствующие контейнеры, вы можете сохранять любые типы данных. Data Lake Storage 1-го поколения обрабатывает сохраняемые данные без учета их типа.

### <a name="DataLakeStoreSecurity"></a>Защита данных в Data Lake Storage 1-го поколения
В Data Lake Storage 1-го поколения используются Azure Active Directory для проверки подлинности и списки контроля доступа (ACL) для управления доступом к данным.

| Функция | ОПИСАНИЕ |
| --- | --- |
| Authentication |Data Lake Storage 1-го поколения интегрируется с Azure Active Directory (AAD) для управления удостоверениями и доступом для всех данных, размещенных в Data Lake Storage 1-го поколения. В результате этой интеграции Data Lake Storage 1-го поколения получает доступ ко всем функциям AAD, включая многофакторную проверку подлинности, условный доступ, контроль доступа на основе ролей, отслеживание использования приложений, мониторинг безопасности и предупреждения и т. д. Data Lake Storage 1-го поколения поддерживает протокол OAuth 2.0 для проверки подлинности в интерфейсе REST. См. разделе [Проверка подлинности в Data Lake Storage 1-го поколения](../data-lake-store/data-lakes-store-authentication-using-azure-active-directory.md)|
| управление доступом; |Data Lake Storage 1-го поколения обеспечивает контроль доступа за счет поддержки разрешений POSIX, предоставляемых протоколом WebHDFS. Списки управления доступом можно включить в корневой папке, вложенных папках, а также в отдельных файлах. Дополнительные сведения о принципе работы списков управления доступом в контексте Data Lake Storage 1-го поколения см. в статье [Контроль доступа в Azure Data Lake Storage 1-го поколения](../data-lake-store/data-lake-store-access-control.md). |
| Шифрование |В Data Lake Storage 1-го поколения можно также включить шифрование данных, хранящихся в учетной записи. Параметры шифрования можно задать во время создания учетной записи Data Lake Storage 1-го поколения. Шифрование данных можно как включить, так и отключить. Дополнительные сведения см. в статье [Шифрование данных в Data Lake Storage 1-го поколения](../data-lake-store/data-lake-store-encryption.md). Инструкции по настройке шифрования см. в статье [Начало работы с Azure Data Lake Storage Gen1 с помощью портала Azure](../data-lake-store/data-lake-store-get-started-portal.md). |

Ссылки на дополнительные сведения о защите данных в Data Lake Storage 1-го поколения приведены ниже.

* Инструкции по защите данных в Azure Data Lake Storage 1-го поколения см. в [этой статье](../data-lake-store/data-lake-store-secure-data.md).

### <a name="applications-compatible-with-data-lake-storage-gen1"></a>Приложения, совместимые с Data Lake Storage 1-го поколения
Data Lake Storage 1-го поколения совместимо с большинством компонентов с открытым исходным кодом в экосистеме Hadoop. Также оно легко интегрируется с прочими службами Azure.  Перейдите по ссылкам ниже для получения дополнительных сведений об использовании Data Lake Storage 1-го поколения как с компонентами с открытым исходным кодом, так и с другими службами Azure.

* Ознакомьтесь со [списком приложений с открытым кодом, совместимых с Data Lake Storage 1-го поколения](../data-lake-store/data-lake-store-compatible-oss-other-applications.md).
* См. статью [Интеграция с другими службами Azure](../data-lake-store/data-lake-store-integrate-with-other-services.md), где описано, как использовать Data Lake Storage 1-го поколения с другими службами Azure для реализации других сценариев.
* См. статью о [сценариях работы с Data Lake Storage 1-го поколения](../data-lake-store/data-lake-store-data-scenarios.md), включая прием, обработку, загрузку и визуализацию данных.

### <a name="what-is-data-lake-storage-gen1-file-system-adl"></a>Что такое файловая система Data Lake Storage 1-го поколения (adl://)?
Доступ к Data Lake Storage 1-го поколения может осуществляться через новую файловую систему AzureDataLakeFilesystem (adl://) в средах Hadoop (имеется в кластере HDInsight). Приложения и службы, использующие adl://, могут использовать дополнительные возможности оптимизации производительности, которые в настоящее время недоступны в WebHDFS. В результате Data Lake Storage 1-го поколения предоставляет возможность либо воспользоваться максимальной производительностью с помощью adl:// (это рекомендуемый вариант), либо сохранить существующий код, продолжая использовать интерфейс API WebHDFS напрямую. Azure HDInsight использует все возможности AzureDataLakeFilesystem для обеспечения максимальной производительности в Data Lake Storage 1-го поколения.

Для доступа к данным в Data Lake Storage 1-го поколения можно использовать `adl://<data_lake_storage_gen1_name>.azuredatalakestore.net`. Дополнительные сведения о доступе к данным в Data Lake Storage 1-го поколения см. в статье [Просмотр свойств хранимых данных](../data-lake-store/data-lake-store-get-started-portal.md#properties).



## <a name="next-steps"></a>Дополнительная информация

* [Общие сведения о хранилище Azure Data Lake Storage Gen2 (предварительная версия)](../storage/blobs/data-lake-storage-introduction.md)
* [Введение в хранилище Azure](../storage/common/storage-introduction.md)