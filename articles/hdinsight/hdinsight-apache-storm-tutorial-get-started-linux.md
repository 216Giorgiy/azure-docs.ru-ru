<properties
	pageTitle="Учебник по Apache Storm: начало работы со Storm под управлением Linux в HDInsight | Microsoft Azure"
	description="Начало работы с аналитикой больших данных с помощью Apache Storm и примеров Storm Starter под управлением Linux в HDInsight. Информация об использовании Storm для обработки данных в режиме реального времени."
	keywords="apache storm, учебник sapache storm, анализ больших данных, storm starter"
	services="hdinsight"
	documentationCenter=""
	authors="Blackmist"
	manager="paulettm"
	editor="cgronlun"/>

<tags
   ms.service="hdinsight"
   ms.devlang="java"
   ms.topic="get-started-article"
   ms.tgt_pltfrm="na"
   ms.workload="big-data"
   ms.date="01/12/2016"
   ms.author="larryfr"/>


# Учебник по Apache Storm в HDInsight: начало работы с анализом больших объемов данных в HDInsight с помощью примеров Storm Starter

Apache Storm — это масштабируемая отказоустойчивая распределенная система выполнения расчетов для обработки данных потоковой передачи в режиме реального времени. С помощью Storm вы можете создать в Azure HDInsight облачный кластер, который анализирует данные в режиме реального времени.

> [AZURE.NOTE]С помощью действий, описанных в данной статье, можно создать кластер HDInsight под управлением Linux. Инструкции по созданию Storm под управлением Windows в кластере HDInsight см. в статье [Учебник по Apache Storm: начало работы с примерами Storm Starter для анализа данных в HDInsight](hdinsight-apache-storm-tutorial-get-started.md)

## Перед началом работы

Необходимое условие для успешного выполнения инструкций этого учебника:

- **Подписка Azure.**. См. [Бесплатная пробная версия Azure](http://azure.microsoft.com/documentation/videos/get-azure-free-trial-for-testing-hadoop-in-hdinsight/).

- **Знакомство с SSH и SCP**. Дополнительные сведения об использовании SSH и SCP с HDInsight можно найти в следующих разделах:

    - **Для клиентов Linux, Unix или OS X**: См. [Использование SSH в Hadoop на HDInsight под управлением Linux из Linux, OS X или Unix](hdinsight-hadoop-linux-use-ssh-unix.md)

	- **Для клиентов Windows**: См. [Использование SSH в Hadoop на HDInsight под управлением Linux из Windows](hdinsight-hadoop-linux-use-ssh-windows.md)

## Создание кластера Storm

Storm в HDInsight использует хранилище BLOB-объектов Azure для хранения файлов журнала и топологий, отправленных в кластер. Чтобы создать учетную запись хранения Azure, которую вы будете использовать с кластером, выполните следующие действия:

1. Войдите на [портал Azure][preview-portal].

2. Последовательно выберите элементы **СОЗДАТЬ**, __Анализ данных__ и __HDInsight__.

	![Создание кластера на портале Azure](./media/hdinsight-apache-storm-tutorial-get-started-linux/new-cluster.png)

3. Введите __Имя кластера__, а затем выберите значение __Storm__ для поля __Тип кластера__. Если __имя кластера__ доступно, рядом с ним появится зеленый флажок.

	![Имя кластера, тип кластера и тип ОС](./media/hdinsight-apache-storm-tutorial-get-started-linux/clustername.png)

	Выберите __Ubuntu__, чтобы создать кластер HDInsight на основе Linux.
    
    > [AZURE.NOTE]Оставьте в поле __Версия__ значение по умолчанию для действий, описанных в этом документе.
	
4. Если у вас есть несколько подписок, щелкните запись __Подписка__, чтобы выбрать подписку Azure для кластера.

5. Щелкните __Группа ресурсов__, чтобы просмотреть список существующих групп ресурсов и выбрать ту, в которой будет создан кластер. Или выберите __Создать__ и введите имя новой группы ресурсов. Если новое имя группы доступно, рядом с ним появится зеленый флажок.

	> [AZURE.NOTE]Эта запись будет выбрана по умолчанию для одной из существующих групп ресурсов (при их наличии).

6. Выберите элемент __Учетные данные__, затем введите данные в поля __Имя пользователя для входа в кластер__ и __Пароль для входа в кластер__. Необходимо также ввести __Имя пользователя SSH__ и __ПАРОЛЬ__ или __ОТКРЫТЫЙ КЛЮЧ__, которые будут использоваться для проверки подлинности пользователя SSH. В завершение нажмите кнопку __Выбрать__, чтобы задать учетные данные.

	![Колонка "Учетные данные кластера"](./media/hdinsight-administer-use-portal-linux/clustercredentials.png)

	Дополнительные сведения об использовании SSH с HDInsight см. в следующих статьях.

	* [Использование SSH с Hadoop под управлением Linux в HDInsight в Linux, Unix или OS X](hdinsight-hadoop-linux-use-ssh-unix.md)

	* [Использование SSH с Hadoop под управлением Linux в HDInsight в Windows](hdinsight-hadoop-linux-use-ssh-windows.md)

6. Выберите запись __Источник данных__, чтобы выбрать существующий источник данных или создать новый.

	![Колонка "Источник данных"](./media/hdinsight-apache-storm-tutorial-get-started-linux/datasource.png)
	
	В настоящее время в качестве источника данных для кластера HDInsight можно выбрать учетную запись хранения Azure. Следующие элементы интерфейса помогут вам понять записи в колонке __Источник данных__.
	
	- __Метод выбора__. Выберите значение __Из всех подписок__, чтобы активировать поиск учетных записей хранения в своих подписках. Задайте значение __Ключ доступа__, если вы хотите ввести __имя хранилища__ и __ключ доступа__ существующей учетной записи хранения.
    
    - __Выберите учетную запись хранения__. Если учетная запись хранения для вашей подписки уже существует, выберите ее в этом поле для использования с кластером.
	
	- __Создать__. Эта команда позволяет создавать новые учетные записи хранения. В появившееся поле введите имя учетной записи хранения. Если имя доступно, появится зеленый флажок.
	
	- __Выбрать контейнер по умолчанию__. Эта команда позволяет ввести имя контейнера по умолчанию и использовать его для кластера. Вы можете ввести любое имя, однако мы рекомендуем использовать такое же имя, как у кластера, чтобы легко распознавать, какой контейнер используется для конкретного кластера.
	
	- __Расположение__ — географический регион, к которому будет относиться существующая или новая учетная запись хранения.
	
		> [AZURE.IMPORTANT]Выбранное расположение для источника данных по умолчанию будет также определять расположение кластера HDInsight. Кластер и источник данных по умолчанию должны находиться в одном регионе.
    
    - __Удостоверение кластера AAD__. Используется для выбора удостоверения Azure Active Directory, которое будет использоваться кластером для доступа к хранилищу озера данных Azure.
    
        > [AZURE.NOTE]Оно не используется в этом документе, поэтому можно оставить значение по умолчанию. Сведения об использовании этой записи и хранилища озера данных Azure с HDInsight см. в статье [Создание кластера HDInsight, который использует хранилище озера данных Azure](data-lake-store-hdinsight-hadoop-use-portal.md).
		
	- __Выбрать__. Эта кнопка позволяет сохранить конфигурацию источника данных.
	
7. Выберите __Ценовые категории узла__, чтобы отобразить сведения об узлах, которые будут созданы для этого кластера. По умолчанию для количества рабочих узлов устанавливается значение __4__. Оценочная стоимость кластера отобразится в нижней части этой колонки.

	![Колонка "Ценовые категории узла"](./media/hdinsight-apache-storm-tutorial-get-started-linux/nodepricingtiers.png)
	
    Для изменения типа виртуальных машин, используемых в каждом из узлов кластера, можно выбрать тип каждого узла. Для этого документа оставьте данные параметры в значениях по умолчанию.
    
	Нажмите кнопку __Выбрать__, чтобы сохранить сведения о __ценовых категориях узла__.

8. Выберите __Необязательная конфигурация__. Эта колонка позволяет присоединить кластер к __Виртуальной сети__, воспользоваться __Действиями скриптов__ для настройки кластера или использовать __Хранилище пользовательских метаданных__ для хранения данных Hive и Oozie.

	![Колонка "Дополнительная конфигурация"](./media/hdinsight-apache-storm-tutorial-get-started-linux/optionalconfiguration.png)
    
    Для действий, описанных в этом документе, оставьте эти параметры в значении __Не указано__.

9. Обязательно выберите параметр __Закрепить на начальной панели__, а затем щелкните __Создать__. После этого кластер будет создан, а на начальную панель портала Azure будет добавлена его плитка. Значок указывает, что выполняется подготовка кластера. После завершения подготовки вместо него будет отображаться значок HDInsight.

	| Подготовка выполняется | Подготовка завершена |
	| ------------------ | --------------------- |
	| ![Индикатор подготовки на начальной панели](./media/hdinsight-apache-storm-tutorial-get-started-linux/provisioning.png) | ![Плитка подготовки кластера](./media/hdinsight-apache-storm-tutorial-get-started-linux/provisioned.png) |

	> [AZURE.NOTE]Обычно создание кластера занимает около 15 минут. Отслеживать процесс подготовки можно с помощью плитки на начальной панели или записи __Уведомления__ в левой части страницы.

##Запуск образца Storm Starter в HDInsight

Примеры [storm-starter](https://github.com/apache/storm/tree/master/examples/storm-starter) включены в кластер HDInsight. Выполняя следующие действия, вы запустите пример WordCount.

1. Подключитесь к кластеру HDInsight с помощью протокола SSH:

		ssh USERNAME@CLUSTERNAME-ssh.azurehdinsight.net
		
	Если для защиты учетной записи SSH используется пароль, будет предложено ввести его. Если используется открытый ключ, может потребоваться использовать параметр `-i`, чтобы указать соответствующий закрытый ключ. Например, `ssh -i ~/.ssh/id_rsa USERNAME@CLUSTERNAME-ssh.azurehdinsight.net`.
		
	Дополнительная информация об использовании SSH с HDInsight на основе Linux приведена в следующих статьях:
	
	* [Использование SSH с Hadoop под управлением Linux в HDInsight в Linux, Unix или OS X](hdinsight-hadoop-linux-use-ssh-unix.md)

	* [Использование SSH с Hadoop под управлением Linux в HDInsight в Windows](hdinsight-hadoop-linux-use-ssh-windows)

2. Запустите пример топологии, используя следующую команду:

        storm jar /usr/hdp/current/storm-client/contrib/storm-starter/storm-starter-topologies-0.9.3.2.2.4.9-1.jar storm.starter.WordCountTopology wordcount
		
	> [AZURE.NOTE]При обновлении HDinsight до более новых версий Storm часть имени файла `0.9.3.2.2.4.9-1` может измениться.

    Эта команда запустит в кластере пример топологии WordCount с понятным именем wordcount. Он будет случайным образом формировать предложения и подсчитывать количество появлений каждого слова в предложениях.

    > [AZURE.NOTE]При отправке топологии в кластер необходимо сначала скопировать jar-файл, содержащий кластер, а затем воспользоваться командой `storm`. Это можно сделать, выполнив команду `scp` на клиенте, на котором находится файл. Например, `scp FILENAME.jar USERNAME@CLUSTERNAME-ssh.azurehdinsight.net:FILENAME.jar`
    >
    > Пример WordCount и другие начальные примеры использования Storm уже включены в ваш кластер в `/usr/hdp/current/storm-client/contrib/storm-starter/`.

##Мониторинг топологии

Пользовательский интерфейс Storm предоставляет веб-интерфейс для работы с запущенными топологиями и включен в состав кластера HDInsight.

Чтобы начать мониторинг топологии из пользовательского интерфейса Storm, выполните следующие действия.

1. Откройте веб-браузер и перейдите по адресу https://CLUSTERNAME.azurehdinsight.net/stormui, где __CLUSTERNAME__ — это имя вашего кластера. Откроется пользовательский интерфейс Storm.

	> [AZURE.NOTE]При появлении соответствующего запроса введите имя пользователя и пароль администратора кластера (admin), которые использовались при создании кластера.

2. В разделе **Topology summary** (Сводка топологии) выберите запись **wordcount** (количество слов) в столбце **Name** (Имя). После этого отобразится дополнительная информация о топологии.

	![Панель мониторинга Storm, отображающая сведения о топологии WordCount в Storm Starter.](./media/hdinsight-apache-storm-tutorial-get-started-linux/topology-summary.png)

	Эта страница содержит следующую информацию.

	* **Topology stats** (Статистика топологий) —основная информация о производительности топологии, упорядоченная по временным промежуткам.

		> [AZURE.NOTE]При выборе определенного временного промежутка меняется информация, отображаемая в других разделах страницы.

	* **Spouts** (Воронки) — основная информация о воронках, в том числе последняя ошибка, возвращенная каждой воронкой.

	* **Bolts** (Сита) — основная информация о ситах.

	* **Topology configuration** (Конфигурация топологии) — подробная информация о конфигурации топологии.

	Эта страница также содержит действия, которые можно выполнять в топологии.

	* **Activate** (Включить) — возобновление обработки отключенной топологии.

	* **Deactivate** (Отключить) — приостановка выполняемой топологии.

	* **Rebalance** (Повторная балансировка) — корректировка параллелизма топологии. После изменения числа узлов в кластере необходимо выполнить повторную балансировку топологий. Это позволяет топологии скорректировать параллелизм для компенсации увеличения или уменьшения количества узлов в кластере. Дополнительные сведения см. в статье [Общие сведения о параллелизме топологии Storm](http://storm.apache.org/documentation/Understanding-the-parallelism-of-a-Storm-topology.html).

	* **Kill** (Удалить) — останавливает выполнение топологии Storm по истечении заданного времени ожидания.

3. На этой странице выберите запись и раздела **Spouts** (Воронки) или **Bolts** (Сита). Отобразится информация о выбранном компоненте.

	![Панель мониторинга Storm со сведениями о выбранных компонентах.](./media/hdinsight-apache-storm-tutorial-get-started-linux/component-summary.png)

	На этой странице отображается следующая информация.

	* **Spout/Bolt stats** (Статистика воронки/сита) —основная информация о производительности соответствующего компонента, упорядоченная по временным промежуткам.

		> [AZURE.NOTE]При выборе определенного временного промежутка меняется информация, отображаемая в других разделах страницы.

	* **Input stats** (Статистика ввода, только для сита) — информация о компонентах, которые производят данные, используемые ситом.

	* **Output stats** (Статистика вывода) — информация о данных, созданных этим ситом.

	* **Executors** (Исполнители) — информация об экземплярах этого компонента.

	* **Errors** (Ошибки) — ошибки, созданные этим компонентом.

4. Во время просмотра информации о воронке и сите выберите запись из столбца **Port** (Порт) в разделе **Executors** (Исполнители), чтобы просмотреть информацию о конкретном экземпляре компонента.

		2015-01-27 14:18:02 b.s.d.task [INFO] Emitting: split default ["with"]
		2015-01-27 14:18:02 b.s.d.task [INFO] Emitting: split default ["nature"]
		2015-01-27 14:18:02 b.s.d.executor [INFO] Processing received message source: split:21, stream: default, id: {}, [snow]
		2015-01-27 14:18:02 b.s.d.task [INFO] Emitting: count default [snow, 747293]
		2015-01-27 14:18:02 b.s.d.executor [INFO] Processing received message source: split:21, stream: default, id: {}, [white]
		2015-01-27 14:18:02 b.s.d.task [INFO] Emitting: count default [white, 747293]
		2015-01-27 14:18:02 b.s.d.executor [INFO] Processing received message source: split:21, stream: default, id: {}, [seven]
		2015-01-27 14:18:02 b.s.d.task [INFO] Emitting: count default [seven, 1493957]

	Эти данные показывают, что слово **seven** (семь) использовалось 1 493 957 раз. Столько раз оно было обнаружено с момента запуска данной топологии.

##Остановка топологии

Вернитесь к странице **Topology summary** (Сводка топологии), чтобы найти топологию подсчета слов, и нажмите кнопку **Kill** (Удалить) в разделе **Topology actions ** (Действия топологии). При появлении запроса введите 10 секунд ожидания перед остановкой топологии. После истечения времени ожидания топология перестанет отображаться во время входа в раздел **Storm UI** (Пользовательский интерфейс Storm) панели мониторинга.

##Сводка

В этом учебнике Apache Storm используется Storm Starter для объяснения принципов создания Storm в кластере HDInsight и использования панели мониторинга Storm для развертывания и отслеживания топологий Storm, а также управления ими.

##<a id="next"></a>Дальнейшие действия

* Следующий документ содержит список других примеров, которые могут использоваться со Storm на HDInsight:

	* [Примеры топологий для Storm в HDInsight](hdinsight-storm-example-topology.md)

[apachestorm]: https://storm.incubator.apache.org
[stormdocs]: http://storm.incubator.apache.org/documentation/Documentation.html
[stormstarter]: https://github.com/apache/storm/tree/master/examples/storm-starter
[stormjavadocs]: https://storm.incubator.apache.org/apidocs/
[azureportal]: https://manage.windowsazure.com/
[hdinsight-provision]: hdinsight-provision-clusters.md
[preview-portal]: https://portal.azure.com/

<!---HONumber=AcomDC_0114_2016-->