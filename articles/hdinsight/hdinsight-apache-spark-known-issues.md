<properties 
	pageTitle="Известные проблемы Apache Spark в HDInsight | Microsoft Azure" 
	description="Известные проблемы Apache Spark в HDInsight." 
	services="hdinsight" 
	documentationCenter="" 
	authors="mumian" 
	manager="paulettm" 
	editor="cgronlun"
	tags="azure-portal"/>

<tags 
	ms.service="hdinsight" 
	ms.workload="big-data" 
	ms.tgt_pltfrm="na" 
	ms.devlang="na" 
	ms.topic="article" 
	ms.date="12/22/2015" 
	ms.author="jgao"/>

# Известные проблемы Apache Spark в Azure HDInsight (Linux)

В этом документе отслеживаются все известные проблемы с общедоступной предварительной версией Spark.

##Утечка интерактивного сеанса Livy
 
**Симптом**

При перезапуске Livy во время работы интерактивного сеанса (из Ambari или в связи с перезагрузкой виртуальной машины headnode 0) происходит утечка сеанса интерактивного задания. Из-за этого новые задания застревают в состоянии "Принято" и не могут быть запущены.

**Устранение.**

Для решения этой проблемы выполните указанные ниже действия.

1. Подключитесь к головному узлу по протоколу SSH. 
2. Выполните следующую команду, чтобы найти идентификаторы приложений для интерактивных заданий, запущенных из Livy: 

        yarn application –list

    По умолчанию задания, запущенные в интерактивном сеансе Livy без прямо заданных имен, будут иметь имя Livy. Если сеанс Livy запускается из записной книжки Jupyter, имя задания будет начинаться с remotesparkmagics\_*.

3. Чтобы аннулировать эти задания, выполните следующую команду:

        yarn application –kill <Application ID>

После этого новые задания начнут выполняться.

##Сервер журналов Spark не запускается 

**Симптом**
 
Сервер журналов Spark не запускается автоматически после создания кластера.

**Устранение.**

Вручную запустите сервер журналов из Ambari.

##Начальная загрузка записной книжки загружается дольше ожидаемого 

**Симптом**

Выполнение первого оператора в записной книжке Jupyter с использованием Spark Magic может занимать больше минуты.

**Устранение.**
 
Решения нет. Иногда это действие занимает минуту.

##Не удается настроить конфигурации ядер и памяти

**Симптом**
 
Невозможно изменить конфигурацию ядер или памяти для ядер Spark и Pyspark.

**Устранение.**
 
Эта функция будет реализована в ближайшее время.

##Приостановка записной книжки Jupyter при создании сеанса

**Симптом**

Если кластеру Spark не хватает ресурсов, при попытке создания сеанса ядра Spark и Pyspark в записной книжке Jupyter будут приостановлены. Устранение

1. Освободите часть ресурсов в кластере Spark.

    - Остановите другие записные книжки Spark в меню "Закрыть и остановить" или нажмите кнопку "Завершить" в обозревателе записных книжек.
    - Остановите другие приложения Spark из YARN.

2. Перезапустите записную книжку, которую вы пытались запустить. Теперь ресурсов должно быть достаточно для создания сеанса.

##Выходные данные записной книжки вызывают проблему форматирования

**Симптом**
 
Неправильное форматирование выходных данных записной книжки после выполнения ячейки из ядер Spark и Pyspark записной книжки Jupyter. Это относится как к успешными результатам выполнения, так и к данным трассировки Spark или другим ошибкам.

**Устранение.**
 
Эта проблема будет решена в следующей версии.

##Опечатки в примерах записных книжек
 
- **Записная книжка Python 4 (Анализ журналов в Spark с помощью пользовательской библиотеки)**

    Текст "Предположим, вы копируете его в wasb:///example/data/iislogparser.py" вместо "Предположим, вы копируете его в wasb:///HdiSamples/HdiSamples/WebsiteLogSampleData/iislogparser.py"".

- **Записная книжка Python 5 (Машинное обучение Spark. Прогнозный анализ на основе данных контроля качества пищевых продуктов с использованием MLLib)**

    Текст "Простой способ понять, каким образом распределены результаты, — применить визуализацию" содержит нерабочий код. Его необходимо изменить следующим образом:

        countResults = df.groupBy('results').count().withColumnRenamed('count', 'cnt').collect() 
        labels = [row.results for row in countResults] 
        sizes = [row.cnt for row in countResults] 
        colors = ['turquoise', 'seagreen', 'mediumslateblue', 'palegreen', 'coral'] 
        plt.pie(sizes, labels=labels, autopct='%1.1f%%', colors=colors) plt.axis('equal') 
        
- **Записная книжка Python 5 (Машинное обучение Spark. Прогнозный анализ на основе данных контроля качества пищевых продуктов с использованием MLLib)**

    В последнем комментарии указано, что ложноотрицательные результаты составляют 12,6 %, а ложноположительные — 16,0 % соответственно. Эти цифры неточны; выполните код, чтобы вывести на экран секторную диаграмму с точными процентными долями.

- **Записные книжки Python 6 и 7**

    Первая ячейка не может зарегистрировать метод sc.stop(), который вызывается при выходе из записной книжки. В некоторых случаях это может вызвать утечку ресурсов Spark. Чтобы этого избежать, перед остановкой записных книжек выполняйте импорт atexit; atexit.register(lambda: sc.stop()). Если утечка ресурсов возникла случайно, отмените вызвавшие утечку приложения YARN, выполнив описанные выше инструкции.
     
## Проблема разрешений в каталоге журналов Spark 

**Симптом**
 
Когда hdiuser отправляет задание с параметром spark-submit, возникает ошибка java.io.FileNotFoundException: /var/log/spark/sparkdriver\_hdiuser.log (Отказано в доступе), а журнал драйверов не перезаписывается.

**Устранение.**
 
1. Добавьте hdiuser в группу Hadoop. 
2. После создания кластера предоставьте разрешения 777 для каталога /var/log/spark. 
3. В Ambari измените путь размещения журнала Spark на каталог с разрешениями 777.  
4. Выполните команду spark-submit как sudo. 

##См. также

- [Обзор. Apache Spark в Azure HDInsight (Linux)](hdinsight-apache-spark-overview.md)
- [Начало работы. Подготовка к работе Apache Spark в Azure HDInsight (Linux) и выполнение интерактивных запросов с помощью SQL Spark](hdinsight-apache-spark-jupyter-spark-sql.md)

<!---HONumber=AcomDC_1223_2015-->