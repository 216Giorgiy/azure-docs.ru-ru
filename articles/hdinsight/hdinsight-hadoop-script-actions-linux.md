<properties
    pageTitle="Разработка действий сценариев с помощью HDInsight на основе Linux | Microsoft Azure"
    description="Узнайте, как настроить кластеры HDInsight на основе Linux с помощью действия сценария."
    services="hdinsight"
    documentationCenter=""
    authors="Blackmist"
    manager="paulettm"
    editor="cgronlun"/>

<tags
    ms.service="hdinsight"
    ms.workload="big-data"
    ms.tgt_pltfrm="na"
    ms.devlang="na"
    ms.topic="article"
    ms.date="10/29/2015"
    ms.author="larryfr"/>

# Разработка действий сценариев с помощью HDInsight

Действия сценариев служат для настройки кластеров Azure HDInsight. Настройка осуществляется либо путем задания параметров конфигурации кластера во время установки, либо установкой дополнительных служб, инструментов или другого программного обеспечения в кластере.

> [AZURE.NOTE]Информация, приведенная в этом документе, относится только к кластерам HDInsight на платформе Linux. Сведения об использовании действий сценариев в кластерах на платформе Windows см. в статье [Разработка действий сценариев с помощью HDInsight (Windows)](hdinsight-hadoop-script-actions.md).

## Что такое действия сценариев

Действия сценариев представляют собой сценарии Bash, которые выполняются на узлах кластера во время подготовки. Действие сценария выполняется от имени привилегированного пользователя и предоставляет права полного доступа к узлам кластера.

Действие сценария можно вызвать при подготовке кластера из __портала Azure__, __Azure PowerShell__ или из __пакета SDK для HDInsight .NET__.

Пошаговое руководство по настройке кластера с использованием действий сценария см. в статье [Настройка кластеров HDInsight с помощью действий сценария](hdinsight-hadoop-customize-cluster-linux.md).

## <a name="bestPracticeScripting"></a>Рекомендации по разработке сценариев

При разработке пользовательского скрипта для кластера HDInsight следует иметь в виду некоторые рекомендации.

- [Выбор версии Hadoop](#bPS1)
- [Предоставление стабильных ссылок на ресурсы сценария](#bPS2)
- [Использование предварительно скомпилированных ресурсов](#bPS4)
- [Обеспечение идемпотентности сценария настройки кластера](#bPS3)
- [Обеспечение высокого уровня доступности кластера](#bPS5)
- [Настройка пользовательских компонентов для использования хранилища больших двоичных объектов Azure](#bPS6)
- [Запись информации в STDOUT и STDERR](#bPS7)
- [Сохранение файлов в формате ASCII с использованием LF в качестве символа завершения строки](#bps8)

> [AZURE.IMPORTANT]Действия скрипта должны быть завершены в течение 60 минут. В противном случае возникнет ошибка времени ожидания. Во время подготовки узла данный сценарий выполняется одновременно с другими процессами установки и настройки. Конкуренция за ресурсы, такие как ЦП или пропускная способность сети, может привести к затягиванию выполнения сценария по сравнению со временем его выполнения в среде разработки.

### <a name="bPS1"></a>Выбор целевой версии Hadoop

В различных версиях HDInsight используются различные версии служб Hadoop и компонентов. Если сценарий предполагает наличие определенной версии службы или компонента, то такой сценарий следует использовать только с версией HDInsight, включающей необходимые компоненты. Сведения о версиях компонентов, включенных в HDInsight, можно найти в документе [Версии компонентов HDInsight](hdinsight-component-versioning.md).

### <a name="bPS2"></a>Предоставление стабильных ссылок на ресурсы сценария

Пользователям нужно сделать так, чтобы все сценарии и ресурсы, используемые сценарием, были доступны в период существования кластера и чтобы версии этих файлов не изменялись на протяжении данного периода. Эти ресурсы потребуются на случай восстановления узлов в кластере из образа.

Мы советуем скачивать и архивировать все данные в вашу учетную запись хранения Azure.

> [AZURE.IMPORTANT]Используемая учетная запись хранения должна быть учетной записью хранения по умолчанию для кластера или общедоступным и открытым только для чтения контейнером в другой учетной записи хранения.

В частности, примеры, предоставляемые корпорацией Майкрософт, хранятся в учетной записи хранения по адресу [https://hdiconfigactions.blob.core.windows.net/](https://hdiconfigactions.blob.core.windows.net/). Эта учетная запись является открытым и доступным только для чтения контейнером, который обслуживает команда HDInsight.

### <a name="bPS4"></a>Использование предварительно скомпилированных ресурсов

Чтобы свести время выполнения сценария к минимуму, избегайте операций, компилирующих ресурсы из исходного кода. Вместо этого выполните предварительную компиляцию ресурсов и сохраните версию в форме двоичного файла в хранилище больших двоичных объектов Azure, чтобы его можно быстро скачать в кластер из сценария.

### <a name="bPS3"></a>Обеспечение идемпотентности сценария настройки кластера

Следует помнить, что в период существования кластера HDInsight нужно будет пересоздать его образ и что в этом случае будет использоваться сценарий настройки кластера. Этот сценарий должен быть идемпотентным. Имеется в виду, что после пересоздания образа сценарий должен обеспечивать возврат кластера к одному и тому же состоянию при каждом его запуске.

Например, если пользовательский сценарий во время своего первого запуска установил приложение в папку /usr/local/bin, то при каждом последующем запуске сценарий должен проверять, существует ли приложение в папке /usr/local/bin, и только после этого переходить к следующим шагам.

### <a name="bPS5"></a>Обеспечение высокого уровня доступности кластера

В кластерах HDInsight под управлением Linux имеется два головных узла, активных в пределах кластера. Действия сценария выполняются на обоих узлах. Если устанавливаемым компонентам требуется только один головной узел, то сценарий должен предусматривать установку компонента только на один из двух головных узлов кластера.

> [AZURE.IMPORTANT]Стандартные службы, устанавливаемые вместе с HDInsight, выполняют отработку отказа между двумя узлами. Однако эта функция не распространяется на пользовательские компоненты, устанавливаемые при выполнении действий сценария. Если требуется высокая доступность компонентов, устанавливаемых с помощью действий сценария, необходимо реализовать собственный механизм отработки отказа, использующий два доступных головных узла.

### <a name="bPS6"></a>Настройка пользовательских компонентов для использования хранилища больших двоичных объектов Azure

Компоненты, устанавливаемые на кластере, могут по умолчанию использовать хранилище распределенной файловой системы Hadoop (HDFS). При пересоздании образа кластера файловая система HDFS форматируется, в результате чего теряются все хранящиеся в ней данные. Вместо этого вам нужно задействовать хранилище BLOB-объектов Azure (WASB), так как оно является стандартным хранилищем для кластера. Сохраняйте его даже при удалении кластера.

Пример ниже копирует файл giraph-examples.jar из локальной файловой системы в хранилище WASB.

    hadoop fs -copyFromLocal /usr/hdp/current/giraph/giraph-examples.jar /example/jars/

### <a name="bPS7"></a>Запись информации в STDOUT и STDERR

Данные, записываемые в STDOUT и STDERR, заносятся в журнал и могут просматриваться после подготовки кластера с помощью веб-интерфейса Ambari.

Большинство программ и пакетов установки добавляют данные в STDOUT и STDERR по умолчанию, однако вам может потребоваться добавить дополнительные записи в журнал. Для отправки текста в STDOUT используйте `echo`. Например:

        echo "Getting ready to install Foo"

По умолчанию ключевое слово `echo` отправляет строку в STDOUT. Чтобы направить строку в STDERR, добавьте `>&2` перед `echo`. Например:

        >&2 echo "An error occured installing Foo"

Эта команда перенаправляет данные из STDOUT (значение 1, которое является значением по умолчанию, поэтому не указано здесь) в STDERR (2). Дополнительные сведения о перенаправлении ввода-вывода см. на странице [http://www.tldp.org/LDP/abs/html/io-redirection.html](http://www.tldp.org/LDP/abs/html/io-redirection.html).

Дополнительные сведения о просмотре журналов, созданных действиями скриптов, см. в статье [Настройка кластеров HDInsight с помощью действия скрипта](hdinsight-hadoop-customize-cluster-linux.md#troubleshooting).

###<a name="bps8"></a> Сохранение файлов в формате ASCII с использованием LF в качестве символа завершения строки

Сценарии Bash должны храниться в формате ASCII. Для завершения строк в этом файле используется символ LF. Если в файлах используется кодировка UTF-8, которая допускает наличие метки порядка байтов в начале файла и использование символа CRLF для завершения строки (зачастую эта кодировка используется редакторами Windows), то сценарий завершится с ошибками, аналогичными приведенным ниже.

    $'\r': command not found
    line 1: #!/usr/bin/env: No such file or directory

## <a name="helpermethods"></a>Вспомогательные методы для пользовательских сценариев

Вспомогательные методы действий скриптов представляют собой служебные программы, которые можно использовать при создании пользовательских скриптов. Их определение приведено на странице [https://hdiconfigactions.blob.core.windows.net/linuxconfigactionmodulev01/HDInsightUtilities-v01.sh](https://hdiconfigactions.blob.core.windows.net/linuxconfigactionmodulev01/HDInsightUtilities-v01.sh). Эти методы могут быть включены в скрипты с помощью следующей команды:

    # Import the helper method module.
    wget -O /tmp/HDInsightUtilities-v01.sh -q https://hdiconfigactions.blob.core.windows.net/linuxconfigactionmodulev01/HDInsightUtilities-v01.sh && source /tmp/HDInsightUtilities-v01.sh && rm -f /tmp/HDInsightUtilities-v01.sh

Эта команда открывает доступ к следующим вспомогательным приложениям, доступным для использования в сценарии.

| Назначение вспомогательного приложения | Описание |
| ------------ | ----------- |
| `download_file SOURCEURL DESTFILEPATH [OVERWRITE]` | Загружает файл из исходного URL-адреса и сохраняет его в указанное расположение. При этом по умолчанию существующий файл не перезаписывается. |
| `untar_file TARFILE DESTDIR` | Извлекает TAR-файл (с помощью `-xf`) в папку назначения. |
| `test_is_headnode` | При запуске на головном узле кластера возвращает значение 1, в противном случае — 0. |
| `test_is_datanode` | Если текущий узел является узлом данных (рабочим узлом), то возвращается значение 1, в противном случае — 0. |
| `test_is_first_datanode` | Если текущий узел является первым узлом данных (рабочим узлом с именем workernode0), возвращается значение 1, в противном случае — 0. |

## <a name="commonusage"></a>Общие варианты использования

В этом разделе содержится руководство по реализации некоторых общих вариантов использования, которые могут понадобиться при написании пользовательского сценария.

### Передача параметров в сценарий

В некоторых случаях для сценария требуется указывать параметры. Например, для извлечения сведений из интерфейса Ambari REST API может потребоваться пароль администратора кластера.

Параметры, передаваемые в скрипт, называются _позиционными параметрами_, т. е. `$1` соответствует первому параметру, `$2` — второму и т. д. Значение `$0` содержит имя самого сценария.

Значения, передаваемые в сценарий в качестве параметров, должны быть заключены в одинарные кавычки ('). Эти значения будут рассматриваться как литералы, и такие символы, как «!», не будут интерпретироваться как специальные.

### Настройка переменных среды

Настройка переменной среды выполняется следующим образом.

    VARIABLENAME=value

Где VARIABLENAME — имя переменной. После этого можно использовать `$VARIABLENAME` для доступа к переменной. Например, чтобы присвоить значение позиционного параметра переменной среды с именем PASSWORD, воспользуйтесь следующей конструкцией.

    PASSWORD=$1

Для последующего доступа к данным используйте `$PASSWORD`.

Переменные среды, заданные в сценарии, существуют только в пределах области сценария. В некоторых случаях может потребоваться добавить переменные среды, которые значимы на уровне системы и значение которых сохранится после выполнения сценария. Обычно это нужно для того, чтобы пользователи, подключаемые к кластеру через SSH, могли использовать установленные сценарием компоненты. Системная переменная создается добавлением переменной среды в папку `/etc/environment`. Например, следующая конструкция добавляет переменную __HADOOP\_CONF\_DIR__.

    echo "HADOOP_CONF_DIR=/etc/hadoop/conf" | sudo tee -a /etc/environment

### Доступ к расположениям, в которых хранятся пользовательские сценарии

Сценарии для настройки кластера должны находиться в учетной записи хранения по умолчанию для кластера или в общедоступном и открытом только для чтения контейнере другой учетной записи хранения. Если сценарий получает доступ к ресурсам в другом расположении, это расположение должно быть общедоступным (или по крайней мере открытым только для чтения). Например, может потребоваться загрузить файл в кластер с помощью метода `download_file`.

Сохранение файла в учетной записи хранения Azure, доступной кластеру (например, в учетной записи хранения по умолчанию), обеспечит быстрый доступ к нему, так как это хранилище находится в сети Azure.

## <a name="deployScript"></a>Контрольный список для развертывания действия сценария

Ниже приведены шаги, которые использовались при подготовке к развертыванию этих скриптов.

- Поместите файлы, содержащие пользовательские скрипты, в месте, доступном из узлов кластера во время развертывания. Это может быть любая из используемых по умолчанию или дополнительных учетных записей хранения, указанных во время развертывания кластера, или другой общедоступный контейнер хранилища.

- Добавьте проверки в сценарии, чтобы гарантировать их идемпотентное выполнение, т. е. возможность многократного выполнения сценария на одном и том же узле.

- Используйте папку для временных файлов, например /tmp, чтобы хранить скачанные файлы, используемый сценариями. После выполнения сценариев очистите эту папку.

- В случае изменений параметров на уровне операционной системы или файлов конфигурации службы Hadoop может потребоваться перезапуск служб HDInsight. За счет этого службы HDInsight смогут автоматически установить любые параметры уровня операционной системы, например заданные в сценариях переменные среды.

## <a name="runScriptAction"></a>Как запустить действие сценария

Действия сценариев можно использовать для настройки кластеров HDInsight с помощью портала Azure, Azure PowerShell или пакета SDK для HDInsight .NET. Указания см. в разделе [Как использовать действие сценария](hdinsight-hadoop-customize-cluster-linux.md#howto).

## <a name="sampleScripts"></a>Примеры пользовательских сценариев

Корпорация Майкрософт предоставляет примеры скриптов для установки компонентов в кластере HDInsight. Примеры скриптов и инструкции по их использованию доступны по приведенным ниже ссылкам:

- [Установка и использование Hue в кластерах HDInsight](hdinsight-hadoop-hue-linux.md)
- [Установка и использование Spark в кластерах HDInsight](hdinsight-hadoop-spark-install-linux.md)
- [Установка и использование R в кластерах HDInsight Hadoop](hdinsight-hadoop-r-scripts-linux.md)
- [Установка и использование Solr в кластерах HDInsight](hdinsight-hadoop-solr-install-linux.md)
- [Установка и использование Giraph в кластерах HDInsight](hdinsight-hadoop-giraph-install-linux.md)  

> [AZURE.NOTE]Приведенные выше документы относятся только к кластерам HDInsight под управлением Linux. Сведения о скриптах, предназначенных для HDInsight под управлением Windows, см. в статье [Разработка действий скриптов с помощью HDInsight (Windows)](hdinsight-hadoop-script-actions.md) или по ссылкам, приведенным в начале каждой статьи.

##Устранение неполадок

Ниже перечислены ошибки, которые могут возникнуть при использовании ваших сценариев.

__Ошибка__: `$'\r': command not found`. Иногда дополняется фразой `syntax error: unexpected end of file`.

_Причина._ Эта ошибка возникает, когда для завершения строк в скрипте используется символ CRLF. В системах UNIX для завершения строк допускается только символ LF.

Зачастую эта проблема возникает при написании сценария в среде Windows, так как в текстовых редакторах для этой системы CRLF является стандартным символом завершения строки.

_Решение._ Если в вашем текстовом редакторе имеется функция выбора формата Unix или использования символа LF для завершения строк, воспользуйтесь ею. Кроме того, в системе Unix вы можете использовать следующие команды изменения CRLF на LF.

> [AZURE.NOTE]Для замены символов CRLF на LF могут использоваться следующие аналогичные команды. Выберите подходящий вариант в зависимости от наличия в системе соответствующих служебных программ.

| Команда | Примечания |
| ------- | ----- |
| `unix2dos -b INFILE` | Для исходного файла будет создана резервная копия с расширением BAK. |
| `tr -d '\r' < INFILE > OUTFILE` | В файле OUTFILE для окончания строк будут использоваться только символы LF. |
| `perl -pi -e 's/\r\n/\n/g' INFILE` | Эта команда изменит исходный файл без создания нового файла. |
| ```sed 's/$'"/`echo \\r`/" INFILE > OUTFILE``` | В файле OUTFILE для окончания строк будут использоваться только символы LF.

__Ошибка__: `line 1: #!/usr/bin/env: No such file or directory`.

_Причина._ Эта ошибка возникает, если скрипт сохранен в кодировке UTF-8 с меткой порядка байтов (BOM).

_Решение._ Сохраните файл в формате ASCII или UTF-8 без метки порядка байтов. Кроме того, для создания нового файла без метки порядка байтов в системе Linux или Unix вы можете использовать следующую команду.

    awk 'NR==1{sub(/^\xef\xbb\xbf/,"")}{print}' INFILE > OUTFILE

В приведенной выше команде замените __INFILE__ на файл с меткой порядка байтов. Для __OUTFILE__ укажите новое имя файла, который будет содержать скрипт без метки порядка байтов.

## <a name="seeAlso"></a>См. также:

[Настройка кластеров HDInsight с помощью действия сценария](hdinsight-hadoop-customize-cluster-linux.md)

<!---HONumber=AcomDC_1203_2015-->