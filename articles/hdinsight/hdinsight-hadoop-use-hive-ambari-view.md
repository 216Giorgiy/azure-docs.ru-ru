---
title: "Использование представлений Ambari для работы с Hive в HDInsight (Hadoop) — Azure | Документы Майкрософт"
description: "Узнайте, как использовать представление Hive в веб-браузере для отправки запросов Hive. Представление Hive — это компонент веб-интерфейса Ambari, поставляемого с кластером HDInsight на основе Linux."
services: hdinsight
documentationcenter: 
author: Blackmist
manager: jhubbard
editor: cgronlun
tags: azure-portal
ms.assetid: 1abe9104-f4b2-41b9-9161-abbc43de8294
ms.service: hdinsight
ms.custom: hdinsightactive
ms.devlang: na
ms.topic: article
ms.tgt_pltfrm: na
ms.workload: big-data
ms.date: 07/31/2017
ms.author: larryfr
ms.translationtype: HT
ms.sourcegitcommit: c30998a77071242d985737e55a7dc2c0bf70b947
ms.openlocfilehash: 80df3da4d62feb814ea2dd97c96e57954093c5c5
ms.contentlocale: ru-ru
ms.lasthandoff: 08/02/2017

---
# <a name="use-the-hive-view-with-hadoop-in-hdinsight"></a>Использование представления Hive с Hadoop в HDInsight

[!INCLUDE [hive-selector](../../includes/hdinsight-selector-use-hive.md)]

Узнайте, как выполнять запросы Hive с помощью представления Hive в Ambari. Ambari — это служебная программа для управления и мониторинга, предоставляемая с кластерами HDInsight под управлением Linux. Одна из возможностей Ambari — это веб-интерфейс, который можно использовать для выполнения запросов Hive.

> [!NOTE]
> У Ambari много разных функций, которые не рассматриваются в этом документе. Дополнительные сведения см. в статье [Управление кластерами HDInsight с помощью веб-интерфейса Ambari](hdinsight-hadoop-manage-ambari.md).

## <a name="prerequisites"></a>Предварительные требования

* Кластер HDInsight под управлением Linux. Сведения о создании кластера см. в статье [Руководство по Hadoop. Начало работы с Hadoop в HDInsight на платформе Linux](hdinsight-hadoop-linux-tutorial-get-started.md).

> [!IMPORTANT]
> Для выполнения действий, описанных в этом документе, необходим кластер HDInsight, который использует Linux. Linux — это единственная операционная система, используемая для работы с HDInsight 3.4 или более поздних версий. Дополнительные сведения см. в разделе [Приближается дата прекращения сопровождения HDI версии 3.3](hdinsight-component-versioning.md#hdinsight-windows-retirement).

## <a name="open-the-hive-view"></a>Открытие представления Hive

Вы можете открыть представления Ambari на портале Azure, выбрав в разделе **Быстрые ссылки** свой кластер HDInsight, а затем — пункт **Просмотры Ambari**.

![раздел портала с быстрыми ссылками](./media/hdinsight-hadoop-use-hive-ambari-view/quicklinks.png)

В списке представлений выберите __Представление Hive__.

![Выбрано представление Hive](./media/hdinsight-hadoop-use-hive-ambari-view/select-hive-view.png)

> [!NOTE]
> При открытии сайта Ambari вы получите запрос на аутентификацию. Введите имя и пароль учетной записи администратора (по умолчанию — `admin`), которые использовались при создании кластера.

Вы должны увидеть страницу, аналогичную показанной ниже.

![Изображение листа запроса для представления Hive](./media/hdinsight-hadoop-use-hive-ambari-view/ambari-hive-view.png)

## <a name="hivequery"></a>Выполнение запроса

Чтобы выполнить запрос Hive, выполните следующие действия в представлении Hive.

1. На вкладке __Запрос__ вставьте в лист следующие инструкции HiveQL:

    ```hiveql
    DROP TABLE log4jLogs;
    CREATE EXTERNAL TABLE log4jLogs(t1 string, t2 string, t3 string, t4 string, t5 string, t6 string, t7 string)
    ROW FORMAT DELIMITED FIELDS TERMINATED BY ' '
    STORED AS TEXTFILE LOCATION '/example/data/';
    SELECT t4 AS sev, COUNT(*) AS cnt FROM log4jLogs WHERE t4 = '[ERROR]' GROUP BY t4;
    ```

    Эти операторы выполняют следующие действия.

   * `DROP TABLE` — удаление таблицы и файла данных, если таблица уже существует.

   * `CREATE EXTERNAL TABLE` — создание "внешней" таблицы в Hive.
   Внешние таблицы хранят только определение таблицы в Hive. Данные остаются в исходном расположении.

   * `ROW FORMAT` — настройка форматирования данных. В данном случае поля всех журналов разделены пробелом.

   * `STORED AS TEXTFILE LOCATION` — место хранения данных и их формат (текст).

   * `SELECT` — подсчет количества строк, в которых столбец t4 содержит значение [ERROR].

     > [!NOTE]
     > Внешние таблицы следует использовать, если исходные данные должны обновляться с использованием внешних источников. Например, с использованием процесса автоматической передачи данных или другой операции MapReduce. Удаление внешней таблицы *не* приводит к удалению данных, будет удалено только определение таблицы.

    > [!IMPORTANT]
    > Оставьте для параметра __База данных__ значение __по умолчанию__. В примерах в этом документе используется база данных по умолчанию, входящая в состав HDInsight.

2. Чтобы выполнить запрос, нажмите кнопку **Выполнить** под листом. Она станет оранжевой, а текст изменится на **Остановить**.

3. Когда запрос будет выполнен, на вкладке **Результаты** появятся результаты этой операции. Вот пример результата запроса:

        sev       cnt
        [ERROR]   3

    На вкладке **Журналы** отображаются сведения, регистрируемые в процессе выполнения задания.

   > [!TIP]
   > В диалоговом окне с раскрывающимся списком **Save results** (Сохранение результатов) в верхнем левом углу раздела **Query Process Results** (Результаты обработки запроса) можно скачать или сохранить результаты.

4. Выберите четыре первые строки запроса, а затем — команду **Выполнить**. Обратите внимание на отсутствие результатов после выполнения задания. Если нажать кнопку **Выполнить**, выбрав часть запроса, запрос выполняется только с использованием выбранных инструкций. В нашем примере не выбрана последняя инструкция, которая извлекает строки из таблицы. Если выбрать только эту строку, а затем нажать кнопку **Выполнить**, отобразятся ожидаемые результаты.

5. Чтобы добавить новый лист, нажмите кнопку **Новый лист** в нижней части **редактора запросов**. На новом листе введите указанные ниже инструкции HiveQL.

    ```hiveql
    CREATE TABLE IF NOT EXISTS errorLogs (t1 string, t2 string, t3 string, t4 string, t5 string, t6 string, t7 string) STORED AS ORC;
    INSERT OVERWRITE TABLE errorLogs SELECT t1, t2, t3, t4, t5, t6, t7 FROM log4jLogs WHERE t4 = '[ERROR]';
    ```

  Эти операторы выполняют следующие действия.

   * **CREATE TABLE IF NOT EXISTS** : создание таблицы, если она до этого не существовала. Так как ключевое слово **Внешний** не используется, создается внутренняя таблица. Внутренняя таблица хранится в хранилище данных Hive и полностью обслуживается Hive. В отличие от внешних таблиц, удаление внутренней таблицы приводит к удалению базовых данных.

   * **STORED AS ORC** : хранение данных в формате ORC (Optimized Row Columnar). Это высокооптимизированный и эффективный формат для хранения данных Hive.

   * **INSERT OVERWRITE ... SELECT** — выбирает из таблицы **log4jLogs** строки, содержащие значение `[ERROR]`, а затем вставляет данные в таблицу **errorLogs**.

     Нажмите кнопку **Выполнить**, чтобы выполнить этот запрос. На вкладке **Результаты** не отображаются сведения, если запрос не возвращает строки. По завершении запроса должно отображаться состояние **Успешно**.

### <a name="visual-explain"></a>Визуальное объяснение

Чтобы отобразить визуализацию плана запроса, выберите под листом вкладку **Visual Explain** (Визуальное пояснение).

Представление запроса **Visual Explain** (Визуальное объяснение) помогает разобраться в потоке сложных запросов. Вы можете просмотреть текстовый эквивалент этого представления, нажав кнопку **Объяснить** в редакторе запросов.

### <a name="tez-ui"></a>Пользовательский интерфейс Tez

Чтобы отобразить пользовательский интерфейс Tez для запроса, выберите под листом вкладку **Tez**.

> [!IMPORTANT]
> Tez используется не для всех запросов. Многие запросы можно разрешить и без применения Tez. 

Если Tez использовался для разрешения запроса, отображается направленный ациклический граф (DAG) . Чтобы просмотреть DAG для ранее выполненных запросов или выполнить отладку процесса Tez, используйте [представление Tez](hdinsight-debug-ambari-tez-view.md) .

## <a name="view-job-history"></a>Просмотр журнала заданий

На вкладке __Задания__ отображается журнал запросов Hive.

![Изображение журнала заданий](./media/hdinsight-hadoop-use-hive-ambari-view/job-history.png)

## <a name="database-tables"></a>Таблицы базы данных

Вкладку __Таблицы__ можно использовать для работы с таблицами в базе данных Hive.

![Изображение вкладки "Таблицы"](./media/hdinsight-hadoop-use-hive-ambari-view/tables.png)

## <a name="saved-queries"></a>Сохраненные запросы

На вкладке "Запрос" можно при желании сохранять запросы. Сохраненные запросы можно повторно использовать с помощью вкладки __Сохраненные запросы__.

![Изображение вкладки "Сохраненные запросы"](./media/hdinsight-hadoop-use-hive-ambari-view/saved-queries.png)

## <a name="user-defined-functions"></a>Определяемые пользователем функции

Инфраструктуру Hive также можно расширить с помощью определяемых пользователем функций (UDF). UDF позволяет реализовать функции или логику, сложно моделируемые в HiveQL.

Вкладка UDF в верхней части представления Hive позволяет объявлять и сохранять наборы определяемых пользователем функций. Эти функции могут использоваться в **редакторе запросов**.

![Изображение вкладки "Определяемая пользователем функция"](./media/hdinsight-hadoop-use-hive-ambari-view/user-defined-functions.png)

После добавления в представление Hive UDF в нижней части **редактора запросов** появляется кнопка **Insert udfs** (Вставить определяемые пользователем функции). Нажав эту кнопку, вы увидите раскрывающийся список функций, определенных в представлении Hive. Выбирая определяемую пользователем функцию, вы добавляете в запрос соответствующие инструкции HiveQL.

Например, вы определили функцию со следующими свойствами:

* имя ресурса — myudfs;

* путь к ресурсу — /myudfs.jar;

* имя определяемой пользователем функции — myawesomeudf;

* имя класса определяемой пользователем функции — com.myudfs.Awesome.

Нажав кнопку **Insert udfs** (Вставить определяемые пользователем функции), вы увидите запись с именем **myudfs**, содержащую раскрываемый список для каждой функции, определяемой для этого ресурса. В нашем примере это функция **myawesomeudf**. Если вы выберете эту запись, в начало запроса будет добавлен следующий код:

```hiveql
add jar /myudfs.jar;
create temporary function myawesomeudf as 'com.myudfs.Awesome';
```

Затем вы можете использовать эту функцию в своем запросе. Например, `SELECT myawesomeudf(name) FROM people;`.

Дополнительные сведения об использовании определяемых пользователем функций с Hive в HDInsight см. в следующих документах:

* [Использование Python с Hive и Pig в HDInsight](hdinsight-python.md)
* [Добавление пользовательских UDF Hive в HDInsight](http://blogs.msdn.com/b/bigdatasupport/archive/2014/01/14/how-to-add-custom-hive-udfs-to-hdinsight.aspx)

## <a name="hive-settings"></a>Параметры Hive

Параметры можно использовать для изменения различных настроек Hive. Например, изменить механизм выполнения для Hive с Tez (по умолчанию) на MapReduce.

## <a id="nextsteps"></a>Дальнейшие действия

Общая информация о Hive в HDInsight.

* [Использование Hive с Hadoop в HDInsight](hdinsight-use-hive.md)

Дополнительная информация о других способах работы с Hadoop в HDInsight.

* [Использование Pig с Hadoop в HDInsight](hdinsight-use-pig.md)
* [Использование MapReduce с Hadoop в HDInsight](hdinsight-use-mapreduce.md)

