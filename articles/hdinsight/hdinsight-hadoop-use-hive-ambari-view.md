---
title: "Использование представлений Ambari для работы с Hive в HDInsight (Hadoop) | Документация Майкрософт"
description: "Узнайте, как использовать представление Hive в веб-браузере для отправки запросов Hive. Представление Hive — это компонент веб-интерфейса Ambari, поставляемого с кластером HDInsight на основе Linux."
services: hdinsight
documentationcenter: 
author: Blackmist
manager: jhubbard
editor: cgronlun
tags: azure-portal
ms.assetid: 1abe9104-f4b2-41b9-9161-abbc43de8294
ms.service: hdinsight
ms.devlang: na
ms.topic: article
ms.tgt_pltfrm: na
ms.workload: big-data
ms.date: 10/28/2016
ms.author: larryfr
translationtype: Human Translation
ms.sourcegitcommit: 2ea002938d69ad34aff421fa0eb753e449724a8f
ms.openlocfilehash: 4cdc1f0a8958edd23f8df02c4d16d3f60fe648bd


---
# <a name="use-the-hive-view-with-hadoop-in-hdinsight"></a>Использование представления Hive с Hadoop в HDInsight
[!INCLUDE [hive-selector](../../includes/hdinsight-selector-use-hive.md)]

Ambari — это служебная программа для управления и мониторинга, предоставляемая с кластерами HDInsight под управлением Linux. Одна из возможностей Ambari — это веб-интерфейс, который можно использовать для выполнения запросов Hive. Он реализован в виде **представления Hive**, входящего в набор представлений Ambari для кластера HDInsight.

> [!NOTE]
> У Ambari много разных функций, которые не рассматриваются в этом документе. Дополнительные сведения см. в статье [Управление кластерами HDInsight с помощью веб-интерфейса Ambari](hdinsight-hadoop-manage-ambari.md).
> 
> 

## <a name="prerequisites"></a>Предварительные требования
* Кластер HDInsight под управлением Linux. Сведения о создании кластера см. в статье [Руководство по Hadoop. Начало работы с Hadoop в HDInsight на платформе Linux](hdinsight-hadoop-linux-tutorial-get-started.md).

## <a name="open-the-hive-view"></a>Открытие представления Hive
Вы можете открыть представления Ambari на портале Azure, выбрав в разделе **Быстрые ссылки** свой кластер HDInsight, а затем — пункт **Просмотры Ambari**.

![Раздел «Быстрые ссылки»](./media/hdinsight-hadoop-use-hive-ambari-view/quicklinks.png)

Кроме того, Ambari можно открыть непосредственно. Перейдите в веб-браузере по адресу https://CLUSTERNAME.azurehdinsight.net (где **CLUSTERNAME** — это имя вашего кластера HDInsight) и выберите набор квадратов в меню страницы (рядом со ссылкой и кнопкой **Администратор** в левой части страницы), чтобы отобразился список доступных представлений. Выберите **представление Hive**.

![Выбор представлений Ambari](./media/hdinsight-hadoop-use-hive-ambari-view/selecthiveview.png).

> [!NOTE]
> При открытии сайта Ambari вы получите запрос на проверку подлинности. Введите имя и пароль учетной записи администратора (по умолчанию — `admin`), которые использовались при создании кластера.
> 
> 

Вы должны увидеть страницу, аналогичную показанной ниже:

![Изображение страницы представления Hive с разделом редактора запросов](./media/hdinsight-hadoop-use-hive-ambari-view/hiveview.png)

## <a name="view-tables"></a>Просмотр таблиц
В разделе **Обозреватель базы данных** на вкладке **Базы данных** выберите пункт **По умолчанию**. Вы увидите список таблиц, входящих в базу данных по умолчанию. В новом кластере HDInsight должна присутствовать только одна таблица — **hivesampletable**.

![Обозреватель баз данных с развернутой базой данных по умолчанию](./media/hdinsight-hadoop-use-hive-ambari-view/databaseexplorer.png)

Добавляя новые таблицы в соответствии с инструкциями, вы можете щелкать значок обновления в правом верхнем углу обозревателя базы данных, чтобы обновлять список доступных таблиц.

## <a name="a-namehivequeryaquery-editor"></a><a name="hivequery"></a>Редактор запросов
В представлении Hive выполните описанные ниже действия, чтобы создать запрос Hive для получения данных, входящих в состав кластера.

1. На странице в разделе **Редактор запросов** вставьте в рабочий лист следующие инструкции HiveQL:
   
        DROP TABLE log4jLogs;
        CREATE EXTERNAL TABLE log4jLogs(t1 string, t2 string, t3 string, t4 string, t5 string, t6 string, t7 string)
        ROW FORMAT DELIMITED FIELDS TERMINATED BY ' '
        STORED AS TEXTFILE LOCATION 'wasbs:///example/data/';
        SELECT t4 AS sev, COUNT(*) AS cnt FROM log4jLogs WHERE t4 = '[ERROR]' GROUP BY t4;
   
    Эти операторы выполняют следующие действия.
   
   * **DROP TABLE** — удаляет таблицу и файл данных, если таблица уже существует.
   * **CREATE EXTERNAL TABLE** — создает новую внешнюю таблицу в Hive. Внешние таблицы хранят только описание самой таблицы в Hive, в то время как данные остаются в исходном расположении.
   * **ROW FORMAT** — указывает Hive, как следует форматировать данные. В данном случае поля всех журналов разделены пробелом.
   * **STORED AS TEXTFILE LOCATION** : информация для Hive о расположении хранения данных (каталог example/data) и об их формате (текстовый).
   * **SELECT** : подсчитывает количество строк, у которых столбец t4 содержит значение [ERROR].
     
     > [!NOTE]
     > Внешние таблицы необходимо использовать в тех случаях, когда ожидается, что исходные данные будут обновляться внешним источником, таким как автоматизированный процесс передачи данных, или другой операцией MapReduce, и при этом нужно, чтобы запросы Hive использовали самые последние данные. Удаление внешней таблицы *не* приводит к удалению данных, будет удалено только определение таблицы.
     > 
     > 
2. Чтобы выполнить запрос, нажмите кнопку **Выполнить** в нижней части окна редактора запросов. Кнопка станет оранжевой, а текст на ней изменится на **Stop execution** (Остановить выполнение). Под окном редактора запросов появится раздел **Query Process Results** (Результаты обработки запроса), содержащий сведения о выполнении задания.
   
   > [!IMPORTANT]
   > В некоторых браузерах записи журнала или результаты могут не обновляться надлежащим образом. Если при выполнении задания записи журнала или полученные результаты не обновляются, попробуйте воспользоваться Mozilla FireFox или Google Chrome.
   > 
   > 
3. После выполнения запроса в разделе **Query Process Results** (Результаты обработки запроса) будут отображены результаты операции. Кнопка **Stop execution** (Остановить выполнение) снова станет зеленой, а текст на ней изменится на **Выполнить**. Вкладка **Результаты** должна содержать указанные ниже сведения.
   
        sev       cnt
        [ERROR]   3
   
    На вкладке **Журналы** отображаются сведения, регистрируемые в процессе выполнения задания. Эти сведения можно использовать для устранения неполадок, возникающих при выполнении запроса.
   
   > [!TIP]
   > Обратите внимание на раскрывающийся список **Сохранить результаты**, расположенный в разделе **Query Process Results** (Результаты обработки запроса) слева вверху. Этот список можно использовать для загрузки или сохранения результатов в хранилище HDInsight в формате CSV-файла.
   > 
   > 
4. Выберите четыре первые строки запроса, а затем — команду **Выполнить**. Обратите внимание на отсутствие результатов после выполнения задания. Это связано с тем, что вы нажали кнопку **Выполнить**, выбрав часть запроса. Следовательно, запрос выполняется только с использованием выбранных инструкций. В нашем примере не выбрана последняя инструкция, которая извлекает строки из таблицы. Если выбрать только эту строку, а затем нажать кнопку **Выполнить**, отобразятся ожидаемые результаты.
5. В нижней части **редактора запросов** нажмите кнопку **Новый лист**, чтобы создать рабочий лист. На новом листе введите указанные ниже инструкции HiveQL.
   
        CREATE TABLE IF NOT EXISTS errorLogs (t1 string, t2 string, t3 string, t4 string, t5 string, t6 string, t7 string) STORED AS ORC;
        INSERT OVERWRITE TABLE errorLogs SELECT t1, t2, t3, t4, t5, t6, t7 FROM log4jLogs WHERE t4 = '[ERROR]';
   
    Эти операторы выполняют следующие действия.
   
   * **CREATE TABLE IF NOT EXISTS** : создание таблицы, если она до этого не существовала. Так как ключевое слово **EXTERNAL** не было использовано, данная таблица будет являться "внутренней", то есть храниться в хранилище данных Hive и полностью обслуживаться Hive. В отличие от внешних таблиц, удаление внутренних таблиц приводит также к удалению данных.
   * **STORED AS ORC** — сохраняет данные в формате Optimized Row Columnar (ORC). Это высокооптимизированный и эффективный формат для хранения данных Hive.
   * **INSERT OVERWRITE ... SELECT** — выбирает из таблицы **log4jLogs** строки, содержащие значение [ERROR], а затем вставляет данные в таблицу **errorLogs**.
     
     Нажмите кнопку **Выполнить**, чтобы выполнить этот запрос. Хотя вкладка **Результаты** не будет содержать никаких сведений (этот запрос не возвращает строки), состояние должно измениться на **Выполнено**.

### <a name="hive-settings"></a>Параметры Hive
Щелкните значок **Параметры** в правой части окна редактора.

![Значки](./media/hdinsight-hadoop-use-hive-ambari-view/settings.png)

Параметры предназначены для изменения различных настроек Hive, например, для изменения подсистемы выполнения для Hive с Tez (значение по умолчанию) на MapReduce.

### <a name="visual-explain"></a>Визуальное объяснение
Щелкните значок **Visual Explain** (Визуальное объяснение) в правой части окна редактора.

![Значки](./media/hdinsight-hadoop-use-hive-ambari-view/visualexplainicon.png)

Это представление запроса **Visual Explain** (Визуальное объяснение), которое помогает разобраться в потоке сложных запросов. Вы можете просмотреть текстовый эквивалент этого представления, нажав кнопку **Объяснить** в редакторе запросов.

![Значок «Визуальное объяснение»](./media/hdinsight-hadoop-use-hive-ambari-view/visualexplain.png)

### <a name="tez"></a>Tez
Щелкните значок **Tez** в правой части окна редактора.

![Значки](./media/hdinsight-hadoop-use-hive-ambari-view/tez.png)

Вы увидите направленный ациклический граф (DAG), который используется Tez для этого запроса, если он существует. Чтобы просмотреть DAG для ранее выполненных запросов или выполнить отладку процесса Tez, используйте [представление Tez](hdinsight-debug-ambari-tez-view.md) .

### <a name="notifications"></a>Уведомления
Щелкните значок **Уведомления** в правой части окна редактора.

![Значки](./media/hdinsight-hadoop-use-hive-ambari-view/notifications.png)

Уведомления — это сообщения, создаваемые при выполнении запросов. Например, вы получите уведомление при отправке запроса или возникновении ошибки.

## <a name="saved-queries"></a>Сохраненные запросы
1. В редакторе запросов создайте лист и введите следующий запрос:
   
        SELECT * from errorLogs;
   
    Выполните запрос, чтобы убедиться, что он работает. Результат будет следующим:
   
        errorlogs.t1     errorlogs.t2     errorlogs.t3     errorlogs.t4     errorlogs.t5     errorlogs.t6     errorlogs.t7
        2012-02-03     18:35:34     SampleClass0     [ERROR]     incorrect     id     
        2012-02-03     18:55:54     SampleClass1     [ERROR]     incorrect     id     
        2012-02-03     19:25:27     SampleClass4     [ERROR]     incorrect     id
2. Нажмите кнопку **Сохранить как** в нижней части окна редактора. Присвойте этому запросу имя **Errorlogs** и щелкните **ОК**. Обратите внимание, что имя листа изменилось на **Errorlogs**.
3. Перейдите на вкладку **Сохраненные запросы** в верхней части страницы представления Hive. Обратите внимание, что запрос **Errorlogs** теперь отображается как сохраненный. Он будет оставаться в этом списке, пока вы не удалите его. Выбрав имя, можно открыть запрос в редакторе.

## <a name="query-history"></a>Журнал запросов
Кнопка **Журнал** в верхней части представления Hive позволяет просматривать ранее выполненные запросы. Нажмите на нее и выберите из списка нужные запросы. Выбранный запрос откроется в редакторе запросов.

## <a name="user-defined-functions-udf"></a>Определяемые пользователем функции
Инфраструктура Hive также может быть расширена с помощью **определяемых пользователем функций (UDF)**. UDF позволяет реализовать функции или логику, сложно моделируемые в HiveQL.

Определяемые пользователем функции можно использовать как часть инструкций HiveQL в запросе. При этом вкладка "Определяемая пользователем функция" в верхней части представления Hive позволяет объявлять и сохранять наборы определяемых пользователем функций, которые могут использоваться в **редакторе запросов**.

После добавления в представление Hive определяемой пользователем функции в нижней части **редактора запросов** появляется кнопка **Insert udfs** (Вставить определяемые пользователем функции). Нажав эту кнопку, вы увидите список функций, определенных в представлении Hive. Выбирая определяемую пользователем функцию, вы добавляете в запрос соответствующие инструкции HiveQL.

Например, вы определили функцию со следующими свойствами:

* имя ресурса — myudfs;
* путь к ресурсу — wasbs:///myudfs.jar;
* имя определяемой пользователем функции — myawesomeudf;
* имя класса определяемой пользователем функции — com.myudfs.Awesome.

Нажав кнопку **Insert udfs** (Вставить определяемые пользователем функции), вы увидите запись с именем **myudfs**, содержащую раскрываемый список для каждой функции, определяемой для этого ресурса. В нашем примере это функция **myawesomeudf**. Если вы выберете эту запись, в начало запроса будет добавлен следующий код:

    add jar wasbs:///myudfs.jar;

    create temporary function myawesomeudf as 'com.myudfs.Awesome';

Затем вы можете использовать эту функцию в своем запросе. Пример: `SELECT myawesomeudf(name) FROM people;`.

Дополнительные сведения об использовании определяемых пользователем функций с Hive в HDInsight см. в следующих ресурсах:

* [Использование Python с Hive и Pig в HDInsight](hdinsight-python.md)
* [Добавление пользовательских UDF Hive в HDInsight](http://blogs.msdn.com/b/bigdatasupport/archive/2014/01/14/how-to-add-custom-hive-udfs-to-hdinsight.aspx)

## <a name="a-idnextstepsanext-steps"></a><a id="nextsteps"></a>Дальнейшие действия
Общая информация о Hive в HDInsight.

* [Использование Hive с Hadoop в HDInsight](hdinsight-use-hive.md)

Дополнительная информация о других способах работы с Hadoop в HDInsight.

* [Использование Pig с Hadoop в HDInsight](hdinsight-use-pig.md)
* [Использование MapReduce с Hadoop в HDInsight](hdinsight-use-mapreduce.md)




<!--HONumber=Nov16_HO3-->


