---
title: "Использование представлений Ambari для работы с Hive в HDInsight (Hadoop) | Документация Майкрософт"
description: "Узнайте, как использовать представление Hive в веб-браузере для отправки запросов Hive. Представление Hive — это компонент веб-интерфейса Ambari, поставляемого с кластером HDInsight на основе Linux."
services: hdinsight
documentationcenter: 
author: Blackmist
manager: jhubbard
editor: cgronlun
tags: azure-portal
ms.assetid: 1abe9104-f4b2-41b9-9161-abbc43de8294
ms.service: hdinsight
ms.devlang: na
ms.topic: article
ms.tgt_pltfrm: na
ms.workload: big-data
ms.date: 02/08/2017
ms.author: larryfr
translationtype: Human Translation
ms.sourcegitcommit: 5ec4b964066687b506686709c3dc5ed5b402fbaf
ms.openlocfilehash: a846d5a70451ed3082b90d87b90bef0eb6da5993
ms.lasthandoff: 02/09/2017


---
# <a name="use-the-hive-view-with-hadoop-in-hdinsight"></a>Использование представления Hive с Hadoop в HDInsight

[!INCLUDE [hive-selector](../../includes/hdinsight-selector-use-hive.md)]

Ambari — это служебная программа для управления и мониторинга, предоставляемая с кластерами HDInsight под управлением Linux. Одна из возможностей Ambari — это веб-интерфейс, который можно использовать для выполнения запросов Hive. Он реализован в виде **представления Hive**, входящего в набор представлений Ambari для кластера HDInsight.

> [!NOTE]
> У Ambari много разных функций, которые не рассматриваются в этом документе. Дополнительные сведения см. в статье [Управление кластерами HDInsight с помощью веб-интерфейса Ambari](hdinsight-hadoop-manage-ambari.md).

## <a name="prerequisites"></a>Предварительные требования

* Кластер HDInsight под управлением Linux. Сведения о создании кластера см. в статье [Руководство по Hadoop. Начало работы с Hadoop в HDInsight на платформе Linux](hdinsight-hadoop-linux-tutorial-get-started.md).

> [!IMPORTANT]
> Для выполнения действий, описанных в этом документе, необходим кластер HDInsight, который использует Linux. Linux — единственная операционная система, используемая для работы с HDInsight 3.4 или более поздней версии. См. дополнительные сведения о [нерекомендуемых версиях HDInsight в Windows](hdinsight-component-versioning.md#hdi-version-32-and-33-nearing-deprecation-date).

## <a name="open-the-hive-view"></a>Открытие представления Hive

Вы можете открыть представления Ambari на портале Azure, выбрав в разделе **Быстрые ссылки** свой кластер HDInsight, а затем — пункт **Просмотры Ambari**.

![Раздел «Быстрые ссылки»](./media/hdinsight-hadoop-use-hive-ambari-view/quicklinks.png)

Кроме того, можно открыть веб-интерфейс Ambari напрямую, открыв в браузере адрес https://CLUSTERNAME.azurehdinsight.net. Замените **CLUSTERNAME** именем кластера HDInsight. Выберите набор квадратов в меню страницы рядом со ссылкой **Администрирование**, чтобы открыть список доступных представлений. Выберите **представление Hive**.

![Выбор представлений Ambari](./media/hdinsight-hadoop-use-hive-ambari-view/selecthiveview.png).

> [!NOTE]
> При открытии сайта Ambari вы получите запрос на аутентификацию. Введите имя и пароль учетной записи администратора (по умолчанию — `admin`), которые использовались при создании кластера.

Вы должны увидеть страницу, аналогичную показанной ниже:

![Изображение страницы представления Hive с разделом редактора запросов](./media/hdinsight-hadoop-use-hive-ambari-view/hiveview.png)

## <a name="view-tables"></a>Просмотр таблиц
В разделе **Обозреватель базы данных** на вкладке **Базы данных** выберите пункт **По умолчанию**. Вы увидите список таблиц, входящих в базу данных по умолчанию. В новом кластере HDInsight должна присутствовать только одна таблица — **hivesampletable**.

![Обозреватель баз данных с развернутой базой данных по умолчанию](./media/hdinsight-hadoop-use-hive-ambari-view/databaseexplorer.png)

Добавляя таблицы в соответствии с инструкциями, вы можете щелкать значок обновления в правом верхнем углу обозревателя базы данных, чтобы обновлять список.

## <a name="a-namehivequeryaquery-editor"></a><a name="hivequery"></a>Редактор запросов

Чтобы выполнить запрос Hive, выполните следующие действия в представлении Hive.

1. На странице в разделе **Редактор запросов** вставьте в рабочий лист следующие инструкции HiveQL:
   
    ```hiveql
    DROP TABLE log4jLogs;
    CREATE EXTERNAL TABLE log4jLogs(t1 string, t2 string, t3 string, t4 string, t5 string, t6 string, t7 string)
    ROW FORMAT DELIMITED FIELDS TERMINATED BY ' '
    STORED AS TEXTFILE LOCATION '/example/data/';
    SELECT t4 AS sev, COUNT(*) AS cnt FROM log4jLogs WHERE t4 = '[ERROR]' GROUP BY t4;
    ```
   
    Эти операторы выполняют следующие действия.
   
   * **DROP TABLE** — удаляет таблицу и файл данных, если таблица уже существует.

   * **CREATE EXTERNAL TABLE** — создает новую внешнюю таблицу в Hive. 
   Внешние таблицы хранят только определение таблицы в Hive. Данные остаются в исходном расположении.

   * **ROW FORMAT** : инструкции по форматированию данных для Hive. В данном случае поля всех журналов разделены пробелом.

   * **STORED AS TEXTFILE LOCATION** : информация для Hive о расположении хранения данных (каталог example/data) и об их формате (текстовый).

   * **SELECT** : подсчитывает количество строк, у которых столбец t4 содержит значение [ERROR].
     
     > [!NOTE]
     > Внешние таблицы следует использовать, если исходные данные должны обновляться с использованием внешних источников. Например, с использованием процесса автоматической передачи данных или другой операции MapReduce. Удаление внешней таблицы *не* приводит к удалению данных, будет удалено только определение таблицы.

2. Чтобы выполнить запрос, нажмите кнопку **Выполнить** в нижней части окна редактора запросов. Она станет оранжевой, а текст изменится на **Stop execution** (Остановить выполнение). Под окном редактора запросов появится раздел **Query Process Results** (Результаты обработки запроса), содержащий сведения о выполнении задания.
   
   > [!IMPORTANT]
   > В некоторых браузерах записи журнала или результаты могут не обновляться надлежащим образом. Если при выполнении задания записи журнала или полученные результаты не обновляются, попробуйте воспользоваться Mozilla FireFox или Google Chrome.
 
3. Когда запрос будет выполнен, в разделе с **результатами обработки запроса** появятся результаты операции. После завершения запроса кнопка **Stop execution** (Остановить выполнение) снова станет зеленой, а текст на ней изменится на **Выполнить**. Вкладка **Результаты** должна содержать указанные ниже сведения.
   
        sev       cnt
        [ERROR]   3
   
    На вкладке **Журналы** отображаются сведения, регистрируемые в процессе выполнения задания.
   
   > [!TIP]
   > В диалоговом окне с раскрывающимся списком **Save results** (Сохранение результатов) в верхнем левом углу раздела **Query Process Results** (Результаты обработки запроса) можно скачать или сохранить результаты.

4. Выберите четыре первые строки запроса, а затем — команду **Выполнить**. Обратите внимание на отсутствие результатов после выполнения задания. Если нажать кнопку **Выполнить**, выбрав часть запроса, запрос выполняется только с использованием выбранных инструкций. В нашем примере не выбрана последняя инструкция, которая извлекает строки из таблицы. Если выбрать только эту строку, а затем нажать кнопку **Выполнить**, отобразятся ожидаемые результаты.

5. В нижней части **редактора запросов** нажмите кнопку **Новый лист**, чтобы добавить новый лист. На новом листе введите указанные ниже инструкции HiveQL.
   
    ```hiveql
    CREATE TABLE IF NOT EXISTS errorLogs (t1 string, t2 string, t3 string, t4 string, t5 string, t6 string, t7 string) STORED AS ORC;
    INSERT OVERWRITE TABLE errorLogs SELECT t1, t2, t3, t4, t5, t6, t7 FROM log4jLogs WHERE t4 = '[ERROR]';
    ```
   
    These statements perform the following actions:
   
   * **CREATE TABLE IF NOT EXISTS** : создание таблицы, если она до этого не существовала. Так как ключевое слово **Внешний** не используется, создается внутренняя таблица. Внутренняя таблица хранится в хранилище данных Hive и полностью обслуживается Hive. В отличие от внешних таблиц, удаление внутренней таблицы приводит к удалению базовых данных.

   * **STORED AS ORC** — сохраняет данные в формате Optimized Row Columnar (ORC). Это высокооптимизированный и эффективный формат для хранения данных Hive.

   * **INSERT OVERWRITE ... SELECT** — выбирает из таблицы **log4jLogs** строки, содержащие значение [ERROR], а затем вставляет данные в таблицу **errorLogs**.
     
     Нажмите кнопку **Выполнить**, чтобы выполнить этот запрос. На вкладке **Результаты** не отображаются сведения, если запрос не возвращает строки. По завершении запроса должно отображаться состояние **Успешно**.

### <a name="hive-settings"></a>Параметры Hive

Щелкните значок **Параметры** в правой части окна редактора.

![Значок параметров для представления Hive](./media/hdinsight-hadoop-use-hive-ambari-view/hive-view-settings-icon.png)

Параметры предназначены для изменения различных настроек Hive, например, для изменения подсистемы выполнения для Hive с Tez (значение по умолчанию) на MapReduce.

### <a name="visualization"></a>Визуализация:

Щелкните значок __Визуализация__ в правой части окна редактора.

![Значок "Визуализация" для представления Hive](./media/hdinsight-hadoop-use-hive-ambari-view/hive-view-visualization-icon.png)

Откроется интерфейс визуализации, где можно создавать визуализации данных, возвращаемых из запроса. Ниже приведен пример визуализации данных из таблицы `hivesampletable` в HDInsight.

![Пример визуализации](./media/hdinsight-hadoop-use-hive-ambari-view/hive-view-visualization.png)

### <a name="visual-explain"></a>Визуальное объяснение

Щелкните значок **Visual Explain** (Визуальное объяснение) в правой части окна редактора.

![Значок Visual explain (Визуальное объяснение) для представления Hive](./media/hdinsight-hadoop-use-hive-ambari-view/hive-view-visual-explain-icon.png)

Это представление запроса **Visual Explain** (Визуальное объяснение), которое помогает разобраться в потоке сложных запросов. Вы можете просмотреть текстовый эквивалент этого представления, нажав кнопку **Объяснить** в редакторе запросов.

![Значок «Визуальное объяснение»](./media/hdinsight-hadoop-use-hive-ambari-view/visualexplain.png)

### <a name="tez"></a>Tez

Щелкните значок **Tez** в правой части окна редактора.

![Значок Tez для представления Hive](./media/hdinsight-hadoop-use-hive-ambari-view/hive-view-tez-icon.png)

Вы увидите направленный ациклический граф (DAG), который используется Tez для этого запроса, если он существует. Чтобы просмотреть DAG для ранее выполненных запросов или выполнить отладку процесса Tez, используйте [представление Tez](hdinsight-debug-ambari-tez-view.md) .

### <a name="notifications"></a>Уведомления

Щелкните значок **Уведомления** в правой части окна редактора.

![Значок "Уведомления" для представления Hive](./media/hdinsight-hadoop-use-hive-ambari-view/hive-view-notifications-icon.png)

Уведомления — это сообщения, создаваемые при выполнении запросов. Например, вы получите уведомление при отправке запроса или возникновении ошибки.

## <a name="saved-queries"></a>Сохраненные запросы

1. В редакторе запросов создайте лист и введите следующий запрос:
   
    ```hiveql
    SELECT * from errorLogs;
    ```
   
    Выполните запрос, чтобы убедиться, что он работает. Вы должны увидеть результат, аналогичный приведенному ниже.
   
        errorlogs.t1     errorlogs.t2     errorlogs.t3     errorlogs.t4     errorlogs.t5     errorlogs.t6     errorlogs.t7
        2012-02-03     18:35:34     SampleClass0     [ERROR]     incorrect     id     
        2012-02-03     18:55:54     SampleClass1     [ERROR]     incorrect     id     
        2012-02-03     19:25:27     SampleClass4     [ERROR]     incorrect     id

2. Нажмите кнопку **Сохранить как** в нижней части окна редактора. Присвойте этому запросу имя **Errorlogs** и щелкните **ОК**. Имя листа изменилось на **Errorlogs**.

3. Перейдите на вкладку **Сохраненные запросы** в верхней части страницы представления Hive. Запрос **Errorlogs** теперь отображается как сохраненный. Он будет оставаться в этом списке, пока вы не удалите его. Выбрав имя, можно открыть запрос в редакторе.

## <a name="query-history"></a>Журнал запросов

Кнопка **Журнал** в верхней части представления Hive позволяет просматривать ранее выполненные запросы. Нажмите на нее и выберите из списка нужные запросы. Выбранный запрос откроется в редакторе запросов.

## <a name="user-defined-functions-udf"></a>Определяемые пользователем функции

Инфраструктура Hive также может быть расширена с помощью **определяемых пользователем функций (UDF)**. UDF позволяет реализовать функции или логику, сложно моделируемые в HiveQL.

Вкладка UDF в верхней части представления Hive позволяет объявлять и сохранять наборы определяемых пользователем функций, которые могут использоваться в **редакторе запросов**.

После добавления в представление Hive UDF в нижней части **редактора запросов** появляется кнопка **Insert udfs** (Вставить определяемые пользователем функции). Нажав эту кнопку, вы увидите раскрывающийся список функций, определенных в представлении Hive. Выбирая определяемую пользователем функцию, вы добавляете в запрос соответствующие инструкции HiveQL.

Например, вы определили функцию со следующими свойствами:

* имя ресурса — myudfs;

* путь к ресурсу — /myudfs.jar;

* имя определяемой пользователем функции — myawesomeudf;

* имя класса определяемой пользователем функции — com.myudfs.Awesome.

Нажав кнопку **Insert udfs** (Вставить определяемые пользователем функции), вы увидите запись с именем **myudfs**, содержащую раскрываемый список для каждой функции, определяемой для этого ресурса. В нашем примере это функция **myawesomeudf**. Если вы выберете эту запись, в начало запроса будет добавлен следующий код:

```hiveql
add jar /myudfs.jar;
create temporary function myawesomeudf as 'com.myudfs.Awesome';
```

Затем вы можете использовать эту функцию в своем запросе. Пример: `SELECT myawesomeudf(name) FROM people;`.

Дополнительные сведения об использовании определяемых пользователем функций с Hive в HDInsight см. в следующих ресурсах:

* [Использование Python с Hive и Pig в HDInsight](hdinsight-python.md)
* [Добавление пользовательских UDF Hive в HDInsight](http://blogs.msdn.com/b/bigdatasupport/archive/2014/01/14/how-to-add-custom-hive-udfs-to-hdinsight.aspx)

## <a name="a-idnextstepsanext-steps"></a><a id="nextsteps"></a>Дальнейшие действия
Общая информация о Hive в HDInsight.

* [Использование Hive с Hadoop в HDInsight](hdinsight-use-hive.md)

Дополнительная информация о других способах работы с Hadoop в HDInsight.

* [Использование Pig с Hadoop в HDInsight](hdinsight-use-pig.md)
* [Использование MapReduce с Hadoop в HDInsight](hdinsight-use-mapreduce.md)


