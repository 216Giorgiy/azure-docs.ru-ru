<properties
   pageTitle="Использование представлений Ambari для работы с Hive в HDInsight (Hadoop) | Microsoft Azure"
   description="Узнайте, как использовать представление Hive в веб-браузере для отправки запросов Hive. Представление Hive — это компонент веб-интерфейса Ambari, поставляемого с кластером HDInsight на основе Linux."
   services="hdinsight"
   documentationCenter=""
   authors="Blackmist"
   manager="paulettm"
   editor="cgronlun"
	tags="azure-portal"/>

<tags
   ms.service="hdinsight"
   ms.devlang="na"
   ms.topic="article"
   ms.tgt_pltfrm="na"
   ms.workload="big-data"
   ms.date="05/20/2016"
   ms.author="larryfr"/>

#Использование представления Hive с Hadoop в HDInsight

[AZURE.INCLUDE [hive-selector](../../includes/hdinsight-selector-use-hive.md)]

Ambari — это служебная программа для управления и мониторинга, предоставляемая с кластерами HDInsight под управлением Linux. Одна из возможностей Ambari — это веб-интерфейс, который можно использовать для выполнения запросов Hive. Он реализован в виде __представления Hive__, которое входит в набор представлений Ambari для кластера HDInsight.

> [AZURE.NOTE] У Ambari много разных функций, которые не рассматриваются в этом документе. Дополнительные сведения см. в статье [Управление кластерами HDInsight с помощью веб-интерфейса Ambari](hdinsight-hadoop-manage-ambari.md).

##Предварительные требования

- Кластер HDInsight под управлением Linux. Информацию о создании кластера см. в статье [Учебник по Hadoop: приступая к работе с Hadoop с Hive в HDInsight на платформе Linux](hdinsight-hadoop-linux-tutorial-get-started.md).

##Открытие представления Hive

Вы можете открыть представления Ambari на портале Azure, выбрав в разделе __Быстрые ссылки__ свой кластер HDInsight, а затем — пункт __Представления Ambari__.

![Раздел «Быстрые ссылки»](./media/hdinsight-hadoop-use-hive-ambari-view/quicklinks.png)

Кроме того, вы можете непосредственно открыть Ambari. Перейдите в веб-браузере по адресу https://CLUSTERNAME.azurehdinsight.net (где __CLUSTERNAME__ — это имя вашего кластера HDInsight) и выберите набор квадратов в меню страницы (рядом со ссылкой и кнопкой __Администратор__ в левой части страницы), чтобы отобразился список доступных представлений. Выберите __Представление Hive __.

![Выбор представлений Ambari](./media/hdinsight-hadoop-use-hive-ambari-view/selecthiveview.png).

> [AZURE.NOTE] При открытии сайта Ambari вы получите запрос на проверку подлинности. Введите имя и пароль учетной записи администратора (по умолчанию — `admin`), которые использовались при создании кластера.

Вы должны увидеть страницу, аналогичную показанной ниже:

![Изображение страницы представления Hive с разделом редактора запросов](./media/hdinsight-hadoop-use-hive-ambari-view/hiveview.png)

##Просмотр таблиц

В разделе __Обозреватель базы данных__ на вкладке __Базы данных__ выберите пункт __По умолчанию__. Вы увидите список таблиц, входящих в базу данных по умолчанию. В новом кластере HDInsight должна присутствовать только одна таблица — __hivesampletable__.

![Обозреватель баз данных с развернутой базой данных по умолчанию](./media/hdinsight-hadoop-use-hive-ambari-view/databaseexplorer.png)

Добавляя новые таблицы в соответствии с инструкциями, вы можете щелкать значок обновления в правом верхнем углу обозревателя базы данных, чтобы обновлять список доступных таблиц.

##<a name="hivequery"></a>Редактор запросов

В представлении Hive выполните описанные ниже действия, чтобы создать запрос Hive для получения данных, входящих в состав кластера.

1. На странице в разделе __Редактор запросов__ вставьте в рабочий лист следующие инструкции HiveQL:

		DROP TABLE log4jLogs;
		CREATE EXTERNAL TABLE log4jLogs(t1 string, t2 string, t3 string, t4 string, t5 string, t6 string, t7 string)
		ROW FORMAT DELIMITED FIELDS TERMINATED BY ' '
		STORED AS TEXTFILE LOCATION 'wasbs:///example/data/';
		SELECT t4 AS sev, COUNT(*) AS cnt FROM log4jLogs WHERE t4 = '[ERROR]' GROUP BY t4;

	Эти инструкции выполняют следующие действия.

	- **DROP TABLE** — удаляет таблицу и файл данных, если таблица уже существует.
	- **CREATE EXTERNAL TABLE** — создает новую внешнюю таблицу в Hive. Внешние таблицы хранят только описание самой таблицы в Hive, в то время как данные остаются в исходном расположении.
	- **ROW FORMAT** — указывает Hive, как следует форматировать данные. В данном случае поля всех журналов разделены пробелом.
	- **STORED AS TEXTFILE LOCATION**: информация для Hive о расположении хранения данных (каталог example/data) и об их формате (текстовый).
	- **SELECT**: подсчитывает количество строк, у которых столбец t4 содержит значение [ERROR].

	>[AZURE.NOTE] Внешние таблицы необходимо использовать в тех случаях, когда ожидается, что исходные данные будут обновляться внешним источником, таким как автоматизированный процесс передачи данных, или другой операцией MapReduce, и при этом нужно, чтобы запросы Hive использовали самые последние данные. Удаление внешней таблицы *не* приводит к удалению данных. Будет удалено только описание таблицы.

2. Чтобы выполнить запрос, нажмите кнопку __Выполнить__ в нижней части окна редактора запросов. Кнопка станет оранжевой, а текст на ней изменится на __Остановить выполнение__. Под окном редактора запросов появится раздел __Результаты обработки запроса__, содержащий сведения о выполнении задания.

    > [AZURE.IMPORTANT] В некоторых браузерах записи журнала или результаты могут не обновляться надлежащим образом. Если при выполнении задания записи журнала или полученные результаты не обновляются, попробуйте воспользоваться Mozilla FireFox или Google Chrome.

3. После выполнения запроса в разделе __Результаты обработки запроса__ будут отображены результаты операции. Кнопка __Остановить выполнение__ снова станет зеленой, а текст на ней изменится на __Выполнить__. Вкладка __Результаты__ должна содержать указанные ниже сведения.

        sev       cnt
        [ERROR]   3

    На вкладке __Журналы__ отображаются сведения, регистрируемые в процессе выполнения задания. Эти сведения можно использовать для устранения неполадок, возникающих при выполнении запроса.

    > [AZURE.TIP] Обратите внимание на раскрывающийся список __Сохранить результаты__, расположенный в разделе __Результаты обработки запроса__ слева вверху. Этот список можно использовать для загрузки или сохранения результатов в хранилище HDInsight в формате CSV-файла.

3. Выберите четыре первые строки запроса, а затем — команду __Выполнить__. Обратите внимание на отсутствие результатов после выполнения задания. Это связано с тем, что вы нажали кнопку __Выполнить__, выбрав часть запроса. Следовательно, запрос выполняется только с использованием выбранных инструкций. В нашем примере не выбрана последняя инструкция, которая извлекает строки из таблицы. Если выбрать только эту строку, а затем нажать кнопку __Выполнить__, отобразятся ожидаемые результаты.

3. В нижней части __редактора запросов__ нажмите кнопку __Создать лист__, чтобы создать рабочий лист. На новом листе введите указанные ниже инструкции HiveQL.

		CREATE TABLE IF NOT EXISTS errorLogs (t1 string, t2 string, t3 string, t4 string, t5 string, t6 string, t7 string) STORED AS ORC;
		INSERT OVERWRITE TABLE errorLogs SELECT t1, t2, t3, t4, t5, t6, t7 FROM log4jLogs WHERE t4 = '[ERROR]';

	Эти инструкции выполняют следующие действия.

	- **CREATE TABLE IF NOT EXISTS**: создание таблицы, если она до этого не существовала. Так как ключевое слово **EXTERNAL** не было использовано, данная таблица будет внутренней. То есть она хранится в хранилище данных Hive, и ею полностью управляет Hive. В отличие от внешних таблиц, удаление внутренних таблиц приводит также к удалению данных.
	- **STORED AS ORC** — сохраняет данные в формате Optimized Row Columnar (ORC). Это высокооптимизированный и эффективный формат для хранения данных Hive.
	- **INSERT OVERWRITE ... SELECT** — выбирает из таблицы **log4jLogs** строки, которые содержат значение [ERROR], а затем вставляет данные в таблицу **errorLogs**.

    Нажмите кнопку __Выполнить__, чтобы выполнить этот запрос. Хотя вкладка __Результаты__ не будет содержать никаких сведений (этот запрос не возвращает строки), состояние должно измениться на __Выполнено__.

###Параметры Hive

Щелкните значок __Параметры__ в правой части окна редактора.

![Значки](./media/hdinsight-hadoop-use-hive-ambari-view/settings.png)

Параметры предназначены для изменения различных настроек Hive, например, для изменения подсистемы выполнения для Hive с Tez (значение по умолчанию) на MapReduce.

###Визуальное объяснение

Щелкните значок __Визуальное объяснение__ в правой части окна редактора.

![Значки](./media/hdinsight-hadoop-use-hive-ambari-view/visualexplainicon.png)

Это представление запроса __Визуальное объяснение__, которое помогает разобраться в потоке сложных запросов. Можно просмотреть текстовый эквивалент этого представления, нажав кнопку __Объяснить__ в редакторе запросов.

![Значок «Визуальное объяснение»](./media/hdinsight-hadoop-use-hive-ambari-view/visualexplain.png)

###Tez

Щелкните значок __Tez__ в правой части окна редактора.

![Значки](./media/hdinsight-hadoop-use-hive-ambari-view/tez.png)

Вы увидите направленный ациклический граф (DAG), который используется Tez для этого запроса, если он существует. Чтобы просмотреть DAG для ранее выполненных запросов или выполнить отладку процесса Tez, используйте [представление Tez](hdinsight-debug-ambari-tez-view.md).

###Уведомления

Щелкните значок __Уведомления__ в правой части окна редактора.

![Значки](./media/hdinsight-hadoop-use-hive-ambari-view/notifications.png)

Уведомления — это сообщения, создаваемые при выполнении запросов. Например, вы получите уведомление при отправке запроса или возникновении ошибки.

##Сохраненные запросы

1. В редакторе запросов создайте лист и введите следующий запрос:

        SELECT * from errorLogs;

    Выполните запрос, чтобы убедиться, что он работает. Результат будет следующим:

        errorlogs.t1 	errorlogs.t2 	errorlogs.t3 	errorlogs.t4 	errorlogs.t5 	errorlogs.t6 	errorlogs.t7
        2012-02-03 	18:35:34 	SampleClass0 	[ERROR] 	incorrect 	id 	
        2012-02-03 	18:55:54 	SampleClass1 	[ERROR] 	incorrect 	id 	
        2012-02-03 	19:25:27 	SampleClass4 	[ERROR] 	incorrect 	id

2. Нажмите кнопку __Сохранить как__ в нижней части окна редактора. Присвойте этому запросу имя __Errorlogs__ и нажмите __ОК__. Обратите внимание, что имя листа изменилось на __Errorlogs__.

3. Перейдите на вкладку __Сохраненные запросы__ в верхней части страницы представления Hive. Обратите внимание, что запрос __Errorlogs__ теперь отображается как сохраненный. Он будет оставаться в этом списке, пока вы не удалите его. Выбрав имя, можно открыть запрос в редакторе.

##Журнал запросов

Кнопка __Журнал__ в верхней части представления Hive позволяет просматривать ранее выполненные запросы. Нажмите на нее и выберите из списка нужные запросы. Выбранный запрос откроется в редакторе запросов.

##Определяемые пользователем функции

Инфраструктура Hive также может быть расширена с помощью **определяемых пользователем функций (UDF)**. UDF позволяет реализовать функции или логику, сложно моделируемые в HiveQL.

Вы можете использовать определяемые пользователем функции как часть инструкций HiveQL в запросе. При этом вкладка «Определяемые пользователем функции» в верхней части представления Hive позволяет объявлять и сохранять наборы определяемых пользователем функций, которые могут использоваться в __редакторе запросов__.

Когда вы добавляете в представление Hive определяемую пользователем функцию, в нижней части __редактора запросов__ появляется кнопка __Вставить определяемые пользователем функции__. Нажав эту кнопку, вы увидите список функций, определенных в представлении Hive. Выбирая определяемую пользователем функцию, вы добавляете в запрос соответствующие инструкции HiveQL.

Например, вы определили функцию со следующими свойствами:

* имя ресурса — myudfs;
* путь к ресурсу — wasbs:///myudfs.jar;
* имя определяемой пользователем функции — myawesomeudf;
* имя класса определяемой пользователем функции — com.myudfs.Awesome.

Нажав кнопку __Вставить UDF__, вы увидите запись с именем __myudfs__, содержащий раскрываемый список для каждой функции, определяемой для этого ресурса. В нашем примере это функция __myawesomeudf__. Если вы выберете эту запись, в начало запроса будет добавлен следующий код:

    add jar wasbs:///myudfs.jar;

    create temporary function myawesomeudf as 'com.myudfs.Awesome';

Затем вы можете использовать эту функцию в своем запросе. Пример: `SELECT myawesomeudf(name) FROM people;`.

Дополнительные сведения об использовании определяемых пользователем функций с Hive в HDInsight см. в следующих ресурсах:

* [Использование Python с Hive и Pig в HDInsight](hdinsight-python.md)

* [Добавление пользовательских UDF Hive в HDInsight](http://blogs.msdn.com/b/bigdatasupport/archive/2014/01/14/how-to-add-custom-hive-udfs-to-hdinsight.aspx)

##<a id="nextsteps"></a>Дальнейшие действия

Общая информация о Hive в HDInsight.

* [Использование Hive с Hadoop в HDInsight](hdinsight-use-hive.md)

Дополнительная информация о других способах работы с Hadoop в HDInsight.

* [Использование Pig с Hadoop в HDInsight](hdinsight-use-pig.md)

* [Использование MapReduce с Hadoop в HDInsight](hdinsight-use-mapreduce.md)

<!---HONumber=AcomDC_0727_2016-->