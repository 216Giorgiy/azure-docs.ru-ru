---
title: "Использование средств визуализации данных с помощью Spark BI в Azure HDInsight | Документация Майкрософт"
description: "Используйте средства визуализации данных для аналитики с помощью Apache Spark BI в кластерах HDInsight"
keywords: "apache spark bi, spark bi, визуализация данных spark, бизнес-аналитика spark"
services: hdinsight
documentationcenter: 
author: nitinme
manager: jhubbard
editor: cgronlun
tags: azure-portal
ms.assetid: 1448b536-9bc8-46bc-bbc6-d7001623642a
ms.service: hdinsight
ms.custom: hdinsightactive,hdiseo17may2017
ms.workload: big-data
ms.tgt_pltfrm: na
ms.devlang: na
ms.topic: article
ms.date: 10/24/2017
ms.author: nitinme
ms.openlocfilehash: 3886923639be8a7bd8167f10db503d7ebf8c1657
ms.sourcegitcommit: 6a6e14fdd9388333d3ededc02b1fb2fb3f8d56e5
ms.translationtype: HT
ms.contentlocale: ru-RU
ms.lasthandoff: 11/07/2017
---
# <a name="apache-spark-bi-using-data-visualization-tools-with-azure-hdinsight"></a>Использование средств визуализации данных с помощью Apache Spark BI в Azure HDInsight

Узнайте, как использовать Power BI и Tableau для визуализации данных в кластере Apache Spark в Azure HDInsight.

## <a name="prerequisites"></a>Предварительные требования

* Кластер Apache Spark в HDInsight. Инструкции см. в статье [Начало работы. Создание кластера Apache Spark в HDInsight на платформе Linux и выполнение интерактивных запросов с помощью SQL Spark](apache-spark-jupyter-spark-sql.md).
* Пример данных в кластере. Дополнительные инструкции см. в статье [Выполнение интерактивных запросов в кластере HDInsight Spark](apache-spark-load-data-run-query.md).
* Power BI: [Power BI Desktop](https://powerbi.microsoft.com/en-us/desktop/) и [пробная подписка Power BI](https://app.powerbi.com/signupredirect?pbi_source=web) (необязательно).
* Tableau: [Tableau Desktop](http://www.tableau.com/products/desktop) и [драйвер Microsoft Spark ODBC](http://go.microsoft.com/fwlink/?LinkId=616229).


## <a name="hivetable"></a>Просмотр примера данных

Записная книжка Jupyter, созданная при работе с [предыдущим руководством](apache-spark-load-data-run-query.md), содержит код для создания таблицы `hvac`. Эта таблица базируется на CSV-файле, доступном во всех кластерах HDInsight Spark в **\HdiSamples\HdiSamples\SensorSampleData\hvac\hvac.csv**. Давайте рассмотрим данные в кластере Spark перед созданием визуализаций.

1. Проверьте наличие необходимых таблиц. Вставьте следующий фрагмент кода в пустую ячейку в записной книжке и нажмите **SHIFT + ВВОД**.

        %%sql
        SHOW TABLES

    Вы увидите примерно такие выходные данные:

    ![Отображение таблиц в Spark](./media/apache-spark-use-bi-tools/show-tables.png)

    Если закрыть записную книжку перед выполнением шага выше, таблица `hvactemptable` будет очищена и не будет включена в выходные данные.
    С помощью средств бизнес-аналитики можно получить доступ к таблицам Hive, размещенным в хранилище метаданных (для таких таблиц в столбце **isTemporary** задано значение **false**). В этом руководстве мы подключимся к созданной нами таблице **hvac**.

2. Убедитесь, что таблица содержит нужные данные. Вставьте следующий фрагмент кода в пустую ячейку в записной книжке и нажмите **SHIFT + ВВОД**.

        %%sql
        SELECT * FROM hvac LIMIT 10

    Вы увидите примерно такие выходные данные:

    ![Отображение строк из таблицы hvac в Spark](./media/apache-spark-use-bi-tools/select-limit.png)

3. Завершите работу записной книжки для освобождения ресурсов. Для этого в записной книжке в меню **Файл** выберите пункт **Close and Halt** (Закрыть и остановить).

## <a name="powerbi"></a>Использование Power BI для визуализации данных Spark

Теперь, когда вы проверили наличие нужных данных, можно использовать Power BI для создания визуализаций, отчетов и информационных панелей на основе этих данных. В этой статье мы рассмотрим простой пример со статическими данными, но если вы хотите ознакомиться с более сложными примерами потоковой передачи, вы можете написать об этом ниже в комментариях.

### <a name="create-a-report-in-power-bi-desktop"></a>Создание отчета в Power BI Desktop
Начиная работать со Spark, в первую очередь необходимо подключиться к кластеру в Power BI Desktop, загрузить данные из кластера, а затем создать базовую визуализацию на основе этих данных.

> [!NOTE]
> Соединитель, приведенный в этой статье, в настоящее время доступен в режиме предварительной версии, но мы рекомендуем испытать его в действии и оставить свои отзывы на сайте [Сообщества Power BI](https://community.powerbi.com/) или форуме [Power BI Ideas](https://ideas.powerbi.com/forums/265200-power-bi-ideas).

1. В Power BI Desktop на вкладке **Домашняя страница** щелкните **Получение данных**, затем — **Подробнее**.

2. Выполните поиск по запросу `Spark`, выберите **Azure HDInsight Spark**, а затем нажмите кнопку **Подключиться**.

    ![Получение данных в Power BI из Apache Spark BI](./media/apache-spark-use-bi-tools/apache-spark-bi-import-data-power-bi.png "Получение данных в Power BI из Apache Spark BI")

3. Введите URL-адрес кластера (в формате `mysparkcluster.azurehdinsight.net`), выберите **DirectQuery**, а затем нажмите кнопку **ОК**.

    ![Подключение к Apache Spark BI](./media/apache-spark-use-bi-tools/connect-to-apache-spark-bi.png "Подключение к Apache Spark BI")

    > [!NOTE]
    > При подключении к Spark можно использовать любой режим подключения. При использовании DirectQuery изменения отображаются в отчетах, при этом весь набор данных не обновляется. В случае импорта данных необходимо обновить набор данных, чтобы увидеть изменения. Дополнительные сведения о том, как и когда следует использовать DirectQuery, см. в статье [Использование DirectQuery в Power BI](https://powerbi.microsoft.com/documentation/powerbi-desktop-directquery-about/). 

4. Введите данные учетной записи для входа в HDInsight: **Имя пользователя** и **Пароль** (по умолчанию используется учетная запись `admin`), а затем нажмите кнопку **Подключиться**.

    ![Имя пользователя и пароль для кластера Spark](./media/apache-spark-use-bi-tools/user-password.png "Имя пользователя и пароль для кластера Spark")

5. Выберите таблицу `hvac` и подождите, пока не появятся данные. Затем нажмите кнопку **Загрузить**.

    ![Имя пользователя и пароль для кластера Spark](./media/apache-spark-use-bi-tools/apache-spark-bi-select-table.png "Имя пользователя и пароль для кластера Spark")

    Теперь у Power BI Desktop есть все сведения, необходимые для подключения к кластеру Spark и загрузки данных из таблицы `hvac`. Таблица и ее столбцы отображаются в области **полей**.

    ![Список таблиц на панели мониторинга Apache Spark BI](./media/apache-spark-use-bi-tools/apache-spark-bi-display-tables.png "Список таблиц на панели мониторинга Apache Spark BI")

7. Создайте визуализацию для отображения расхождений между целевой температурой и фактической температурой для каждого здания: 

    1. В области **визуализаций** выберите **Диаграмма с областями**. Перетащите поле **BuildingID** в раздел **Ось**, а поля **ActualTemp** и **TargetTemp** в раздел **значений**.

        ![Создание визуализаций данных Spark с помощью Apache Spark BI](./media/apache-spark-use-bi-tools/apache-spark-bi-add-value-columns.png "Создание визуализаций данных Spark с помощью Apache Spark BI")

    2. По умолчанию представление показывает сумму для **фактической температуры** и **целевой температуры**. Для обоих полей из раскрывающегося списка выберите **Среднее** для получения средней фактической и целевой температуры для обоих зданий.

        ![Создание визуализаций данных Spark с помощью Apache Spark BI](./media/apache-spark-use-bi-tools/apache-spark-bi-average-of-values.png "Создание визуализаций данных Spark с помощью Apache Spark BI")

    3. Визуализация данных должна соответствовать снимку экрана ниже. Наведите указатель мыши на визуализацию, чтобы отобразить всплывающие подсказки с соответствующими данными.

        ![Создание визуализаций данных Spark с помощью Apache Spark BI](./media/apache-spark-use-bi-tools/apache-spark-bi-area-graph.png "Создание визуализаций данных Spark с помощью Apache Spark BI")

11. Щелкните **Файл**, **Сохранить**, а затем введите имя файла `spark.pbix`. 

### <a name="publish-the-report-to-the-power-bi-service-optional"></a>Публикация отчета в службе Power BI (необязательно)
Теперь у вас есть полнофункциональный отчет в Power BI Desktop, и на этом можно остановиться. Но многие предпочитают подробнее ознакомиться с преимуществами службы Power BI, которая позволяет пользователям в организации совместно использовать отчеты и информационные панели. 

В рамках этого раздела вы опубликуете набор данных и отчет, содержащийся в созданном файле Power BI Desktop. Затем закрепите визуализацию из созданного отчета на информационной панели. Информационные панели обычно используются, чтобы сосредоточиться на подмножестве данных в отчете. В вашем отчете содержится только одна визуализация, но тем не менее выполнение шагов ниже по-прежнему актуально.

1. В Power BI Desktop на вкладке **Домашняя страница** щелкните **Опубликовать**.

    ![Публикация из Power BI Desktop](./media/apache-spark-use-bi-tools/apache-spark-bi-publish.png "Публикация из Power BI Desktop")

2. Выберите рабочую область, в которой вы хотите опубликовать набор данных и отчет, а затем нажмите кнопку **Выбор**. На рисунке ниже выбран параметр по умолчанию **Моя рабочая область**.

    ![Выбор рабочей области для публикации набора данных и отчета](./media/apache-spark-use-bi-tools/apache-spark-bi-select-workspace.png "Выбор рабочей области для публикации набора данных и отчета") 

3. После того как Power BI Desktop вернет сообщение об успешной публикации, щелкните ссылку, чтобы **открыть "spark.pbix" в Power BI**.

    ![Публикация завершилась успешно, щелкните, чтобы ввести учетные данные](./media/apache-spark-use-bi-tools/apache-spark-bi-publish-success.png "Публикация завершилась успешно, щелкните, чтобы ввести учетные данные") 

4. В службе Power BI щелкните ссылку, чтобы **ввести учетные данные**.

    ![Ввод учетных данных в службе Power BI](./media/apache-spark-use-bi-tools/apache-spark-bi-enter-credentials.png "Ввод учетных данных в службе Power BI")

5. Щелкните ссылку, чтобы **изменить учетные данные**.

    ![Изменение учетных данных в службе Power BI](./media/apache-spark-use-bi-tools/apache-spark-bi-edit-credentials.png "Изменение учетных данных в службе Power BI")

6. Введите данные учетной записи для входа в HDInsight (обычно это учетная запись по умолчанию `admin`, используемая в Power BI Desktop), а затем нажмите кнопку **Вход**.

    ![Вход в кластер Spark](./media/apache-spark-use-bi-tools/apache-spark-bi-sign-in.png "Вход в кластер Spark")

7. В левой области выберите **Рабочие области** > **Моя рабочая область** > **Отчеты**, а затем щелкните **spark**.

    ![Отчет в списке раздела отчетов в левой области](./media/apache-spark-use-bi-tools/apache-spark-bi-service-left-pane.png "Отчет в списке раздела отчетов в левой области")

    Вы также увидите **spark** в списке раздела **Наборы данных** в левой области.

8. Визуальный элемент, созданный в Power BI Desktop, теперь доступен в службе. Чтобы закрепить его на информационной панели, наведите указатель мыши на него и щелкните значок закрепления.

    ![Отчет в службе Power BI](./media/apache-spark-use-bi-tools/apache-spark-bi-service-report.png "Отчет в службе Power BI")

9. Выберите "Новая информационная панель", введите имя `SparkDemo`, а затем нажмите кнопку **Pin** (Закрепить).

    ![Закрепление на новой информационной панели](./media/apache-spark-use-bi-tools/apache-spark-bi-pin-dashboard.png "Закрепление на новой информационной панели")

10. В отчете нажмите кнопку **Перейти к информационной панели**. 

    ![Переход к информационной панели](./media/apache-spark-use-bi-tools/apache-spark-bi-open-dashboard.png "Переход к информационной панели")

Ваш визуальный элемент закреплен на информационной панели. Вы можете добавить в отчет другие визуальные элементы, а затем закрепить их на этой же информационной панели. Дополнительные сведения об отчетах и информационных панелях см. в статьях [Отчеты в Power BI](https://powerbi.microsoft.com/documentation/powerbi-service-reports/) и [Панели мониторинга в службе Power BI](https://powerbi.microsoft.com/documentation/powerbi-service-dashboards/).

## <a name="tableau"></a>Использование Tableau Desktop для визуализации данных Spark

> [!NOTE]
> Этот раздел применим только для кластеров Spark 1.5.2, созданных в Azure HDInsight.
>
>

1. Установите [Tableau Desktop](http://www.tableau.com/products/desktop) на компьютере, на котором вы выполняете действия из этого руководства по Apache Spark BI.

2. Убедитесь, что на этом компьютере также установлен драйвер ODBC Microsoft Spark. Вы можете скачать драйвер [здесь](http://go.microsoft.com/fwlink/?LinkId=616229).

1. Запустите Tableau Desktop. В левой области в списке сервера для подключения щелкните **Spark SQL**. Если Spark SQL по умолчанию не отображается в левой области, вы можете найти его, щелкнув **Другие серверы**.
2. В диалоговом окне подключения Spark SQL укажите значения, показанные на снимке экрана ниже, и нажмите кнопку **ОК**.

    ![Подключение к кластеру для Apache Spark BI](./media/apache-spark-use-bi-tools/connect-to-tableau-apache-spark-bi.png "Подключение к кластеру для Apache Spark BI")

    Если вы установили на компьютер **драйвер Microsoft ODBC Spark** , в раскрывающемся списке проверки подлинности будет пункт [служба Microsoft Azure HDInsight](http://go.microsoft.com/fwlink/?LinkId=616229) .
3. В следующем окне в раскрывающемся списке **Схема** щелкните значок **Найти**, а затем щелкните **по умолчанию**.

    ![Поиск схемы для Apache Spark BI](./media/apache-spark-use-bi-tools/tableau-find-schema-apache-spark-bi.png "Поиск схемы для Apache Spark BI")
4. Для поля **Таблица** еще раз щелкните значок **Найти**, чтобы вывести список всех таблиц Hive, доступных в кластере. Вы должны увидеть таблицу **hvac** , созданную ранее с помощью записной книжки.

    ![Поиск схемы для Apache Spark BI](./media/apache-spark-use-bi-tools/tableau-find-table-apache-spark-bi.png "Поиск схемы для Apache Spark BI")
5. Перетащите таблицу в поле в правом верхней части окна. Tableau импортирует данные и отображает схему (выделено красным прямоугольником).

    ![Добавление таблиц в Tableau для Apache Spark BI](./media/apache-spark-use-bi-tools/tableau-add-table-apache-spark-bi.png "Добавление таблиц в Tableau для Apache Spark BI")
6. Щелкните вкладку **Лист1** слева внизу. Создайте визуализацию, на которой представлены средняя целевая температура фактическая температура для всех зданий для каждой даты. Перетащите поля **Дата** и **Код здания** в раздел **Столбцы**, а поля **Actual Temp**(Фактическая температура)/**Target Temp** (Целевая температура) — в раздел **Строки**. В разделе **Метки** выберите **Область**, которая будет использоваться для визуализации данных Spark.

     ![Добавление полей для визуализации данных Spark](./media/apache-spark-use-bi-tools/spark-data-visualization-add-fields.png "Добавление полей для визуализации данных Spark")
7. По умолчанию значения полей температуры отображаются как статистическое выражение. Если необходимо отобразить среднюю температуру, это можно сделать из раскрывающегося списка, как показано ниже.

    ![Получение среднего значения температуры для визуализации данных Spark](./media/apache-spark-use-bi-tools/spark-data-visualization-average-temperature.png "Получение среднего значения температуры для визуализации данных Spark")

8. Можно также наложить одну карту температуры на другую, чтобы лучше понять разницу между целевой и фактической температурой. Перемещайте указатель мыши в угол нижней области карты, пока курсор не примет форму красного кружка. Перетащите карту на другую карту в верхней части и отпустите кнопку мыши, когда указатель мыши примет форму красного прямоугольника.

    ![Слияние карт для визуализации данных Spark](./media/apache-spark-use-bi-tools/spark-data-visualization-merge-maps.png "Слияние карт для визуализации данных Spark")

     Визуализация данных должна измениться, как показано на снимке экрана.

    ![Выходные данные Tableau для визуализации данных Spark](./media/apache-spark-use-bi-tools/spark-data-visualization-tableau-output.png "Выходные данные Tableau для визуализации данных Spark")
9. Щелкните **Сохранить** для сохранения рабочего листа. Можно создать панели мониторинга и добавить на них один или несколько листов.

## <a name="next-steps"></a>Дальнейшие действия

Из этой статьи вы узнали, как создать кластер, как создать кадры данных Spark для запроса данных и как получить доступ к этим данным из средств бизнес-аналитики. Теперь вы можете просмотреть инструкции по управлению ресурсами кластера и отладке заданий, запущенных в кластере Spark в HDInsight.

* [Управление ресурсами кластера Apache Spark в Azure HDInsight](apache-spark-resource-manager.md)
* [Отслеживание и отладка заданий в кластере Apache Spark в HDInsight на платформе Linux](apache-spark-job-debugging.md)

