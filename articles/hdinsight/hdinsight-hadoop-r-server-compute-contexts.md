---
title: "Параметры контекста вычислений для R Server в HDInsight | Документация Майкрософт"
description: "Сведения о разных вариантах контекста вычислений, доступных для пользователей R Server в HDInsight."
services: HDInsight
documentationcenter: 
author: jeffstokes72
manager: jhubbard
editor: cgronlun
ms.assetid: 0deb0b1c-4094-459b-94fc-ec9b774c1f8a
ms.service: HDInsight
ms.devlang: R
ms.topic: article
ms.tgt_pltfrm: na
ms.workload: data-services
ms.date: 02/28/2017
ms.author: jeffstok
translationtype: Human Translation
ms.sourcegitcommit: 841e70fa3a80bbeb7e2281246bac2f99c0de899f
ms.openlocfilehash: 169743012b1f50d67d5eafdb279e706719752eb8
ms.lasthandoff: 11/22/2016


---
# <a name="compute-context-options-for-r-server-on-hdinsight"></a>Варианты контекста вычислений для R Server в HDInsight
Microsoft R Server в кластере Azure HDInsight предоставляет новейшие возможности для анализа на основе R. Это решение использует данные, хранящиеся в файловой системе HDFS в контейнере, размещенном в вашей учетной записи хранения [BLOB-объектов Azure](../storage/storage-introduction.md "хранилище BLOB-объектов Azure"), Data Lake Store или локальной файловой системе Linux. Так как R Server основывается на R с открытым кодом, вы сможете использовать в своих приложениях на основе R любые из более чем 8000 пакетов R с открытым кодом. Также вы можете использовать подпрограммы [ScaleR](http://www.revolutionanalytics.com/revolution-r-enterprise-scaler "ScaleR от компании Revolution Analytics")из пакета аналитики корпорации Майкрософт для больших объемов данных, который предоставляется вместе с R Server.  

Для подключения к кластеру и выполнения скриптов на языке R удобно использовать граничный узел кластеров. На граничном узле вы можете выполнять распараллеленные распределенные функции на ядрах сервера граничного узла. Также вы можете выполнять эти функции на узлах кластера с помощью контекста вычислений Hadoop MapReduce ScaleR или Spark.

## <a name="compute-contexts-for-an-edge-node"></a>Контексты вычислений для граничного узла
Как правило, сценарий R, выполняемый на R Server на граничном узле, выполняется в интерпретаторе R на этом узле. Исключением являются те действия, которые вызывают функцию ScaleR. Вызовы ScaleR будут осуществляться в среде вычислений с учетом настройки контекста вычислений ScaleR.  При выполнении R-скрипта на граничном узле можно получить следующие значения контекста вычислений: локальный последовательный (local), локальный параллельный (localpar), Map Reduce и Spark.

Значения "local" и "localpar" отличаются только способом выполнения вызовов rxExec. Они оба выполняют другие вызовы RX-функций параллельно по всем доступным ядрам, если только не указаны другие действия посредством параметра ScaleR numCoresToUse, такие как rxOptions(numCoresToUse=6). В следующей таблице собраны различные параметры контекста вычислений.

| Контекст вычислений  | Метод настройки                      | Контекст выполнения                        |
| ---------------- | ------------------------------- | ---------------------------------------- |
| Локальный последовательный | rxSetComputeContext(‘local’)    | Распараллеленное выполнение во всех ядрах сервера граничного узла, за исключением вызовов rxExec, которые выполняются последовательно. |
| Локальный параллельный   | rxSetComputeContext(‘localpar’) | Распараллеленное выполнение во всех ядрах сервера граничного узла. |
| Spark            | RxSpark()                       | Распараллеленное распределенное выполнение с использованием Spark во всех узлах кластера HDI |
| Map Reduce       | RxHadoopMR()                    | Распараллеленное распределенное выполнение с использованием Map Reduce во всех узлах кластера HDI |

Если вы хотите использовать распараллеленное выполнение для повышения производительности, у вас есть три варианта. Выбор варианта зависит от характера аналитического задания, а также размера и расположения данных.

## <a name="guidelines-for-deciding-on-a-compute-context"></a>Рекомендации по выбору контекста вычислений
Сейчас нет строгих правил для выбора контекста вычислений. Но есть некоторые базовые принципы, которые помогут вам определиться или хотя бы сузить выбор еще до запуска теста производительности. К ним относятся следующие:

1. Локальная файловая система Linux работает быстрее, чем HDFS.
2. Повторный анализ выполняется быстрее для данных в локальной среде, особенно в формате XDF.
3. Из текстовых источников данных желательно передавать лишь небольшие объемы данных. Если нужные данные имеют большой объем, преобразуйте их в формат XDF перед анализом.
4. При копировании или потоковой передаче на граничный узел больших объемов данных для анализа нагрузка быстро становится запредельной.
5. Spark работает быстрее, чем MapReduce для анализа в Hadoop.

С учетом этих принципов ниже приведены некоторые общие правила выбора контекста вычислений.

### <a name="local"></a>Local
* Если нужно проанализировать данные небольшого размера и не требуется повторный анализ, их следует направить потоком прямо в подпрограмму анализа и использовать контекст "local" или "localpar".
* Если нужно проанализировать данные небольшого или среднего размера, для которых потребуется повторный анализ, скопируйте их в локальную файловую систему, импортируйте в XDF-формат и проанализируйте в контексте "local" или "localpar".

### <a name="hadoop-spark"></a>Hadoop Spark
* Если нужно проанализировать большой объем данных, импортируйте их в Spark DataFrame с помощью RxHiveData или RxParquetData либо в XDF-файл в файловой системе HDFS (при наличии достаточного пространства для хранения) и проанализируйте эти данные в контексте Spark.

### <a name="hadoop-map-reduce"></a>Hadoop Map Reduce
* Используйте, только при нерешаемых проблемах с использованием контекста вычислений Spark из-за замедления производительности.  

## <a name="inline-help-on-rxsetcomputecontext"></a>Встроенная справка по rxSetComputeContext
Чтобы получить дополнительные сведения по контекстам вычислений ScaleR с соответствующими примерами, воспользуйтесь встроенной справкой в консоли R с помощью метода rxSetComputeContext, например:

    > ?rxSetComputeContext

Можно также просмотреть [руководство по распределенным вычислениям ScaleR](https://msdn.microsoft.com/microsoft-r/scaler-distributed-computing), доступное в библиотеке [R Server MSDN](https://msdn.microsoft.com/library/mt674634.aspx "R Server в библиотеке MSDN").

## <a name="next-steps"></a>Дальнейшие действия
Из этой статьи вы узнали, как создать новый кластер HDInsight с R Server. Вы также получили основные сведения об использовании консоли R в сеансе SSH. Теперь мы рекомендуем изучить следующие статьи, чтобы узнать о других методах работы с R Server в HDInsight.

* [Общие сведения об R Server в HDInsight (предварительная версия)](hdinsight-hadoop-r-server-overview.md)
* [Приступая к работе с R Server в HDInsight (предварительная версия)](hdinsight-hadoop-r-server-get-started.md)
* [Установка RStudio Server в HDInsight (если установка не была выполнена при создании кластера)](hdinsight-hadoop-r-server-install-r-studio.md)
* [Параметры службы хранилища Azure для R Server в HDInsight (предварительная версия)](hdinsight-hadoop-r-server-storage.md)


