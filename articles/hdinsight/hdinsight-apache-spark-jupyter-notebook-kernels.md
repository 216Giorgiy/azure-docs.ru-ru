<properties 
	pageTitle="Ядра, доступные для записных книжек Jupyter в кластерах HDInsight Spark на платформе Linux | Microsoft Azure" 
	description="Узнайте о дополнительных ядрах, доступных для записных книжек Jupyter с кластерами Spark в HDInsight на платформе Linux." 
	services="hdinsight" 
	documentationCenter="" 
	authors="nitinme" 
	manager="paulettm" 
	editor="cgronlun"
	tags="azure-portal"/>

<tags 
	ms.service="hdinsight" 
	ms.workload="big-data" 
	ms.tgt_pltfrm="na" 
	ms.devlang="na" 
	ms.topic="article" 
	ms.date="02/17/2016" 
	ms.author="nitinme"/>


# Ядра, доступные для использования записными книжками Jupyter с кластерами Spark в HDInsight (Linux)

Кластер Apache Spark в HDInsight (Linux) включает записные книжки Jupyter, которые вы можете использовать для тестирования приложений. По умолчанию записная книжка Jupyter предоставляется с ядром **Python2**. Ядра — это программа, которая выполняет и интерпретирует ваш код. Кластеры Spark в HDInsight предоставляют два дополнительных ядра, которые вы можете использовать с записной книжкой Jupyter, а именно:

1. **PySpark** (для приложений, написанных на языке Python).
2. **Spark** (для приложений, написанных на языке Scala);

В этой статье вы узнаете, как использовать эти ядра и какие преимущества они дают.

**Предварительные требования:**

Необходимо следующее:

- Подписка Azure. См. [Бесплатная пробная версия Azure](https://azure.microsoft.com/documentation/videos/get-azure-free-trial-for-testing-hadoop-in-hdinsight/).
- Кластер Apache Spark в HDInsight на платформе Linux. Инструкции см. в разделе [Создание кластеров Apache Spark в Azure HDInsight](hdinsight-apache-spark-jupyter-spark-sql.md).

## Как использовать ядра? 

1. На начальной панели [портала Azure](https://portal.azure.com/) щелкните элемент кластера Spark (если он закреплен на начальной панели). Кроме того, вы можете перейти к кластеру, выбрав пункты **Просмотреть все** и **Кластеры HDInsight**.   

2. В колонке кластера Spark щелкните **Быстрые ссылки**, затем в колонке **Панель мониторинга кластера** выберите **Jupyter Notebook**. При появлении запроса введите учетные данные администратора для кластера.

	> [AZURE.NOTE] Также можно открыть Jupyter Notebook для своего кластера, открыв следующий URL-адрес в браузере. Замените __CLUSTERNAME__ именем кластера.
	>
	> `https://CLUSTERNAME.azurehdinsight.net/jupyter`

2. Создание новой записной книжки с новыми ядрами. Щелкните **Создать**, а затем выберите пункт **Pyspark** или **Spark**. Для приложений Scala следует использовать ядро Spark, а для приложений Python — ядро PySpark.

	![Создание новой записной книжки Jupyter](./media/hdinsight-apache-spark-jupyter-notebook-kernels/jupyter-kernels.png "Создание новой записной книжки Jupyter")

3. Записная книжка должна открыться с выбранным ядром.

## Зачем использовать новые ядра?

Ниже приведены несколько преимуществ использования новых ядер.

1. **Предустановки контекстов**. С ядром **Python2**, которое предоставляется с записными книжками Jupyter, необходимо настроить явно контексты Spark, SQL или Hive перед началом работы с приложением, которое вы разрабатываете. При использовании новых ядер (**Spark** или **PySpark**) эти контексты будут доступны вам по умолчанию. а именно:

	* **sc** для контекста Spark;
	* **sqlContext** для контекста SQL;
	* **hiveContext** для контекста Hive.


	Это значит, что для настройки этих контекстов вам не придется выполнять операторы следующего вида:

		###################################################
		# YOU DO NOT NEED TO RUN THIS WITH THE NEW KERNELS
		###################################################
		sc = SparkContext('yarn-client')
		sqlContext = SQLContext(sc)
		hiveContext = HiveContext(sc)

	Вместо этого вы сможете сразу использовать в своем приложении предустановленные контексты.
	
2. **Волшебные команды**. Ядро PySpark предоставляет несколько "волшебных команд". Это специальные команды, которые можно вызывать с `%%` (например `%%MAGIC` <args>). Волшебная команда должна быть первым словом в ячейке кода и может состоять из нескольких строк содержимого. Волшебное слово должно быть первым словом в ячейке. Любые другие слова перед волшебной командой, даже комментарии, приведут к ошибке. Дополнительные сведения о волшебных командах см. [здесь](http://ipython.readthedocs.org/en/stable/interactive/magics.html).

	В следующей таблице перечислены различные волшебные команды, доступные для ядер.

	| Волшебная команда | Пример | Описание |
	|-----------|---------------------------------|--------------|
	| help | `%%help` | Формирует таблицу из всех доступных волшебных слов с примерами и описанием. |
	| info | `%%info` | Выводит сведения о сеансе для текущей конечной точки Livy. |
	| configure | `%%configure -f {"executorMemory": "1000M", "executorCores": 4`} | Настраивает параметры для создания сеанса. Флаг force (-f) является обязательным, если сеанс уже был создан, иначе сеанс будет удален и создан заново. Список допустимых параметров приведен в разделе [Тело запроса сеансов POST Livy](https://github.com/cloudera/livy#request-body). Параметры должны передаваться в виде строки JSON. |
	| sql | `%%sql -o <variable name>`<br> `SHOW TABLES` | Выполняет запрос SQL к sqlContext. Если передан параметр `-o`, результат запроса сохраняется в контексте %%local Python в качестве таблицы данных [Pandas](http://pandas.pydata.org/). |
	| hive | `%%hive -o <variable name>`<br> `SHOW TABLES` | Выполняет запрос Hive к hivelContext. Если передан параметр -o, результат запроса сохраняется в контексте %%local Python в качестве таблицы данных [Pandas](http://pandas.pydata.org/). |
	| local | `%%local`<br>`a=1` | Весь код в последующих строках будет выполнен локально. В качестве кода должен быть указан корректный код Python. |
	| журналы | `%%logs` | Выводит журналы для текущего сеанса Livy. |
	| удалить | `%%delete -f -s <session number>` | Удаляет указанный сеанс для текущей конечной точки Livy. Обратите внимание, что нельзя удалить сеанс, который был инициирован самим ядром. |
	| cleanup | `%%cleanup -f` | Удаляет все сеансы для текущей конечной точки Livy, включая сеанс этой записной книжки. Флаг -f является обязательным. |

3. **Автоматическая визуализация**. Ядро **Pyspark** автоматически визуализирует выходные данные запросов Hive и SQL. Вы можете выбрать различные типы средства визуализации, включая таблицы, круговые диаграммы, графики, диаграммы с областями и линейчатые диаграммы.


## Рекомендации по использованию новых ядер

Какое бы ядро вы ни использовали (Python2, PySpark или Spark), работающие записные книжки будут задействовать ресурсы кластера. Поскольку в случае записной книжки Python2 контексты создаются напрямую, при выходе из приложения их можно аннулировать.

В случае с ядрами PySpark и Spark контексты предустановлены, а значит, их нельзя аннулировать явным образом. Это значит, что, если вы выйдете из записной книжки, контекст может остаться запущенным, отнимая ресурсы кластера. При работе с ядрами PySpark и Spark рекомендуется использовать параметр **Закрыть и остановить** в меню **Файл** записной книжки. Программа аннулирует контекст и закроет записную книжку.


## Примеры

Открыв записную книжку Jupyter, вы увидите в корневом каталоге две папки.

* Папка **PySpark** содержит примеры записных книжек, в которых используется новое ядро **Python**.
* Папка **Scala** содержит примеры записных книжек, в которых используется новое ядро **Spark**.

Чтобы узнать о различных волшебных командах, вы можете открыть записную книжку **00 - [READ ME FIRST] Spark Magic Kernel Features** из каталога **PySpark** или **Spark**. Также можно использовать другие примеры записных книжек в этих каталогах, чтобы узнать, как реализовать различные сценарии с помощью записных книжек Jupyter с кластерами HDInsight Spark.

## Отзыв

Новые ядра находятся в стадии развития и будут улучшаться со временем. Кроме того, это может означать, что по мере развития этих ядер API могут измениться. Мы будем признательны вам за любые отзывы о работе с новыми ядрами. Ваши комментарии помогут нам оформить финальную версию этих ядер. Отзывы и замечания оставляйте в разделе **Комментарии** под данной статьей.


## <a name="seealso"></a>См. также:


* [Обзор: Apache Spark в Azure HDInsight](hdinsight-apache-spark-overview.md)

### Сценарии

* [Использование Spark со средствами бизнес-аналитики. Выполнение интерактивного анализа данных с использованием Spark в HDInsight с помощью средств бизнес-аналитики](hdinsight-apache-spark-use-bi-tools.md)

* [Использование Spark с машинным обучением. Использование Spark в HDInsight для анализа температуры в здании на основе данных системы кондиционирования](hdinsight-apache-spark-ipython-notebook-machine-learning.md)

* [Использование Spark с машинным обучением. Использование Spark в HDInsight для прогнозирования результатов контроля качества пищевых продуктов](hdinsight-apache-spark-machine-learning-mllib-ipython.md)

* [Потоковая передача Spark. Использование Spark в HDInsight для сборки приложений потоковой передачи данных в режиме реального времени](hdinsight-apache-spark-eventhub-streaming.md)

* [Анализ журнала веб-сайта с использованием Spark в HDInsight](hdinsight-apache-spark-custom-library-website-log-analysis.md)

### Создание и запуск приложений

* [Создание автономного приложения с использованием Scala](hdinsight-apache-spark-create-standalone-application.md)

* [Удаленный запуск заданий с помощью Livy в кластере Spark](hdinsight-apache-spark-livy-rest-interface.md)

### Средства и расширения

* [Использование подключаемого модуля средств HDInsight для IntelliJ IDEA для создания и отправки приложений Spark Scala](hdinsight-apache-spark-intellij-tool-plugin.md)

* [Использование записных книжек Zeppelin с кластером Spark в HDInsight](hdinsight-apache-spark-use-zeppelin-notebook.md)

### Управление ресурсами

* [Управление ресурсами кластера Apache Spark в Azure HDInsight](hdinsight-apache-spark-resource-manager.md)

<!---HONumber=AcomDC_0330_2016-->