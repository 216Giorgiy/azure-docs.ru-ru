---
title: Обзор HDInsight 4.0 (предварительная версия) в Azure
description: Сравнение функций и ограничений HDInsight 3.6 и HDInsight 4.0, а также рекомендации по обновлению.
ms.service: hdinsight
author: mamccrea
ms.author: mamccrea
ms.reviewer: mamccrea
ms.topic: overview
ms.date: 10/04/2018
ms.openlocfilehash: 34582e66dec3b2f97efba7856ccfbf678f8f1f63
ms.sourcegitcommit: c37122644eab1cc739d735077cf971edb6d428fe
ms.translationtype: HT
ms.contentlocale: ru-RU
ms.lasthandoff: 12/14/2018
ms.locfileid: "53408091"
---
# <a name="hdinsight-40-overview-preview"></a>HDInsight 4.0 (предварительная версия)

Azure HDInsight является одной из самых популярных служб среди корпоративных клиентов для аналитики с открытым кодом Apache Hadoop и Apache Spark в Azure. HDInsight (HDI) 4.0 является облачным дистрибутивом компонентов Apache Hadoop из платформы [Hortonworks Data Platform (HDP) 3.0](https://docs.hortonworks.com/HDPDocuments/HDP3/HDP-3.0.0/release-notes/content/relnotes.html). Эта статья содержит сведения о последнем выпуске Azure HDInsight и инструкции по обновлению.

## <a name="whats-new-in-hdi-40"></a>Новые возможности в HDI 4.0

### <a name="apache-hive-30-and-llap"></a>Apache Hive 3.0 и LLAP

Для аналитической обработки с низкой задержкой (LLAP) Apache Hive используются постоянные серверы запросов и выполняющееся в памяти кэширование. Это ускоряет выполнение SQL-запросов к данным, размещенным в удаленном облачном хранилище. Hive LLAP использует набор постоянных управляющих программ, которые выполняют фрагментов запросов Hive. Выполнение запросов в LLAP аналогично выполнению запросов в Hive без LLAP: рабочие задачи выполняются в управляющих программах LLAP, а не в контейнерах.

Преимущества Hive LLAP:

* Возможность выполнять глубокий анализ SQL, в том числе сложные соединения, вложенные запросы, функции управления окнами, сортировку, определяемые пользователем функции и сложные статистические вычисления, без ущерба для производительности и масштабируемости.

* Интерактивные запросы к данным в том же хранилище, в котором выполняется их подготовка, что исключает необходимость перемещать данные из хранилища в другую подсистему для аналитической обработки.

* Кэширование результатов запросов позволяет многократно использовать результаты ранее вычисленных запросов, что экономит время и ресурсы, затрачиваемые на выполнение задач кластера, необходимых для выполнения запроса.

### <a name="hive-dynamic-materialized-views"></a>Динамические материализованные представления Hive

Hive теперь поддерживает динамические материализованные представления, или предварительное вычисление соответствующих сводок. Эту функцию можно использовать для ускорения обработки запросов в хранилищах данных. Материализованные представления могут храниться в собственном коде в Hive и прозрачно использовать ускорение обработки LLAP.

### <a name="hive-transactional-tables"></a>Транзакционные таблицы Hive

HDI 4.0 включает в себя Apache Hive 3, для которого требуется соответствие требованиям к атомарности, согласованности, изоляции и устойчивости (ACID) для транзакционных таблиц, которые размещены в хранилище данных Hive. Доступ к совместимым с ACID таблицам и табличным данным и управление ими осуществляет Hive. Данные в таблицах, поддерживающих операции создания, извлечения, обновления и удаления (CRUD), должны быть представлены в формате ORC, но таблицы только для вставки поддерживают все форматы файлов.

* В ACID версии 2 повышена производительность формата хранения и подсистемы выполнения. 

* Компонент ACID включен по умолчанию для обеспечения полной поддержки обновления данных.

* Улучшенные возможности ACID дают возможность обновлять и удалять данные на уровне строки.

* Снижение производительности при этом отсутствует.

* Группирование не требуется.

* Служба Spark может считывать и записывать данные в совместимых с ACID таблицах Hive с помощью соединителя хранилища данных Hive.

Узнайте больше об [Apache Hive 3](https://docs.hortonworks.com/HDPDocuments/HDP3/HDP-3.0.0/hive-overview/content/hive_whats_new_in_this_release_hive.html).

### <a name="apache-spark"></a>Apache Spark

Apache Spark получает обновляемые таблицы и транзакции ACID с помощью соединителя хранилища данных Hive. Соединитель хранилища данных Hive позволяет зарегистрировать транзакционные таблицы Hive в качестве внешних таблиц в Spark для получения доступа ко всем функциям транзакций. Предыдущие версии поддерживали только оперирование секциями таблиц. Соединитель хранилища данных Hive также поддерживает кадры данных потоковой передачи для потоковой передачи операций чтения и записи в транзакционные таблицы и таблицы потоковой передачи Hive из Spark.

Исполнители Spark могут подключаться непосредственно к управляющим программам Hive LLAP, чтобы извлекать и обновлять данные посредством транзакций, что позволяет Hive сохранить контроль над данными.

Apache Spark в HDInsight 4.0 поддерживает следующие сценарии:

* Обучение моделей машинного обучения с помощью транзакционной таблицы, используемой для создания отчетов.
* Безопасное добавление столбцов из Spark ML в таблицу Hive с помощью транзакций ACID.
* Запуск задания потоковой передачи Spark в канале изменений из таблицы потоковой передачи Hive.
* Создание ORC-файлов непосредственно в задании структурированной потоковой передачи Spark.

Вам больше не нужно беспокоиться о случайных попытках доступа к транзакционным таблицам Hive непосредственно из Spark, которые приводят к несогласованным результатам, возникновению повторяющихся данных или повреждению данных. В HDI 4.0 таблицы Spark и таблицы Hive хранятся в отдельных метахранилищах. Используйте соединитель хранилища данных Hive, чтобы явно регистрировать транзакционные таблицы Hive как внешние таблицы Spark.

Узнайте больше об [Apache Spark](https://docs.hortonworks.com/HDPDocuments/HDP3/HDP-3.0.0/spark-overview/content/analyzing_data_with_apache_spark.html).


### <a name="apache-oozie"></a>Apache Oozie

Apache Oozie 4.3.1 входит в состав HDI 4.0 со следующими изменениями:

* Oozie больше не выполняет действия Hive. Интерфейс командной строки Hive удален и заменен BeeLine.

* Вы можете исключить нежелательные зависимости из общей библиотеки, добавив шаблон исключения в файл **job.properties**.

Узнайте больше об [Apache Oozie](https://docs.hortonworks.com/HDPDocuments/HDP3/HDP-3.0.0/release-notes/content/patch_oozie.html).

## <a name="how-to-upgrade-to-hdi-40"></a>Как выполнить обновление до HDI 4.0

Как и для любого выпуска основного номера версии, важно тщательно протестировать компоненты перед внедрением последней версии в рабочей среде. Можно начать процесс обновления до HDI 4.0, но во избежание случайных сбоев по умолчанию предлагается HDI 3.6.

Поддерживаемый способ обновления более ранних версий HDI до HDI 4.0 отсутствует. Из-за изменения форматов данных в хранилище метаданных и больших двоичных объектах версия HDI 4.0 несовместима с предыдущими версиями. Важно отделить новую среду HDI 4.0 от текущей рабочей среды. Если развернуть HDI 4.0 в текущей среде, хранилище метаданных будет обновлено, и это невозможно будет отменить.  

## <a name="limitations"></a>Ограничения

* HDI 4.0 не поддерживает MapReduce. Вместо этого используйте Apache Tez. Узнайте больше об [Apache Tez](https://tez.apache.org/).

* В HDI 4.0 больше не используется представление Hive. 

* Интерпретатор оболочки в Apache Zeppelin не поддерживается в кластерах Spark и Interactive Query.

* Вы не можете *запретить* использование LLAP в кластере Spark LLAP. LLAP можно только выключить.

* Azure Data Lake Storage 2-го поколения не поддерживает сохранение записных книжек Juypter в кластере Spark.

## <a name="next-steps"></a>Дополнительная информация

* [Документация по Azure HDInsight](index.yml)
* [Заметки о выпуске](hdinsight-release-notes.md)
