<properties
   pageTitle="Анализ полученных с датчиков данных с помощью Apache Storm и HBase | Microsoft Azure"
   description="В этой статье вы узнаете, как подключить к Apache Storm к виртуальной сети. Используйте Storm с HBase для обработки данных датчиков из концентратора событий и их визуализации с помощью D3.js."
   services="hdinsight"
   documentationCenter=""
   authors="Blackmist"
   manager="paulettm"
   editor="cgronlun"/>

<tags
   ms.service="hdinsight"
   ms.devlang="java"
   ms.topic="article"
   ms.tgt_pltfrm="na"
   ms.workload="big-data"
   ms.date="01/28/2016"
   ms.author="larryfr"/>

# Анализ полученных с датчиков данных с использованием Apache Storm, концентратора событий и базы данных HBase в службе HDInsight (Hadoop)

Узнайте, как с помощью Apache Storm в службе HDInsight можно обрабатывать данные, отправленные с датчиков в концентратор событий Azure, и визуализировать эти данные с помощью D3.js. В этом документе также описывается, как с помощью виртуальной сети Azure соединить кластеры Storm в HDInsight и HBase в HDInsight и хранить данные из топологии в базе данных HBase.

> [AZURE.NOTE] Информация, представленная в данном документе, основана на использовании кластера Storm под управлением Windows в HDInsigh. Сведения о работе с концентратором событий Azure из кластера Storm под управлением Linux в HDInsight можно найти в разделе [Обработка событий из концентраторов событий Azure с помощью Storm в HDInsight](hdinsight-storm-develop-java-event-hub-topology.md).

## Предварительные требования

* Подписка Azure. См. [Бесплатная пробная версия Azure](http://azure.microsoft.com/documentation/videos/get-azure-free-trial-for-testing-hadoop-in-hdinsight/).

* [Кластер Apache Storm в HDInsight](hdinsight-apache-storm-tutorial-get-started.md)

* [Node.js](http://nodejs.org/) (используется для веб-сайта панели мониторинга, а также для отправки данных с датчиков в концентратор событий)

* [Java и пакет JDK 1.7](http://www.oracle.com/technetwork/java/javase/downloads/index.html)

* [Maven](http://maven.apache.org/what-is-maven.html)

* [Git](http://git-scm.com/)

> [AZURE.NOTE] Java, JDK, Maven и Git доступны также через диспетчер пакетов [Chocolatey NuGet](http://chocolatey.org/).

## Архитектура

![схема архитектуры](./media/hdinsight-storm-sensor-data-analysis/devicesarchitecture.png)

В этом примере используются следующие компоненты:

* **Концентратор событий Azure**. Предоставляет собираемые с датчиков данные. В примере используется приложение, создающее фиктивные данные.

* **Storm в HDInsight**. В реальном времени обрабатывает данные, получаемые из концентратора событий.

* **HBase в HDInsight**. Необязательный компонент, выступающий в роли постоянного хранилище данных NoSQL.

* **Служба виртуальной сети Azure**. Необязательный компонент, который необходим при использовании базы данных HBase. Позволяет устанавливать безопасное соединение между кластерами Storm в HDInsight и HBase в HDInsight.

* **Веб-сайт панели мониторинга**. Пример панели мониторинга, на которой в режиме реального времени строятся диаграммы на основе полученных данных.

	* Веб-сайт построен на Node.js. Его можно проверить на любой клиентской операционной системе или развернуть в службе веб-сайтов Azure.

	* Для обмена данными в режиме реального времени между топологией Storm и веб-сайтом используется библиотека [Socket.io](http://socket.io/).

		> [AZURE.NOTE] Это сведения о реализации примера. На практике можно использовать любую платформу, например сокеты прямого доступа WebSocket или SignalR.

	* Для построения диаграмм из данных, отправляемых на веб-сайт, используется [D3.js](http://d3js.org/).

Топология считывает данные из концентратора событий с помощью класса **com.microsoft.eventhubs.spout.EventHubSpout** в кластере Storm в HDInsight. Связь с веб-сайтом реализована с использованием библиотеки [socket.io-client.java](https://github.com/nkzawa/socket.io-client.java).

При необходимости связь с базой данных HBase можно реализовать с помощью класса [org.apache.storm.hbase.bolt.HBaseBolt](https://storm.apache.org/javadoc/apidocs/org/apache/storm/hbase/bolt/class-use/HBaseBolt.html) в системе Storm.

Схема топологии выглядит так.

![схема топологии](./media/hdinsight-storm-sensor-data-analysis/sensoranalysis.png)

> [AZURE.NOTE] Это очень упрощенная схема топологии. Во время выполнения для каждого раздела концентратора событий, с которого считываются данные, создается экземпляр каждого компонента. Экземпляры распределяются между узлами в кластере. Обмен данными между ними выглядит следующим образом.
>
> * Данные из «воронки» равномерно передаются в средство синтаксического анализа.
> * Данные из средства синтаксического анализа передаются в панель мониторинга и базу данных HBase (если используется). Данные группируются по идентификатору устройства, чтобы сообщения с одного устройства всегда перенаправлялись в один и тот же компонент.

### Компоненты

* **«Воронка» концентратора событий**. Пример реализации «воронки» можно найти на сайте GitHub в статье [Примеры HDInsight Storm](https://github.com/hdinsight/hdinsight-storm-examples).

* **ParserBolt.java**. Из «воронки» отправляются необработанные данные JSON. Иногда за один раз может отправляться сразу несколько событий. «Сито» определяет, как считывать данные, отправляемые из воронки, и отправляет их в новый поток в виде кортежа с несколькими полями.

* **DashboardBolt.java**. Определяет, как использовать клиентскую библиотеку Socket.io для Java для отправки данных в реальном времени в панель мониторинга на веб-сайте.

## Подготовка среды

Прежде чем использовать этот пример, необходимо создать концентратор событий Azure, который топология Storm будет считывать. Кроме того, необходимо создать топологию Storm в HDInsight, так как компонент, используемый для чтения данных из концентратора событий, доступен только в кластере.

> [AZURE.NOTE] Впоследствии «воронка» концентратора событий будет доступна из Maven.

### Настройка концентраторов Event Hub

В этом примере концентратор событий выступает в роли источника данных. Чтобы создать новый концентратор Event Hub, выполните следующие действия.

1. На [классическом портале Azure](https://manage.windowsazure.com) выберите **СОЗДАТЬ > Служебная шина > Концентратор событий > Настраиваемое создание**.

2. В диалоговом окне **Добавление нового концентратора событий** укажите параметры **Имя концентратора событий** и **Регион** (регион, в котором будет создан концентратор), а затем создайте новое пространство имен или выберите существующее. Затем щелкните стрелку для продолжения.

2. В диалоговом окне **Настройка концентратора событий** задайте значения параметров **Число разделов** и **Хранение сообщений**. В этом примере числу разделов присвойте значение 10, а хранению сообщений — 1.

3. Создав концентратор, выберите пространство имен и щелкните **Концентраторы событий**. После этого выберите концентратор, который вы только что создали.

4. Выберите **Настроить** и создайте две новые политики доступа, используя следующую информацию.

	<table>
<tr><th>Имя</th><th>Разрешения</th></tr>
<tr><td>Устройства</td><td>Отправка</td></tr>
<tr><td>Storm</td><td>Прослушивание</td></tr>
</table>После создания разрешений выберите значок **Сохранить** в нижней части страницы. Таким образом вы создадите политики общего доступа, которые будут использоваться для отправки сообщений в этот концентратор и для чтения сообщений, полученных из него.

5. Сохранив политики, щелкните в нижней части страницы **Генератор общего ключа доступа**, чтобы получить ключ для политик **устройства** и **storm**. Сохраните их, поскольку они понадобятся позже.

### Создание кластера Storm в HDInsight

1. Перейдите на [классический портал Azure](https://manage.windowsazure.com/).

2. В области слева щелкните **HDInsight**, а затем в левом нижнем углу страницы щелкните **+Создать**.

3. Во втором столбце щелкните значок HDInsight и выберите **Настраиваемая**.

4. На странице **Сведения о кластере** введите имя кластера и выберите **Storm** для параметра**Тип кластера**. Щелкните стрелку для продолжения.

5. В качестве значения количества **Узлов данных**, используемых в этом кластере, введите 1.

	> [AZURE.NOTE] Для сокращения затрат на кластер, который описан в этой статье, установите для параметра **Размер кластера** значение 1. Завершив работу с кластером, удалите его.

6. Введите **имя пользователя** и **пароль** администратора и нажмите стрелку для продолжения.

4. Для **Учетной записи хранения** выберите **Создать новое хранилище** или выберите существующую запись хранения. Выберите или введите **Имя учетной записи** и **Контейнер по умолчанию**. В левом нижнем углу щелкните значок с флажком, чтобы создать кластер Storm.

## Скачивание и установка «воронки» концентратора событий

1. Скачайте [проект с примерами HDInsight Storm](https://github.com/hdinsight/hdinsight-storm-examples/). Найдите скачанный файл **lib/eventhubs/eventhubs-storm-spout-0.9-jar-with-dependencies.jar**.

2. В командной строке введите указанную ниже команду, чтобы установить файл **eventhubs-storm-spout-0.9-jar-with-dependencies.jar** в локальное хранилище Maven. Это позволит вам в дальнейшем быстро добавить этот файл в качестве ссылки в проект Storm.

		mvn install:install-file -Dfile=target/eventhubs-storm-spout-0.9-jar-with-dependencies.jar -DgroupId=com.microsoft.eventhubs -DartifactId=eventhubs-storm-spout -Dversion=0.9 -Dpackaging=jar

## Скачивание и настройка проекта

Для скачивания проекта с GitHub выполните следующую команду.

	git clone https://github.com/Blackmist/hdinsight-eventhub-example

После выполнения команды у вас будет следующая структура каталогов.

	hdinsight-eventhub-example/
		TemperatureMonitor/ - this is the Java topology
			conf/
				Config.properties
				hbase-site.xml
			src/
			test/
			dashboard/ - this is the node.js web dashboard
			SendEvents/ - utilities to send fake sensor data

> [AZURE.NOTE] Мы не приводим подробные сведения о коде примера, так как весь код сопровожден комментариями.

Откройте файл **Config.properties** и добавьте сведения, которые вы использовали при создании концентратора событий. После добавления этих сведений сохраните файл.

	eventhubspout.username = storm

	eventhubspout.password = <the key of the 'storm' policy>

	eventhubspout.namespace = <the event hub namespace>

	eventhubspout.entitypath = <the event hub name>

	eventhubspout.partitions.count = <the number of partitions for the event hub>

	## if not provided, will use storm's zookeeper settings
	## zookeeper.connectionstring=localhost:2181

	eventhubspout.checkpoint.interval = 10

	eventhub.receiver.credits = 1024

## Локальная компиляция и тестирование

Перед началом тестирования вам необходимо запустить панель мониторинга, чтобы просмотреть выходные данные топологии и создать данные для хранения в концентраторе событий.

### Запуск веб-приложения

1. Откройте новое окно командной строки или терминала и перейдите в каталог **hdinsight-eventhub-example/dashboard**. Затем установите необходимые для веб-приложения зависимости, используя следующую команду.

		npm install

2. Запустите веб-приложение с помощью следующей команды.

		node server.js

	Должно появиться примерно такое сообщение:

		Server listening at port 3000

2. Откройте веб-браузер и введите в адресной строке ****http://localhost:3000/**. Вы должны увидеть страницу, аналогичную показанной ниже:

	![веб-панель мониторинга](./media/hdinsight-storm-sensor-data-analysis/emptydashboard.png)

	Не закрывайте окно командной строки или терминала. После завершения тестирования остановите веб-сервер с помощью клавиш CTRL+C.

### Начало создания данных

> [AZURE.NOTE] Для описанных в этом разделе действий используется Node.js. Таким образом эти действия могут выполняться на любой платформе. Примеры для других языков см. в каталоге **SendEvents**.


1. Откройте новое окно командной строки или терминала и перейдите в каталог **hdinsight-eventhub-example/SendEvents/nodejs**. Затем установите необходимые для приложения зависимости, используя следующую команду.

		npm install

2. Откройте файл **app.js** в текстовом редакторе и добавьте полученные ранее сведения о концентраторе событий.

		// ServiceBus Namespace
		var namespace = 'servicebusnamespace';
		// Event Hub Name
		var hubname ='eventhubname';
		// Shared access Policy name and key (from Event Hub configuration)
		var my_key_name = 'devices';
		var my_key = 'key';

2. Для добавления новых записей в концентратор событий используйте следующую команду.

		node app.js

	Вы должны увидеть несколько строк выходных данных, среди которых будет информация, отправленная в концентратор событий. Эти строки будут выглядеть примерно так:

		{"TimeStamp":"2015-02-10T14:43.05.00320Z","DeviceId":0,"Temperature":7}
		{"TimeStamp":"2015-02-10T14:43.05.00320Z","DeviceId":1,"Temperature":39}
		{"TimeStamp":"2015-02-10T14:43.05.00320Z","DeviceId":2,"Temperature":86}
		{"TimeStamp":"2015-02-10T14:43.05.00320Z","DeviceId":3,"Temperature":29}
		{"TimeStamp":"2015-02-10T14:43.05.00320Z","DeviceId":4,"Temperature":30}
		{"TimeStamp":"2015-02-10T14:43.05.00320Z","DeviceId":5,"Temperature":5}
		{"TimeStamp":"2015-02-10T14:43.05.00320Z","DeviceId":6,"Temperature":24}
		{"TimeStamp":"2015-02-10T14:43.05.00320Z","DeviceId":7,"Temperature":40}
		{"TimeStamp":"2015-02-10T14:43.05.00320Z","DeviceId":8,"Temperature":43}
		{"TimeStamp":"2015-02-10T14:43.05.00320Z","DeviceId":9,"Temperature":84}

### Запуск топологии

2. Запустите топологию локально, выполнив следующую команду.

	mvn compile exec:java -Dstorm.topology=com.microsoft.examples.Temperature

	Эта команда запустит топологию, прочтет файлы с концентратора Event Hub и отправит их в панель мониторинга, функционирующую на Azure Websites. На веб-панели мониторинга должны появиться линии примерно, как на рисунке ниже.

	![панель мониторинга с данными](./media/hdinsight-storm-sensor-data-analysis/datadashboard.png)

3. Не закрывая панель мониторинга, отправьте в нее новые данные с помощью команды `node app.js` (использовалась на предыдущих этапах). Значения температуры генерируются случайным образом, поэтому граф будет изменяться, отображая новые значения.

3. Убедившись, что все работает, остановите топологию, нажав клавиши CTRL+C. Чтобы остановить приложение SendEvent, выберите окно и нажмите любую клавишу. С помощью клавиш CTRL+C также можно остановить веб-сервер.

## Пакетирование и развертывание топологии HDInsight

Используя свою среду разработки, с помощью описанных ниже действий запустите температурную топологию в своем кластере Storm в HDInsight.

### Публикация панели мониторинга на веб-сайте

1. Чтобы развернуть панель мониторинга на веб-сайте Azure, выполните действия, описанные в статье [Создание и развертывание веб-приложения Node.js в службе приложений Azure](../app-service-web/web-sites-nodejs-develop-deploy-mac.md). Запишите URL-адрес веб-сайта, который будет выглядеть примерно так: **mywebsite.azurewebsites.net**.

2. Когда веб-сайт будет создан, перейдите к нему на классическом портале Azure и откройте вкладку **Настройка**. Включите **Подключения Web Socket** и в нижней части страницы нажмите кнопку **Сохранить**.

2. Откройте файл **hdinsight-eventhub-example\\TemperatureMonitor\\src\\main\\java\\com\\microsoft\\examples\\bolts\\DashboardBolt.java** и в следующей строке укажите URL-адрес опубликованной панели мониторинга.

		socket = IO.socket("http://mywebsite.azurewebsites.net");

3. Сохраните файл **DashboardBolt.java**.

### Создание пакета топологии и его развертывание

1. Выполните следующую команду, чтобы создать из своего проекта пакет JAR.

		mvn package

	Это создаст файл под именем **TemperatureMonitor-1.0-SNAPSHOT.jar** в **целевом**каталоге вашего проекта.

2. Выложите топологию в кластер Storm в HDInsight и запустите ее там с помощью **панели мониторинга Storm**. Инструкции, как это сделать, приведены в статье [Развертывание топологий Storm и управление ими](hdinsight-storm-deploy-monitor-topology.md).

3. После запуска топологии откройте в браузере опубликованный в Azure веб-сайт и с помощью команды `node app.js` отправьте данные в концентратор событий. Веб-панель мониторинга должна начать обновлять данные.

	!["Веб-транзакции"](./media/hdinsight-storm-sensor-data-analysis/datadashboard.png)

## Использование HBase (дополнительно)

Чтобы использовать Storm и HBase вместе, необходимо создать виртуальную сеть Azure и затем создать в ней кластер Storm и HBase.

### Создание виртуальной сети Azure (дополнительно)

Если вы планируете использовать в этом примере базу данных HBase, вам необходимо создать виртуальную сеть Azure, в которой будут размещены кластеры Storm в HDInsight и HBase в HDInsight.

1. Перейдите на [классический портал Azure](https://manage.windowsazure.com).

2. В нижней части страницы щелкните **+Создать** > **Сетевые службы** > **Виртуальная сеть** > **Быстрое создание**.

3. Введите или выберите следующие значения:

	- **Имя**. Имя вашей виртуальной сети.

	- **Адресное пространство**. Выбирайте адресное пространство виртуальной сети таким образом, чтобы оно было достаточно большим для обеспечения адресов для всех узлов в кластере. В противном случае подготовка завершится ошибкой.

	- **Максимальное число ВМ**. Выберите максимальное количество виртуальных машин.

	- **Расположение**.Расположение должно совпадать с расположением кластера HBase, который вы создадите.

	- **DNS-сервер**. В этой статье используется внутренний DNS-сервер, предоставляемый службой Azure. Поэтому вы можете выбрать вариант **Нет**. Более продвинутые сетевые конфигурации с другими DNS-серверами также поддерживаются. Подробные инструкции см. в статье [Разрешение имен (DNS)](../virtual-network/virtual-networks-name-resolution-for-vms-and-role-instances.md).

4. Щелкните **Создать виртуальную сеть**. В списке появится имя новой виртуальной сети. Подождите, пока в столбце «Состояние» не появится значение **Создано**.

5. В основной области щелкните только что созданную виртуальную сеть.

6. В верхней части страницы щелкните **ПАНЕЛЬ МОНИТОРИНГА**.

7. В разделе **Сводка** узнайте и запишите **ИДЕНТИФИКАТОР ВИРТУАЛЬНОЙ СЕТИ**. Он вам понадобится в процессе подготовки кластеров Storm и HBase.

8. В верхней части страницы щелкните **НАСТРОЙКИ**.

9. В нижней части страницы будет указано имя подсети по умолчанию: **Subnet-1**. Используйте клавишу**добавить подсеть**, чтобы добавить **Subnet-2** (Подсеть 2). Эти подсети будут содержать кластеры Storm и HBase

	> [AZURE.NOTE] В этой статье используются кластеры с одним узлом. Если вы хотите создать кластер с несколькими узлами, вам необходимо проверить количество адресов подсети (**CIDR(ADDRESS COUNT)**), которая будет использоваться для кластера. Количество адресов должен быть больше, чем количество рабочих узлов плюс семь (шлюз: 2, Headnode: 2, Zookeeper: 3). Например, если вам нужен кластер HBase на 10 узлов, количество адресов для подсети должно быть больше 17 (10 + 7). В противном случае развертывание завершится ошибкой.
	>
	> Настоятельно рекомендуется назначать одну подсеть для одного кластера.

11. В нижней части страницы нажмите кнопку **Сохранить**.

### Создание кластера Storm и HBase в виртуальной сети

1. Перейдите на [классический портал Azure](https://manage.windowsazure.com/).

2. В области слева щелкните **HDInsight**, а затем в левом нижнем углу страницы щелкните **+Создать**.

3. Во втором столбце щелкните значок HDInsight и выберите **Настраиваемая**.

4. На странице **Сведения о кластере** введите имя кластера и выберите **Storm** для параметра**Тип кластера**. Щелкните стрелку для продолжения.

5. В качестве значения количества **Узлов данных**, используемых в этом кластере, введите 1. Для параметра **Регион/виртуальная сеть** выберите виртуальную сеть Azure, которую вы создали ранее. В качестве параметра **Подсеть виртуальной сети** выберите **Subnet-1**.

	> [AZURE.NOTE] Для сокращения затрат на кластер, который описан в этой статье, установите для параметра **Размер кластера** значение 1. Завершив работу с кластером, удалите его.

6. Введите **имя пользователя** и **пароль** администратора и нажмите стрелку для продолжения.

4. Для **Учетной записи хранения** выберите **Создать новое хранилище** или выберите существующую учетную запись хранения. Выберите или введите **Имя учетной записи** и **Контейнер по умолчанию**. В левом нижнем углу щелкните значок с флажком, чтобы создать кластер Storm.

5. Повторите эти действия, чтобы создать новый кластер **HBase**. Ниже приведены основные различия.

	* **Тип кластера**. Выберите **HBase**.

	* **Подсети виртуальной сети**. Выберите **Subnet-2**.

	* **Учетная запись хранения**. Используйте другой контейнер, а не тот, что используется для кластера Storm.

### Обнаружение DNS-суффикса HBase

Чтобы записывать данные в базу данных HBase из кластера Storm, требуется полное доменное имя для кластера HBase. Чтобы получить эту информацию, сделайте вот что.

	curl -u <username>:<password> -k https://<clustername>.azurehdinsight.net/ambari/api/v1/clusters/<clustername>.azurehdinsight.net/services/hbase/components/hbrest

В возвращенных данных JSON найдите запись **"host\_name"**. Здесь указаны полные доменные имена узлов в кластере. Например:

	...
	"host_name": "wordkernode0.<clustername>.b1.cloudapp.net
	...

Часть доменного имени, начинающаяся с имени кластера, является DNS-суффиксом, например **mycluster.b1.cloudapp.net**.

### Активация «сита» HBase

1. Откройте файл **hdinsight-eventhub-example\\TemperatureMonitor\\conf\\hbase-site.xml** и в указанной ниже строке замените записи `suffix` на DNS-суффикс кластера HBase. После внесения этих изменений сохраните файл.

		<value>zookeeper0.suffix,zookeeper1.suffix,zookeeper2.suffix</value>

	«Сито» HBase будет использовать эти сведения для обмена данными с кластером HBase.

1. Откройте файл **hdinsight-eventhub-example\\TemperatureMonitor\\src\\main\\java\\com\\microsoft\\examples\\bolts** в текстовом редакторе и раскомментируйте следующие строки (удалите `//` в начале строк). После внесения этих изменений сохраните файл.

		topologyBuilder.setBolt("HBase", new HBaseBolt("SensorData", mapper).withConfigKey("hbase.conf"), spoutConfig.getPartitionCount())
    	  .fieldsGrouping("Parser", "hbasestream", new Fields("deviceid")).setNumTasks(spoutConfig.getPartitionCount());

	Компонент "сито" HBase будет активирован.

	> [AZURE.NOTE] Активировать «сито» HBase следует только при развертывании в кластер Storm. Для локального тестирования активировать этот компонент не нужно.

### Данные HBase и Storm

Перед запуском топологии вам необходимо подготовить HBase для приема данных.

1. Подключитесь к кластеру HBase через удаленный рабочий стол.

2. На рабочем столе откройте окно командной строки HDInsight и введите следующую команду.

    cd %HBASE\_HOME% bin\\hbase shell

3. В оболочке HBase введите следующую команду, чтобы создать таблицу, в которой будут храниться данные с датчиков.

    create 'SensorData', 'cf'

4. Убедитесь, что таблица пуста. Для этого введите следующую команду.

    scan 'SensorData'

Запустив топологию в кластере Storm и обработав данные, с помощью команды `scan 'SensorData'` можно проверить, добавились ли данные в HBase.


## Дальнейшие действия

Теперь вы знаете, как использовать Storm для чтения данных с концентратора событий и просматривать сведения из Storm на внешней панели мониторинга с помощью SignalR и D3.js. Если вы выполнили дополнительные действия, вы также узнали, как настроить HDInsight в виртуальной сети и организовать взаимодействие между топологией Storm и базой данных HBase с помощью «сита» HBase.

* Дополнительные примеры топологий Storm со службой HDinsight см. в статье:

    * [Примеры топологий для Storm в HDInsight.](hdinsight-storm-example-topology.md)

* Дополнительные сведения об Apache Storm см. на сайте [Apache Storm](https://storm.incubator.apache.org/).

* Дополнительные сведения о базе данных HBase в службе HDInsight см. в статье [Обзор HBase с HDInsight](hdinsight-hbase-overview.md).

* Дополнительные сведения о библиотеке Socket.io см. на сайте [socket.io](http://socket.io/).

* Дополнительные сведения о D3.js см. в статье [D3.js — документы, управляемые данными](http://d3js.org/).

* Сведения о создании топологий на Java см. в статье [Разработка топологий Java для Apache Storm в HDInsight](hdinsight-storm-develop-java-topology.md).

* Сведения о создании топологий на .NET см. в статье [Разработка топологий для Apache Storm в HDInsight на C# с помощью Visual Studio](hdinsight-storm-develop-csharp-visual-studio-topology.md).

[azure-portal]: https://manage.windowsazure.com/

<!---HONumber=AcomDC_0204_2016-->