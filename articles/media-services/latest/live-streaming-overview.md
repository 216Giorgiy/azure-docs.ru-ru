---
title: Общие сведения о потоковой трансляции с использованием служб мультимедиа Azure | Документация Майкрософт
description: В этой статье содержатся общие сведения о потоковой трансляции в реальном времени с использованием Служб мультимедиа Azure версии 3.
services: media-services
documentationcenter: ''
author: Juliako
manager: femila
editor: ''
ms.service: media-services
ms.workload: media
ms.tgt_pltfrm: na
ms.devlang: ne
ms.topic: article
ms.date: 01/15/2019
ms.author: juliako
ms.openlocfilehash: 91e24fb274c1f9895046e8e2e7d760d02d196ccd
ms.sourcegitcommit: a1cf88246e230c1888b197fdb4514aec6f1a8de2
ms.translationtype: HT
ms.contentlocale: ru-RU
ms.lasthandoff: 01/16/2019
ms.locfileid: "54354184"
---
# <a name="live-streaming-with-azure-media-services-v3"></a>Потоковая трансляция в Службах мультимедиа Azure версии 3

Службы мультимедиа Azure дают возможность предоставлять клиентам события прямой трансляции в облаке Azure. Для потоковой передачи событий прямой трансляции с помощью Служб мультимедиа вам потребуются:  

- камера для записи события;
- динамический видеокодировщик, преобразующий сигналы с камеры (или другого устройства, например ноутбука) в исходный поток, который передается в Службы мультимедиа; этот поток может содержать сигналы, связанные с рекламой, например метки SCTE-35;
- компоненты Служб мультимедиа, которые дают возможность принимать, просматривать, упаковывать, записывать, шифровать и транслировать события в реальном времени непосредственно клиентам или в сеть доставки содержимого (CDN) для дальнейшего распространения.

Эта статья содержит подробное описание, рекомендации по использованию и схемы основных компонентов, участвующих в потоковой трансляции с помощью Служб мультимедиа.

## <a name="live-streaming-workflow"></a>Рабочий процесс для потоковой трансляции в реальном времени

Рабочий процесс для потоковой трансляции в реальном времени включает перечисленные ниже шаги.

1. Создание **события прямой трансляции**.
2. Создание объекта **ресурса**.
3. Создание компонента **выходных данных прямой трансляции** с использованием имени созданного ресурса.
4. Создание **политики потоковой трансляции** и **ключа содержимого** (если необходимо шифровать содержимое с помощью DRM).
5. Создание **потокового указателя** с встроенным типом **политики потоковой трансляции** (если DRM не используется).
6. Создание списка путей на основе **политики потоковой трансляции**, чтобы получать URL-адреса для использования (детерминированные).
7. Получение имени узла для **конечной точки потоковой передачи**, с которой должна идти трансляция (убедитесь, что конечная точка потоковой передачи работает). 
8. Объединение URL-адреса (полученного на шаге 6) с именем узла (полученного на шаге 7), чтобы получить полный URL-адрес.
9. Если вы хотите прекратить просмотр **событий прямой трансляции**, необходимо остановить потоковую передачу событий, удалив **указатель потоковой передачи**.

Дополнительные сведения см. в [руководстве по потоковой трансляции в реальном времени](stream-live-tutorial-with-api.md) на примере [использования .NET Core](https://github.com/Azure-Samples/media-services-v3-dotnet-core-tutorials/tree/master/NETCore/Live).

## <a name="overview-of-main-components"></a>Общие сведения об основных компонентах

Для потоковой трансляции с помощью Служб мультимедиа как в реальном времени, так и по запросу необходим хотя бы один компонент [StreamingEndpoint](https://docs.microsoft.com/rest/api/media/streamingendpoints). При создании учетной записи Служб мультимедиа в нее добавляется компонент StreamingEndpoint **по умолчанию** в состоянии **Остановлен**. Необходимо запустить компонент StreamingEndpoint, указав конечную точку, из которой будет выполняться потоковая передача содержимого зрителям. Можно использовать компонент **StreamingEndpoint** по умолчанию или создать другой с необходимой конфигурацией и заданными параметрами сети CDN **.** При желании можно активировать несколько компонентов StreamingEndpoints, каждый из которых предназначен для отдельной сети CDN и предоставляет уникальное имя узла для доставки содержимого. 

В Службах мультимедиа за прием и обработку видеопотоков отвечают компоненты [LiveEvent](https://docs.microsoft.com/rest/api/media/liveevents). При создании компонента LiveEvent создается входная конечная точка, которая используется для передачи сигнала с удаленного кодировщика в реальном времени. Удаленный динамический кодировщик транслирует в эту точку канал доставки, используя протокол [RTMP](https://www.adobe.com/devnet/rtmp.html) или [Smooth Streaming](https://msdn.microsoft.com/library/ff469518.aspx) (фрагментированный MP4). Для протокола приема Smooth Streaming поддерживаются следующие схемы URL-адресов: `http://` или `https://`. Для протокола приема RTMP поддерживаются следующие схемы URL-адресов: `rtmp://` или `rtmps://`. Дополнительные сведения см. в статье о [рекомендуемых кодировщиках потоковой трансляции](recommended-on-premises-live-encoders.md).

Как только компонент **LiveEvent** начинает принимать исходный поток, можно использовать конечную точку предварительного просмотра (URL-адрес предварительного просмотра), чтобы перед публикацией убедиться, что вы принимаете потоковую трансляцию в реальном времени. Убедившись, что предварительный просмотр транслируется нормально, используйте компонент LiveEvent, чтобы сделать потоковую трансляцию доступной для доставки через одну или несколько предварительно созданных точек **StreamingEndpoint**. Для этого создайте объект [LiveOutput](https://docs.microsoft.com/rest/api/media/liveoutputs) в компоненте **LiveEvent**. 

Объект **LiveOutput** действует, как магнитофон: захватывает трансляцию и записывает ее в ресурс Asset в вашей учетной записи Службы мультимедиа. Записанное содержимое сохраняется в учетной записи хранения Azure, подключенной к вашей учетной записи, в контейнере, определенном ресурсом Asset.  Компонент **LiveOuput** также позволяет управлять некоторыми свойствами исходящей прямой трансляции, в частности тем, какая ее часть сохраняется в записи архива (емкость функции DVR в облаке). Архив на диске — это циклическое архивное "окно", которое пропускает только тот объем содержимого, который указан в свойстве **archiveWindowLength** компонента **LiveOutput**. Содержимое, выходящее за рамки этого окна, автоматически удаляется из контейнера хранилища и не подлежит восстановлению. В компоненте LiveEvent можно создать несколько объектов LiveOutput (до трех) с разными длиной и параметрами архивации.  

Службы мультимедиа дают возможность использовать **динамическую упаковку**, что позволяет предварительно просматривать и передавать в форматах [MPEG DASH, HLS и Smooth Streaming](https://en.wikipedia.org/wiki/Adaptive_bitrate_streaming) потоковые трансляции из исходного потока, отправленного в службу. Ваши зрители могут воспроизводить трансляцию с помощью любых проигрывателей, поддерживающих HLS, DASH и Smooth Streaming. Для доставки потока в любом из этих протоколов можно использовать [Проигрыватель мультимедиа Azure](http://amp.azure.net/libs/amp/latest/docs/index.html) в мобильном или веб-приложении.

Службы мультимедиа обеспечивают доставку содержимого, зашифрованного динамически (**динамическое шифрование**) по стандарту Advanced Encryption Standard (AES-128) или в любой из трех основных систем управления цифровыми правами (DRM): Microsoft PlayReady, Google Widevine и Apple FairPlay. Авторизованным клиентам также предоставляется служба доставки ключей AES и лицензий DRM. Дополнительные сведения о шифровании содержимого с помощью Служб мультимедиа см. в [обзоре системы защиты содержимого](content-protection-overview.md).

При желании также можно применить динамическую фильтрацию, которая позволяет настраивать количество дорожек, форматы, скорость и окно времени презентации для передачи на проигрыватели. Чтобы узнать больше, ознакомьтесь со [Фильтры и динамические манифесты](filters-dynamic-manifest-overview.md).

### <a name="new-capabilities-for-live-streaming-in-v3"></a>Новые возможности потоковой трансляции в версии 3

API-интерфейсы Служб мультимедиа версии 3 дают возможность использовать такие новые функции:

- Новый режим с низкой задержкой. Дополнительные сведения см. в разделе с описанием [задержки](live-event-latency.md).
- Улучшенная поддержка RTMP (повышенная стабильность и поддержка исходного кодировщика).
- Безопасный прием RTMPS.<br/>При создании LiveEvent вы получаете четыре URL-адреса приема. 4 URL-адреса для приема практически идентичны, они имеют тот же токен потоковой передачи (AppId) с отличной частью номера порта. Два из этих URL-адресов являются первичным и резервным для RTMPS.   
- Вы можете вести потоковые трансляции событий в реальном времени длительностью до 24 часов, используя Службы мультимедиа для перекодирования исходного потока с одной скоростью в поток вывода с несколькими скоростями. 

## <a name="liveevent-types"></a>Типы LiveEvent

Есть два типа компонентов [LiveEvent](https://docs.microsoft.com/rest/api/media/liveevents): сквозной режим и кодирование в реальном времени. 

### <a name="pass-through"></a>Сквозной режим

![Сквозной режим](./media/live-streaming/pass-through.png)

При использовании сквозного режима локальный динамический кодировщик генерирует многоскоростной видеопоток и передает его как исходный в компонент LiveEvent с помощью протокола RTMP или фрагментированного MP4. Затем LiveEvent передает входящие видеопотоки без какой-либо дальнейшей обработки. Такой сквозной режим оптимизирован для длительно выполняющихся событий прямой трансляции или непрерывной круглогодичной линейной потоковой трансляции. Создавая LiveEvent такого типа, укажите значение None (LiveEventEncodingType.None).

При этом исходный поток передается с разрешением до 4K и частотой 60 кадров в секунду при помощи видеокодеков H.264/AVC или H.265/HEVC, а также аудиокодека AAC (AAC-LC, HE-AACv1 или HE-AACv2).  Дополнительные сведения см. в статье, посвященной [сравнительным характеристикам и ограничениям типов LiveEvent](live-event-types-comparison.md).

> [!NOTE]
> Метод сквозной доставки — наиболее экономичный способ осуществления потоковой передачи в режиме реального времени, если передается ряд событий за длительный период времени и у вас уже есть локальные кодировщики. См. сведения о [ценах](https://azure.microsoft.com/pricing/details/media-services/).
> 

См. реальный пример в [MediaV3LiveApp](https://github.com/Azure-Samples/media-services-v3-dotnet-core-tutorials/blob/master/NETCore/Live/MediaV3LiveApp/Program.cs#L126).

### <a name="live-encoding"></a>Кодирование в реальном времени  

![Кодирование в реальном времени](./media/live-streaming/live-encoding.png)

При использовании кодирования в реальном времени с помощью Служб мультимедиа ваш локальный динамический кодировщик передает односкоростной видеопоток в качестве исходного в LiveEvent (с помощью протоколов RTMP или фрагментированного Mp4). LiveEvent кодирует этот входящий односкоростной поток в [многоскоростной видеопоток](https://en.wikipedia.org/wiki/Adaptive_bitrate_streaming) и делает его доступным для доставки на устройства воспроизведения с помощью протоколов MPEG-DASH, HLS и Smooth Streaming. Создавая LiveEvent такого типа, укажите тип кодирования **Standard** (LiveEventEncodingType.Standard).

Исходный поток передается с разрешением до 1080p и частотой 30 кадров в секунду при помощи видеокодека H.264/AVC и аудиокодека AAC (AAC-LC, HE-AACv1 или HE-AACv2). Дополнительные сведения см. в статье, посвященной [сравнительным характеристикам и ограничениям типов LiveEvent](live-event-types-comparison.md).

## <a name="liveevent-types-comparison"></a>Сравнение типов LiveEvent

В следующей статье приведена сравнительная таблица характеристик двух типов LiveEvent: [Сравнение типов LiveEvent](live-event-types-comparison.md).

## <a name="liveoutput"></a>Компонент LiveOutput

Компонент [LiveOutput](https://docs.microsoft.com/rest/api/media/liveoutputs) дает возможность управлять свойствами исходящей прямой трансляции, в частности тем, какая ее часть записывается (объем DVR в облаке) и могут ли зрители начать просмотр трансляции. Отношения между компонентами **LiveEvent** и соответствующими **LiveOutput** похожи на традиционное телевещание, когда канал (**LiveEvent**) передает постоянный поток видео, а запись (**LiveOutput**) ограничивается определенным периодом времени (например, вечерние новости с 18:30 до 19:00). Телевизионные передачи можно записывать с помощью устройства записи цифрового видео (DVR). Аналогичная функция в LiveEvents управляется с помощью свойства ArchiveWindowLength. Это длительность временного диапазона ISO-8601 (например, PTHH:MM:SS), задающая объем DVR. Для нее можно задать значение от 3 минут до 25 часов.

> [!NOTE]
> Компоненты **LiveOutput** запускаются при создании и останавливаются при удалении. При удалении компонента **LiveOutput** базовый компонент **Asset** и его содержимое не удаляются. 
>
> Если вы опубликовали **указатели потоковой передачи** в ресурсе для **LiveOutput**, событие (до окна DVR) будет по-прежнему доступно для просмотра до времени окончания **указателя потоковой передачи** или до тех пор, пока вы не удалите его, в зависимости от того, что произойдет раньше.   

Дополнительные сведения см. в статье [Using a cloud DVR](live-event-cloud-dvr.md) (Использование облачного DVR).

## <a name="streamingendpoint"></a>StreamingEndpoint

Настроив передачу потока данных в **LiveEvent**, можно запустить событие потоковой трансляции, создав компоненты **Asset**, **LiveOutput** и **StreamingLocator**. Так вы сможете запустить архивацию потока и сделать его доступным для зрителей через конечную точку [StreamingEndpoint](https://docs.microsoft.com/rest/api/media/streamingendpoints).

При создании учетной записи служб мультимедиа в нее добавляется конечная точка потоковой передачи по умолчанию в состоянии "Остановлена". Чтобы начать потоковую передачу содержимого и воспользоваться функциями динамической упаковки и динамического шифрования, конечная точка потоковой передачи, из которой необходимо выполнять потоковую передачу содержимого, должна находиться в состоянии "Выполняется".

## <a name="a-idbilling-liveevent-states-and-billing"></a><a id="billing" />Состояния LiveEvent и выставление счетов

Как только компонент LiveEvent переходит в состояние **Выполняется**, начинает начисляться плата за его использование. Чтобы остановить начисление платы за использование компонента LiveEvent, его нужно остановить.

Дополнительные сведения о состояниях и выставлении счетов см. [здесь](live-event-states-billing.md).

## <a name="latency"></a>Latency

Дополнительные сведения о задержке LiveEvents см. [здесь](live-event-latency.md).

## <a name="next-steps"></a>Дополнительная информация

- [Сравнение типов LiveEvent](live-event-types-comparison.md)
- [Состояния и выставление счетов](live-event-states-billing.md)
- [Задержка](live-event-latency.md)
