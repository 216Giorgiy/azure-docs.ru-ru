---
title: Предложения и лексемы в API лингвистического анализа | Документация Майкрософт
description: Сведения о разделении предложений и лексемы в API лингвистического анализа в Cognitive Services.
services: cognitive-services
author: DavidLiCIG
manager: wkwok
ms.service: cognitive-services
ms.component: linguistic-analysis
ms.topic: article
ms.date: 03/21/2016
ms.author: davl
ms.openlocfilehash: 4681098a0e56640e95463272be44f7432be26839
ms.sourcegitcommit: 95d9a6acf29405a533db943b1688612980374272
ms.translationtype: HT
ms.contentlocale: ru-RU
ms.lasthandoff: 06/23/2018
ms.locfileid: "35380185"
---
# <a name="sentence-separation-and-tokenization"></a>Разделение предложений и лексемы

## <a name="background-and-motivation"></a>Предыстория и мотивация

Первый шаг лингвистического анализа текста заключается в том, чтобы разбить его на предложения и лексемы.

### <a name="sentence-separation"></a>Разделение предложения

На первый взгляд кажется, что разбивка текста на предложения проста: просто найдите метки конца предложения и там прервите предложение.
Однако эти метки часто являются сложными и неоднозначными.

Рассмотрим следующий пример текста:

> Что вы сказали?!? Я не слышал о "новом предложении" директора. Это важно для г. Смита и г. Смит.

Этот текст содержит три предложения:

- Что вы сказали?!?
- Я не слышал о "новом предложении" директора.
- Это важно для г. Смита и г. Смит.

Обратите внимание, что концы предложений отмечены совершенно по-разному.
Первое заканчивается комбинацией вопросительных и восклицательного знаков (иногда называемых лигатура из вопросительных и восклицательных знаков).
Второе заканчивается точкой или полной остановкой, но следующая цитата должна быть втянута в предыдущее предложение.
В третьем предложении вы можете увидеть, как точка может использоваться для обозначения сокращений.
Глядя только на пунктуацию, вы получаете хороший набор примеров, но для определения истинных границ предложения требуется дальнейшая работа.

### <a name="tokenization"></a>Выделение лексем

Следующая задача — разбить эти предложения на лексемы.
В большинстве случаев английские лексемы разделяются пробелами.
(Поиск лексем или слов в английском языке гораздо проще, чем в китайском, где практически не используются пробелы между словами.
Первое предложение может быть написано как "Чтовысказали?")

Есть несколько сложных случаев.
Во-первых, пунктуация часто (но не всегда) должна отделяться от окружающего контекста.
Во-вторых, есть английские *сокращения*, такие как "didn't" или "it's", где слова были сжаты и сокращены в мелкие кусочки. Цель выделения лексем состоит в том, чтобы разбить последовательность символов на слова.

Вернемся к примерам предложений выше.
Теперь мы разместили "центральную точку" (&middot;) между каждой отдельной лексемой.

- Что &middot; &middot; вы &middot; сказали &middot; ?!?
- Я &middot; &middot; не &middot; слышал &middot; о &middot; &middot;новом&middot; &middot; предложении &middot; &middot; директора &middot; . &middot; "
- Это &middot; &middot; важно &middot; для &middot; г. &middot; Смита и &middot; г. &middot; Смит &middot; .

Обратите внимание, что большинство лексем — это слова, которые можно найти в словаре (например, *важный*, *директор*).
Другие исключительно состоят из знаков препинания.
Наконец, есть более необычные лексемы, которые представляют собой такие сокращения, как *n't* для *not*, знаки принадлежности, подобные *'s* и т.д. Выделение лексем позволяет нам обрабатывать, например, слово *didn't* и фразу *did not*  более последовательно.

## <a name="specification"></a>Спецификация

Важно принимать последовательные решения о том, что включает в себя предложение и лексема.
Мы полагаемся на спецификацию из [Penn Treebank](https://www.cis.upenn.edu/~treebank/) (некоторые дополнительные сведения доступны здесь: [https://www.cis.upenn.edu/~treebank/tokenization.html]).
