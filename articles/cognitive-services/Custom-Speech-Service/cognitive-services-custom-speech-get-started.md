---
title: Приступая к работе с Пользовательской службой распознавания речи в Azure | Документация Майкрософт
description: Описывается, как подписаться на Пользовательскую службу распознавания речи и связать действия службы с подпиской Azure для обучения модели и ее развертывания.
services: cognitive-services
author: PanosPeriorellis
manager: onano
ms.service: cognitive-services
ms.subservice: custom-speech
ms.topic: article
ms.date: 02/08/2017
ms.author: panosper
ms.openlocfilehash: 7392459f0b80558aac22bd585c0d30bf4105d76f
ms.sourcegitcommit: 95822822bfe8da01ffb061fe229fbcc3ef7c2c19
ms.translationtype: HT
ms.contentlocale: ru-RU
ms.lasthandoff: 01/29/2019
ms.locfileid: "55224451"
---
# <a name="get-started-with-custom-speech-service"></a>Приступая к работе с Пользовательской службой распознавания речи

[!INCLUDE [Deprecation note](../../../includes/cognitive-services-custom-speech-deprecation-note.md)]

Изучите основные возможности Пользовательской службы распознавания речи и узнайте, как создавать, развертывать и использовать акустические и языковые модели для потребностей приложения. Дополнительную документацию и пошаговые инструкции можно будет найти на портале Пользовательской службы распознавания речи после регистрации.

## <a name="samples"></a>Примеры  
Мы предоставляем хороший пример, с которого можно начать работу. Его можно найти [здесь](https://github.com/Microsoft/Cognitive-Custom-Speech-Service).

## <a name="prerequisites"></a>Предварительные требования  

### <a name="subscribe-to-custom-speech-service-and-get-a-subscription-key"></a>Подписка на Пользовательскую службу распознавания речи и получение ключа подписки
Прежде чем экспериментировать с приведенным выше примером, вам необходимо подписаться на Пользовательскую службу распознавания речи и получить ключ подписки. Перейдите к [подпискам](https://portal.azure.com/#create/Microsoft.CognitiveServices/apitype/CustomSpeech) или следуйте инструкциям, приведенным [здесь](CustomSpeech-How-to-Topics/cognitive-services-custom-speech-subscribe.md). В этом руководстве можно использовать как первичный, так и вторичный ключ. Обязательно следуйте рекомендациям по обеспечению секретности и безопасности вашего ключа API.

### <a name="get-the-client-library-and-example"></a>Получение клиентской библиотеки и примера
Вы можете скачать клиентскую библиотеку и пример с помощью [пакета SDK](https://www.microsoft.com/cognitive-services/en-us/SDK-Sample?api=bing%20speech&category=sdk). Содержимое скачанного ZIP-файла нужно извлечь в папку по своему усмотрению. Многие пользователи выбирают папку Visual Studio 2015.

## <a name="creating-a-custom-acoustic-model"></a>Создание пользовательской акустической модели
Чтобы настроить акустическую модель для определенной области, требуется получить коллекцию данных речи. Эта коллекция состоит из набора звуковых файлов с данными речи и текстового файла, который содержит расшифровку каждого звукового файла. Представленные звуковые данные должны соответствовать сценарию, в котором планируется использовать систему распознавания речи.

Например:  Если вы хотите оптимизировать распознавание речи в шумных производственных условиях, звуковые файлы должны содержать речь людей, записанных на фоне соответствующего шума.
Если вы хотите улучшить распознавание речи конкретного человека, например хотите транскрибировать запись цикла передач с одним ведущим, звуковые файлы должны содержать примеры речи только этого человека.

Подробное описание того, как создать пользовательскую акустическую модель, можно найти [здесь](CustomSpeech-How-to-Topics/cognitive-services-custom-speech-create-acoustic-model.md).

## <a name="creating-a-custom-language-model"></a>Создание пользовательской языковой модели
Процедура создания пользовательской языковой модели аналогична созданию акустической модели, только вместо звуковых данных в ней используется текст. Этот текст должен содержать несколько примеров запросов или высказываний, которые должны произносить пользователи или которые они уже произнесли (или ввели) в вашем приложении, что было зарегистрировано в журнале.

Подробное описание того, как создать пользовательскую языковую модель, можно найти [здесь](CustomSpeech-How-to-Topics/cognitive-services-custom-speech-create-language-model.md).

## <a name="creating-a-custom-speech-to-text-endpoint"></a>Создание пользовательской конечной точки преобразования речи в текст
После создания пользовательской акустической модели и (или) языковой модели их можно развернуть в пользовательской конечной точке преобразования речи в текст. Чтобы создать пользовательскую конечную точку, выберите "Deployments" (Развертывания) в меню "CRIS" в верхней части страницы. Отобразится таблица "Deployments" (Развертывания), содержащая текущие пользовательские конечные точки. Если вы еще не создали конечные точки, эта таблица будет пустой. Текущий языковой стандарт отражается в заголовке таблицы. Если вы хотите создать развертывание для другого языка, щелкните "Change Locale" (Изменить языковой стандарт). Дополнительные сведения о поддерживаемых языках можно найти в разделе об изменении языкового стандарта.

Подробно описание того, как создать пользовательскую конечную точку преобразования речи в текст, можно найти [здесь](CustomSpeech-How-to-Topics/cognitive-services-custom-speech-create-endpoint.md).

## <a name="using-a-custom-speech-endpoint"></a>Использование пользовательской конечной точки распознавания речи
Запросы могут отправляться на конечную точку преобразования речи в текст CRIS почти так же, как и на используемую по умолчанию конечную точку распознавания речи Microsoft Cognitive Services. Обратите внимание на то, что эти конечные точки функционально идентичны конечным точкам SAPI. Поэтому функциональные возможности, предоставляемые SAPI посредством клиентской библиотеки или REST API, доступны и для вашей пользовательской конечной точки.

Подробное описание того, как работать с пользовательской конечной точкой преобразования речи в текст, можно найти [здесь](CustomSpeech-How-to-Topics/cognitive-services-custom-speech-use-endpoint.md).


Обратите внимание на то, что конечные точки, созданные с помощью CRIS, могут обрабатывать разное число параллельных запросов в зависимости от категории, выбранной для подписки. В случае отправки большего числа запросов на распознавание будет возвращен код ошибки 429 (слишком много запросов). Дополнительные сведения приведены на [странице цен](https://www.microsoft.com/cognitive-services/en-us/pricing). Кроме того, для категории "Бесплатный" действует месячная квота запросов. В случае использования конечной точке этой категории с превышением месячной квоты служба возвращает код ошибки 403 (запрещено).

Служба предполагает, что звуковые данные передаются в режиме реального времени. Если они отправляются быстрее, то запрос будет считаться выполняющимся, пока не истечет длительность его звука в режиме реального времени.

* [Обзор](cognitive-services-custom-speech-home.md)
* [Часто задаваемые вопросы](cognitive-services-custom-speech-faq.md)
* [Глоссарий](cognitive-services-custom-speech-glossary.md)
