---
title: Использование модели ONNX из пользовательской службы визуального распознавания с Windows ML в Cognitive Services | Документы Майкрософт
description: Сведения о создании приложения Windows UWP, в котором используется модель ONNX, экспортированная из Cognitive Services.
services: cognitive-services
author: larryfr
manager: cgronlun
ms.service: cognitive-services
ms.component: custom-vision
ms.topic: conceptual
ms.date: 06/19/2018
ms.author: larryfr
ms.openlocfilehash: 0b128ba1800e74c20c09a9c5711c8473f1dd00d0
ms.sourcegitcommit: 828d8ef0ec47767d251355c2002ade13d1c162af
ms.translationtype: HT
ms.contentlocale: ru-RU
ms.lasthandoff: 06/25/2018
ms.locfileid: "36939429"
---
# <a name="tutorial-use-an-onnx-model-from-custom-vision-with-windows-ml-preview"></a>Руководство по использованию модели ONNX из пользовательской службы визуального распознавания с Windows ML (предварительная версия)

Сведения об использовании модели ONNX, экспортированной из пользовательской службы визуального распознавания, с Windows ML (предварительная версия).

В этом документе содержатся сведения об использовании файла ONNX, экспортированного из пользовательской службы визуального распознавания с Windows ML. Приводится пример приложения Windows UWP. В пример входит обученная модель, которая может распознавать собак и кошек. Также приводятся действия по использованию в примере собственной модели.

> [!div class="checklist"]
> * Сведения о примере приложения
> * Получение примера кода
> * Выполнение примера
> * Использование своей модели

## <a name="prerequisites"></a>предварительным требованиям

* Устройство Windows 10 с:

    * камерой;

    * Visual Studio 2017 версии 15.7 или более поздней с включенной рабочей нагрузкой __Разработка приложений для универсальной платформы Windows__;

    * включенным режимом разработчика. Дополнительные сведения см. в статье о [включении устройства для разработки](https://docs.microsoft.com/windows/uwp/get-started/enable-your-device-for-development).

* Файл ONNX, экспортированный из пользовательской службы визуального распознавания (необязательно). Дополнительные сведения см. в статье [Экспорт модели для использования на мобильных устройствах](https://docs.microsoft.com/azure/cognitive-services/custom-vision-service/export-your-model).

    > [!NOTE]
    > Чтобы использовать свою модель, выполните действия, описанные в разделе [Использование собственной модели](#use-your-own-model).

## <a name="about-the-example-app"></a>Сведения о примере приложения

Приложение является универсальным приложением Windows UWP. Для предоставления изображений для модели оно использует камеру на устройстве Windows 10. Теги и оценки, возвращаемые моделью, отображаются под предварительным просмотром видео.

* Для извлечения отдельных кадров при поступлении данных через камеру используется [MediaFrameReader](https://docs.microsoft.com/uwp/api/windows.media.capture.frames.mediaframereader). Затем кадры отправляются в модель для оценки.

* Модель возвращает теги, которым она была обучена, и значение с плавающей запятой, показывающее степень уверенности в том, что изображение содержит этот элемент.

### <a name="the-ui"></a>Пользовательский интерфейс

Пользовательский интерфейс для примера приложения создан с помощью элементов управления __CaptureElement__ и __TextBlock__. Элемент управления CaptureElement позволяет просматривать видео с камеры, а элемент управления TextBlock отображает результаты, возвращаемые из модели. 

### <a name="the-model"></a>Модель

Предоставленная с примером модель (`cat-or-dog.onnx`) была создана и обучена с помощью пользовательской службы визуального распознавания для Cognitive Services. Затем обученная модель была экспортирована как модель ONNX. Дополнительные сведения об использовании этой службы см. в документах о [построении классификатора](https://docs.microsoft.com/azure/cognitive-services/custom-vision-service/getting-started-build-a-classifier) и [экспорте модели для использования на мобильных устройствах](https://docs.microsoft.com/azure/cognitive-services/custom-vision-service/export-your-model).

> [!IMPORTANT]
> Предоставленная с примером модель была обучена на основе небольшого набора изображений собак и кошек. Поэтому ее нельзя назвать самой лучшей по распознаванию этих животных.

### <a name="the-model-class-file"></a>Файл класса модели

CS-файл создается при добавлении файла ONNX в приложение Windows UWP. У этого файла то же имя, что и у файла `.onnx` (`cat-or-dog` в этом примере), и он содержит классы, используемые для работы с моделью из C#. Однако сущности в создаваемом классе могут иметь такие имена, как `_x0033_04aa07b_x002D_6c8c_x002D_4641_x002D_93a6_x002D_f3152f8740a1_028da4e3_x002D_9c6e_x002D_480b_x002D_b53c_x002D_c1db13d24d70ModelInput`. Эти записи можно спокойно переименовать (щелкните запись правой кнопкой мыши и выберите команду "Переименовать") на понятные имена.

> [!NOTE]
> В примере кода выполнен рефакторинг созданных имен класса и метода на следующие:
>
> * `ModelInput`
> * `ModelOutput`
> * `Model`
> * `CreateModel`

### <a name="camera-access"></a>Доступ к камере

Вкладка __Возможности__ в файле `Package.appxmanifest` настроена для предоставления доступа к веб-камере и микрофону.

> [!NOTE]
> Несмотря на то, что в этом примере не используется звук, для получения доступа к камере на устройстве требовалось включить микрофон.

Приложение пытается получить доступ к камере (если она имеется) на задней панели устройства. Чтобы начать запись видео с камеры, используется класс [MediaCapture](https://docs.microsoft.com/uwp/api/Windows.Media.Capture.MediaCapture). Для записи видеокадров и их отправки в модель применяется [MediaFrameReader](https://docs.microsoft.com/uwp/api/Windows.Media.Capture.Frames.MediaFrameReader).

## <a name="get-the-example-code"></a>Получение примера кода

Пример приложения доступен по адресу: [https://github.com/Azure-Samples/Custom-Vision-ONNX-UWP](https://github.com/Azure-Samples/Custom-Vision-ONNX-UWP).

## <a name="run-the-example"></a>Выполнение примера

1. Чтобы запустить приложение из Visual Studio, нажмите клавишу `F5`. Вам может быть предложено включить режим разработчика. Дополнительные сведения см. в статье о [включении устройства для разработки](https://docs.microsoft.com/windows/uwp/get-started/enable-your-device-for-development).

2. При появлении запроса разрешите приложению доступ к камере и микрофону на вашем устройстве.

3. Наведите камеру на собаку или кошку. В приложении под предварительным просмотром отображается оценка, определяющая, содержит ли изображение собаку или кошку.

    > [!TIP]
    > Если у вас нет собаки или кошки, воспользуйтесь фотографией одного из этих животных.

## <a name="use-your-own-model"></a>Использование своей модели

Чтобы использовать собственную модель, выполните следующие действия.

> [!IMPORTANT]
> В этом разделе происходит переименование текущей модели (cat-or-dog.cs) и рефакторинг имен класса и метода новой модели. Это позволяет исключить конфликты имен с моделью в примере.

1. Обучите модель с помощью пользовательской службы визуального распознавания. Сведения об обучении модели см. в статье о [построении классификатора](https://docs.microsoft.com/azure/cognitive-services/custom-vision-service/getting-started-build-a-classifier).

2. Экспортируйте обученную модель как модель ONNX. Сведения об экспорте модели см. документе об [экспорте модели для использования на мобильных устройствах](https://docs.microsoft.com/azure/cognitive-services/custom-vision-service/export-your-model).

3. В обозревателе решений правой кнопкой мыши щелкните файл __cat-or-dog.cs__ и переименуйте его в __cat-or-dog.txt__. Переименование позволяет исключить конфликты имен с новой моделью.

    > [!TIP]
    > Можно также выбрать другие имена для имен классов в новой модели, но проще всего повторно использовать существующие имена.

4. В обозревателе решений правой кнопкой мыши щелкните запись __VisionApp__, а затем выберите __Добавить__ > __Существующий элемент...__.

5. Чтобы создать класс для модели, выберите файл ONNX для импорта, а затем нажмите кнопку __Добавить__. В обозреватель решений будет добавлен новый класс с тем же именем, что и у файла ONNX (но с расширением `.cs`).

6. Откройте созданный CS-файл и найдите имена указанных далее элементов.

    > [!IMPORTANT]
    > В качестве руководства по распознаванию классов и функций используйте файл `cat-or-dog.txt` примера.

    * Класс, который определяет входные данные модели. Созданное имя может быть аналогично `_x0033_04aa07b_x002D_6c8c_x002D_4641_x002D_93a6_x002D_f3152f8740a1_028da4e3_x002D_9c6e_x002D_480b_x002D_b53c_x002D_c1db13d24d70ModelInput`. Переименуйте этот класс в __ModelInput__.
    * Класс, который определяет выходные данные модели. Созданное имя может быть аналогично `_x0033_04aa07b_x002D_6c8c_x002D_4641_x002D_93a6_x002D_f3152f8740a1_028da4e3_x002D_9c6e_x002D_480b_x002D_b53c_x002D_c1db13d24d70ModelOutput`. Переименуйте этот класс в __ModelOutput__.
    * Класс, который определяет модель. Созданное имя может быть аналогично `_x0033_04aa07b_x002D_6c8c_x002D_4641_x002D_93a6_x002D_f3152f8740a1_028da4e3_x002D_9c6e_x002D_480b_x002D_b53c_x002D_c1db13d24d70Model`. Переименуйте этот класс в __Model__.
    * Метод, который создает модель. Созданное имя может быть аналогично `Create_x0033_04aa07b_x002D_6c8c_x002D_4641_x002D_93a6_x002D_f3152f8740a1_028da4e3_x002D_9c6e_x002D_480b_x002D_b53c_x002D_c1db13d24d70Model`. Переименуйте этот метод в __CreateModel__.

7. В обозревателе решений переместите файл `.onnx` в папку __Ресурсы__. 

8. Чтобы включить файл ONNX в пакет приложения, выберите файл `.onnx` и в окне свойств задайте для параметра __Действие при сборке__ значение __Содержимое__.

9. Откройте файл __MainPage.xaml.cs__. Найдите следующую строку и измените имя файла на имя нового файла `.onnx`.

    ```csharp
    var file = await StorageFile.GetFileFromApplicationUriAsync(new Uri($"ms-appx:///Assets/cat-or-dog.onnx"));
    ```

    Это изменение загружает новую модель во время выполнения.

10. Выполните сборку и запустите приложение. Теперь оно использует новую модель для оценки изображений.

## <a name="next-steps"></a>Дополнительная информация

Сведения о других способах экспорта и использования модели пользовательской службы визуального распознавания см. в следующих документах:

* [Экспорт модели](https://docs.microsoft.com/azure/cognitive-services/custom-vision-service/export-your-model)
* [Использование экспортированной модели Tensorflow в приложении Android](https://github.com/Azure-Samples/cognitive-services-android-customvision-sample)
* [Использование экспортированной модели CoreML в приложении Swift iOS](https://go.microsoft.com/fwlink/?linkid=857726)
* [Использование экспортированной модели CoreML в приложении iOS с помощью Xamarin](https://github.com/xamarin/ios-samples/tree/master/ios11/CoreMLAzureModel)

Дополнительные сведения об использовании моделей ONNX с Windows ML см. в статье [Интеграция модели в приложение с использованием Windows ML](https://docs.microsoft.com/windows/uwp/machine-learning/integrate-model).
