<properties 
	pageTitle="Введение в фабрику данных Azure" 
	description="Узнайте, как использовать службу фабрики данных Azure для формирования обработки данных, хранилища данных и служб перемещения данных, чтобы создавать конвейеры, производящие надежные данные." 
	services="data-factory" 
	documentationCenter="" 
	authors="spelluru" 
	manager="jhubbard" 
	editor="monicar"/>

<tags 
	ms.service="data-factory" 
	ms.workload="data-services" 
	ms.tgt_pltfrm="na" 
	ms.devlang="na" 
	ms.topic="article" 
	ms.date="03/09/2015" 
	ms.author="spelluru"/>

# Введение в службу фабрики данных Azure
<!--
The **Azure Data Factory** service is a fully managed service for composing data storage, processing, and movement services into streamlined, scalable, and reliable data production pipelines.  Developers can use Data Factory to transform semi-structured, unstructured and structured data from on-premises and cloud sources into trusted information. Developers build data-driven workflows (pipelines) that join, aggregate and transform data sourced from their on-premises, cloud-based and internet services, and set up complex data processing through simple JSON scripting. The Azure Data Factory service provides monitoring and management of these pipelines at a glance with a rich visual experience offered through the Azure Preview Portal. The information produced by pipelines can be easily consumed using BI and analytics tools, and other applications to reliably drive key business insights and decisions.
-->

**Фабрика данных Azure** является полностью управляемой системой для создания служб хранения, обработки и перемещения данных и превращения этих служб в упрощенные, масштабируемые и надежные конвейеры производства данных. Служба фабрики данных дает вам следующие возможности. 

- Создание управляемых данными рабочих процессов (конвейеров), которые комбинируют, статистически обрабатывают и преобразуют данные, полученные из локальных, облачных и интернет-хранилищ. 
- Преобразование частично структурированных, неструктурированных и структурированных данных из самых разнообразных источников в достоверные сведения.
- Создание данных в удобной для дальнейшего использования форме с помощью бизнес-аналитики, средств анализа и других приложений. 
- Настройка процесса обработки сложных данных с помощью простых скриптов JSON.
- Мониторинг и управление конвейерами благодаря широким визуальным возможностям, предоставляемым на портале предварительной версии Azure.  


<!--
This article provides an overview of the Azure Data Factory service, the value it provides, and the scenarios it supports.
--> 

## Обзор
Обычно проекты интеграции данных развивались вокруг создания процессов извлечения, преобразования и загрузки (Extract-Transform-Load - ETL). То есть данные извлекаются из различных источников данных внутри организации, преобразовываются для соответствия целевой схеме корпоративного хранилища данных (Enterprise Data Warehouse - EDW) и загружаются в EDW. Впоследствии EDW используется в качестве единого источника истины для решений бизнес-аналитики. 

![Traditional ETL][image-data-factory-introduction-traditional-ETL]

Современный ландшафт корпоративных данных продолжает расти экспоненциально в объеме, разнообразии и сложности. Он более разнообразный, чем когда-либо, так как присутствуют локальные и облачные данные различных форм и скоростей.  Обработка данных должна выполняться между разными географическими расположениями и включает в себя сочетание программного обеспечения с открытым исходным кодом, коммерческих решений и пользовательских служб обработки; это ресурсоемкие процессы, которые сложно интегрировать и обслуживать.  Гибкость, необходимая для адаптации к современному меняющемуся ландшафту данных большого размера, - это возможность слияния традиционных хранилищ EDW с потребностями современных систем производства информации.  

![Todays Diverse Processing Landscape][image-data-factory-introduction-todays-diverse-processing-landspace]

**Служба фабрики данных Azure** - это сложная платформа для организации работы с традиционными EDW и в условиях меняющейся среды данных. Она предоставляет предприятиям возможность использовать все доступные им данные для принятия решений на основе этих данных. Служба фабрики данных Azure позволяет предприятиям использовать все это разнообразие, предоставляя платформу для организации процессов обработки, хранения и перемещения данных и объединения их в конвейеры производства информации, а также для управления массивами достоверных данных.

Вот какие возможности дает вам служба фабрики данных Azure:

- **Комфортная работа с различными системами хранения и обработки данных.** 
Служба фабрики данных позволяет создавать конвейеры производства информации, которые перемещают и обрабатывают как локальные (например, SQL Server), так и облачные источники данных, такие как база данных SQL Azure, таблица Azure и BLOB-объекты. 
- **Преобразование данных в достоверную информацию.** 
Служба фабрики данных поддерживает обработку Hive, Pig и C#, а также ключевые функции обработки, такие как автоматическое управление кластером Hadoop (HDInsight), повторные попытки при временных ошибках, настраиваемые политики времени ожидания и предупреждения.  
- **Мониторинг конвейеров данных в одном окне.** 
Служба фабрики данных предоставляет полное и достоверное представление о службах хранения, обработки и перемещения данных.  Она помогает быстро оценить работоспособность конвейера данных от начала до конца, выявить проблемы и при необходимости предпринять корректирующие действия. Вы также можете в визуальном режиме отслеживать происхождение данных и взаимосвязи между разными данными во всех ваших источниках, а также просматривать журналы по выполнению заданий, работоспособности системы и зависимостям, не покидая одной панели мониторинга.
- **Получите исчерпывающие сведения из преобразованных данных.**
Служба фабрики данных позволяет создавать конвейеры данных, производящие достоверные данные, которые могут использоваться бизнес-аналитикой, средствами анализа и другими приложениями.

<!--
Today, to take advantage of the benefits of Data Factory, developers interact directly with individual data pipelines, storage services, and compute services.  As the Data Factory service evolves over time, we will introduce additional storage and processing services, and new mechanisms of grouping compute and storage services and data pipelines together into 'Hubs'.  We describe Hubs here in our introduction, as this nascent concept appears throughout the service as a precursor for future releases.

An Azure Data Factory Hub is a container for storage and compute services (both referred to as Linked services), as well as for the data pipelines that use and run on those resources. The Hub container allows the Data Factory to be divided into logical or domain specific groupings.  For example, an enterprise may have a "West US Azure Hub" which manages all of the Linked services and pipelines focused in the West US data center, or a "Sales EDW Hub" which manages all the Linked services and pipelines associated with populating and processing data for the Sales EDW.  An important characteristic of Hubs is that a pipeline runs on a single hub. This means that when defining a pipeline, all of the Linked services referenced by tables or activities within that pipeline must have the same Hub name as the pipeline itself.

Hubs will help to encapsulate storage and compute in a way where pipelines can reference only a Hub rather than the specific services and tables it uses. The Hub can then use policies to decide where to run a pipeline. This will have several important impacts. One is that it will provide easier scale-up as more Linked services can be added to a Hub, and pipelines can be load-balanced across these new Linked services. Another is that it will reuse of pipeline definitions on different Hubs.

-->

## Модель приложения
На следующей схеме показана модель приложения, поддерживаемая службой фабрики данных Azure.

![Application Model][image-data-factory-application-model]

Существуют три этапа производства информации в фабрике данных Azure.

- **Подключение и сбор**. На этом этапе данные из различных источников импортируются в центры данных. Конвейер в фабрике данных может иметь одну или несколько задач. Используйте одну или несколько задач **копирования** в конвейере данных, чтобы осуществить сбор данных из исходных хранилищ данных и с помощью центра данных перенести их в конечное хранилище для дальнейшей обработки. Кластер HDInsight (вычисление) и связанное с ним хранилище BLOB-объектов (хранение) вместе образуют центр данных HDInsight. Для использования центра данных HDInsight скопируйте все исходные данные в связанное с HDInsight хранилище BLOB-объектов Azure, чтобы эти данные могли обрабатываться кластером HDInsight. Конвейер потребляет вычислительные ресурсы центра данных, такого как кластер HDInsight.      
- **Преобразование и обогащение**. На этом этапе выполняется обработка собранных данных. Например, **действие HDInsight** в конвейере может обрабатывать данные, расположенные в связанном хранилище BLOB-объектов Azure, с помощью преобразований, используя скрипты Hive и Pig для получения достоверных сведений. Конвейеры можно объединить в цепочку (как показано на схеме) таким образом, что наборы данных, выходящие из одного конвейера, становятся входящими для другого конвейера, расположенного как в том же, так и в другом центре данных.  
- **Публикация**. На этом этапе данные публикуются, чтобы их можно было использовать в инструментах бизнес-аналитики и других приложениях. Например, действие копирования в конвейере может копировать выходные данные, полученные в ходе обработки на этапе преобразования и обогащения, в хранилище данных (например, локальную систему SQL Server), на основе которого уже можно создавать решения бизнес-аналитики.   

<!--

Фабрики данных дают разработчикам возможность создавать конвейеры, представляющие собой группы действий перемещения и/или обработки данных, которые принимают один или несколько входных наборов данных и производят один или несколько выходных наборов данных. Конвейеры могут запускаться один раз или по гибкому диапазону расписаний (ежечасно, ежедневно, еженедельно и др.). Набор данных - это именованное представление данных. Диапазон описываемых данных может варьироваться от простых байтов, частично структурированных данных, таких как CSV-файлы, вплоть до таблиц или моделей.

Конвейеры, состоящие из действий перемещения данных (например, действий копирования), часто применяются для импорта или экспорта данных из всех источников данных (базы данных, файлы, службы SaaS и др.), используемых организацией в центре данных.
 
Когда данные находятся в **центре**, **конвейеры**, размещенные в вычислительных службах центра, используются для преобразования данных в подходящую для использования форму (в инструментах бизнес-аналитики, приложениях, заказчиками и т.д.).  
  
Наконец, **конвейеры** могут соединяться в цепочку (как показано на схеме) так, чтобы выходные **наборы данных** одного конвейера были входными наборами другого.  Это позволяет разложить сложные потоки данных на **конвейеры**, которые выполняются внутри центра данных или охватывают несколько центров.  Такое использование **конвейеров** предоставляет организациям строительные блоки для создания лучших в своем роде локальных и облачных служб, а также служб SaaS (Software-as-a-Service - программное обеспечение как услуга) - и все это через объектив единой и легко управляемой фабрики данных.
--> 

## Простор для творчества

Вы можете проектировать и создавать фабрики данных с помощью одного из следующих средств.

- **Портал предварительной версии Azure**. Выноски фабрики данных на портале предварительной версии Azure предоставляют обширные возможности для создания связанных служб и фабрик данных. **Редактор фабрик данных**, который также является частью портала, позволяет легко создавать связанные службы, таблицы, наборы данных и конвейеры, просто указывая определения JSON для таких артефактов. В разделе [Редактор фабрик данных][data-factory-editor] приведены общие сведения о редакторе, а в разделе [Приступая к работе с фабрикой данных][datafactory-getstarted] описан пример использования портала и редактора для создания и развертывания фабрики данных.   
- **Azure PowerShell**. Если вы знакомы с системой PowerShell и предпочитаете использовать ее вместо пользовательского интерфейса портала, можете воспользоваться командлетами фабрики данных Azure, которые входят в состав Azure PowerShell, для создания и развертывания фабрик данных. В разделе [Создание и мониторинг фабрики данных Azure с помощью Azure PowerShell][create-data-factory-using-powershell] можно найти простой пример, а в разделе [Учебник. Перемещение и обработка файлов журнала с помощью фабрики данных][adf-tutorial] - усложненный пример использования командлетов PowerShell для создания и развертывания фабрики данных. Полная документация по командлетам фабрики данных содержится в [справочнике по командлетам фабрики данных][adf-powershell-reference], который можно найти в библиотеке MSDN.  
- **Библиотека классов .NET**. Фабрики данных можно создавать программными средствами с помощью пакета .NET SDK для фабрик данных. В разделе [Создание, мониторинг фабрик данных и управление ими с помощью пакета SDK для .NET][create-factory-using-dotnet-sdk] приведено пошаговое руководство по созданию фабрики данных с помощью пакета SDK для .NET. Полная документация по пакету .NET SDK для фабрик данных приведена в [справочнике по библиотеке классов фабрики данных][msdn-class-library-reference].  
- **REST API**. API REST, предоставляемый службой фабрики данных Azure, можно использовать для создания и развертывания фабрик данных. Полная документация по REST API для фабрик данных приведена в [справочнике по REST API фабрики данных][msdn-rest-api-reference]. 


## Терминология
В этом разделе вы познакомитесь с терминологией, связанной с фабрикой данных Azure.

### Фабрика данных
**Фабрика данных Azure** имеет один или несколько конвейеров, которые обрабатывают данные в связанных хранилищах (служба хранилища Azure, база данных SQL Azure, локальная система SQL Server и т. д.), используя связанные вычислительные службы, такие как Azure HDInsight. Фабрика данных Azure не содержит внутри себя данные, вместо этого данные размещаются в указанных выше хранилищах.  

### Связанные службы
**Связанная служба** - это служба, которая связана с фабрикой данных Azure. Вот какие службы могут быть связанными:

- **Хранилище данных**, такое как служба хранилища Azure, база данных SQL Azure или локальная система SQL Server. Хранилище данных - это контейнер для входных и выходных наборов данных.    
- **Вычислительная служба**, такая как Azure HDInsight и машинное обучение Microsoft Azure. Вычислительная служба обрабатывает входные данные и формирует выходные.  

### Набор данных
**Набор данных** - это именованное представление данных. Диапазон описываемых данных может быть от простых байт, частично структурированных данных, таких как CSV-файлы, и вплоть до реляционных таблиц, или даже моделей. **Таблица** фабрики данных является набором данных с определенной схемой и прямоугольной формой. После создания связанной службы в хранилище данных, которое ссылается на хранилище данных, можно определить наборы данных, представляющие входные и выходные данные, которые помещаются в хранилище данных. 


### Конвейер
**Конвейер** в фабрике данных Azure обрабатывает данные в связанной службе хранилища с помощью связанных вычислительных служб. Он содержит последовательность действий, где каждое действие выполняет определенную операцию обработки. Например, **действие копирования** копирует данные из исходного хранилища в целевое хранилище, а **действие HDInsight** использует кластер Azure HDInsight для обработки данных с помощью запросов Hive или скриптов Pig. Фабрика данных может иметь один или несколько конвейеров. 

Вот какие типичные шаги необходимо выполнить для создания экземпляра фабрики данных Azure:

1. Создать **фабрику данных**.
2. Создать **связанную службу** для каждого хранилища данных или каждой вычислительной службы.
3. Создать входные и выходные **наборы данных**.
4. Создать **конвейер**. 

### Действие
Шаг обработки данных в конвейере, который принимает один или несколько входных наборов данных и создает один или несколько выходных наборов данных.  Действия выполняются в среде выполнения (например, в кластере Azure HDInsight) и считывают или записывают данные в хранилище данных, связанное с фабрикой данных Azure. 

Служба фабрики данных Azure поддерживает следующие действия в конвейере. 

- **Действие копирования** копирует данные из хранилища данных в другое хранилище данных. Подробные сведения о том, какие хранилища данных поддерживает действие копирования, см. в разделе [Копирование данных с помощью фабрики данных Azure][copy-data-with-adf]. 
- **Действие HDInsight** обрабатывает данные, запуская сценарии Hive и Pig или программы MapReduce в кластере HDInsight. Дополнительные сведения см. в разделах [Использование Pig и Hive в фабрике данных][use-pig-hive] и [Вызов программ MapReduce из фабрики данных][run-map-reduce]. 
- **Действие оценки пакетов на базе машинного обучения Azure** вызывает API оценки пакетов на базе машинного обучения Azure. Подробные сведения см. в разделе [Создание прогнозирующих конвейеров с помощью фабрик данных Azure и машинного обучения Azure][azure-ml-adf]. 
- **Действие хранимой процедуры** вызывает хранимую процедуру в базе данных SQL Azure. Подробные сведения см. в статье [Действие хранимой процедуры][msdn-stored-procedure-activity] библиотеки MSDN.   

### Срез
Таблица в фабрике данных Azure состоит из срезов. Ширина среза определяется расписанием - ежечасно или ежедневно. Если в расписании указано "ежечасно", то срез производится каждый час с момента начала и до момента окончания конвейера. Например, если дата и время начала конвейера имеет значение 03.03.2015 06:00:00 (6 часов утра), а дата и время окончания - 03.03.2015 09:00:00 (9 часов утра того же дня), создается три среза данных - по одному за каждый интервал длиной в 1 час: 6:00-7:00, 7:00-8:00 и 8:00-9:00.    

Срезы позволяют работать с подмножеством данных для определенного временного окна (например: срез, который создается за время (час) с 13:00 до 14:00). 

### Действие для среза
**Запуск** - это единица обработки среза. Может быть один или несколько запусков для среза, если выполняются повторные попытки или вы повторно производите срез в случае сбоя. Срез идентифицируется по времени начала.

### Шлюз управления данными
**Шлюз управления данными Microsoft Data Management Gateway** - это программное обеспечение, которое подключает локальные источники данных к облачным службам для дальнейшего использования. Вам необходимо установить по крайней мере один шлюз в своей корпоративной среде и зарегистрировать его на портале фабрики данных Azure, прежде чем добавлять локальные источники данных как связанные службы.
 
### Центр данных
**Центр данных** - это контейнер для хранения данных и вычислительных служб. Например, кластер Hadoop с HDFS в качестве хранилища и Hive/Pig в качестве вычислений (обработки) - это центр данных. Подобным образом корпоративное хранилище данных (EDW) можно смоделировать как центр данных (база данных - как хранилище, а хранимые процедуры и/или инструмент ETL (извлечение, преобразование и загрузка) - как вычислительные службы).  Конвейеры используют хранилища данных и запускаются на ресурсах вычислений в центре данных. В данный момент поддерживается только центр HDInsight.

Центр данных позволяет разделить фабрику данных на логические или доменные группы. Например, группа "West US Azure Hub" управляет всеми связанными службами (хранилища данных и вычислительными) и конвейерами, сконцентрированными в западной части США; а группа "Sales EDW Hub" управляет всеми связанными службами и конвейерами, задействованными в заполнении и обработке данных для корпоративного хранилища данных продаж.

Важной характеристикой центра является то, что один конвейер запускается в одном центре. Это означает, что при определении конвейера все связанные службы, на которые ссылаются таблицы или действия внутри данного конвейера, должны иметь такое же имя центра, как и сам конвейер. Если свойство HubName для связанной службы не указано, то такая связанная служба помещается в центр "Default".

## Дальнейшие действия

1. [Приступая к работе с фабрикой данных][datafactory-getstarted]. Эта статья содержит пошаговый учебник с примером создания фабрики данных Azure, которая копирует данные из большого двоичного объекта Azure в базу данных SQL Azure.
2. [Учебник. Перемещение и обработка файлов журнала с помощью фабрики данных][adf-tutorial]. В этой статье на **пошаговом примере** показано, как при помощи фабрики данных Azure реализовать **реалистичный сценарий** преобразования данных файлов журнала в подробные сведения.
3. [Фабрика данных - часто задаваемые вопросы][adf-faq]. В данной статье приведен список часто задаваемых вопросов и ответов на них. 
3. [Распространенные сценарии использования фабрики данных Azure][adf-common-scenarios]. В этой статье описано несколько популярных сценариев использования службы фабрики данных Azure.


[Power-Query-Azure-Table]: http://office.microsoft.com/en-001/excel-help/connect-to-microsoft-azuretable-storage-HA104122607.aspx
[Power-Query-Azure-Blob]: http://office.microsoft.com/en-001/excel-help/connect-to-microsoft-azure-blob-storage-HA104113447.aspx
[Power-Query-Azure-SQL]: http://office.microsoft.com/en-001/excel-help/connect-to-a-microsoft-azure-sql-database-HA104019809.aspx
[Power-Query-OnPrem-SQL]: http://office.microsoft.com/en-001/excel-help/connect-to-a-sql-server-database-HA104019808.aspx

[adf-faq]: data-factory-faq.md

[copy-data-with-adf]: data-factory-copy-activity.md
[use-pig-hive]: data-factory-pig-hive-activities.md
[run-map-reduce]: data-factory-map-reduce.md
[azure-ml-adf]: data-factory-create-predictive-pipelines.md
[adf-common-scenarios]: data-factory-common-scenarios.md
[create-factory-using-dotnet-sdk]: data-factory-create-data-factories-programmatically.md
[data-factory-editor]: data-factory-editor.md
[create-data-factory-using-powershell]: data-factory-monitor-manage-using-powershell.md

[adf-powershell-reference]: https://msdn.microsoft.com/library/dn820234.aspx 


[msdn-stored-procedure-activity]: https://msdn.microsoft.com/library/dn912649.aspx
[msdn-class-library-reference]: https://msdn.microsoft.com/library/dn883654.aspx
[msdn-rest-api-reference]: https://msdn.microsoft.com/library/dn906738.aspx

[adf-tutorial]: data-factory-tutorial.md
[datafactory-getstarted]: data-factory-get-started.md

[image-data-factory-introduction-traditional-ETL]: ./media/data-factory-introduction/TraditionalETL.PNG

[image-data-factory-introduction-todays-diverse-processing-landspace]:./media/data-factory-introduction/TodaysDiverseDataProcessingLandscape.PNG

[image-data-factory-application-model]:./media/data-factory-introduction/DataFactoryApplicationModel.png

[image-data-factory-data-flow]:./media/data-factory-introduction/DataFactoryDataFlow.png




<!--HONumber=49-->