---
title: 'Выходные данные Stream Analytics: возможности хранения и анализа | Microsoft Docs'
description: Узнайте о вариантах вывода данных Stream Analytics, включая данные Power BI, для получения результатов анализа.
keywords: преобразование данных, результаты анализа, параметры хранилища данных
services: stream-analytics,documentdb,sql-database,event-hubs,service-bus,storage
documentationcenter: ''
author: jeffstokes72
manager: jhubbard
editor: cgronlun

ms.service: stream-analytics
ms.devlang: na
ms.topic: article
ms.tgt_pltfrm: na
ms.workload: data-services
ms.date: 09/26/2016
ms.author: jeffstok

---
# Выходные данные Stream Analytics: возможности хранения и анализа
Создавая задание Stream Analytics, необходимо учитывать, каким образом будут использоваться полученные данные. Каким образом вы будете просматривать результаты задания Stream Analytics и где будете их хранить?

Для работы с различными шаблонами приложений служба Azure Stream Analytics предлагает различные параметры хранения выходных данных и просмотра результатов анализа. Это позволяет легко просматривать выходные данные задания, гибко их применять, отправлять в хранилище и использовать в других целях. Любой выход, настраиваемый в задании, должен существовать до момента запуска задания и начала потока событий. Например, при выводе данных в хранилище BLOB-объектов задание не создаст учетную запись хранения автоматически. Ее необходимо создать перед тем, как запускать задание ASA.

## Хранилище озера данных Azure
Stream Analytics поддерживает [хранилище озера данных Azure](https://azure.microsoft.com/services/data-lake-store/). Это хранилище позволяет сохранять данные с любым размером, типом и скоростью приема в одном месте для эксплуатационной и исследовательской аналитики. В настоящий момент создание и настройка выходных данных хранилища озера данных поддерживается только на классическом портале Azure. Кроме того, Stream Analytics необходимо разрешение на доступ к хранилищу данных озера. Сведения об авторизации и о том, как зарегистрироваться для получения предварительной версии хранилища данных озера (при необходимости), приведены в [статье о выходных данных озера](stream-analytics-data-lake-output.md).

### Авторизация Azure Data Lake Store
Если для хранения выходных данных на портале управления Azure выбрано хранилище Data Lake, вам будет предложено авторизовать подключение к существующей службе Data Lake Store.

![Авторизация хранилища озера данных](./media/stream-analytics-define-outputs/06-stream-analytics-define-outputs.png)

Затем заполните свойства выходных данных Data Lake Store, как показано ниже.

![Авторизация хранилища озера данных](./media/stream-analytics-define-outputs/07-stream-analytics-define-outputs.png)

В таблице ниже приведены имена и описание свойств, необходимых для создания выходных данных хранилища озера данных.

<table>
<tbody>
<tr>
<td><B>ИМЯ СВОЙСТВА</B></td>
<td><B>ОПИСАНИЕ</B></td>
</tr>
<tr>
<td>Псевдоним выходных данных</td>
<td>Это понятное имя, которое используется в запросах для направления выходных данных запроса в соответствующее хранилище озера данных.</td>
</tr>
<tr>
<td>Имя учетной записи</td>
<td>Имя учетной записи хранения Data Lake, в которую отправляются выходные данные. Появится раскрывающийся список учетных записей хранилища озера данных, к которым имеет доступ вошедший на портал пользователь.</td>
</tr>
<tr>
<td>Шаблон префикса пути (<I>необязательное свойство</I>)</td>
<td>Путь к файлу, используемый для записи файлов в указанной учетной записи хранилища озера данных. <BR>{date}, {time}<BR>Пример 1. folder1/logs/{дата}/{время}<BR>Пример 2. folder1/logs/{дата}</td>
</tr>
<tr>
<td>Формат даты (<I>необязательное свойство</I>)</td>
<td>Если в префиксе пути используется маркер даты, вы можете выбрать формат даты для упорядочивания своих файлов. Пример: ГГГГ/ММ/ДД</td>
</tr>
<tr>
<td>Формат времени (<I>необязательное свойство</I>)</td>
<td>Если в префиксе пути используется маркер времени, укажите формат времени для упорядочивания своих файлов. В настоящее время поддерживается только один формат&#160;— ЧЧ.</td>
</tr>
<tr>
<td>Формат сериализации событий</td>
<td>Формат сериализации для выходных данных. Поддерживаются форматы JSON, CSV и Avro.</td>
</tr>
<tr>
<td>Кодирование</td>
<td>Если используется формат CSV или JSON, необходимо указать формат кодирования. В настоящее время единственным поддерживаемым форматом кодирования является UTF-8.</td>
</tr>
<tr>
<td>Разделитель</td>
<td>Применяется только для сериализации CSV-файлов. Служба Stream Analytics позволяет использовать ряд распространенных разделителей для сериализации данных в формате CSV. Поддерживаются такие разделители: запятая, точка с запятой, пробел, табуляция и вертикальная черта.</td>
</tr>
<tr>
<td>Формат</td>
<td>Применяется только для сериализации JSON. Вариант «строки-разделители» предусматривает форматирование выходных данных таким образом, что каждый объект JSON будет отделен новой строкой. Вариант «массив» означает, что выходные данные будут отформатированы как массив объектов JSON.</td>
</tr>
</tbody>
</table>

### Обновление авторизации хранилища озера данных
Необходимо будет повторно аутентифицировать учетную запись Data Lake Store, если с момента создания задания или последней аутентификации пароль был изменен.

![Авторизация хранилища озера данных](./media/stream-analytics-define-outputs/08-stream-analytics-define-outputs.png)

## База данных SQL
[База данных SQL Azure](https://azure.microsoft.com/services/sql-database/) может служить местом назначения для выходных реляционных данных, а также для выходных данных приложений, которые зависят от содержимого, размещенного в реляционной базе данных. Задания Stream Analytics будут записывать данные в существующую таблицу в Базе данных SQL Azure. Обратите внимание, что схема таблицы должна в точности соответствовать полям и их типам в выходных данных задания. [Хранилище данных SQL Azure](https://azure.microsoft.com/documentation/services/sql-data-warehouse/) также можно задать для выходных данных с помощью параметра вывода базы данных SQL (это функция из предварительной версии). В таблице ниже приведены имена и описание свойств для создания выходных данных Базы данных SQL.

| Имя свойства | Описание |
| --- | --- |
| Псевдоним выходных данных |Это понятное имя, которое используется в запросах для направления выходных данных запроса в соответствующую базу данных. |
| База данных |Имя базы данных, в которую отправляются выходные данные. |
| Имя сервера |Имя сервера базы данных SQL. |
| Имя пользователя |Имя пользователя, который имеет право на запись в базу данных. |
| Пароль |Пароль для подключения к базе данных. |
| Таблица |Имя таблицы, в которую будут записываться выходные данные. В имени таблицы учитывается регистр символов, а схема этой таблицы должна точно соответствовать количеству и типам полей в выходных данных задания. |

> [!NOTE]
> В настоящее время для выходных данных задания в Stream Analytics поддерживается предложение базы данных SQL Azure. Однако менее виртуальная машина Azure с SQL Server, к которой подключена база данных, не поддерживается. Это может быть изменено в будущих выпусках.
> 
> 

## Хранилище BLOB-объектов
Хранилище BLOB-объектов предоставляет экономичное и масштабируемое решение для хранения в облаке больших объемов неструктурированных данных. Общие сведения о хранилище больших двоичных объектов Azure и его использовании см. в документации по [работе с большими двоичными объектами](../storage/storage-dotnet-how-to-use-blobs.md).

В таблице ниже приведены имена и описание свойств для создания выходных данных в хранилище BLOB-объектов.

<table>
<tbody>
<tr>
<td>ИМЯ СВОЙСТВА</td>
<td>ОПИСАНИЕ</td>
</tr>
<tr>
<td>Псевдоним выходных данных</td>
<td>Это понятное имя, которое используется в запросах для направления выходных данных запроса в хранилище BLOB-объектов.</td>
</tr>
<tr>
<td>Учетная запись хранения</td>
<td>Имя учетной записи хранения, в которую отправляются выходные данные.</td>
</tr>
<tr>
<td>Ключ учетной записи хранения</td>
<td>Секретный ключ, связанный с учетной записью хранения.</td>
</tr>
<tr>
<td>Контейнер хранилища</td>
<td>Контейнеры обеспечивают логическую группировку BLOB-объектов, хранящихся в службе BLOB-объектов Microsoft Azure. При передаче BLOB-объекта в службу BLOB-объектов для него необходимо указать контейнер.</td>
</tr>
<tr>
<td>Шаблон префикса пути (необязательное свойство)</td>
<td>Путь к файлу, используемый для записи BLOB-объектов в указанном контейнере.<BR>Чтобы указать периодичность записи BLOB-объектов, в пути можно использовать один или несколько экземпляров следующих двух переменных:<BR>{date}, {time}<BR>Пример&#160;1: cluster1/logs/{date}/{time}<BR>Пример&#160;2: cluster1/logs/{date}</td>
</tr>
<tr>
<td>Формат даты (необязательное свойство)</td>
<td>Если в префиксе пути используется маркер даты, вы можете выбрать формат даты для упорядочивания своих файлов. Пример: ГГГГ/ММ/ДД</td>
</tr>
<tr>
<td>Формат времени (необязательное свойство)</td>
<td>Если в префиксе пути используется маркер времени, укажите формат времени для упорядочивания своих файлов. В настоящее время поддерживается только один формат&#160;— ЧЧ.</td>
</tr>
<tr>
<td>Формат сериализации событий</td>
<td>Формат сериализации для выходных данных. Поддерживаются форматы JSON, CSV и Avro.</td>
</tr>
<tr>
<td>Кодирование</td>
<td>Если используется формат CSV или JSON, необходимо указать формат кодирования. В настоящее время единственным поддерживаемым форматом кодирования является UTF-8.</td>
</tr>
<tr>
<td>Разделитель</td>
<td>Применяется только для сериализации CSV-файлов. Служба Stream Analytics позволяет использовать ряд распространенных разделителей для сериализации данных в формате CSV. Поддерживаются такие разделители: запятая, точка с запятой, пробел, табуляция и вертикальная черта.</td>
</tr>
<tr>
<td>Формат</td>
<td>Применяется только для сериализации JSON. Вариант «строки-разделители» предусматривает форматирование выходных данных таким образом, что каждый объект JSON будет отделен новой строкой. Вариант «массив» означает, что выходные данные будут отформатированы как массив объектов JSON.</td>
</tr>
</tbody>
</table>

## Концентратор событий
[Концентраторы событий](https://azure.microsoft.com/services/event-hubs/) — это высокомасштабируемая служба приема данных о событиях публикации и подписки. Она может принимать миллионы событий в секунду. Концентратор событий может использоваться в качестве места назначения выходных данных, например в случае, когда выходные данные задания Stream Analytics становятся входными данными для другого задания потоковой передачи.

Чтобы настроить потоки данных концентраторов событий как выходные данные, требуется ряд параметров.

| Имя свойства | Описание |
| --- | --- |
| Псевдоним выходных данных |Это понятное имя, которое используется в запросах для направления выходных данных запроса в концентратор событий. |
| Пространство имен служебной шины |Пространство имен Service Bus — это контейнер для набора сущностей обмена сообщениями. При создании нового концентратора событий создается также пространство имен служебной шины. |
| Концентратор событий |Имя выходных данных концентратора событий. |
| Имя политики концентратора событий |Политика общего доступа, которую можно создать на вкладке с настройками концентратора событий. Каждой политике общего доступа присваивается имя, а также задаются разрешения и ключи доступа. |
| Ключ политики концентратора событий |Ключ общего доступа, используемый для проверки подлинности при получении доступа к пространству имен служебной шины. |
| Столбец ключа раздела (необязательное свойство) |Этот столбец содержит ключ раздела для выходных данных концентратора событий. |
| Формат сериализации событий |Формат сериализации для выходных данных. Поддерживаются форматы JSON, CSV и Avro. |
| Кодирование |В настоящее время единственным поддерживаемым форматом кодирования файлов CSV и JSON является UTF-8. |
| Разделитель |Применяется только для сериализации CSV-файлов. Служба Stream Analytics позволяет использовать ряд распространенных разделителей для сериализации данных в формате CSV. Поддерживаются такие разделители: запятая, точка с запятой, пробел, табуляция и вертикальная черта. |
| Формат |Применяется только для типа JSON. Вариант «строки-разделители» предусматривает форматирование выходных данных таким образом, что каждый объект JSON будет отделен новой строкой. Вариант «массив» означает, что выходные данные будут отформатированы как массив объектов JSON. |

## Power BI
Для визуализации результатов анализа в качестве места назначения выходных данных для задания Stream Analytics можно использовать службу [Power BI](https://powerbi.microsoft.com/). Визуализация позволяет создавать панели мониторинга оперативных данных, формировать отчеты и составлять отчетности на основе метрик.

### Авторизация учетной записи Power BI
1. Если служба Power BI выбрана в качестве места назначения для выходных данных на портале управления Azure, вам будет предложено авторизовать существующего пользователя Power BI или создать новую учетную запись Power BI.
   
   ![Авторизация пользователя Power BI](./media/stream-analytics-define-outputs/01-stream-analytics-define-outputs.png)
2. Создайте учетную запись (если она еще не создана), а затем щелкните «Авторизовать сейчас». Появится следующий экран:
   
   ![Power BI в учетной записи Azure](./media/stream-analytics-define-outputs/02-stream-analytics-define-outputs.png)
3. На этом этапе укажите рабочую или учебную учетную запись для авторизации выходных данных Power BI. Если вы еще не зарегистрировались в Power BI, выберите параметр «Зарегистрироваться сейчас». Рабочая или учебная учетная запись, которая используется для Power BI, может отличаться от учетной записи в подписке Azure, с помощью которой вы вошли в систему.

### Настройка свойств выходных данных Power BI
После авторизации учетной записи Power BI можно настроить свойства для выходных данных Power BI. В таблице ниже приведены имена и описание свойств для настройки выходных данных в Power BI.

| Имя свойства | Описание |
| --- | --- |
| Псевдоним выходных данных |Это понятное имя, которое используется в запросах для направления выходных данных запроса в соответствующее место назначения в Power BI. |
| Рабочая область группы |Чтобы иметь возможность обмениваться данными с другими пользователями Power BI, вы можете выбрать группы в своей учетной записи Power BI или щелкнуть "Моя рабочая область", если не хотите записывать данные в группу. Для обновления существующей группы требуется повторно выполнить проверку подлинности в службе Power BI. |
| Имя набора данных |Имя набора данных для использования в выходных данных Power BI. |
| Имя таблицы |Имя таблицы в наборе выходных данных Power BI. В настоящее время для вывода выходных данных из заданий Stream Analytics в Power BI можно использовать только одну таблицу в наборе данных. |

Пошаговые инструкции по настройки выходных данных и панели мониторинга Power BI см. в статье [Azure Stream Analytics и Power BI](stream-analytics-power-bi-dashboard.md) статьи.

> [!NOTE]
> Не создавайте вручную набор данных и таблицу на панели мониторинга Power BI. Они будут автоматически созданы при запуске задания, когда задание начнет вносить выходные данные в Power BI. Обратите внимание: если запрос задания не создает никаких результатов, набор данных и таблица не создаются. Кроме того, если в Power BI уже есть набор данных и таблица с именем, аналогичным указанному в этом задании Stream Analytics, существующие данные будут перезаписаны.
> 
> 

### Повторная авторизация в Power BI
Необходимо будет повторно выполнить проверку подлинности учетной записи Power BI, если с момента создания задания или последней проверки подлинности пароль был изменен. Если в клиенте Azure Active Directory (AAD) настроена Multi-Factor Authentication (MFA), вам также потребуется каждые две недели обновлять авторизацию Power BI. Признаком этой проблемы является отсутствие выходных данных задания и наличие записи «Ошибка проверки подлинности пользователя» в журналах операций:

  ![Ошибка маркера обновления Power BI](./media/stream-analytics-define-outputs/03-stream-analytics-define-outputs.png)

Чтобы устранить эту проблему, остановите выполнение задания и перейдите к выходным данным Power BI. Щелкните ссылку "Обновить авторизацию" и перезапустите задание с момента его последней остановки во избежание потери данных.

  ![Повторная авторизация в Power BI](./media/stream-analytics-define-outputs/04-stream-analytics-define-outputs.png)

## Хранилище таблиц
[Табличное хранилище Azure](../storage/storage-introduction.md) отличается высокой степенью доступности и масштабируемости, позволяя приложению автоматически осуществлять масштабирование в соответствии с нуждами пользователя. Табличное хранилище является хранилищем ключей и атрибутов NoSQL корпорации Майкрософт и позволяет работать со структурированными данными с менее жесткими ограничениями схемы. Хранилище таблиц Azure можно использовать для постоянного хранения данных и эффективного их извлечения.

В таблице ниже приведены имена и описание свойств для создания выходных данных в табличном хранилище.

| Имя свойства | Описание |
| --- | --- |
| Псевдоним выходных данных |Это понятное имя, которое используется в запросах для направления выходных данных запроса в табличное хранилище. |
| Учетная запись хранения |Имя учетной записи хранения, в которую отправляются выходные данные. |
| Ключ учетной записи хранения |Ключ доступа, связанный с учетной записью хранения. |
| Имя таблицы |Это имя таблицы. Если таблица не существует, она будет создана. |
| Ключ раздела |Имя выходного столбца, содержащего ключ раздела. Ключ раздела — это уникальный идентификатор раздела в пределах конкретной таблицы, являющийся первой частью первичного ключа сущности. Это строковое значение размером до 1 КБ. |
| Ключ строки |Имя выходного столбца, содержащего ключ строки. Ключ строки — это уникальный идентификатор сущности внутри конкретного раздела. Он является второй частью первичного ключа сущности. Ключ строки — это строковое значение размером до 1 КБ. |
| Размер пакета |Количество записей в пакетной операции. Для большинства заданий достаточно значения по умолчанию. Дополнительные сведения об изменении этого параметра см. в статье о [характеристиках пакетных операций с таблицами](https://msdn.microsoft.com/library/microsoft.windowsazure.storage.table.tablebatchoperation.aspx). |

## Очереди служебной шины
[Очереди служебной шины](https://msdn.microsoft.com/library/azure/hh367516.aspx) доставляют сообщения конкурирующим потребителям по типу FIFO (первым пришел, первым вышел). Обычно получатели принимают и обрабатывают сообщения в порядке их добавления в очередь, и каждое сообщение принимается и обрабатывается только одним потребителем сообщений.

В таблице ниже приведены имена и описание свойств для создания выходных данных в очереди.

| Имя свойства | Описание |
| --- | --- |
| Псевдоним выходных данных |Это понятное имя, которое используется в запросах для направления выходных данных запроса в очередь служебной шины. |
| Пространство имен служебной шины |Пространство имен Service Bus — это контейнер для набора сущностей обмена сообщениями. |
| Имя очереди |Имя очереди служебной шины. |
| Имя политики очереди |При создании очереди можно также создать политики общего доступа на вкладке с настройками очереди. Каждой политике общего доступа присваивается имя, разрешения и ключи доступа. |
| Ключ политики очереди |Ключ общего доступа, используемый для проверки подлинности при получении доступа к пространству имен служебной шины. |
| Формат сериализации событий |Формат сериализации для выходных данных. Поддерживаются форматы JSON, CSV и Avro. |
| Кодирование |В настоящее время единственным поддерживаемым форматом кодирования файлов CSV и JSON является UTF-8. |
| Разделитель |Применяется только для сериализации CSV-файлов. Служба Stream Analytics позволяет использовать ряд распространенных разделителей для сериализации данных в формате CSV. Поддерживаются такие разделители: запятая, точка с запятой, пробел, табуляция и вертикальная черта. |
| Формат |Применяется только для типа JSON. Вариант «строки-разделители» предусматривает форматирование выходных данных таким образом, что каждый объект JSON будет отделен новой строкой. Вариант «массив» означает, что выходные данные будут отформатированы как массив объектов JSON. |

## Разделы шины обслуживания
Если очереди служебной шины предоставляют принцип взаимодействия "один к одному" (отправитель с получателем), то [разделы служебной шины](https://msdn.microsoft.com/library/azure/hh367516.aspx) позволяют использовать принцип взаимодействия "один ко многим".

В таблице ниже приведены имена и описание свойств для создания выходных данных в табличном хранилище.

| Имя свойства | Описание |
| --- | --- |
| Псевдоним выходных данных |Это понятное имя, которое используется в запросах для направления выходных данных запроса в раздел служебной шины. |
| Пространство имен служебной шины |Пространство имен Service Bus — это контейнер для набора сущностей обмена сообщениями. При создании нового концентратора событий создается также пространство имен служебной шины. |
| Имя раздела |Разделы являются сущностями обмена сообщениями, как концентраторы событий и очереди. Они предназначены для сбора потоков событий с нескольких различных устройств и служб. Созданному разделу присваивается определенное имя. Сообщения, отправленные в раздел, будут недоступны, пока не создана подписка. Поэтому убедитесь, что раздел содержит одну или несколько подписок. |
| Имя политики раздела |При создании раздела можно также создать политики общего доступа на вкладке настройки раздела. Каждой политике общего доступа присваивается имя, а также задаются разрешения и ключи доступа. |
| Ключ политики раздела |Ключ общего доступа, используемый для проверки подлинности при получении доступа к пространству имен служебной шины. |
| Формат сериализации событий |Формат сериализации для выходных данных. Поддерживаются форматы JSON, CSV и Avro. |
| Кодирование |Если используется формат CSV или JSON, необходимо указать формат кодирования. В настоящее время единственным поддерживаемым форматом кодирования является UTF-8. |
| Разделитель |Применяется только для сериализации CSV-файлов. Служба Stream Analytics позволяет использовать ряд распространенных разделителей для сериализации данных в формате CSV. Поддерживаются такие разделители: запятая, точка с запятой, пробел, табуляция и вертикальная черта. |

## DocumentDB
[Azure DocumentDB](https://azure.microsoft.com/services/documentdb/) — это полностью управляемая служба баз данных документов NoSQL, которая обеспечивает запросы и операции с данными без схемы, надежную производительность и быструю разработку.

В таблице ниже приведены имена и описание свойств для создания выходных данных DocumentDB.

<table>
<tbody>
<tr>
<td>ИМЯ СВОЙСТВА</td>
<td>ОПИСАНИЕ</td>
</tr>
<tr>
<td>Имя учетной записи</td>
<td>Имя учетной записи DocumentDB. Оно также может быть конечной точкой учетной записи.</td>
</tr>
<tr>
<td>Ключ учетной записи</td>
<td>Общедоступный ключ доступа к учетной записи DocumentDB.</td>
</tr>
<tr>
<td>База данных</td>
<td>Имя базы данных DocumentDB.</td>
</tr>
<tr>
<td>Шаблон имен коллекций</td>
<td>Шаблон имен для используемых коллекций. Формат имени коллекции можно составить с помощью необязательного маркера {partition}, где разделы начинаются с 0.<BR>(например, Ниже представлены допустимые входные данные:<BR>MyCollection{partition}<BR>MyCollection<BR>Обратите внимание, что коллекции должны существовать до запуска задания Stream Analytics и не будут созданы автоматически.</td>
</tr>
<tr>
<td>Ключ раздела</td>
<td>Имя поля в выходных событиях, указывающее ключ для разделения выходных данных между коллекциями.</td>
</tr>
<tr>
<td>Идентификатор документа</td>
<td>Имя поля в выходных событиях, используемое для указания основного ключа, на котором основаны операции вставки или обновления.</td>
</tr>
</tbody>
</table>


## Получение справки
Дополнительную помощь и поддержку вы можете получить на нашем [форуме Azure Stream Analytics](https://social.msdn.microsoft.com/Forums/ru-RU/home?forum=AzureStreamAnalytics).

## Дальнейшие действия
Вы получили основные сведения о Stream Analytics, управляемой службе аналитики потоковой передачи данных из Интернета вещей. Дополнительные сведения об этой службе см. на следующих ресурсах:

* [Приступая к работе с Azure Stream Analytics](stream-analytics-get-started.md)
* [Масштабирование заданий в службе Azure Stream Analytics](stream-analytics-scale-jobs.md)
* [Справочник по языку запросов Azure Stream Analytics](https://msdn.microsoft.com/library/azure/dn834998.aspx)
* [Справочник по API-интерфейсу REST управления Stream Analytics](https://msdn.microsoft.com/library/azure/dn835031.aspx)

<!--Link references-->
[stream.analytics.developer.guide]: ../stream-analytics-developer-guide.md
[stream.analytics.scale.jobs]: stream-analytics-scale-jobs.md
[stream.analytics.introduction]: stream-analytics-introduction.md
[stream.analytics.get.started]: stream-analytics-get-started.md
[stream.analytics.query.language.reference]: http://go.microsoft.com/fwlink/?LinkID=513299
[stream.analytics.rest.api.reference]: http://go.microsoft.com/fwlink/?LinkId=517301

<!---HONumber=AcomDC_0928_2016-->