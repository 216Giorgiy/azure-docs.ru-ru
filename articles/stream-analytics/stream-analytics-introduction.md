<properties 
	pageTitle="Введение в Stream Analytics | Azure" 
	description="Понимание анализа потоков Azure" 
	services="stream-analytics" 
	documentationCenter="" 
	authors="jeffstokes72" 
	manager="paulettm" 
	editor="cgronlun"/>

<tags 
	ms.service="stream-analytics" 
	ms.devlang="na" 
	ms.topic="article" 
	ms.tgt_pltfrm="na" 
	ms.workload="data-services" 
	ms.date="05/06/2015" 
	ms.author="jeffstok"/>


# Введение в Azure Stream Analytics

Azure Stream Analytics является полностью управляемой службой, обеспечивающей низкую задержку, высокий уровень доступности и масштабируемую обработку сложных событий посредством потоковой передачи данных в облако.


## Введение в Azure Stream Analytics (видео)

В этом [видео](http://azure.microsoft.com/documentation/videos/introduction-to-azure-stream-analytics-with-santosh-balasubramanian/) Сантош Баласубраманян (Santosh Balasubramanian) и Скотт Хансельман (Scott Hanselman) рассказывают о службе Azure Stream Analytics. (Длительность: 11:22)

> [AZURE.VIDEO introduction-to-azure-stream-analytics-with-santosh-balasubramanian]

## Обзор и причины создания

Сегодня по сети передается огромное количество данных на высоких скоростях. Организации, которые могут обрабатывать и реагировать на эти данные в режиме реального времени, могут существенно повысить свою эффективность и дифференцировать себя на рынке. Сценарии анализа потока в режиме реального времени можно найти во всех следующих отраслях: персонализированный торговый анализ в режиме реального времени и сигналы, предлагаемые компаниями, которые предоставляют финансовые услуги; выявление мошенничества в режиме реального времени; службы защиты данных и личной информации; надежный сбор и анализ данных, поступающих от датчиков и приводов, вмонтированных в физические объекты ("Интернет вещей", или IoT); потоковая аналитика переходов на сайтах и приложения для управления отношениями с клиентами (CRM), отправляющие сигналы при падении уровня обслуживания клиента в течение определенного промежутка времени. Компании ищут наиболее гибкий, надежный и экономичный способ осуществления такого потокового анализа данных для событий в режиме реального времени для успешной деятельности в современном высококонкурентном мире.

Создание систем потоковой обработки является сложной задачей. Такие потоковые операции, как корреляция и группировка, должны не только эффективно внедряться, но также должны быть масштабируемыми и отказоустойчивыми. Для этого требуется выполнить дополнительные задачи оперативного характера, включая развертывание, отладку и наблюдение. Затраты, связанные с построением и обслуживанием такого решения быстро растут. Более крупные предприятия отказались платить такую большую цену, создавая решения под заказ, в то время как небольшие компании часто не могут воспользоваться такой возможностью из-за высокого барьера доступа и чрезмерно высоких затрат. Azure Stream Analytic позволяет преодолеть эти трудности.

Azure Stream Analytics – это служба потоковой обработки в режиме реального времени под полным управлением, которая размещена в Microsoft Azure. Она обеспечивает высокую надежность, малую задержку и масштабируемую обработку потоковых данных сложных событий. Эта служба позволяет разработчикам легко объединять потоки данных с историческими записями или ссылочными данными для легкого и быстрого получения бизнес-информации.

Несколько раз щелкнув мышью на портале Azure, клиенты могут создавать потоковые задания с использованием похожего на SQL языка, чтобы задавать преобразования, а также отслеживать масштаб и скорость их общего потокового конвейера. Службу можно легко масштабировать, начиная от нескольких килобайт и заканчивая гигабайтом или несколькими событиями, обрабатываемых в секунду. Большинство других потоковых решений, которые доступны сегодня, требуют от клиентов написания сложного пользовательского кода, в то время как, используя Azure Stream Analytics, клиенту достаточно написать простой, декларативный, знакомый SQL-код.

В службе Azure Stream Analytics доступен целый ряд операторов от простых фильтров до сложных корреляций. Простые операторы языка SQL-подобных запросов Stream Analytics позволяют в считанные минуты выполнить следующие действия: определить такие оконные операции на основе времени как оконные агрегаты, коррелировать множественные потоки для выявления таких закономерностей как последовательности или даже сравнивать текущие условия с историческими значениями и моделями. Указание конвейера потоковой передачи сводится к настройке его входных и выходных данных, а также предоставлению SQL-подобного запроса, описывающего необходимые преобразования. Хотя этого достаточно для большинства простых случаев, более масштабные и сложные сценарии можно задать путем настройки службы Stream Analytics. Пользователи могут определять, какой объем вычислительной мощности необходимо выделить для каждого этапа конвейера для достижения нужной пиковой пропускной способности.

В настоящее время служба Azure Stream Analytics подключается непосредственно к концентраторам событий Azure для получения потока и к службе BLOB-объектов Azure — для получения исторических данных. Используя целый ряд входных и выходных интерфейсов концентраторов событий Azure, вы можете легко интегрировать Azure Stream Analytics с другими источниками данных и модулями обработки без потери потоковых вычислений. Данные могут записываться из Stream Analytics в службу хранилища Azure Storage, где их позже можно снова обработать как последовательность событий или использовать в других формах пакетной аналитики с помощью Azure HDInsight. Azure Stream Analytics основана на многолетнем опыте исследовательской работы Microsoft по разработке высокоточных потоковых обработчиков данных, критичных ко времени их обработки, а также интеграции языков для их интуитивного определения. Azure Stream Analytics создана с использованием опыта сообщества открытого исходного кода Hadoop, YARN и REEF в области масштабируемой обработки.


## Ключевые возможности

### Простота использования
Stream Analytics поддерживает простую декларативную модель запроса для описания преобразований. Для оптимизации работы мы в качестве доменного языка (DSL) выбрали SQL. Таким образом мы оградили клиентов от чрезмерных технических сложностей, лежащих в основе нашей системы потоковой передачи. С помощью языка запросов Stream Analytics вы можете быстро и легко реализовать временные функции, включая соединения с привязкой ко времени, оконные агрегаты, временные фильтры, а также другие операции общего характера, например соединения, агрегаты данных, прогнозирования и фильтры.

Хотя мы и расширили семантику SQL несколькими способами, знакомыми пользователям SQL, мы остаемся в синтаксических границах стандарта SQL, чтобы облегчить реализацию и использование инструментов. Дополнительные сведения о нашем языке запросов см. в разделе "Дальнейшие действия".

### Масштабируемость
Stream Analytics способна обрабатывать события при высокой пропускной способности, до 1 Гб/с. Благодаря интеграции с концентраторами событий Azure решение способно принимать в секунду миллионы событий, которые поступают из подключенных устройств, потоков с переходами и файлов журналов. И это только незначительная часть большого количества возможностей. Для этого мы задействовали возможности секционирования концентраторов событий, которые обеспечивают обработку со скоростью 1 МБ/с на секцию. Stream Analytics предоставляет поддержку секционирования при обработке этих принятых событий по горизонтальной и вертикальной оси. Пользователь может разбить вычислительную обработку на целый ряд логических шагов при определении запроса, каждый из которых может дополнительно быть разделен на элементы выполнения с параллельными данными. Со временем Stream Analytics будет автоматически масштабироваться в зависимости от скорости получения событий, сложности обработки и ожидаемых задержек, чтобы пользователи могли соответствующим образом настраивать свои рабочие нагрузки. Дополнительные сведения о реализации масштабируемости приведены по ссылкам в разделе "Дальнейшие действия".

### Надежность, воспроизводимость и быстрое восстановление
При сбоях узлов служба Stream Analytics предотвращает потери данных и обеспечивает непрерывность бизнес-процессов благодаря встроенным функциям восстановления и профилактического копирования памяти в контрольных точках. Эти возможности реализованы с помощью архитектуры модели Stream Analytics с привязкой к клиенту. Служба спроектирована таким образом, чтобы сохранять состояние оптимизации возобновления после сбоя узла, повторных вычислений, а также для кэширования исходящих данных с целью эффективного учета сбоев на последующих участках.

Благодаря функции внутренней поддержки состояния служба может обеспечивать воспроизводимость результатов, если предусмотрена возможность архивирования событий и многократного применения обработки в будущем с получением одинаковых результатов. Эта функция позволяет клиентам вернуться назад во времени и исследовать вычисления по сценариям наподобие анализа основных причин и анализа "что если". В сочетании эти функции обеспечивают быстрое восстановление после сбоев узлов обработки, проводя быструю повторную обработку потерянного состояния.

### Малые задержки
В настоящее время Stream Analytics оптимизирована под сквозные наблюдаемые задержки порядка менее секунды. Это позволяет системе осуществлять непрерывную обработку при высокой пропускной способности. Модель взаимодействия – адаптивная модель с пакетной обработкой данных, основанная на запросах, которая работает на основе настроенного времени ожидания и предельных размеров. Таким образом, события и другие записи разделяются на пакеты до достижении пределов. Система может обеспечить малую задержку даже при высокой пропускной способности.

### Ссылочные данные
Stream Analytics предоставляет пользователям возможность указывать и использовать ссылочные данные. Это могут быть исторические данные или данные с меньшей вариативностью по времени. Система упрощает использование ссылочных данных, которые рассматриваются как любой другой входящий поток событий для объединения с другими потоками событий, принимаемыми в режиме реального времени для выполнения преобразований. Дополнительные сведения о построении и использовании ссылочных данных см. в разделе "Дальнейшие действия".



## Коммерческие предпосылки выбора Azure Stream Analytics

### Низкая стоимость
Служба Stream Analytics оптимизирована для обеспечения очень низкой стоимости пуска в эксплуатацию и поддержки аналитических решений в режиме реального времени. Служба построена таким образом, чтобы вы могли оплачивать ее исходя из интенсивности ее использования вами. Интенсивность использования определяется на основе объема обработанных событий и объема вычислительной мощности, провизионированной в кластере для обработки соответствующих потоковых задач.

### Быстрая реализация
Благодаря Stream Analytics вы получаете решение для обработки событий с высокой масштабируемостью в режиме реального времени без необходимости какого-либо оборудования или других первоначальных расходов, а также без затрат времени на установку или настройку. Обо всем этом для вас позаботился Azure. Вы можете настроить и запустить решение в считанные минуты, просто подписавшись на службу через портал Azure. На портале с понятным пользовательским интерфейсом доступно краткое пошаговое руководство, с помощью которого вы можете настроить и протестировать ваш источник ввода данных, а также хранилище для выводимых данных. Редактор простых запросов поддерживает функции автозаполнения и предоставления рекомендаций.

### Быстрая разработка
Stream Analytics позволяет уменьшить нестыковки и понизить сложность разработки аналитических функций для масштабирования распределенных систем. Разработчики просто описывают нужное преобразование на языке запросов на основе SQL, а система автоматически распределяет рабочую нагрузку с учетом масштабирования, производительности и надежности, исключая необходимость процедурного программирования, которое необходимо в большинстве решений потоковой обработки. Благодаря своим встроенным возможностям и удобному в использовании порталу Stream Analytics предоставляет высококвалифицированным разработчикам возможность быстрой и легкой обработки в режиме реального времени, при которой можно не беспокоиться о таких аспектах, как обслуживание инфраструктуры, текущее обслуживание и масштабирование.

## Сценарии и варианты использования

### Анализ в режиме реального времени с помощью "Интернета вещей" (IoT)
По мере того как устройства становятся все более интеллектуальными и все большее количество устройств поддерживает коммуникационные возможности, перспективы возможностей обработки данных, создаваемых и собираемых с этих устройств, расширяются как в области коммерции, так и в области потребительского рынка. Ожидается, что при таком большом количестве данных можно быстро объединять и обрабатывать данные, получая более подробные сведения об окружающей нас среде и об устройствах, которыми мы постоянно пользуемся. Традиционный сценарий IoT можно описать на примере торгового автомата.

Торговые автоматы регулярно отправляют такие данные, как наличие продукта, состояние и температура, на полевой шлюз (если торговый автомат не поддерживает IP-протокол) или на облачный шлюз (при поддержке IP-протокола) для передачи данных в систему. Входной поток данных обрабатывается и преобразуется, чтобы полученные в результате вычислений выходные данные могли сразу передаваться через шлюзы на устройство для выполнения соответствующих действий. Например, при перегреве машины устройству может потребоваться перезагрузка или автоматическое выполнение обновления встроенного ПО без вмешательства человека. Обработанные выходные данные могут также активировать и выдачу других оповещений и уведомлений техническому специалисту, причем можно реализовать автоматическое планирование на основе событий.

По мере того как все большее количество данных собирается и обрабатывается, для разработки и обучения на основе шаблонов, встречающихся в системе, можно использовать и машинное обучение. Например, вы можете спрогнозировать момент, когда машины необходимо обслужить, на основе потоков событий в режиме реального времени, поступающих в систему, или запланировать профилактическое обслуживание в графике технического специалиста, когда что-то может пойти не так.

Такую схему отправки информации устройствами в систему обработки и потенциального принятия мер на основе результатов, обработанных в режиме реального времени, можно часто наблюдать в случаях использования IoT. Другие подобные сценарии включают подключение автомобилей, аналитику потоков и переходов и техническое управление. Чтобы оптимизировать эту цепь обратной связи с целью получения малых задержек и высокой пропускной способности, службу Stream Analytics можно использовать для приема данных из концентраторов событий Azure с целью обработки данных и их передачи обратно на концентратор событий для соответствующего подключенного устройства с целью выполнения соответствующего действия.


![Azure Stream Analytics: анализ в режиме реального времени с помощью "Интернета вещей" (IoT)][img.stream.analytics.scenario1]


### Анализ телеметрии и журнала с помощью панели мониторинга
По мере того как количество устройств, машин и приложений растет, распространенным вариантом корпоративного использования в деловой сфере является необходимость отслеживания изменяющихся потребностей бизнеса и реагирования на них за счет формирования развитой аналитики в квазиреальном режиме времени. Канонический сценарий анализа телеметрии и данных журналов можно описать на примере интернет-службы или приложения. Тем не менее такая модель поведения, как правило, характерна для компаний, которые собирают данные в отношении телеметрии приложения или устройства и отчитываются о них.

Приложение или служба регулярно собирают данные об исправности. Собираются данные, представляющие текущее состояние приложения или инфраструктуры на момент времени, журналы запросов пользователей и другие данные, которые представляют собой действия или манипуляции, осуществляемые в приложении. Архивные данные сохраняются в большом двоичном объекте или других типах хранилищ данных для дальнейшей обработки.

По последней тенденции, направленной на отображение данных в режиме реального времени, помимо сохранения данных в большом двоичном объекте или другом типе хранилища результатов анализа исторических данных, клиенты стремятся обработать и преобразовать поток входящих данных непосредственно таким образом, чтобы его можно было сразу же предоставить пользователям в виде панелей мониторинга и/или уведомлений, если требуется выполнить какое-либо действие. Например, если сайт службы поддержки выходит из строя, обслуживающий персонал можно уведомить, чтобы начать исследовать причину сбоя и быстро ее устранить. Согласно некоторым из таких вариантов использования человек, как правило, наблюдает за панелью мониторинга в режиме реального времени на основе обновленного набора данных после обработки полученных данных при помощи Stream Analytics.
 
![Azure Stream Analytics: анализ телеметрии и журналов с помощью панелей мониторинга][img.stream.analytics.scenario2]

### Архивирование событий для дальнейшей обработки
Потребности компаний в отношении быстрого и гибкого выполнения продолжают расти. Теперь организации и разработчики выбирают простые в использовании облачные платформы, чтобы удовлетворить потребность в большей гибкости, и подыскивают платформы, которые позволяют им принимать и обрабатывать непрерывный поток данных, создаваемый их системами в квазиреальном режиме времени. В настоящее время эти клиенты не смогут использовать службу, оптимизированную для записи в хранилище данных с малой задержкой, и, таким образом, теряют некоторые важные массивы данных, которые могут оказаться ценными с точки зрения получения информации о работе компании. Традиционный сценарий архивирования событий можно описать следующим образом.

Данные от различных устройств и платформ, рассредоточенных по всему миру, направляются в централизованный сборщик данных. После поступления данных в центральное хранилище над ними выполняются некоторые преобразующие операции без сохранения состояния, например очистка личных сведений, добавление геотегов и подстановка IP-адреса. Преобразованные данные затем архивируются в хранилищах больших двоичных объектов и готовы к непосредственному использованию с помощью HDInsight и других средств обработки в автономном режиме.

![Azure Stream Analytics: архивирование событий для дальнейшей обработки][img.stream.analytics.scenario3]
 
## Получение справки
Дополнительную помощь и поддержку вы можете получить на нашем [форуме Azure Stream Analytics](https://social.msdn.microsoft.com/Forums/en-US/home?forum=AzureStreamAnalytics).

## Дальнейшие действия

- [Введение в Azure Stream Analytics](stream-analytics-introduction.md)
- [Приступая к работе с Azure Stream Analytics](stream-analytics-get-started.md)
- [Масштабирование заданий в службе Azure Stream Analytics](stream-analytics-scale-jobs.md)
- [Справочник по языку запросов Azure Stream Analytics](https://msdn.microsoft.com/library/azure/dn834998.aspx)
- [Справочник по API-интерфейсу REST управления Stream Analytics](https://msdn.microsoft.com/library/azure/dn835031.aspx)


<!--Image references-->
[img.stream.analytics.scenario1]: ./media/stream-analytics-introduction/Introduction-to-Azure-Stream-Analytics_01.png
[img.stream.analytics.scenario2]: ./media/stream-analytics-introduction/Introduction-to-Azure-Stream-Analytics_02.png
[img.stream.analytics.scenario3]: ./media/stream-analytics-introduction/Introduction-to-Azure-Stream-Analytics_03.png


<!--Link references-->
[stream.analytics.developer.guide]: ../stream-analytics-developer-guide.md
[stream.analytics.scale.jobs]: stream-analytics-scale-jobs.md
[stream.analytics.limitations]: ../stream-analytics-limitations.md
[stream.analytics.introduction]: stream-analytics-introduction.md
[stream.analytics.get.started]: stream-analytics-get-started.md
[stream.analytics.query.language.reference]: http://go.microsoft.com/fwlink/?LinkID=513299
[stream.analytics.rest.api.reference]: http://go.microsoft.com/fwlink/?LinkId=517301

<!--HONumber=54--> 