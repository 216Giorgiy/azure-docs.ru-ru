<properties 
	pageTitle="Использование ссылочных данных | Microsoft Azure" 
	description="Использование ссылочных данных в качестве входного потока" 
	keywords="big data analytics,cloud service,internet of things,managed service,stream processing,streaming analytics,streaming data"
	services="stream-analytics" 
	documentationCenter="" 
	authors="jeffstokes72" 
	manager="paulettm" 
	editor="cgronlun"/>

<tags 
	ms.service="stream-analytics" 
	ms.devlang="na" 
	ms.topic="article" 
	ms.tgt_pltfrm="na" 
	ms.workload="data-services" 
	ms.date="10/05/2015" 
	ms.author="jeffstok"/>

# Использование ссылочных данных в качестве входных данных

Ссылочные данные — это ограниченный набор данных, являющийся по своей сути статическим или медленно изменяющимся. Такие данные используются для выполнения уточняющего запроса или соотнесения с вашим потоком данных. Для использования ссылочных данных в задании Azure Stream Analytics обычно используется [соединение ссылочных данных](https://msdn.microsoft.com/library/azure/dn949258.aspx) в запросе. Служба Stream Analytics использует хранилище BLOB-объектов Azure как уровень хранилища для ссылочных данных. С помощью фабрики данных Azure ссылочные данные можно преобразовать и (или) скопировать в хранилище BLOB-объектов Azure из [любого количества облачных и локальных хранилищ данных](./articles/data-factory-data-movement-activities.md) для использования в качестве ссылочных данных.

## Настройка ссылочных данных

Чтобы настроить ссылочные данные, необходимо сначала создать входные данные соответствующего типа. В таблице ниже описано каждое свойство, которое необходимо указать во время создания входных ссылочных данных.

<table>
<tbody>
<tr>
<td>Имя свойства</td>
<td>Описание</td>
</tr>
<tr>
<td>Псевдоним входных данных</td>
<td>Понятное имя, с помощью которого запрос задания будет ссылаться на эти входные данные.</td>
</tr>
<tr>
<td>Учетная запись хранения</td>
<td>Имя учетной записи хранения, в которой находятся файлы больших двоичных объектов. Если учетная запись расположена в одной подписке с заданием Stream Analytics, ее имя можно выбрать из раскрывающегося списка.</td>
</tr>
<tr>
<td>Ключ учетной записи хранения</td>
<td>Секретный ключ, связанный с учетной записью хранения. Заполняется автоматически, если учетная запись хранения расположена в одной подписке с заданием Stream Analytics.</td>
</tr>
<tr>
<td>Контейнер хранилища</td>
<td>Контейнеры обеспечивают логическую группировку BLOB-объектов, хранящихся в службе BLOB-объектов Microsoft Azure. При передаче BLOB-объекта в службу BLOB-объектов для него необходимо указать контейнер.</td>
</tr>
<tr>
<td>Шаблон префикса пути (необязательное свойство)</td>
<td>Путь к файлу, используемый для поиска больших двоичных объектов в указанном контейнере. В пути можно указать один или несколько экземпляров следующих двух переменных:<BR>{date}, {time}<BR>Пример&#160;1: products/{date}/{time}/product-list.csv<BR>Пример&#160;2: products/{date}/product-list.csv
</tr>
<tr>
<td>Формат даты (необязательное свойство)</td>
<td>Если в указанном шаблоне пути использовалась переменная {date}, из раскрывающегося списка поддерживаемых форматов можно выбрать формат даты для упорядочивания файлов. Пример: ГГГГ/ММ/ДД</td>
</tr>
<tr>
<td>Формат времени (необязательное свойство)</td>
<td>Если в указанном шаблоне пути использовалась переменная {time}, из раскрывающегося списка поддерживаемых форматов можно выбрать формат времени для упорядочивания файлов. Пример: ЧЧ</td>
</tr>
<tr>
<td>Формат сериализации событий</td>
<td>Чтобы запросы работали как следует, в задании Stream Analytics нужно указать, какой формат сериализации используется для потоков входящих данных. Поддерживаемые форматы для ссылочных данных: CSV и JSON.</td>
</tr>
<tr>
<td>Кодирование</td>
<td>В настоящее время единственным поддерживаемым форматом кодирования является UTF-8.</td>
</tr>
</tbody>
</table>

## Создание ссылочных данных по расписанию

Если ссылочные данные являются медленно изменяющимся набором данных, вы можете включить поддержку обновления ссылочных данных. Для этого укажите соответствующий шаблон пути во входной конфигурации, используя маркеры {date} и {time}. На основе этого шаблона пути служба Stream Analytics будет выбирать обновленные определения ссылочных данных. Например, шаблон ````"/sample/{date}/{time}/products.csv"```` с форматом даты «ГГГГ-ММ-ДД» и форматом времени «ЧЧ:ММ» указывает службе Stream Analytics выбрать обновленный BLOB-объект ````"/sample/2015-04-16/17:30/products.csv"```` 16 апреля 2015 г. в 17:30 в часовом поясе UTC.

> [AZURE.NOTE]В настоящее время задания Stream Analytics ищут обновления больших двоичных объектов, только если время компьютера совпадает со временем, закодированным в имени большого двоичного объекта. Например, задание будет искать файл /sample/2015-04-16/17:30/products.csv в промежутке между 17:30 и 17:30:59,9 16 апреля 2015 г. в часовом поясе UTC. Как только часы компьютера покажут 17:31, задание прекратит поиск файла /sample/2015-04-16/17:30/products.csv и начнет поиск файла /sample/2015-04-16/17:31/products.csv. Большие двоичные объекты ссылочных данных за прошедшее время учитываются только при первом запуске задания. В этот момент задание ищет самый новый BLOB-объект, созданный перед указанным временем запуска задания. Это позволяет обеспечить наличие непустого набора ссылочных данных на момент начала задания. Если такой набор данных не найден, задание завершается ошибкой, а на экране появляется диагностическое сообщение.

[Фабрика данных Azure](http://azure.microsoft.com/documentation/services/data-factory/) может использоваться для управления заданием по созданию обновленных BLOB-объектов, необходимых службе Stream Analytics для обновления определений ссылочных данных. Фабрика данных представляет собой облачную службу интеграции информации, которая организует и автоматизирует перемещение и преобразование данных. Фабрика данных позволяет [подключаться к большому количеству облачных и локальных хранилищ данных](./articles/data-factory-data-movement-activities.md), а также легко перемещать данные по заданному расписанию. Дополнительные сведения и пошаговые инструкции, с помощью которых можно настроить конвейер фабрики данных и создать ссылочные данные для службы Stream Analytics, обновляемые по заданному расписанию, см. в этом [примере на сайте GitHub](https://github.com/Azure/Azure-DataFactory/tree/master/Samples/ReferenceDataRefreshForASAJobs).

## Получение справки
Дополнительную помощь и поддержку вы можете получить на нашем [форуме Azure Stream Analytics](https://social.msdn.microsoft.com/Forums/RU-RU/home?forum=AzureStreamAnalytics).

## Дальнейшие действия
Вы получили основные сведения о Stream Analytics, управляемой службе аналитики потоковой передачи данных из Интернета вещей. Дополнительные сведения об этой службе см. на следующих ресурсах:

- [Приступая к работе с Azure Stream Analytics](stream-analytics-get-started.md)
- [Масштабирование заданий в службе Azure Stream Analytics](stream-analytics-scale-jobs.md)
- [Справочник по языку запросов Azure Stream Analytics](https://msdn.microsoft.com/library/azure/dn834998.aspx)
- [Справочник по API-интерфейсу REST управления Stream Analytics](https://msdn.microsoft.com/library/azure/dn835031.aspx)

<!--Link references-->
[stream.analytics.developer.guide]: ../stream-analytics-developer-guide.md
[stream.analytics.scale.jobs]: stream-analytics-scale-jobs.md
[stream.analytics.introduction]: stream-analytics-introduction.md
[stream.analytics.get.started]: stream-analytics-get-started.md
[stream.analytics.query.language.reference]: http://go.microsoft.com/fwlink/?LinkID=513299
[stream.analytics.rest.api.reference]: http://go.microsoft.com/fwlink/?LinkId=517301

<!---HONumber=Oct15_HO2-->