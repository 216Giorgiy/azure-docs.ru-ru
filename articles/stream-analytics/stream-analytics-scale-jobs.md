<properties
	pageTitle="Задания по масштабированию в Azure Stream Analytics для увеличения пропускной способности | Microsoft Azure"
	description="Узнайте, как масштабировать задания Stream Analytics с помощью настройки входных разделов, настройки определения запроса и определения единиц потоковой передачи."
	keywords="задания аналитики, поток данных, потоковая передача данных"
	services="stream-analytics"
	documentationCenter=""
	authors="jeffstokes72"
	manager="paulettm"
	editor="cgronlun"/>

<tags
	ms.service="stream-analytics"
	ms.devlang="na"
	ms.topic="article"
	ms.tgt_pltfrm="na"
	ms.workload="data-services"
	ms.date="11/23/2015"
	ms.author="jeffstok"/>

# Задания по масштабированию в Azure Stream Analytics для увеличения пропускной способности #

Узнайте, как вычислить *единицы потоковой передачи* для заданий Stream Analytics и как масштабировать задания Stream Analytics с помощью настройки входных разделов, настройки определения запроса и определения единиц потоковой передачи.

## Из каких частей состоит задание службы Stream Analytics? ##
Определение задания Azure Stream Analytics включает запрос, а также входные и выходные данные. Входные данные – это точки, откуда задания считывают данные из потока, запрос используется для преобразования потока входных данных, а выходные данные являются точками, куда направляются результаты задания.

Задание требует по крайней мере один источник входных данных для потока данных. Входной источник потока данных может храниться в концентраторе событий служебной шины Azure или в хранилище больших двоичных объектов Azure. Дополнительные сведения см. во [введении в службу Azure Stream Analytics](stream-analytics-introduction.md), [статье о начале работы с Azure Stream Analytics](stream-analytics-get-started.md) и [руководстве разработчика по Azure Stream Analytics](../stream-analytics-developer-guide.md).

## Настройка единиц потоковой передачи ##
Единицы потоковой передачи представляют ресурсы и мощность, необходимые для выполнения задания Azure Stream Analytics. Единицы потоковой передачи предоставляют способ описания относительной мощности обработки события, основываясь на измерении загрузки ЦП, памяти и скорости чтения и записи. Каждая единица потоковой передачи соответствует пропускной способности около 1 МБ/с.

Выбор необходимого количества единиц потоковой передачи для конкретного задания зависит от конфигурации раздела для входных данных и запроса, определенного для задания. На классическом портале Azure для каждого задания можно выбрать количество единиц потоковой передачи согласно указанной квоте. Каждая подписка Azure по умолчанию включает квоту до 50 единиц потоковой передачи для всех заданий аналитики в определенном регионе. Чтобы увеличить количество единиц потоковой передачи для вашей подписки, свяжитесь со [службой технической поддержки Майкрософт](http://support.microsoft.com).

Число единиц потоковой передачи для использования в одном задании зависит от конфигурации раздела для входных данных и запроса, определенного для задания. Обратите внимание, что необходимо использовать допустимое значение единиц потоковой передачи. Допустимые значения начинаются с 1, 3, 6 и затем по возрастающей с шагом в 6, как показано ниже.

![Масштабирование единиц потоковой передачи Azure Stream Analytics][img.stream.analytics.streaming.units.scale]

В этой статье показано, как вычислить и настроить запрос для увеличения пропускной способности аналитических заданий.

## Расчет максимального количества единиц потоковой передачи для задания ##
Общее число единиц потоковой передачи, которое можно использовать заданием Stream Analytics, зависит от числа шагов в запросе, определенных для задания, и количества разделов для каждого шага.

### Шаги в запросе ###
Запрос может иметь один или несколько шагов. Каждый шаг — это вложенный запрос, определенный с помощью ключевого слова WITH. Запрос, находящийся за пределами ключевого слова WITH, также учитывается в качестве шага (например, инструкция SELECT в следующем запросе).

	WITH Step1 AS (
		SELECT COUNT(*) AS Count, TollBoothId
		FROM Input1 Partition By PartitionId
		GROUP BY TumblingWindow(minute, 3), TollBoothId, PartitionId
	)

	SELECT SUM(Count) AS Count, TollBoothId
	FROM Step1
	GROUP BY TumblingWindow(minute,3), TollBoothId

Предыдущий запрос включает 2 шага.

> [AZURE.NOTE]Этот образец запроса будет описан далее в этой статье.

### Разделы шага ###

Разделение шага требует наличия следующих условий.

- Источник входных данных должен быть секционирован. Дополнительные сведения см. в [руководстве разработчика по Stream Analytics](../stream-analytics-developer-guide.md) и [руководстве по программированию концентраторов событий](../azure-event-hubs-developer-guide.md).
- Инструкция SELECT запроса должна читаться из разделенного источника входных данных.
- Запрос внутри шага должен включать ключевое слово **Partition By**.

Если запрос разделен, входные данные событий будут обработаны и объединены в отдельные группы секции, а выходные данные событий будут сгенерированы для каждой из групп. Если желательно иметь объединенный запрос, необходимо создать второй неразделенный шаг для объединения.

### Рассчитайте максимальное количество единиц потоковой передачи для задания ###

Все несекционированные шаги можно масштабировать до шести единиц потоковой передачи для задания Stream Analytics. Для добавления дополнительных единиц потоковой передачи данных шаг должен быть секционирован. Каждая секция может включать шесть единиц потоковой передачи.

<table border="1">
<tr><th>Запрос задания</th><th>Максимальное количество единиц потоковой передачи для задания</th></td>

<tr><td>
<ul>
<li>Запрос содержит один шаг.</li>
<li>Шаг не секционирован.</li>
</ul>
</td>
<td>6</td></tr>

<tr><td>
<ul>
<li>Поток входных данных секционирован по 3.</li>
<li>Запрос содержит один шаг.</li>
<li>Шаг является секционированным.</li>
</ul>
</td>
<td>18</td></tr>

<tr><td>
<ul>
<li>Запрос состоит из двух шагов.</li>
<li>Ни один из шагов не секционирован.</li>
</ul>
</td>
<td>6</td></tr>



<tr><td>
<ul>
<li>Поток входных данных секционирован по 3.</li>
<li>Запрос состоит из двух шагов. Входной шаг секционирован, а второй шаг — нет.</li>
<li>Инструкция SELECT считывает из секционированных входных данных.</li>
</ul>
</td>
<td>24 (18 и 6 секционированных и несекционированных шагов соответственно)</td></tr>
</table>

### Пример шкалы ###
Следующий запрос вычисляет количество машин, проходящих через пропускной пункт с тремя пунктами для оплаты и пропускной способности три минуты для каждого пункта. Этот запрос можно масштабировать до шести единиц потоковой передачи.

	SELECT COUNT(*) AS Count, TollBoothId
	FROM Input1
	GROUP BY TumblingWindow(minute, 3), TollBoothId, PartitionId

Чтобы использовать дополнительные единицы потоковой передачи для запроса, входной поток данных и запрос должны быть секционированы. При наличии раздела потока данных, равного 3, следующий измененный запрос можно масштабировать до 18 единиц потоковой передачи.

	SELECT COUNT(*) AS Count, TollBoothId
	FROM Input1 Partition By PartitionId
	GROUP BY TumblingWindow(minute, 3), TollBoothId, PartitionId

Если запрос секционирован, входные данные событий будут обработаны и объединены в отдельные группы секций. Кроме того, для каждой из групп будут сформированы выходные данные событий. Секционирование может вызвать некоторые непредвиденные результаты, если поле **Group-by** не является ключом секции во входном потоке данных. Например, поле TollBoothId в предыдущем примере запроса не является ключом раздела Input1. Данные из пункта 1 можно распределить между несколькими секциями.

Каждая из секций Input1 будет обрабатываться отдельно с помощью Stream Analytics, и будет создаваться несколько записей для автомобиля, проходящего через один и тот же пункт. Если нельзя изменить ключ секции ввода, эту проблему можно устранить, добавив дополнительные несекционированные действия, например:

	WITH Step1 AS (
		SELECT COUNT(*) AS Count, TollBoothId
		FROM Input1 Partition By PartitionId
		GROUP BY TumblingWindow(minute, 3), TollBoothId, PartitionId
	)

	SELECT SUM(Count) AS Count, TollBoothId
	FROM Step1
	GROUP BY TumblingWindow(minute, 3), TollBoothId

Этот запрос можно увеличить до 24 единиц потоковой передачи.

>[AZURE.NOTE]При объединении двух потоков убедитесь, что потоки разделены с помощью ключа раздела для объединяемого столбца и количество разделов в обоих потоках одинаковое.


## Настройка раздела задания Stream Analytics ##

**Настройка единицы потоковой передачи для задания**

1. Перейдите на [классический портал Azure](https://manage.windowsazure.com).
2. Щелкните **Stream Analytics** в области слева.
3. Выберите задание Stream Analytics, которое необходимо расширить.
4. В верхней части страницы щелкните **МАСШТАБ**.

![Масштабирование единиц потоковой передачи Azure Stream Analytics][img.stream.analytics.streaming.units.scale]

На портале Azure параметры масштаба доступны в разделе "Параметры":

![Настройка задания Stream Analytics на портале Azure][img.stream.analytics.preview.portal.settings.scale]

## Мониторинг производительности задания ##

На классическом портале можно отслеживать пропускную способность задания событий в секунду:

![Отслеживание заданий Azure Stream Analytics][img.stream.analytics.monitor.job]

Рассчитайте ожидаемую пропускную способность рабочей нагрузки событий в секунду. Если пропускная способность меньше, чем ожидалось, настройте входную секцию и запрос, а также добавьте в задание дополнительные единицы потоковой передачи.

## Масштабирование пропускной способности службы ASA — сценарий для компьютера Raspberry Pi ##


Рассмотрите следующий эксперимент, чтобы понять, как в типичном сценарии масштабируется пропускная способность службы ASA для нескольких единиц потоковой передачи. Этот эксперимент состоит в следующем: данные датчиков (клиентов) отправляются в концентратор событий, служба ASA обрабатывает эти данные и отправляет предупреждение или статистические сведения в качестве выходных данных на другой концентратор событий.

Клиент отправляет синтезированные данные датчиков в формате JSON на концентраторы событий в службу ASA. Выходные данные также отправляются в формате JSON. Ниже приведен пример данных.

    {"devicetime":"2014-12-11T02:24:56.8850110Z","hmdt":42.7,"temp":72.6,"prss":98187.75,"lght":0.38,"dspl":"R-PI Olivier's Office"}

Запрос: "Send an alert when the light is switched off"

    SELECT AVG(lght),
	 “LightOff” as AlertText
	FROM input TIMESTAMP
	BY devicetime
	 WHERE
		lght< 0.05 GROUP BY TumblingWindow(second, 1)

Измерение пропускной способности. Пропускная способность в этом контексте — это объем входных данных, обрабатываемых службой ASA в определенный промежуток времени (10 минут). Чтобы обеспечить оптимальную пропускную способность для обработки входных данных, поток входных данных и запрос должны быть секционированы. В запрос также включается COUNT(), что позволяет подсчитать количество обработанных событий ввода. Чтобы убедиться, что служба ASA не просто ожидает поступления событий ввода, в каждую секцию концентратора событий ввода были предварительно загружены входные данные в достаточном объеме (300 МБ).

Ниже приведены результаты с увеличением количества единиц потоковой передачи и соответствующими данными о числе секций в концентраторах событий.

<table border="1">
<tr><th>Секции ввода</th><th>Секции вывода</th><th>Единицы потоковой передачи</th><th>Поддерживаемая пропускная способность
</th></td>

<tr><td>12</td>
<td>12</td>
<td>6</td>
<td>4,06&#160;МБ/с</td>
</tr>

<tr><td>12</td>
<td>12</td>
<td>12</td>
<td>8,06&#160;МБ/с</td>
</tr>

<tr><td>48</td>
<td>48</td>
<td>48</td>
<td>38,32&#160;МБ/с</td>
</tr>

<tr><td>192</td>
<td>192</td>
<td>192</td>
<td>172,67&#160;МБ/с</td>
</tr>

<tr><td>480</td>
<td>480</td>
<td>480</td>
<td>454,27&#160;МБ/с</td>
</tr>

<tr><td>720</td>
<td>720</td>
<td>720</td>
<td>609,69&#160;МБ/с</td>
</tr>
</table>

![img.stream.analytics.perfgraph][img.stream.analytics.perfgraph]

## Получение справки ##
За дополнительной помощью обращайтесь на наш [форум Azure Stream Analytics](https://social.msdn.microsoft.com/Forums/ru-RU/home?forum=AzureStreamAnalytics).


## Дальнейшие действия ##

- [Введение в Azure Stream Analytics](stream-analytics-introduction.md)
- [Приступая к работе с Azure Stream Analytics](stream-analytics-get-started.md)
- [Масштабирование заданий в службе Azure Stream Analytics](stream-analytics-scale-jobs.md)
- [Справочник по языку запросов Azure Stream Analytics](https://msdn.microsoft.com/library/azure/dn834998.aspx)
- [Справочник по API-интерфейсу REST управления Stream Analytics](https://msdn.microsoft.com/library/azure/dn835031.aspx)


<!--Image references-->

[img.stream.analytics.monitor.job]: ./media/stream-analytics-scale-jobs/StreamAnalytics.job.monitor.png
[img.stream.analytics.configure.scale]: ./media/stream-analytics-scale-jobs/StreamAnalytics.configure.scale.png
[img.stream.analytics.perfgraph]: ./media/stream-analytics-scale-jobs/perf.png
[img.stream.analytics.streaming.units.scale]: ./media/stream-analytics-scale-jobs/StreamAnalyticsStreamingUnitsExample.jpg
[img.stream.analytics.preview.portal.settings.scale]: ./media/stream-analytics-scale-jobs/StreamAnalyticsPreviewPortalJobSettings.png

<!--Link references-->

[microsoft.support]: http://support.microsoft.com
[azure.management.portal]: http://manage.windowsazure.com
[azure.event.hubs.developer.guide]: http://msdn.microsoft.com/library/azure/dn789972.aspx

[stream.analytics.developer.guide]: ../stream-analytics-developer-guide.md
[stream.analytics.introduction]: stream-analytics-introduction.md
[stream.analytics.get.started]: stream-analytics-get-started.md
[stream.analytics.query.language.reference]: http://go.microsoft.com/fwlink/?LinkID=513299
[stream.analytics.rest.api.reference]: http://go.microsoft.com/fwlink/?LinkId=517301
 

<!---HONumber=AcomDC_1203_2015-->