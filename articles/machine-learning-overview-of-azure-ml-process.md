<properties title="Azure Machine Learning API service operations" pageTitle="Операции со службой API машинного обучения | Azure" description="Creating and managing Azure Machine Learning web services" metaKeywords="" services="machine-learning" solutions="" documentationCenter="" authors="garye" manager="paulettm" editor="cgronlun" videoId="" scriptId="" />

<tags ms.service="machine-learning" ms.workload="data-services" ms.tgt_pltfrm="na" ms.devlang="na" ms.topic="article" ms.date="08/06/2014" ms.author="garye" />


# Операции со службой API машинного обучения Azure 
Типичный проект машинного обучения Microsoft Azure (Azure ML) включает в себя следующие высокоуровневые действия:  

1.	Получение, анализ и подготовка данных
2.	Создание экспериментов машинного обучения, в которых применяются различные алгоритмы машинного обучения
3.	Обучение, тестирование и формирование обученной модели
4.	Создание операционного рабочего процесса с помощью обученной модели и развертывание рабочего процесса в производственной среде
5.	Наблюдение за производительностью модели и последующих обновлений  

>Термин "эксперимент" используется для описания интерактивного рабочего процесса, который может включать в себя ввод данных и операции с ними, тренеры и счетчики очков в виде направленного ациклического графа (DAG). После того как рабочий процесс опубликован как веб-служба Azure, он больше не является интерактивным. Это означает, что для его изменения модель необходимо обновить, а затем переиздать, чтобы обновить веб-службу и ее поведение.  

Шаги 1-3 обычно выполняет специалист по обработке данных посредством множественных итераций, по окончании которых модель машинного обучения передается в техническую группу, а также группу операций, для интегрирования в производственные системы, что позволить применять модель машинного обучения в производственной среде.  

Традиционный процесс интегрирования и развертывания модели машинного обучения в производственную систему может занимать несколько недели или даже месяцев, в зависимости от кода, применяемого для формирования моделей, например, R, Python, C# или Java, процесса интеграции платформы и инфраструктурных особенностей, а также процедуры планирования развертывания.  

Azure ML позволяет упростить данный процесс путем оптимизации и рационализации процесса создания и анализ модели, а затем обеспечения удобных условий для развертывания эксперимента в виде веб-службы в Azure, что существенно сокращает общую продолжительность всего процесса (начиная с проведения экспериментов с моделью и заканчивая выполнением модели в производственной среде в виде веб-службы).  

В этом документе приводится описание концепций и шагов по настройке веб-службы Azure ML на основе эксперимента машинного обучения.  

# Обзор процесса Azure ML  #
Azure ML позволяет создавать веб-службы на основе экспериментов машинного обучения, которые определяются в системе Azure Machine Learning Studio (ML Studio). Веб-служба Azure ML может использоваться для создания прогнозов на основе фактических входных данных в режиме реального времени или в пакетном режиме.  
 
На рисунке ниже показана общая схема процесса, состоящая из двух этапов: сначала формируется модель, а затем выполняется ее публикация в виде веб-службы. В этом документе подробно рассматривается правая часть рис. 1 (публикация веб-службы оценки) и объясняются концепции, задействуемые в данном процессе. 

![][1]  

Рис. 1: Подготовка, формирование и публикация веб-службы оценки  

# Веб-службы Azure ML #
В контексте машинного обучения (ML) веб-служба представляет собой программный интерфейс, обеспечивающий связь между внешними приложениями и рабочим процессом машинного обучения. Она обеспечивает обмен данными с моделью оценки в режиме реального времени с целью получения результатов прогнозирования и встраивания результатов во внешние клиентские приложения. Для развертывания, размещения и управления веб-службами Azure ML в системе Azure ML используется Microsoft Azure. С помощью Azure ML можно создавать службы двух типов.  

## Служба запрос-ответ (RRS) ##
Служба запрос-ответ (RRS) является масштабируемой веб-службой с низким временем задержки, используемой в качестве интерфейса с моделями без изменения состояния, которые создаются и публикуются в среде экспериментов.   

- Интерфейс REST API: RRS представляет собой веб-службу RESTFul. 
-	Интерфейс службы: интерфейс веб-службы RRS определяется как часть схемы эксперимента, использующая порты ввода-вывода в эксперименте Azure ML Studio.
-	Стадии разработки: Являясь частью рабочего процесса Azure ML, служба RRS сначала формируется в промежуточной среде и может быть там протестирована. Как только служба считается полностью сформированной и готовой к производству, она развертывается в производственной среде. 
-	Развертывание в Azure: результатом развертывания службы RRS является конечная точка веб-службы Azure.
-	Параметры интерфейса: Запрос в службу RRS представляет собой данные, которые необходимо оценить с помощью конкретного эксперимента в Studio. ответ представляет собой результат прогнозирования модели. 
-	Значения ответа: RRS принимает одиночную строку входных параметров и формирует на выходе тоже одиночную строку. выходная строка может содержать несколько столбцов.   

## Служба пакетного выполнения (BES) ##
Служба пакетного выполнения (BES) представляет собой службу для асинхронной оценки группы записей данных. Входные данные для BES похожи на входные данные, используемые в RRS. Основная разница заключается в том, что служба BES считывает группу записей из различных источников, например, BLOB-объектов, таблиц в Azure, SQL Azure, HD Insight (запросы Hive) и источников HTTP.  Результаты оценки выводятся в файл в хранилище BLOB-объектов Azure, а в качестве ответа возвращается конечная точка хранилища.  

BES также предоставляет интерфейсы для определения состояния выполняемого процесса оценки и отмены запроса. BES может выполнять пакеты модели с очень большими объемами данных.  

-	Интерфейс REST API: BES представляет собой веб-службу RESTFul.
-	Интерфейс службы: по аналогии со службой RRS, интерфейс веб-службы BES определяется как часть схемы модели, использующая порты ввода-вывода в эксперименте Azure ML Studio.
-	Стадии разработки: Являясь частью рабочего процесса для создания BES, данная служба сначала формируется в промежуточной среде и может быть там протестирована. После того как служба оказывается полностью сформированной и готовой к использованию, она развертывается в производственной среде. 
-	Развертывание в Azure: результатом развертывания службы BES является конечная точка веб-службы Azure.
-	Параметры интерфейса: Запрос в службу BES представляет собой URL-адрес файла в большом двоичном объекте Azure или вводимые записи SAS, которые необходимо оценить. ответ записывается в большой двоичный объект Azure, а в ответ возвращается URL-адрес конечной точки хранилища ответов.  

# Публикация веб-службы Azure ML #
Azure ML Studio предоставляет браузерное приложение, позволяющее легко создавать и выполнять эксперименты машинного обучения в графическом интерфейсе пользователя с помощью различных источников данных, модулей манипулирования данными и проверки достоверности, а также алгоритмов машинного обучения. Эксперимент в ML Studio создается в виде направленного ациклического графа (DAG) модулей обработки данных.  

После того как эксперимент настроен и успешно запущен для обучения на основе данных, его можно сохранить в виде обученной модели и использовать для оценки. Затем обученная модель применяется в эксперименте оценки или в рабочем процессе и публикуется в виде веб-службы Azure.  

## Эксперимент обучения ##
Эксперимент может содержать различные модули для загрузки данных и манипулирования ими, применения алгоритмов машинного обучения и анализа результатов. Модель обучения использует набор обучающих данных и алгоритм обучения для прогнозирования ответа.  

Как только модель успешно выполнит свой рабочий цикл, модель обучения можно сохранить в виде повторно используемого компонента для оценки тестовых наборов данных и запросов.

![][2]  

Рис. 2: Пример сохранения обученной модели в эксперименте

После сохранения, обученная модель будет доступна в разделе обученных моделей приложения.

![][3]  

Рис. 3: раздел обученных моделей, где показан список моделей

## Эксперимент оценки ##
Эксперимент оценки формирует прогнозы с помощью обученной модели и образцами данных.  

На рис. 1 выше показано применение модели оценки в эксперименте. В Studio это является частью модулей "Машинное обучение".

![][4]  

Рис. 4: модель оценки 

### Сравнение службы запрос-ответ и службы пакетного выполнения ###
При формировании экспериментов оценки, которые будут опубликованы в виде веб-служб, в зависимости от сценария оценки может быть выбран любой эксперимент. Если запрос оценки будет включать в себя оценку одиночной записи, например, запрос, чтобы определить, собирается ли абонент A поменять оператора связи (прогноз текучести клиентов), то это может быть оценено в режиме реального времени и будет создано в качестве веб-службы RRS. Служба будет возвращать результат модели прогнозирования в режиме реального времени (в случае вышеупомянутого примера прогноза текучести клиентов результатом может быть "да" либо отсутствие ответа).  

Служба BES применяется для оценки операций, когда за один запрос необходимо оценить много записей (например, когда пакет записей, содержащих данные об абонентах, отправляется в службу, которую необходимо оценить). Запрос в этом случае будет асинхронным (все записи обрабатываются и сохраняются в большом двоичном объекте Azure перед возвращением ответа после выполнения всей обработки).  
  
### Использование обученной модели ###
Для создания эксперимента оценки в него будет добавлена обученная модель ("Прогнозатор дохода взрослых" на рис. 3). Другие модули, используемые для обучения обученной модели, можно сейчас удалить. Финальный рабочий процесс будет теперь иметь вид, который показан на рис. 5 ниже. 

### Входные и выходные порты ###
После настройки эксперимента с обученной моделью (см. раздел выше) и оценки обновленного эксперимента необходимо настроить входные и выходные порты, которые задают точки входа и выхода для данных в модели прогнозирования, а также результат прогноза и будут действовать как определения интерфейса для опубликованной веб-службы. Входной порт модели оценки можно настроить, как показано ниже, если щелкнуть правой кнопкой мыши точку входа.

![][5]  

Рис. 5: настройка входного порта оценки 

Аналогичным образом, можно настроить выходной порт модели оценки (как показано ниже).

![][6]  

Рис. 6: настройка выходного порта  

## Публикация службы ##
После настройки портов и выполнения эксперимента модель можно опубликовать в виде веб-службы. Сначала служба публикуется в промежуточной среде, а затем тестируется там (это позволяет убедиться, что она возвращает ожидаемые результаты). После этого служба считается готовой к производственному развертыванию.  

### Публикация в промежуточной среде ###
Если щелкнуть значок "Публикация веб-службы", веб-служба будет развернута в промежуточной среде. 

![][7]  

Рис. 7: кнопка "Публикация веб-службы"  

После публикации модели в качестве веб-службы в промежуточной среде ее можно протестировать с помощью входных параметров, а затем маркировать для развертывания в производственной среде. Панель мониторинга показывает ссылку для тестирования. 

![][8]  

Рис. 8: панель мониторинга веб-службы

Если щелкнуть ссылку для тестирования и предоставить параметры для оценки, то веб-службу можно будет протестировать в промежуточной среде. Тестовый запрос оценивается с помощью модели и основан на введенных данных. В ответ возвращается результат оценки. 

### Публикация в производственной среде ###
Публикация веб-службы в производственной среде позволяет сделать ее доступной для других приложений, которые смогут применять ее для прогнозирования и оценки. После успешного развертывания в промежуточной среде и тестирования веб-служба маркируется для развертывания в производственной среде. 

![][9]  

Рис. 9: маркировка готовности веб-службы к развертыванию в производственной среде

Эта операция не выполняет сам процесс развертывания, а создает уведомление для пользователю, который имеет соответствующие разрешения и может развернуть службу в производственной среде.

![][10]  

Рис. 10: уведомление о развертывании и возможность развертывания в производственной среде

## Вызов веб-службы ##
#### RRS ####
Веб-служба RRS является конечной точкой REST и может вызываться из клиентских приложений с помощью различных языков программирования. На странице справке API имеется ссылка на пример кода для вызова новой веб-службы с примерами на языках C#, R и Python.

![][11]  

Рис. 11: пример кода для вызова службы RRS  

## Эксперименты, не связанные с оценкой ##
Помимо формирования веб-служб оценки можно создавать эксперименты для выполнения других задач, например для извлечение данных и их преобразования. В этом случае веб-служба не будет выполнять операции машинного обучения. Она использует возможности манипулирования данными системы Azure ML Studio для чтения информации из различных источников информации, преобразования типов данных, их фильтрации и применения, а также математических операций.   

### Публикация веб-службы, не связанной с оценкой ###
Процедура публикации веб-службы, не связанной с оценкой, аналогична процедуре для службы оценки, описанной выше. Основным различием является то, что выходной порт в модели оценки не определен.

# Обновление опубликованной службы #
Опубликованную веб-службу может потребоваться обновить по разным причинам, например, вследствие обновления обучающих данных, изменения схемы данных, используемой для обучения и оценки, необходимости улучшения алгоритма или других изменений, вносимых в исходную модель машинного обучения. Такие изменения будут влиять как на обученную модель, так и на результаты оценки, и будут требовать публикации обновленной веб-службы.

![][12]  

Рис. 12: редактирование модели и публикация обновленной веб-службы оценки  

## Обновление обученной модели ##
Изменения, вносимые в эксперимент обучения, требуют повторного обучения обученной модели. Для этого может потребоваться редактирование опубликованной модели. В примере ниже показан рабочий процесс оценки (см. рис. 5 выше) после удаления существующей обученной модели.

![][13]  

Рис. 13: обученная модель удалена из рабочего процесса  

На следующем этапе будет нужно добавить необходимые модули для разделения данных на обучающие и тестовые сегменты, применения алгоритма обучения, обучения модели, оценки обучающих данных и анализа результатов. Следует отметить, что требуемые модули будут зависеть от других изменений, которые будет необходимо внести в эксперимент, например, применение другого алгоритма обучения. (рис. 14)  

Как только будут добавлены новые модули, их будет нужно настроить соответствующим образом и только потом повторно выполнить эксперимент. Например, красный круг в примере ниже указывает, что для модели обучения не был настроен столбец метки.

![][14]  

Рис. 14: модули, добавленные для повторного обучения модели.  

Если щелкнуть модель обучения и установить имя столбца "Метка", то проблема будет устранена. 

![][15]  

Рис. 15: выбор столбца дохода в качестве метки  

## Сохранение обновленной обученной модели ##
После корректной настройки всех новых модулей эксперимент следует сохранить и выполнить снова (эксперимент должен быть выполнен успешно). Затем модель обучения можно сохранить (как показано на рис. 2 выше). Разница состоит в том, что в данном случае для обновления существующей обученной модели необходимо установить соответствующий флажок. 

![][16]  

Рис. 16: обновление существующей обученной модели

## Публикация обновленной службы ##
После обновления обученной модели следует повторить процедуру, описанную в разделе выше (публикация **веб-службы Azure ML**).  

-	Использование (теперь обновленной) обученной модели в эксперименте оценки
-	Настройка портов ввода-вывода
-	Публикация в промежуточной среде
-	Публикация в производственной среде  

После обновления эксперимента, создания и оценки новой обученной модели щелкните "Публикация веб-службы" для публикации службы. Новая служба перезапишет текущую.


<!--Image references-->
[1]: ./media/machine-learning-overview-of-azure-ml-process/oamlp1.png
[2]: ./media/machine-learning-overview-of-azure-ml-process/oamlp2.png
[3]: ./media/machine-learning-overview-of-azure-ml-process/oamlp3.png
[4]: ./media/machine-learning-overview-of-azure-ml-process/oamlp4.png
[5]: ./media/machine-learning-overview-of-azure-ml-process/oamlp5.png
[6]: ./media/machine-learning-overview-of-azure-ml-process/oamlp6.png
[7]: ./media/machine-learning-overview-of-azure-ml-process/oamlp7.png
[8]: ./media/machine-learning-overview-of-azure-ml-process/oamlp8.png
[9]: ./media/machine-learning-overview-of-azure-ml-process/oamlp9.png
[10]: ./media/machine-learning-overview-of-azure-ml-process/oamlp10.png
[11]: ./media/machine-learning-overview-of-azure-ml-process/oamlp11.png
[12]: ./media/machine-learning-overview-of-azure-ml-process/oamlp12.png
[13]: ./media/machine-learning-overview-of-azure-ml-process/oamlp13.png
[14]: ./media/machine-learning-overview-of-azure-ml-process/oamlp14.png
[15]: ./media/machine-learning-overview-of-azure-ml-process/oamlp15.png
[16]: ./media/machine-learning-overview-of-azure-ml-process/oamlp16.png

<!--Link references-->
