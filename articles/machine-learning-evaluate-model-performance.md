<properties 
	pageTitle="Оценка эффективности модели в Машинном обучении Microsoft Azure | Azure" 
	description="Описание способов оценки эффективности модели в Машинном обучении Microsoft Azure." 
	services="machine-learning"
	documentationCenter="" 
	authors="bradsev" 
	manager="paulettm" 
	editor="cgronlun"/>

<tags 
	ms.service="machine-learning" 
	ms.workload="data-services" 
	ms.tgt_pltfrm="na" 
	ms.devlang="na" 
	ms.topic="article" 
	ms.date="03/11/2015" 
	ms.author="bradsev" />


# Оценка эффективности модели в Машинном обучении Microsoft Azure

В этом разделе показано, как оценивать эффективность модели в Студии машинного обучения Microsoft Azure. Также вы найдете здесь краткое описание показателей, доступных для этой задачи. Доступны три стандартных сценария управляемого обучения: 

* регрессия;
* двоичная классификация; 
* классификация по нескольким классам.


Оценка эффективности модели является одним из основных этапов процесса обработки и анализа данных. Она показывает, насколько успешно обученная модель обрабатывает (прогнозирует) набор данных. 

Оценка модели в Машинном обучении Azure основывается на двух основных модулях машинного обучения: **Модель оценки** и **Модель перекрестной проверки**. Эти модули позволяют видеть эффективность модели в пересчете на различные показатели, обычно используемые в машинном обучении и статистике.

##Сравнение оценки и перекрестной проверки##
Оценка и перекрестная проверка - это стандартные способы для измерения эффективности модели. Оба модуля генерируют показатели оценки, которые вы можете проверить или сравнить с показателями других моделей.

**Модель оценки** ожидает в качестве входных данных подсчитанный набор данных (или два таких набора, если нужно сравнить эффективность двух различных моделей). Это означает, что вы должны обучить свою модель с помощью модуля **Модель обучения** и сделать прогнозы насчет набора данных с помощью модуля **Модель подсчета**, прежде чем вы сможете оценить результаты. Оценка основывается на подсчитанных метках или вероятностях вместе с истинной меткой. Все эти значения являются результатом модуля **Модель подсчета**.

Кроме того, вы можете использовать перекрестную проверку, чтобы автоматически выполнить ряд операций "обучить-подсчитать-оценить" (10 сборок) для различных подмножеств входных данных. Входные данные делятся на 10 частей: одна резервируется для тестирования, а остальные 9 - для обучения. Этот процесс повторяется 10 раз, затем из показателей оценки выводится средняя величина. Эта процедура позволяет определить, насколько хорошо модель будет обобщаться на новых наборах данных. Модуль **Модель перекрестной проверки** берет необученную модель и несколько группированных наборов данных, а затем в дополнение к усредненным результатам выводит результаты оценки каждой из 10 сборок.

В следующих разделах мы построим простые модели регрессии и классификации и оценим их эффективность, используя модули **Модель оценки** и **Модель перекрестной проверки**.

##Оценка модели регрессии##
Предположим, мы хотим предсказать цену автомобиля, используя такие параметры, как размеры, мощность, характеристики двигателя и т. д. Это типичная задача регрессии, где целевой переменной (*цена*) является непрерывное числовое значение. Мы можем подобрать простую модель линейной регрессии, которая сможет прогнозировать цену автомобиля, учитывая значения параметров этого автомобиля. Эту модель регрессии можно использовать для подсчета того же набора данных, который использовался для обучения. После того как мы получим прогнозируемые цены на все автомобили, мы сможем оценить эффективность модели. Для этого мы сравним, насколько прогнозы отличаются от фактических цен в среднем. Для иллюстрации этого сценария возьмем набор данных  *Automobile price data (Raw) dataset*, доступный в разделе **Сохраненные базы данных** Студии машинного обучения Microsoft Azure.
 
###Создание эксперимента###
Добавьте следующие модули в рабочую область Студии машинного обучения Microsoft Azure:

- Данные о ценах на автомобили (необработанные)
- Линейная регрессия
- Модель обучения
- Модель подсчета
- Модель оценки


Соедините порты, как показано на рисунке 1 и установите для столбца "Метка" **модуля "Модель обучения"** значение *price*.
 
![Evaluating a Regression Model](media/machine-learning-evaluate-model-performance/1.png)

Рисунок 1. Оценка модели регрессии.

###Проверка результатов оценки###
После того как эксперимент проведен, щелкните выходной порт модуля **Модель оценки** и выберите *Visualize*, чтобы увидеть результаты оценки. Показатели оценки, доступные для моделей регрессии: *Mean Absolute Error*, *Root Mean Absolute Error*, *Relative Absolute Error*, *Relative Squared Error* и *Coefficient of Determination*.

Термин "ошибка" здесь означает разницу между прогнозируемым значением и истинным значением. Абсолютное значение или квадрат этой разницы обычно вычисляется, чтобы зафиксировать абсолютную величину ошибки во всех экземплярах, так как разница между прогнозируемым и истинным значением иногда может быть отрицательным числом. Показатели ошибки измеряют прогнозируемую эффективность модели регрессии с точки зрения среднего отклонения ее прогнозов от истинных значений. Чем ниже значения ошибок, тем более точно модель прогнозирует. Общий показатель ошибок 0 означает, что модель идеально подбирает данные.

Для определения способности модели подбирать данные также часто используется коэффициент детерминации, который также известен как R-квадрат. Его можно интерпретировать как пропорцию отклонений, которые объясняются моделью. В этом случае чем выше пропорция, тем лучше. Значение 1 означает идеальное совпадение.
 
![Linear Regression Evaluation Metrics](media/machine-learning-evaluate-model-performance/2.png)

Рисунок 2. Показатели оценки линейной регрессии.

###Использование перекрестной проверки###
Как уже упоминалось ранее, вы можете повторно выполнять обучение, подсчет и оценку автоматически с помощью модуля **Модель перекрестной проверки**. Для этого вам потребуются набор данных, необученная модель и модуль **Модель перекрестной проверки** (см. рисунок ниже). Не забудьте установить значение  *price* для столбца "Метка" в свойствах модуля **Модель перекрестной проверки**.

![Cross-Validating a Regression Model](media/machine-learning-evaluate-model-performance/3.png)

Рисунок 3. Перекрестная проверка модели регрессии.

После того как эксперимент проведен, вы можете проверить результаты оценки. Для этого щелкните правый выходной порт модуля **Модель перекрестной проверки**. Вы увидите подробное представление показателей для каждой итерации (сборки) и усредненные результаты каждого из показателей (рис. 4).
 
![Cross-Validation Results of a Regression Model](media/machine-learning-evaluate-model-performance/4.png)

Рисунок 4. Результаты перекрестной проверки модели регрессии.

##Оценка модели двоичной классификации##
При использовании двоичной классификации целевая переменная имеет только два возможных результата, например: {0, 1} или {ложь, истина}, {отрицательный, положительный}. Предположим, вы получили набор данных взрослых специалистов с некоторыми демографическими переменными и переменными их занятости. Вас просят предсказать уровень их доходов. Результат нужно выразить в виде, бинарной переменной со значениями {"<=50 000", ">50 000"}. Иными словами, отрицательный класс представляет специалистов, которые зарабатывают меньше 50 000 $ в год, а положительный класс представляет всех остальных специалистов. Как и в сценарии с регрессией, мы должны обучить модель, посчитать некоторые данные и оценивать результаты. Основным различием этого сценария будет показателей, которые вычисляет и выводит Машинное обучение Azure. Для иллюстрации сценария прогнозирования уровня доходов мы используем набор данных[Взрослые](http://archive.ics.uci.edu/ml/datasets/Adult), чтобы создать эксперимент Машинного обучения Azure и оценить эффективность в двухклассной регрессионной логистической модели, широко используемого двоичного классификатора.

###Создание эксперимента###
Добавьте следующие модули в рабочую область Студии машинного обучения Microsoft Azure:

- Набор данных Adult Census Income Binary Classification
- Двухклассная регрессионная логистическая модель
- Модель обучения
- Модель подсчета
- Модель оценки

Соедините порты, как показано на рисунке 5 и установите для столбца "Метка" модуля **Модель обучения** значение *income*.

![Evaluating a Binary Classification Model](media/machine-learning-evaluate-model-performance/5.png)

Рисунок 5. Оценка модели двоичной классификации.

###Проверка результатов оценки###
После того как эксперимент проведен, щелкните выходной порт модуля **Модель оценки** и выберите *Visualize*, чтобы увидеть результаты оценки (рис. 7). Показатели оценки, доступные для моделей двоичной классификации: *Accuracy*, *Precision*, *Recall*, *F1 Score* и *AUC*. Кроме того, модуль выводит матрицы неточностей, которые показывают количество истинно положительных, ложно отрицательных, ложно положительных и истинно отрицательных результатов, а также кривые  *ROC*, *Precision/Recall* и *Lift*.

Правильность выражается пропорцией правильно классифицированных экземпляров. Это, как правило, первый показатель, который вы видите во время оценки классификатора. Но если тестовые данные не сбалансированы (большинство экземпляров относятся к одному из классов) или вас больше интересует эффективность на одном из классов, правильность не будет отражать фактическую эффективность классификатора. Предположим, вы тестируете в сценарии классификации уровня дохода, данные, в которых 99 % экземпляров представляют людей, которые зарабатывают меньше или ровно 50 000 $ в год. Можно достичь уровня точности 0,99 путем прогнозирования класса "<=50K" для всех экземпляров. Кажется, что классификатор в целом хорошо справляется с заданием, но в действительности он не смог правильно классифицировать ни одно из лиц с высоким уровнем дохода (1 %).

Поэтому будет целесообразно вычислить дополнительные показатели, которые фиксируют более конкретные аспекты оценки. Прежде чем углубляться в подробности таких показателей, важно понять матрицу неточностей оценки двоичной классификации. Класс меток в обучающем множестве может принимать только 2 возможных значения, которые обычно называются положительным или отрицательным. Положительные и отрицательные экземпляры, которые классификатор прогнозирует правильно, называются истинно положительными (ИП) и истинно отрицательными (ИО) результатами соответственно. Точно так же неправильно классифицированные экземпляры называются ложно положительными (ЛП) и ложно отрицательными результатами (ЛО). Матрица неточностей - это таблица, которая показывает количество случаев, которые подпадают под каждую из этих четырех категорий. Машинное обучение Azure автоматически определяет, какой из двух классов в наборе данных является положительным классом. Если метки класса являются логическими операторами или целыми числами, то экземпляры с метками "истина" или "1" присваиваются положительному классу. Если метки являются строками, как в случае с набором данных о доходах, метки сортируются в алфавитном порядке. Первый уровень присваивается отрицательному классу, а второй уровень - положительному классу.

![Binary Classification Confusion Matrix](media/machine-learning-evaluate-model-performance/6a.png)

Рисунок 6. Матрица неточностей двоичной классификации.

Возвращаясь к проблеме классификации доходов, нужно задать несколько оценочных вопросов, которые помогут определить эффективность используемого классификатора. Вполне естественный вопрос: "Сколько лиц, которые по прогнозам модели зарабатывают > 50 000 $ (ИП + ЛП), были классифицированы правильно (ИП)?" На этот вопрос можно ответить, взглянув на показатель **Точность** модели, который представляет собой долю положительных результатов, классифицированных правильно: ИП/(ИП + ЛП). Другой распространенный вопрос: "Из всех высокооплачиваемых специалистов с доходом > 50 000 $ (ИП + ЛП) скольких классификатор классифицировал правильно (ИП)?" На самом деле это **Полнота** или процент истинно положительных результатов. ИП/(ИП + ЛП) классификатора. Вы могли заметить, что существует очевидный компромисс между точностью и полнотой. Например, обрабатывая относительно сбалансированный набор данных, классификатор, который прогнозирует в основном положительные экземпляры, будет иметь высокий уровень полноты, но довольно низкий уровень точности, так как многие отрицательные экземпляры будут неправильно классифицированы из-за большого количества ложно позитивных результатов. Чтобы увидеть график изменения этих двух показателей, щелкните кривую "ТОЧНОСТЬ/ПОЛНОТА" на странице вывода результатов оценки (верхняя левая часть рисунка 7).

![Binary Classification Evaluation Results](media/machine-learning-evaluate-model-performance/7.png)

Рисунок 7. Результаты оценки двоичной классификации.

Еще один похожий показатель, который часто используется, - это **Показатель F1**, который учитывает и точность и полноту. Это среднее гармоническое этих 2 показателей, которое вычисляется так: F1 = 2 (точность x полнота) / (точность + полнота). Показатель F1 - это удобный способ обобщения оценки в одно число. Но все-таки рекомендуется смотреть на точность и полноту вместе, чтобы лучше понять поведение классификатора.

Кроме того, можно увидеть процент истинно положительных результатов по сравнению с процентом ложно позитивных результатов на кривой **соотношений истинных и ложных результатов и ложного обнаружения сигналов** и соответствующее значение **площади под кривой**. Чем ближе эта кривая к верхнему левому углу, тем выше эффективность классификатора. То есть речь идет о максимальном проценте истинно положительных результатов и минимальном проценте ложно положительных результатов. Кривые, близкие к диагонали графика, получаются из классификаторов, которые, как правило, делают прогнозы, близкие к случайному угадыванию.

###Использование перекрестной проверки###
Как и в примере регрессии, мы можем выполнить перекрестную проверку, чтобы многократно обучить, посчитать и оценить разные подмножества данных автоматически. Подобным образом мы можем использовать модуль **Модель перекрестной проверки**, необученную регрессионную логистическую модель и набор данных В столбце "Метка" должно быть установлено значение *income* в свойствах модуля **Модель перекрестной проверки**. Если по завершении эксперимента щелкнуть правый порт вывода в модуле **Модель перекрестной проверки**, вы увидите значения показателей двоичной классификации для каждой сборки, а также среднее значение и стандартное отклонение каждого из них. 
 
![Cross-Validating a Binary Classification Model](media/machine-learning-evaluate-model-performance/8.png)

Рисунок 8. Перекрестная проверка модели двоичной классификации.

![Cross-Validation Results of a Binary Classifier](media/machine-learning-evaluate-model-performance/9.png)

Рисунок 9. Результаты перекрестной проверки модели двоичной классификации.

##Оценка модели классификации по нескольким классам##
В этом эксперименте мы будем использовать популярный набор данных [Iris](http://archive.ics.uci.edu/ml/datasets/Iris "Iris"), который содержит экземпляры 3 различных типов (классов) оболочки растения ирис. Для каждого экземпляра существует 4 значения признаков: длина и ширина чашелистика и длина и ширина лепестка. В предыдущих экспериментах мы обучали и тестировали модели, используя те же наборы данных. Здесь мы будем использовать модуль разделения, чтобы создать 2 подмножества данных: первый набор данных будем обучать, а второй - подсчитывать и оценивать. 
Набор данных Iris находится в открытом доступе в [Репозитории машинного обучения UCI](http://archive.ics.uci.edu/ml/index.html). Его можно скачать с помощью модуля **Читатель**.

###Создание эксперимента###
Добавьте следующие модули в рабочую область Студии машинного обучения Microsoft Azure:

- Читатель
- Лес решений с несколькими классами
- Разделение
- Модель обучения
- Модель подсчета
- Модель оценки

Соедините порты, как показано на рисунке 10.

Установите значение 5 для индекса столбца "Метка" в модуле "Модель обучения". У этого набора данных нет строки заголовка, но мы знаем, что этикетки находятся в пятом столбце.

Щелкните модуль **Читатель** и установите для свойства *Data source* значение *Web URL via HTTP*, а для параметра  *URL* укажите значение http://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data.

Укажите дробное число экземпляров, которые будут использоваться для обучения модуля **Разделение** (например, 0,7).
 
![Evaluating a Multiclass Classifier](media/machine-learning-evaluate-model-performance/10.png)

Рисунок 10. Оценка классификатора с несколькими классами

###Проверка результатов оценки###
Запустите эксперимент и щелкните порт вывода в модуле **Модель оценки**. В этом случае результаты оценки представлены в виде матрицы неточностей. Матрица показывает фактические экземпляры по сравнению с прогнозируемыми для всех 3 классов.
 
![Multiclass Classification Evaluation Results](media/machine-learning-evaluate-model-performance/11.png)

Рисунок 11. Результаты оценки классификации по нескольким классам.

###Использование перекрестной проверки###
Как уже упоминалось ранее, вы можете повторно выполнять обучение, подсчет и оценку автоматически с помощью модуля **Модель перекрестной проверки**. Вам потребуется набор данных, необученная модель и модуль **Модель перекрестной проверки** см рисунок ниже) Снова нужно установить значение для столбца "Метка" в модуле **Модель перекрестной проверки** (в данном случае индекс столбца = 5). Если по завершении эксперимента щелкнуть правый порт вывода в модуле **Модель перекрестной проверки**, вы увидите значения показателей для каждой сборки, а также среднее значение и стандартное отклонение. Отображаемые здесь показатели похожи на показатели, о которых шла речь в разделе, посвященном двоичной классификации. Но обратите внимание, что в классификации по нескольким классам истинно положительные/отрицательные результаты и ложно положительные/отрицательные результаты вычисляются путем подсчета на основе каждого класса, так как не существует общего положительного или отрицательного класса. Например, при расчете точности или полноты класса "Ирис щетинистый" предполагается, что это положительный класс, а все остальные являются отрицательными.
 
![Cross-Validating a Multiclass Classification Model](media/machine-learning-evaluate-model-performance/12.png)

Рисунок 12. Перекрестная проверка модели классификации по нескольким классам.


![Cross-Validation Results of a Multiclass Classification Model](media/machine-learning-evaluate-model-performance/13.png)

Рисунок 13. Результаты перекрестной проверки модели классификации по нескольким классам.

<!--HONumber=49-->