<properties
   pageTitle="Настройка производительности запросов и объединения данных с помощью Elasticsearch в Azure | Microsoft Azure"
   description="Набор рекомендаций по оптимизации производительности поисковых операций и запросов для Elasticsearch."
   services=""
   documentationCenter="na"
   authors="mabsimms"
   manager="marksou"
   editor=""
   tags=""/>

<tags
   ms.service="guidance"
   ms.devlang="na"
   ms.topic="article"
   ms.tgt_pltfrm="na"
   ms.workload="na"
   ms.date="02/18/2016"
   ms.author="masimms"/>
   
# Настройка производительности запросов и объединения данных с помощью Elasticsearch в Azure

Этот материал входит в [цикл статей, посвященных вопросам Elasticsearch](guidance-elasticsearch.md).

Elasticsearch обеспечивает поддержку поиска в данных, что является основной причиной использования этого решения. Пользователи должны иметь возможность быстро находить искомую информацию. Кроме того, система должна предоставлять возможность задавать вопросы о данных, искать корреляции и принимать бизнес-решения на основе анализа. Все это позволяет превратить простую информацию в ценные данные.

В этом документе описаны рекомендации, которые следует учитывать при выборе метода оптимизации производительности поисковых операций и запросов в системе.

Все рекомендации по повышению производительности в значительной мере зависят от сценариев, которые применимы в конкретном случае, объема индексируемых данных, а также скорости, с которой приложения и пользователи запрашивают данные. Чтобы оценить преимущества для конкретных сценариев, следует тщательно проверять результаты любого изменения конфигурации или структуры индексирования, используя собственные данные и рабочие нагрузки. В связи с этим здесь также описывается ряд тестов производительности, выполненных для одного конкретного сценария с разными конфигурациями. Вы можете адаптировать использованный подход для оценки производительности собственных систем.

## Рекомендации по повышению производительности индексирования и запросов

В этом разделе приведены некоторые распространенные факторы, которые следует учитывать при проектировании индексов, которые должны поддерживать быстрое выполнение поисковых операций и запросов.

### Использование одного индекса для нескольких типов данных

В индекс Elasticsearch можно добавлять данные разного типа. Тем не менее рекомендуется создавать отдельный индекс для каждого типа. Учтите следующие моменты.

- Для разных типов могут указываться разные анализаторы, поэтому не всегда понятно, какой из них следует использовать Elasticsearch, если запрос выполняется на уровне индекса, а не на уровне типа. Дополнительные сведения см. в разделе [Avoiding Type Gotchas](https://www.elastic.co/guide/en/elasticsearch/guide/current/mapping.html#_avoiding_type_gotchas) (Сложности при использовании разных типов).

- Сегменты индексов, содержащих несколько типов, скорее всего, будут больше сегментов индексов с одним типом. При выполнении запросов размер сегмента играет немалую роль: чем больше сегмент, тем больше усилий требуется Elasticsearch для фильтрации данных.

- Если объемы данных разных типов слишком отличаются, данные одного типа могут фрагментарно распределиться по нескольким сегментам, что снижает эффективность операций поиска, извлекающих эти данные.

![](./media/guidance-elasticsearch/query-performance1.png)

***Рис. 1. Результаты использования одного индекса для разных типов***

Рис. 1 демонстрирует этот сценарий. В верхней части схемы представлено использование одного индекса для документов типа А и Б. Документов типа А намного больше. Тем не менее при поиске последних будут запрашиваться все четыре сегмента. В нижней части схемы показан результат при создании отдельных индексов для каждого типа. В этом случае при поиске документов типа А требуется доступ только к двум сегментам.

Если сегменты небольшие, данные распределяются более равномерно, что упрощает распределение нагрузки между узлами для Elasticsearch.

Различные типы могут иметь разные сроки хранения. Поэтому архивация старых данных, которые размещены в одних сегментах с активными данными, может оказаться непростой задачей.

Тем не менее использование одного индекса для разных типов может предоставлять преимущества, если:

- при поиске постоянно запрашиваются разные типы, содержащиеся в одном индексе;

- количество документов каждого типа небольшое. Обработка отдельного набора сегментов для каждого типа может создать значительную нагрузку.

### Оптимизация типов индексов

Индекс Elasticsearch содержит копию исходных документов JSON, которые использовались для его заполнения. Они хранятся в поле [*\_source*](https://www.elastic.co/guide/en/elasticsearch/reference/current/mapping-source-field.html#mapping-source-field) каждого индексированного элемента. Эти данные недоступны для поиска, но они возвращаются по умолчанию при выполнении запросов *get* и *search*. Тем не менее данные, хранящиеся в этом поле, повышают нагрузку и занимают место, из-за чего увеличивается размер сегментов и объем операций ввода-вывода. Поле *\_source* можно отключить по отдельности для каждого типа:

```http
PUT my_index
{
    "mappings": {
		"my_type": {
			"_source": {
				"enabled": false
			}
		}
	}
}
```

Отключение этого поля исключает возможность выполнять следующие операции:

- обновление данных в индексе с помощью API *обновления*;
- выполнение операций поиска, возвращающих выделенные данные;
- повторная индексация из одного индекса Elasticsearch непосредственно в другой;
- изменение сопоставлений или параметров анализа;
- отладка запросов путем просмотра исходного документа.
 
### Повторная индексация данных

Количество доступных для индекса сегментов в конечном счете определяет его емкость. Можно изначально предположить (учитывая конкретный случай), сколько сегментов потребуется, но всегда следует заранее рассматривать стратегию повторного индексирования документа. Во многих случаях повторное индексирование следует планировать с учетом увеличения объема данных. В целях оптимизации поиска изначально можно не выделять большое количество сегментов для индекса и вместо этого выделять новые сегменты по мере увеличения объема данных. Иногда, если оценка увеличения объема данных оказалась неточной, повторное индексирование необходимо выполнять по ходу.

> [AZURE.NOTE] Повторная индексация может быть необязательна для данных, которые быстро устаревают. В этом случае приложение может создавать новый индекс для каждого периода времени. Такими данными могут быть, например, журналы производительности или данные аудита, которые каждый день можно сохранять в новом индексе.

По сути, повторная индексация представляет собой создание нового индекса на основе данных в старом индексе и последующее удаление старого индекса. Если индекс большой, этот процесс может занять некоторое время. При необходимости в течение этого периода следует обеспечить доступность данных для поиска. По этой причине следует создать [псевдоним для каждого индекса](https://www.elastic.co/guide/en/elasticsearch/reference/current/indices-aliases.html) и настроить получение запрашиваемых данных с использованием этих псевдонимов. При повторной индексации укажите псевдоним старого индекса, а по завершении этой процедуры замените его на новый индекс. Этот подход также удобен для доступа к данным на основе времени, для которых создается новый индекс каждый день. Для доступа к текущим данным следует использовать псевдоним, который меняется на псевдоним нового индекса при его создании.

### Управление сопоставлениями

В Elasticsearch сопоставления используются, чтобы определить способ интерпретации данных в каждом поле документа. Каждый тип имеет свои собственные сопоставления, что фактически определяет его схему. Elasticsearch использует эти сведения для создания обращенных индексов для каждого поля в документах типа. В любом документе каждое поле имеет тип данных (например, *строка*, *дата* или *длинное целое*) и значение. Сопоставления можно самостоятельно задать при создании индекса. Кроме того, они могут быть выведены в Elasticsearch при добавлении новых документов в тип. Тем не менее необходимо учитывать следующие моменты.

- Сопоставления, созданные динамически, могут привести к ошибкам в зависимости от способа интерпретации полей при добавлении документов в индекс. Например, документ 1 содержит поле А с числом, а Elasticsearch добавляет сопоставление, которое указывает, что тип этого поля — *длинное целое*. Если в следующем добавляемом документе поле А содержит нечисловые данные, произойдет сбой. В этом случае при добавлении первого документа тип поля А, вероятно, нужно было интерпретировать, как "строка". Этих проблем можно избежать, указав это сопоставление при создании индекса.

- При создании документов следует учитывать, что слишком большие сопоставления вызывают значительную нагрузку во время операций поиска, занимают большой объем памяти и приводят к отрицательному результату поисковых запросов. Используйте единое соглашение об именовании для полей документов одного типа. К примеру, не используйте в документах разные варианты имени поля, такие как first\_name, FirstName и forename. Используйте одинаковое имя во всех документах. Кроме того, не следует использовать значения в качестве ключей (это распространенный подход в базах данных, состоящих из групп столбцов, однако он может привести к снижению эффективности и сбоям при использовании с Elasticsearch). Дополнительные сведения см. в разделе [Mapping Explosion](https://www.elastic.co/blog/found-crash-elasticsearch#mapping-explosion) (Избыточное сопоставление).

- При необходимости используйте значение *not\_analyzed*, чтобы избежать разметки. Например, если в документе содержится строковое поле *data* со значением ABC-DEF, можно попытаться выполнить поиск всех документов, соответствующих этому значению следующим образом:

```http
GET /myindex/mydata/_search
{
	"query" : {
		"filtered" : {
			"filter" : {
				"term" : {
					"data" : "ABC-DEF"
				}
			}
		}
	}
}
```

Однако этот поиск завершится сбоем из-за того, как была размечена строка ABC-DEF при индексировании. Она будет разделена на два маркера — ABC и DEF (по дефису). Эта функция предназначена для поддержки полнотекстового поиска, но если необходимо, чтобы строка интерпретировалась как единый атомарный элемент, отключите разметку при добавлении документа в индекс. Можно использовать такое сопоставление:

```http
PUT /myindex
{
	"mappings" : {
		"mydata" : {
			"properties" : {
				"data" : {
					"type" : "string",
					"index" : "not_analyzed"
				}
			}
		}
	}
}
```

Дополнительные сведения см. в статье [Finding Exact Values](https://www.elastic.co/guide/en/elasticsearch/guide/current/_finding_exact_values.html#_term_filter_with_text) (Поиск точных значений).

### Использование значений doc values

При выполнении большинства запросов и операций объединения требуется, чтобы данные были отсортированы в рамках операции поиска. Для сортировки необходима возможность сопоставления одного или несколько значений со списком документов. Чтобы упростить этот процесс, Elasticsearch может загрузить все значения поля, используемого в качестве ключа сортировки, в память. Эти данные называются *fielddata*. Кэширование fielddata в памяти позволяет сократить число операций ввода-вывода. Кроме того, это может быть быстрее, чем многократное считывание одних и тех же данных с диска. Тем не менее если поле поддерживает большое количество элементов, данные fielddata, сохраненные в памяти, могут потреблять большой объем пространства кучи, что, вероятно, повлияет на возможность выполнения других одновременных операций или вызовет сбой Elasticsearch из-за переполнения хранилища.

В качестве альтернативного подхода Elasticsearch также поддерживает значения *doc values*. Эти значения подобны элементу fielddata в памяти, за исключением того, что они хранятся на диске и создаются, когда данные сохраняются в индексе (fielddata создаются динамически при выполнении запроса). doc values не потребляют пространство кучи. Поэтому их удобно использовать для запросов, которые сортируют или объединяют данные в полях, которые могут содержать большое количество уникальных значений. Кроме того, благодаря уменьшению нагрузки на кучу может сократиться разница между производительностью получения данных с диска и считывания их из памяти, сбор мусора будет выполняться реже, а также уменьшится степень влияния на другие одновременные операции, которые используют память.

Чтобы включить или отключить значения doc values, в индексе необходимо задать соответствующее значение атрибута *doc\_values* в разделе свойств, как показано ниже:

```http
PUT /myindex
{
	"mappings" : {
		"mydata" : {
			"properties" : {
				"data" : {
					...
				"doc_values": true
				}
			}
		}
	}
}
```

> [AZURE.NOTE] Атрибут doc\_values активирован по умолчанию в Elasticsearch 2.0.0 и более поздней версии.

Эффективность использования этого атрибута, скорее всего, сильно зависит от конкретных данных и сценариев запросов. Чтобы точно определить, подходит ли вам этот метод, понадобится провести тестирование производительности. Следует также отметить, что значения doc values не поддерживают проанализированные строковые поля. Дополнительные сведения см. в статье [Doc Values](https://www.elastic.co/guide/en/elasticsearch/guide/current/doc-values.html#doc-values) (Формат doc\_values).

### Использование клиентских узлов

Все запросы обрабатывает первый узел, который их получает. Этот узел отправляет дальнейшие запросы на все узлы, содержащие сегменты запрашиваемых индексов, а затем собирает результаты, чтобы вернуть ответ. Если запрос включает в себя объединение данных или выполнение сложных вычислений, за соответствующую обработку отвечает начальный узел. Если требуется поддержка относительно небольшого числа сложных запросов, можно создать пул клиентских узлов, чтобы снизить нагрузку на узлы данных. И наоборот, если необходимо обрабатывать большое количество простых запросов, отправляйте эти запросы прямо в узлы данных и используйте балансировщик нагрузки для их равномерного распределения.

### Использование реплик для уменьшения количества конфликтов из-за запросов

Распространенный метод повышения производительности запросов заключается в создании большого числа реплик каждого индекса. Таким образом, при запросе данные будут извлекаться из реплик. Тем не менее использование этого метода может существенно ухудшить производительность операций приема данных, поэтому в сценариях со смешанными рабочими нагрузками его следует использовать с осторожностью. Если же реплики распределены между узлами и не конкурируют за ресурсы с основными сегментами, которые являются частью одного индекса, этот метод достаточно эффективный. Помните, что можно динамически увеличивать и уменьшать число реплик для индекса.

### Кэширование запросов к сегментам

Elasticsearch может кэшировать в память запрашиваемые локальные данные в каждом сегменте. Таким образом запросы, которые получают доступ к одним и тем же данным, выполняются быстрее, так как данные можно получать из памяти, а не с диска. Данные в кэше становятся недействительны, как только сегмент обновляется и данные изменяются. Частота обновления соответствует значению параметра индекса *refresh\_interval*. По умолчанию кэширование запросов к сегментам для индекса отключено, но его можно включить следующим образом:

```http
PUT /myindex/_settings
{
	"index.requests.cache.enable": true
}
```

Кэширование запросов к сегментам наиболее эффективно использовать по отношению к относительно статичным данным, например историческим данным или данным журнала.

## Тестирование и анализ производительности операций объединения и поиска
В этом разделе описаны результаты тестов, выполненных для кластеров и индексов в различных конфигурациях. При запуске каждого теста индекс был пустой. Затем он заполнялся по мере выполнения операций массовой вставки (в результате каждой операции добавлялась 1000 документов). В то же время каждые 5 секунд выполнялись запросы для поиска конкретных данных и создания сводных данных. Целью тестов было определить влияние объема данных на производительность запросов.

У всех документов в индексе была одинаковая схема. В следующей таблице перечислены поля в схеме:

 Имя | Тип | Примечания |
  ----------------------------- | ------------ | -------------------------------------------------------- |
 План | Строка | В рамках теста создается 200 уникальных организаций. |
 CustomField1–CustomField5 |Строка |Это пять строковых полей, для которых задается пустая строка.|
 DateTimeRecievedUtc |Timestamp |Дата и время добавления документа.|
 Узел |Строка |Для этого поля задается пустая строка.|
 HttpMethod |Строка |Для этого поля задается одно из следующих значений: POST, GET, PUT.|
 HttpReferrer |Строка |Для этого поля задается пустая строка.|
 HttpRequest |Строка |Это поле заполняется произвольным текстом длиной от 10 до 200 символов.|
 HttpUserAgent |Строка |Для этого поля задается пустая строка.|
 HttpVersion |Строка |Для этого поля задается пустая строка.|
 OrganizationName |Строка |Для этого поля задается значение поля Organization.|
 SourceIp |IP-адрес |Это поле содержит IP-адрес, указывающий на источник данных. |
 SourceIpAreaCode |Длинное целое |Для этого поля задается значение 0.|
 SourceIpAsnNr |Строка |Для этого поля задается значение "AS#####".|
 SourceIpBase10 |Длинное целое |Для этого поля задается значение 500.|
 SourceIpCountryCode |Строка |Это поле содержит двухзначный код страны. |
 SourceIpCity |Строка |Это поле содержит строку, определяющую город в стране. |
 SourceIpLatitude |Double |Это поле содержит случайное значение.|
 SourceIpLongitude |Double |Это поле содержит случайное значение.|
 SourceIpMetroCode |Длинное целое |Для этого поля задается значение 0.|
 SourceIpPostalCode |Строка |Для этого поля задается пустая строка.|
 SourceLatLong |Географическая точка |Для этого поля задается случайная географическая точка.|
 SourcePort |Строка |В этом поле указывается случайное число в виде строки.|
 TargetIp |IP-адрес |Это поле заполняется случайным IP-адресом в диапазоне 0.0.100.100–255.9.100.100.|
 SourcedFrom |Строка |Для этого поля задается строка MonitoringCollector.|
 TargetPort |Строка |В этом поле указывается случайное число в виде строки.|
 Rating |Строка |Это поле заполняется одним из 20 разных строковых значений, которое выбирается случайным образом.|
 UseHumanReadableDateTimes |Логический |Для этого поля задается значение false.|

Ниже представлены запросы, которые выполнялись в составе пакетной операции при каждой итерации теста (в остальной части статьи для ссылки на эти запросы будут использоваться имена, выделенные курсивом):

- Сколько документов с каждым значением поля *Rating* введены за последние 15 минут (*число по оценке*)?

- Сколько документов добавлены в течение каждого 5-минутного интервала за последние 15 минут (*число по времени*)?

- Сколько документов с каждым значением поля *Rating* добавлены для каждой страны за последние 15 минут (*число по странам*)?

- Какие 15 организаций наиболее часто встречаются в документах, добавленных за последние 15 минут (*15 самых распространенных организаций*)?

- Сколько разных организаций встречаются в документах, добавленных за последние 15 минут (*число уникальных организаций*)?

- Сколько документов добавлены за последние 15 минут (*общее число добавлений*)?

- Сколько разных значений *SourceIp* встречаются в документах, добавленных за последние 15 минут (*число уникальных IP-адресов*)?

Тесты выполнены, чтобы определить влияние следующих переменных:

- **Тип диска**. Тест выполнен на шестиузловом кластере с виртуальными машинами серии D4 на базе стандартного хранилища (жесткие диски) и на шестиузловом кластере с виртуальными машинами серии DS4 на базе хранилища класса Premium (SSD).

- **Увеличение размера виртуальной машины**. Тест выполнен на шестиузловом кластере, состоящем из виртуальных машин серии DS3 (*небольшой* кластер), а затем на таком же кластере с виртуальными машинами серии DS4 (*средний* кластер) и виртуальными машинами серии DS14 (*большой* кластер). В следующей таблице приведены основные характеристики виртуальной машины для каждого SKU:

HDInsight |SKU виртуальной машины |Количество ядер |Количество дисков данных |ОЗУ (ГБ)|
--------- |--------------- |----------------- |---------------------- |--------|
Малый |Standard DS3 |4 |8 |14 |
Средний |Standard DS4 |8 |16 |28 |
Крупный |Standard DS14 |16 |32 |112 |

- **Значения doc values**. Изначально при выполнении тестов для параметра индекса *doc\_values* было задано значение *true*. Затем для выполнения некоторых тестов значение *doc\_values* было изменено на *false*.

## Результаты производительности по типу диска

В таблице ниже приведено время отклика операций в рамках теста на шестиузловом кластере с виртуальными машинами серии D4 (с использованием HDD) и серии DS4 (с использованием SSD). Конфигурация Elasticsearch в обоих кластерах была одинаковой. Данные были распределены по 16 дискам на каждом узле. Для виртуальной машины Java, где был запущен Elasticsearch, на каждом узле было выделено 14 ГБ ОЗУ. Оставшийся объем памяти (также 14 ГБ) предназначался для операционной системы. Каждый тест выполнялся в течение 24 часов. Этого периода достаточно, чтобы влияние увеличения объема данных стало очевидным, а система стабилизировалась:

 HDInsight |Операции и запросы |Среднее время отклика (мс)|
 -----------|---------------------------- |--------------------------|
 D4 |Прием |978 |
 |Число по оценке |103 |
 |Число по времени |134 |
 |Число по странам |199 |
 |15 самых распространенных организаций |137 |
 |Число уникальных организаций |139 |
 |Число уникальных IP-адресов |510 |
 |Общее число добавлений |89 |
 DS4 |Прием |511 |
 |Число по оценке |187 |
 |Число по времени |411 |
 |Число по странам |402 |
 |15 самых распространенных организаций |307 |
 |Число уникальных организаций |320 |
 |Число уникальных IP-адресов |841 |
 |Общее число добавлений |236 |

На первый взгляд можно предположить, что кластер DS4 выполнил намного меньше запросов, чем кластер D4, и в некоторых случаях время отклика было в два раза больше (или хуже). Однако еще рано делать окончательные выводы. В следующей таблице приведено число операций приема на каждый кластер (при каждой операции загружается 1000 документов):

 HDInsight | Операции приема
 ----------|---------------------
 D4 | 264 769              
 DS4 | 503 157              

Во время теста кластер DS4 загрузил почти вдвое больше данных, чем кластер D4. Таким образом, при анализе времени отклика для каждой операции следует также учитывать, сколько документов проверяется во время каждого запроса и сколько документов возвращаются.

Это динамические показатели, так как объем документов в индексе постоянно увеличивается. Чтобы определить сравнительные показатели, нельзя просто разделить 503 137 на 264 769 (число операций приема для каждого кластера), а затем умножить результат на среднее время отклика для каждого запроса, выполненного кластером D4, так как при этом не учитывается число одновременных операций ввода-вывода, выполняемых во время приема.

Вместо этого необходимо определить физический объем данных, записываемых на диск и считываемых из него, во время выполнения теста. План тестирования JMeter позволяет получить эти сведения для каждого узла. Сводные результаты приведены в таблице ниже.

 HDInsight |Среднее число записанных и считанных байт по каждой операции|
  --------- |--------------------------------------------|
 D4 |13 471 557 |
 DS4 |24 643 470 |

Согласно этим показателям, кластер DS4 поддерживал скорость ввода-вывода, которая приблизительно в 1,8 раз превышает этот показатель по кластеру D4. Учитывая то, что все остальные ресурсы одинаковые, эта разница должна быть связана с используемыми дисками (SSD и жесткие диски).

Чтобы обосновать это предположение, на следующих графиках показано, как выполнялись операции ввода-вывода с течением времени для каждого кластера:

![](./media/guidance-elasticsearch/query-performance2.png)

На графике для кластера D4 видны значительные отличия, особенно во время первой части теста. Вероятно, это обусловлено регулированием, выполняемым для снижения скорости ввода-вывода. На начальных стадиях тестирования запросы обрабатываются быстро, так как объем данных для анализа небольшой. Поэтому диски в кластере D4, скорее всего, функционировали на грани предела операций ввода-вывода, несмотря на то, что не каждая такая операция возвращала большой объем данных. Кластер DS4 может поддерживать высокую скорость операций ввода-вывода без существенного увеличения степени регулирования, при этом скорость операций ввода-вывода более постоянная.

Для иллюстрации этой теории на следующих графиках показано, как операции ввода-вывода диска время от времени блокировали ЦП (время ожидания диска, показанное на графиках, — это промежуток времени, когда ЦП ожидал ввода-вывода).

![](./media/guidance-elasticsearch/query-performance3.png)

Важно понимать, что в этом сценарии тестирования есть две основные причины, по которым операции ввода-вывода блокировали ЦП.

- Считывание данных с диска или их запись на диск подсистемой ввода-вывода.

- Регулирование подсистемы ввода-вывода в среде размещения. Максимальная пропускная способность дисков Azure на базе стандартного хранилища — 500 операций ввода-вывода, а дисков на базе хранилища класса Premium — 5000 операций ввода-вывода.

Для кластера D4 время ожидания операций ввода-вывода во время первой части теста в обратном порядке соотносится со скоростью операций ввода-вывода. Периоды низкой скорости операций ввода-вывода соответствуют длительным периодам, в течение которых ЦП был заблокирован.

Это означает, что операции ввода-вывода регулируются. По мере добавления большего количества данных в кластер ситуация меняется, и во время второй части теста пики времени ожидания операций ввода-вывода соответствуют пикам пропускной способности ввода-вывода. На этом этапе ЦП блокируется, чтобы выполнить фактические операции ввода-вывода. Опять же, при использовании кластера DS4 время ожидания операций ввода-вывода гораздо более равномерное и каждый пик совпадает с эквивалентным пиком производительности ввода-вывода, а не достигается за счет ухудшения показателя последнего. Это значит, что регулирования практически или совсем не происходит.

Есть еще один фактор, который следует рассмотреть. При тестировании кластера D4 возникли 10 584 ошибки приема и 21 ошибка запроса. При тестировании кластера DS4 никакие ошибки не наблюдались.

## Результаты производительности в зависимости от размера

В таблице ниже приведены результаты тестирования для среднего (DS4) и большого (DS14) кластеров. Для хранения данных в каждой виртуальной машине использовались SSD. Каждый тест выполнялся в течение 24 часов.

| HDInsight |Операции и запросы |Количество запросов |Среднее время отклика (мс)|
|  -------------- |---------------------------- |-------------------- |--------------------------|
| Средний (DS4) |Прием |503 157 |511 |
| |Число по оценке |6958 |187 |
| |Число по времени |6958 |411 |
| |Число по странам |6958 |402 |
| |15 самых распространенных организаций |6958 |307 |
| |Число уникальных организаций |6956 |320 |
| |Число уникальных IP-адресов |6955 |841 |
| |Общее число добавлений |6958 |236 |
| Большой (DS14) |Прием |502 714 |511 |
| |Число по оценке |7041 |201 |
| |Число по времени |7040 |298 |
| |Число по странам |7039 |363 |
| |15 самых распространенных организаций |7038 |244 |
| |Число уникальных организаций |7037 |283 |
| |Число уникальных IP-адресов |7037 |681 |
| |Общее число добавлений |7038 |200 |

<!-- 
DISCUSSION POINTS:

Similar volume of data ingested – same disk configuration for each cluster, and ingestion rate is 
constrained by I/O performance?

Average response time for queries decreases with SKU.

Show CPU graphs

Show memory utilization – more data cached, fewer GCs, etc.

-->

<!--
To isolate the effects of the ingestion operations and show how query performance varies as nodes scale up, a second set of tests was performed using the same nodes. The ingestion part of the test was omitted, and the index on each node was pre-populated with 100 million documents. An amended set of queries was performed; the time element limiting documents to those added in the last 15 minutes was removed as the data was now static. The tests ran for 90 minutes; there is less need to allow the system to stabilize due to the fixed amount of data. The following table summarizes the results obtained on each cluster:

> [AZURE.NOTE] The amended version of the test that omits the data ingestion process and that uses a set of indexes containing 100 million documents is referred to as the *query-only* test in the remainder of this document. You should not compare the performance of the queries in this test with that of the tests that perform ingestion and query operations because the queries have been modified and the volume of documents involved is different.

 |Cluster        |Operation/Query              |Number of Requests   Average Response Time (ms)
 | --------------| ----------------------------| -------------------- ----------------------------
 | Small (DS3)   | Count By Rating             |                      
 |               | Count Over Time             |                      
 |               | Hits By Country             |                      
 |               | Top 15 Organizations        |                      
 |               | Unique Count Organizations  |                      
 |               | Unique IP Count             |                      
 |               | Total Hits Counts           |                      
 | Medium (DS4)  | Count By Rating             |                      
 |               | Count Over Time             |                      
 |               | Hits By Country             |                      
 |               | Top 15 Organizations        |                      
 |               | Unique Count Organizations  |                      
 |               | Unique IP Count             |                      
 |               | Total Hits Counts           |                      
 | Large (DS14)  | Count By Rating             |                      
 |               | Count Over Time             |                      
 |               | Hits By Country             |                      
 |               | Top 15 Organizations        |                      
 |               | Unique Count Organizations  |                      
 |               | Unique IP Count             |                      
 |               | Total Hits Counts           |                      

### Performance Results – Scaling Out
-->


<!--
To show the system scales out with the number of nodes, tests were run using DS14 clusters comprising 1, 3, and 6 nodes. This time, only the query-only test was performed, using 100 million documents and running for 90 minutes:

> [AZURE.NOTE] For detailed information on how scaling out can affect the behavior of data ingestion operations, see the document [Maximizing Data Ingestion Performance with Elasticsearch on Azure](https://github.com/mspnp/azure-guidance/blob/master/Elasticsearch-Data-Ingestion-Performance.md).

|  Cluster   |Operation/Query              |Number of Requests   |Average Response Time (ms)
|  --------- |---------------------------- |-------------------- |----------------------------
|  1 Node    |Count By Rating              |                     |
|            |Count Over Time              |                     |
|            |Hits By Country              |                     |
|            |Top 15 Organizations         |                     |
|            |Unique Count Organizations   |                     |
|            |Unique IP Count              |                     |
|            |Total Hits Counts            |                     |
|  3 Nodes   |Count By Rating              |                     |
|            |Count Over Time              |                     |
|            |Hits By Country              |                     |
|            |Top 15 Organizations         |                     |
|            |Unique Count Organizations   |                     |
|            |Unique IP Count              |                     |
|            |Total Hits Counts            |                     |
|  6 Nodes   |Count By Rating              |                     |
|            |Count Over Time              |                     |
|            |Hits By Country              |                     |
|            |Top 15 Organizations         |                     |
|            |Unique Count Organizations   |                     |
|            |Unique IP Count              |                     |
|            |Total Hits Counts            |                     |
-->

<!--
### Performance Results – Number of Replicas

The ingestion and query tests were run against an index with a single replica. The tests were repeated on the 6-node DS4 and DS14 clusters using an index configured with two replicas. All tests ran for 24 hours. The table below shows the comparative results for one and two replicas:

|  Cluster|  Operation/Query            | response time 1 Replica (ms)| response time 2 Replicas (ms) | % Difference in Response Time
|  -------| ----------------------------| ----------------------------|----------- -------------------|--------------------- --------
|  DS4    |   Ingestion                 |   511                       |               655             |                          +28%
|         |   Count By Rating           |   187                       |               168             |                          -10%
|         |   Count Over Time           |   411                       |               309             |                          -25%
|         |   Hits By Country           |   402                       |               562             |                          +40%
|         |   Top 15 Organizations      |   307                       |               366             |                          +19%
|         |   Unique Count Organizations|   320                       |               378             |                          +18%
|         |   Unique IP Count           |   841                       |               987             |                          +17%
|         |   Total Hits Counts         |   236                       |               236             |                          +0%
|  DS14   |   Ingestion                 |   511                       |               618             |                          +21%
|         |   Count By Rating           |   201                       |               275             |                          +37%
|         |   Count Over Time           |   298                       |               466             |                          +56%
|         |   Hits By Country           |   363                       |               529             |                          +46%
|         |   Top 15 Organizations      |   244                       |               407             |                          +67%
|         |   Unique Count Organizations|   283                       |               403             |                          +42%
|         |   Unique IP Count           |   681                       |               823             |                          +21%
|         |   Total Hits Counts         |   200                       |               221             |                          +11%


NEED ## OF DOCUMENTS RETURNED TO JUSTIFY THIS DATA, OTHERWISE PERF FOR 2 REPLICAS LOOKS OFF!

PRESENT QUERY-ONLY TEST RESULTS TO SHOW BETTER RESULTS
-->

## Результаты производительности при использовании doc values

Тесты приема и запросов проводились с включенными значениями doc values. Как результат, в Elasticsearch сохранялись данные, используемые для сортировки полей на диске. Затем тесты были выполнены с отключенными значениями doc values. Таким образом, в Elasticsearch динамически создавались и кэшировались в памяти данные fielddata. Все тесты выполнялись в течение 24 часов.
 
 В следующей таблице сравнивается время отклика для тестов, выполненных на шестиузловых кластерах с виртуальными машинами серий D4, DS4 и DS14.

| HDInsight |Операции и запросы |doc values включены (мс) | doc values отключены (мс) | Разница в % |
|  --------- |---------------------------| -----------------------|--------------------------  |--------------------|
| D4 |Прием | 978 | 835 | –15 % |
| |Число по оценке | 103 | 132 | +28 % |
| |Число по времени | 134 | 189 | +41 % |
| |Число по странам | 199 | 259 | +30 % |
| |15 самых распространенных организаций | 137 | 184 | +34 % |
| |Число уникальных организаций | 139 | 197 | +42 % |
| |Число уникальных IP-адресов | 510 | 604 | +18 % |
| |Общее число добавлений | 89 | 134 | +51 % |
| DS4 |Прием | 511 | 581 | +14 % |
| |Число по оценке | 187 | 190 | +2 % |
| |Число по времени | 411 | 409 | –0,5 % |
| |Число по странам | 402 | 414 | +3 % |
| |15 самых распространенных организаций | 307 | 284 | –7 % |
| |Число уникальных организаций | 320 | 313 | –2 % |
| |Число уникальных IP-адресов | 841 | 955 | +14 % |
| |Общее число добавлений | 236 | 281 | +19 % |
| DS14 |Прием | 511 | 571 | +12 % |
| |Число по оценке | 201 | 232 | +15 % |
| |Число по времени | 298 | 341 | +14 % |
| |Число по странам | 363 | 457 | +26 % |
| |15 самых распространенных организаций | 244 | 338 | +39 % |
| |Число уникальных организаций | 283 | 350 | +24 % |
| |Число уникальных IP-адресов | 681 | 909 | +33 % |
| |Общее число добавлений | 200 | 245 | +23 % |


<!--
The next table compares the number of ingestion operations performed by the tests:

  Cluster   Ingestion Operations – Doc Values Enabled   ## Ingestion Operations – Doc Values Disabled   % Difference in ## Ingestion Operations
  --------- ---------------------------------------------- ----------------------------------------------- -----------------------------------------
  D4        264769                                         408690                                          +54%
  DS4       503137                                         578237                                          +15%
  DS14      502714                                         586472                                          +17%

The improved ingestion rates occur with doc values disabled as less data is being written to disk as documents are inserted. The improved performance is especially noticeable with the D4 VM using HDDs to store data. In this case, the response time for ingestion operations also decreased by 15% (see the first table in this section). This could be due to the reduced pressure on the HDDs which were likely running close to their IOPS limits in the test with doc values enabled; see the [Disk Type](#performance-results-disk-type) test for more information. The following graph compares the I/O performance of the D4 VMs with doc values enabled (values held on disk) and doc values disabled (values held in memory):

![](./media/guidance-elasticsearch/query-performance4.png)

In contrast, the ingestion figures for the VMs using SSDs show a small increase in the number of documents but also an increase in the response time of the ingestion operations. With one or two small exceptions, the query response times were also worse. The SSDs are less likely to be running close to their IOPS limits with doc values enabled, so changes in performance are more likely due to increased processing activity and the overhead of managing the JVM heap. This is evident by comparing the CPU utilization with doc values enabled and disabled. The next graph highlights this data for the DS4 cluster, where most of the CPU utilization moves from the 30%-40% band with doc values enabled, to the 40%-50% band with doc values disabled (the DS14 cluster showed a similar trend):

![](./media/guidance-elasticsearch/query-performance5.png)

To isolate the effects that doc values on query performance from data ingestion, a pair of query-only tests were performed for each cluster as follows:

In the first test, the Elasticsearch index was created with doc values enabled, the index was pre-populated with 100 million documents, and then modified set of queries used by the replica tests were performed repeatedly for 90 minutes while performance statistics were gathered.

In the second test, the Elasticsearch index was created with doc values disabled, populated, and then subjected to the same query load for the same period as the first test.
-->

<!--
## Appendix: The Query and Aggregation Performance Test

This appendix describes the performance test performed against the Elasticsearch cluster. The tests were run by using JMeter running on a separate set of VMs. Details the configuration of the test environment are described in [Creating a Performance Testing Environment for Elasticsearch on Azure][]. To perform your own testing, you can create your own JMeter test plan manually following the guidance in this appendix, or you can use the automated test scripts available separately. See [Running the Automated Elasticsearch Performance Tests][] for further information.

The data query workload performed the set of queries described below while performing a large-scale upload of documents at the same time (the data was uploaded by using a JUnit test, following the same approach for the data ingestion tests described in the document Maximizing Data Ingestion Performance with Elasticsearch on Azure.) The purpose of this workload was to simulate a production environment where new data is constantly being added while searches are performed. The queries were structured to retrieve only the most recent data from documents added in the last 15 minutes.

Each document was stored in a single index named *sample*, and had the type *ctip*. You can use the following HTTP request to create the index. The *number\_of\_replicas* and *number\_of\_shards* settings varied from the values shown below in many of the tests. Additionally, for the tests that used fielddata rather than doc values, each property was annotated with the attribute *"doc\_values" : false*.

**Important**. The index was dropped and recreated prior to each test run.

```http
PUT /sample
{  
    "settings" : {
        "number_of_replicas": 1,
        "refresh_interval": "30s",
        "number_of_shards": "5",
        "index.translog.durability": "async"    
    },
    "ctip": {
        "mappings": {
            "event": {
                "_all": {
                    "enabled": false
                },
                "_timestamp": {
                    "enabled": true,
                    "store": true,
                    "format": "date_time"
                },
                "properties": {
                    "Organization": {
                        "type": "string",
                        "index": "not_analyzed"
                    },
                    "CustomField1": {
                        "type": "string",
                        "index": "not_analyzed"
                    },
                    "CustomField2": {
                        "type": "string",
                        "index": "not_analyzed"
                    },
                    "CustomField3": {
                        "type": "string",
                        "index": "not_analyzed"
                    },
                    "CustomField4": {
                        "type": "string",
                        "index": "not_analyzed"
                    },
                    "CustomField5": {
                        "type": "string",
                        "index": "not_analyzed"
                    },
                    "DateTimeReceivedUtc": {
                        "type": "date",
                        "format": "dateOptionalTime"
                    },
                    "Host": {
                        "type": "string",
                        "index": "not_analyzed"
                    },
                    "HttpMethod": {
                        "type": "string",
                        "index": "not_analyzed"
                    },
                    "HttpReferrer": {
                        "type": "string",
                        "index": "not_analyzed"
                    },
                    "HttpRequest": {
                        "type": "string",
                        "index": "not_analyzed"
                    },
                    "HttpUserAgent": {
                        "type": "string",
                        "index": "not_analyzed"
                    },
                    "HttpVersion": {
                        "type": "string",
                        "index": "not_analyzed"
                    },
                    "OrganizationName": {
                        "type": "string",
                        "index": "not_analyzed"
                    },
                    "SourceIp": {
                        "type": "ip"
                    },
                    "SourceIpAreaCode": {
                        "type": "long"
                    },
                    "SourceIpAsnNr": {
                        "type": "string",
                        "index": "not_analyzed"
                    },
                    "SourceIpBase10": {
                        "type": "long"
                    },
                    "SourceIpCity": {
                        "type": "string",
                        "index": "not_analyzed"
                    },
                    "SourceIpCountryCode": {
                        "type": "string",
                        "index": "not_analyzed"
                    },
                    "SourceIpLatitude": {
                        "type": "double"
                    },
                    "SourceIpLongitude": {
                        "type": "double"
                    },
                    "SourceIpMetroCode": {
                        "type": "long"
                    },
                    "SourceIpPostalCode": {
                        "type": "string",
                        "index": "not_analyzed"
                    },
                    "SourceIpRegion": {
                        "type": "string",
                        "index": "not_analyzed"
                    },
                    "SourceLatLong": {
                        "type": "geo_point",
                        "doc_values": true,
                        "lat_lon": true,
                        "geohash": true
                    },
                    "SourcePort": {
                        "type": "string",
                        "index": "not_analyzed"
                    },
                    "SourcedFrom": {
                        "type": "string",
                        "index": "not_analyzed"
                    },
                    "TargetIp": {
                        "type": "ip"
                    },
                    "TargetPort": {
                        "type": "string",
                        "index": "not_analyzed"
                    },
                    "Rating": {
                        "type": "string",
                        "index": "not_analyzed"
                    },
                    "UseHumanReadableDateTimes": {
                        "type": "boolean"
                    }
                }
            }
        }
    }
}

```

The following queries were performed by the test:

- How many documents with each *Rating* value have been entered in the last 15 minutes?

```http
GET /sample/ctip/_search
{
  "query": {
    "bool": {
      "must": [
        {
          "range": {
            "DateTimeReceivedUtc": {
              "gte": "now-15m",
              "lte": "now"
            }
          }
        }
      ],
      "must_not": [],
      "should": []
    }
  },
  "from": 0,
  "size": 0,
  "aggs": {
    "2": {
      "terms": {
        "field": "Rating",
        "size": 5,
        "order": {
          "_count": "desc"
        }
      }
    }
  }
}

```

- How many documents have been added in each 5 minute interval during the last 15 minutes?

```http
GET /sample/ctip/_search 
{
  "query": {
    "bool": {
      "must": [
        {
          "range": {
            "DateTimeReceivedUtc": {
              "gte": "now-15m",
              "lte": "now"
            }
          }
        }
      ],
      "must_not": [],
      "should": []
    }
  },
  "from": 0,
  "size": 0,
  "sort": [],
  "aggs": {
    "2": {
      "date_histogram": {
        "field": "DateTimeReceivedUtc",
        "interval": "5m",
        "time_zone": "America/Los_Angeles",
        "min_doc_count": 1,
        "extended_bounds": {
          "min": "now-15m",
          "max": "now"
        }
      }
    }
  }
}

```

- How many documents of each *Rating* value have been added for each country in the last 15 minutes?

```http
GET /sample/ctip/_search 
{
  "query": {
    "filtered": {
      "query": {
        "query_string": {
          "query": "*",
          "analyze_wildcard": true
        }
      },
      "filter": {
        "bool": {
          "must": [
            {
              "query": {
                "query_string": {
                  "query": "*",
                  "analyze_wildcard": true
                }
              }
            },
            {
              "range": {
                "DateTimeReceivedUtc": {
                  "gte": "now-15m",
                  "lte": "now"
                }
              }
            }
          ],
          "must_not": []
        }
      }
    }
  },
  "size": 0,
  "aggs": {
    "2": {
      "terms": {
        "field": "Rating",
        "size": 5,
        "order": {
          "_count": "desc"
        }
      },
      "aggs": {
        "3": {
          "terms": {
            "field": "SourceIpCountryCode",
            "size": 15,
            "order": {
              "_count": "desc"
            }
          }
        }
      }
    }
  }
}

```

- Which 15 organizations occur most frequently in documents added in the last 15 minutes?

``` http
GET /sample/ctip/_search
{
  "query": {
    "filtered": {
      "query": {
        "query_string": {
          "query": "*",
          "analyze_wildcard": true
        }
      },
      "filter": {
        "bool": {
          "must": [
            {
              "query": {
                "query_string": {
                  "query": "*",
                  "analyze_wildcard": true
                }
              }
            },
            {
              "range": {
                "DateTimeReceivedUtc": {
                  "gte": "now-15m",
                  "lte": "now"
                }
              }
            }
          ],
          "must_not": []
        }
      }
    }
  },
  "size": 0,
  "aggs": {
    "2": {
      "terms": {
        "field": "Organization",
        "size": 15,
        "order": {
          "_count": "desc"
        }
      }
    }
  }
}

```

- How many different organizations occur in documents added in the last 15 minutes?

```http
GET /sample/ctip/_search
{
  "query": {
    "filtered": {
      "query": {
        "query_string": {
          "query": "*",
          "analyze_wildcard": true
        }
      },
      "filter": {
        "bool": {
          "must": [
            {
              "query": {
                "query_string": {
                  "query": "*",
                  "analyze_wildcard": true
                }
              }
            },
            {
              "range": {
                "DateTimeReceivedUtc": {
                  "gte": "now-15m",
                  "lte": "now"
                }
              }
            }
          ],
          "must_not": []
        }
      }
    }
  },
  "size": 0,
  "aggs": {
    "2": {
      "cardinality": {
        "field": "Organization"
      }
    }
  }
}

```

- How many documents have been added in the last 15 minutes?

```http
GET /sample/ctip/_search
{
  "query": {
    "filtered": {
      "query": {
        "query_string": {
          "query": "*",
          "analyze_wildcard": true
        }
      },
      "filter": {
        "bool": {
          "must": [
            {
              "query": {
                "query_string": {
                  "analyze_wildcard": true,
                  "query": "*"
                }
              }
            },
            {
              "range": {
                "DateTimeReceivedUtc": {
                  "gte": "now-15m",
                  "lte": "now"
                }
              }
            }
          ],
          "must_not": []
        }
      }
    }
  },
  "size": 0,
  "aggs": {}
}

```

- How many different *SourceIp* values occur in documents added in the last 15 minutes?

```http
GET /sample/ctip/_search
{
  "query": {
    "filtered": {
      "query": {
        "query_string": {
          "query": "*",
          "analyze_wildcard": true
        }
      },
      "filter": {
        "bool": {
          "must": [
            {
              "query": {
                "query_string": {
                  "query": "*",
                  "analyze_wildcard": true
                }
              }
            },
            {
              "range": {
                "DateTimeReceivedUtc": {
                  "gte": "now-15m",
                  "lte": "now"
                }
              }
            }
          ],
          "must_not": []
        }
      }
    }
  },
  "size": 0,
  "aggs": {
    "2": {
      "cardinality": {
        "field": "SourceIp"
      }
    }
  }
} 

```

[Running the Automated Elasticsearch Performance Tests]: guidance-elasticsearch-running-automated-performance-tests.md
[Creating a Performance Testing Environment for Elasticsearch on Azure]: guidance-elasticsearch-creating-performance-testing-environment.md
-->

<!---HONumber=AcomDC_0224_2016-->