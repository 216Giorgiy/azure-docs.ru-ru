---
title: Настройка производительности TCP/IP для виртуальных машин Azure | Документация Майкрософт
description: Узнайте, различные распространенные TCP/IP методы настройки производительности, а также их связь с виртуальными машинами Azure.
services: virtual-network
documentationcenter: na
author:
- rimayber
- dgoddard
- stegag
- steveesp
- minale
- btalb
- prachank
manager: paragk
editor: ''
ms.assetid: ''
ms.service: virtual-network
ms.devlang: na
ms.topic: article
ms.tgt_pltfrm: na
ms.workload: infrastructure-services
ms.date: 3/30/2019
ms.author:
- rimayber
- dgoddard
- stegag
- steveesp
- minale
- btalb
- prachank
ms.openlocfilehash: 664c8b659152a370d7fb31907b6cdbcd414dce31
ms.sourcegitcommit: 9f4eb5a3758f8a1a6a58c33c2806fa2986f702cb
ms.translationtype: MT
ms.contentlocale: ru-RU
ms.lasthandoff: 04/03/2019
ms.locfileid: "58905109"
---
# <a name="tcpip-performance-tuning-for-azure-vms"></a>TCP/IP Настройка производительности для виртуальных машин Azure

В этой статье предназначена для обсуждения распространенные методы настройки производительности TCP/IP и их рекомендации для виртуальных машин, работающих в Microsoft Azure. Важно иметь базовое понимание понятий и затем мы обсудим, как они настроены.

## <a name="common-tcpip-tuning-techniques"></a>Распространенные методы настройки TCP/IP

### <a name="mtu-fragmentation-and-large-send-offload-lso"></a>MTU, фрагментации и большой отправки Offload (LSO)

#### <a name="explanation-of-mtu"></a>Объяснение MTU

Данных (MTU) — это самый большой размер фрейм (пакет), указанного в байтах, которые могут быть отправлены через сетевой интерфейс. Значение MTU является значением настраиваемого параметра по умолчанию используется значение MTU на виртуальных машинах Azure, и значение по умолчанию для большинства устройств сети глобально, – 1500 байтов.

#### <a name="explanation-of-fragmentation"></a>Объяснение фрагментации

Фрагментация возникает при отправке пакета, превышает MTU сетевого интерфейса. Стек TCP/IP нарушит пакет на более мелкие части (фрагменты), которые соответствуют интерфейсам MTU. Фрагментация происходит на уровне IP и не зависит от базового протокола (например, TCP). При отправке пакета 2000 байтов через сетевой интерфейс с значение MTU 1500, затем он будет разделить на один пакет 1500 байтов и один пакет 500 байт.

Сетевые устройства в пути между источником и назначением можете удалить пакеты, которые превышают размер MTU или фрагментировать пакет на более мелкие части.

#### <a name="the-dont-fragment-df-bit-in-an-ip-packet"></a>Бит «Don't Fragment (DF)» в IP-пакет

Черная — флажок в заголовке протокола IP. DF бит задан, указывает, что промежуточные сетевые устройства на пути между отправителем и получателем должна не фрагментацию. Есть много причин, почему может задаваться этот бит (см. разделе обнаружение пути ниже примером). Когда сетевое устройство получает пакет с фрагментировать и этот пакет превышает MTU для интерфейса устройства, а затем стандартное поведение заключается в том, для устройства удалить пакет и отправить пакет «ICMP связи с необходимостью фрагментации» обратно в исходный источник пакет.

#### <a name="performance-implications-of-fragmentation"></a>Последствия фрагментации для производительности

Фрагментация может повлиять снижению производительности. Одним из основных причин снижения производительности является ЦП и памяти последствия фрагментации и повторную сборку пакетов. Когда сетевого устройства требуется fragment пакет, его необходимо распределить ресурсы ЦП и памяти для выполнения фрагментации. Же должно происходить, когда собираются пакет. Сетевое устройство необходимо хранить все фрагменты, пока они поступают, его можно собрать их исходный пакет. Этот процесс фрагментации/сборка также может вызывать задержки из-за фрагментации/сборка процесс.

Другие возможные снижения производительности фрагментации подразумевается, что фрагментированных пакетов могут приходить в неправильном порядке. Неупорядоченные пакетов может привести к таких сетевых устройств для удаления неупорядоченных пакеты -, потребуется повторно передавать весь пакет. Перечислены типичные сценарии для удаления фрагментов безопасности устройств, например сетевые брандмауэры или после получения сетевого устройства буферы исчерпаны. При получения сетевого устройства буферы исчерпаны, сетевое устройство пытается воссоздать фрагментированных пакетов, но отсутствуют ресурсы для хранения и reassume пакет.

Фрагментация может восприниматься как отрицательное операции, но поддержка для фрагментации необходим для подключения различных сетей через Интернет.

#### <a name="benefits-and-consequences-of-modifying-the-mtu"></a>Преимущества и последствия изменения MTU

В качестве общие инструкции увеличение MTU можно создать сеть более эффективно. Каждый пакет, который передается имеет дополнительную информацию о заголовке, добавляемого исходный пакет. Несколько пакетов означает дополнительные заголовка дополнительной нагрузки и сети является менее эффективным, в результате.

Например размер заголовка Ethernet — 14 байт, а также 4-байтовое кадра проверьте последовательности (FCS) для обеспечения согласованности кадра. Если один пакет 2000-байтовое отправляется, 18 дополнительных байт для Ethernet добавляется в сети. Если пакет фрагментированы в пакет 1500 байтов и 500-байтовый пакет, каждый пакет будет иметь заголовок кадра протокола Ethernet - 18 байт или 36 байтов. В то время как один пакет 2000-байтовое может присутствовать только заголовок кадра протокола Ethernet 18 байтов.

Это важно отметить, что увеличение MTU само по себе не создаст обязательно эффективнее сети. Если приложение отправляет пакеты только 500 байт, тем же размером заголовка будет существовать ли значение MTU является 1500 или 9000 байт. В порядке, в сети быть более эффективным, затем она также должна использовать больший размер пакета, которые задаются относительно MTU.

#### <a name="azure-and-vm-mtu"></a>Azure и MTU виртуальной Машины

По умолчанию для виртуальных машин Azure составляет 1 500 байт. Стек виртуальной сети Azure будет пытаться fragment пакет до 1400 байт. Тем не менее виртуальной сети Azure stack позволит пакетов до 2006 байт при «Don't Fragment» бит задан в IP-заголовке.

Важно отметить, что это не означает, что стек виртуальной сети Azure по своей природе неэффективно, так как фрагменты пакетов до 1400 байт, а виртуальные машины имеют значение MTU 1500. Но на деле является намного меньше, чем 1400 или 1500 байт большое количество сетевых пакетов.

#### <a name="azure-and-fragmentation"></a>Azure и фрагментации

Сегодня стек виртуальной сети Azure настраивается для удаления «Неупорядоченного диапазона фрагментов» - это означает фрагментированных пакетов, которые не прибудут в исходном порядке фрагментированных. Эти пакеты удаляются в первую очередь из-за было объявлено в ноября 2018 года, вызывается FragmentStack уязвимость сети.

FragmentSmack является дефект в обработке ядро Linux повторную сборку фрагментированных пакетов IPv4 и IPv6. Удаленный злоумышленник может использовать этот недостаток для операции сборки дорогостоящие фрагмент триггера, которые влечет за собой повышенную ЦП и отказ в обслуживании в целевой системе.

#### <a name="tune-the-mtu"></a>Настройка MTU

Виртуальные машины Azure поддерживают настраиваемые MTU так же, как и любой другой операционной системе. Тем не менее фрагментация, которая происходит в пределах Azure и подробно описана выше, необходимо учитывать при настройке MTU.

Azure не рекомендует пользователям увеличить их MTU виртуальной Машины. Данного обсуждения предполагается также подробно объясняется, как Azure реализует MTU и выполняет фрагментацию уже сегодня.

> [!IMPORTANT]
>Увеличение MTU не показано для повышения производительности и может иметь отрицательное влияние на производительность приложения.
>
>

#### <a name="large-send-offload-lso"></a>Разгрузка большой отправки (LSO)

Большой отправки Offload (LSO) может повысить производительность сети за счет разгрузки сегментации пакетов Ethernet-адаптеру. С помощью LSO включена стек TCP/IP будет создавать большого пакета TCP и отправьте Ethernet-адаптеру для сегментации перед пересылкой. Преимуществом LSO является то, что он может освободить ЦП от сегментирования пакетов в размер пакетов, которые соответствуют MTU и разгрузка обработки для интерфейса Ethernet, где он выполняется в оборудовании. Дополнительные сведения о преимуществах LSO можно найти в [производительности в документации по Microsoft Network Adapter](https://docs.microsoft.com/windows-hardware/drivers/network/performance-in-network-adapters#supporting-large-send-offload-lso).

При включении LSO клиенты Azure могут см. в разделе кадра больших размеров при захвате выполнение пакетов. Эти размеры больших кадров может стать причиной некоторых клиентов идею, что фрагментация или кадры крупных размеров, которые MTU используется, если она не. С помощью LSO адаптер ethernet можно объявить большего размера MSS в стек TCP/IP для создания большего размера пакета TCP. Это весь кадр несегментированный пересылаются в адаптер Ethernet и будет видима в записи пакета, выполняемые на виртуальной Машине. Тем не менее пакет будет разбит на многие части адаптер Ethernet в соответствии с адаптер Ethernet MTU.

### <a name="tcpmss-window-scaling-and-pmtud"></a>Масштабирование окна TCP/MSS и PMTUD

#### <a name="explanation-of-tcp-mss"></a>Объяснение TCP MSS

Максимальный размер сегмента (MSS) TCP — это параметр, предназначенный для задания максимального размера сегмента TCP относительно избежать фрагментации пакетов TCP. Операционные системы обычно устанавливается MSS как MSS = по умолчанию - IP-адрес & верхний колонтитул TCP размер (20 байт или 40 байт). Поэтому интерфейс с MTU 1500 будет иметь MSS 1460. Тем не менее, MSS, можно настроить.

Этот параметр является соглашение в трехстороннее подтверждение TCP, при настройке сеанса TCP между источником и назначением. Обе стороны отправки значение MSS и меньшее из двух используется для подключения TCP.

Промежуточных сетевых устройств, таких как VPN-шлюзов, включая VPN-шлюза Azure, имеют возможность настроить MTU, независимо от источника и назначения для обеспечения оптимальной сетевой производительности. Таким образом следует отметить, что размер MTU источник и назначение только не единственная факторами, влияющими на фактическое значение MSS.

#### <a name="explanation-of-path-mtu-discovery-pmtud"></a>Объяснение обнаружение MTU пути (PMTUD)

При согласовании MSS, не может означать, что фактический MSS, который может использоваться как другие сетевые устройства в пути между источником и назначением может иметь меньшее значение MTU, чем источник и назначение. Таким образом устройство которого MTU меньше, чем пакет будет удалить пакет и отправлять обратно сообщение сообщений протокола ICMP (Internet Control) связи с необходимостью фрагментации (типа 3, 4 кода), содержащий его MTU. Это сообщение проверки связи ICMP позволяет на исходном узле уменьшить его MTU путь соответствующим образом. Этот процесс называется обнаружением MTU пути.

Процесс PMTUD по своей природе неэффективен и влияет на производительность сети. При отправке пакетов, превышать сетевых путей MTU, пакеты необходимо повторно с нижней MSS. Если отправитель не получает ICMP Fragmentation Needed пакета, возможно, из-за сетевой брандмауэр в пути (которые называют PMTUD blackhole), то отправитель не знает, что ему следует уменьшить MSS и будет постоянно повторной передачи пакета. По этой причине мы не рекомендуем увеличить размер MTU виртуальной Машины Azure.

#### <a name="vpn-considerations-with-mtu"></a>Рекомендации по подключению VPN с MTU

Клиенты, использующие виртуальных машин, выполняющих инкапсуляция (например, IPSec VPN) может повлиять дополнительные размер пакета и MTU. Виртуальные частные сети добавьте исходный пакет таким образом увеличить размер пакетов и требовать меньше MSS будут добавляться дополнительные заголовки.

Для Azure рекомендуется задать фиксация TCP MSS 1350 байт и MTU для интерфейса туннеля 1400. Дополнительные сведения можно найти на [VPN устройства и страница параметров IPSec/IKE](https://docs.microsoft.com/azure/vpn-gateway/vpn-gateway-about-vpn-devices).

### <a name="latency-round-trip-time-and-tcp-window-scaling"></a>Задержка, время приема-передачи и масштабирование окна TCP

#### <a name="latency-and-round-trip-time"></a>Время задержки и приема-передачи

Задержки в сети регулируется скорости света по сети оптоволоконные волокон. Реальность такова, пропускная способность сети TCP является также эффективно управляемое (практические максимальные значения) из-за времени приема-передачи (RTT) между двумя сетевыми устройствами.

| | | | |
|-|-|-|-|
|Маршрутизация|Distance|Одностороннее времени|Время приема-передачи (RTT)|
|Нью-Йорка до Сан-Франциско|4,148 км|21 ms|42 ms|
|Нью-Йорк, Лондон|5,585 км|28 ms|56 ms|
|Нью-Йорка для Сидней|15,993 км|80 мс|160 мс|

В этой таблице показаны Бразилию расстояние между двумя расположениями, однако в сетях, расстояние обычно больше, чем Бразилию расстояние. Является простой формулы для вычисления МИНИМАЛЬНОЕ время приема-Передачи, как это определяется скорости света: минимальное время приема-Передачи = 2 * (расстояние в километрах / скорость передачи).

Можно использовать стандартное значение 200 для скорости передачи — задано расстояние в метрах свет проходит в 1 миллисекунде.

В примере Нью-Йорка до Сан-Франциско это расстояние Бразилию 4,148 км. Минимальное время приема-Передачи = 2 * (4,148 / 20). Выходные данные формула будет в миллисекундах.

Если в качестве физического расстояния между двумя расположениями предопределенной реальностью, максимальной производительности сети является обязательным, наиболее логичным вариантом является Выбор места назначения с наименьшее расстояние между ними. Основным проектные решения в виртуальной сети можно сделать для оптимизации путь трафика и снижения задержки. Эти сведения о виртуальной сети, описаны рекомендации по проектированию сети ниже в разделе.

#### <a name="latency-and-round-trip-time-effects-on-tcp"></a>Эффекты времени задержки и круговой путь через TCP-

Цикла приема-передачи (RTT) времени имеет непосредственное влияние на максимальную пропускную способность TCP. Протокол TCP имеет смысл размер окна. Размер окна равен максимальный объем трафика, которое может быть отправлено через TCP-подключение, прежде чем отправитель должен получать подтверждения от получателя. Если TCP MSS равно 1460 и размер окна TCP имеет значение 65535 отправитель может отправлять пакеты 45 прежде, чем она должна получать подтверждения от получателя. Если подтверждение приема не получено отправитель будет передавать. В этом примере размер окна TCP / TCP MSS = отправленных пакетов. Или 65535 / 1460 округляется до 45.

Это состояние «Ожидание подтверждения», как механизм для создания надежной доставки данных, это фактически приводит, что время приема-Передачи повлиять на пропускную способность TCP. Чем дольше выполняется отправитель ожидает подтверждения, тем дольше также ждать перед отправкой данных.

Формула для расчета максимальная пропускная способность одного соединения TCP выглядит следующим образом: Размер окна / (задержка приема-Передачи в миллисекундах / 1000) = максимум байт/сек. В таблице ниже форматируется в мегабайтах для удобства чтения и максимальное мегабайт / пропускную способность одного соединения TCP.

| | | | |
|-|-|-|-|
|Размер окна TCP в байтах|Задержка приема-Передачи<br/>в миллисекундах|Максимальная<br/>МБ / пропускную способность|Максимальная<br/> Мегабит в пропускную способность|
|65535|1|65.54|524.29|
|65535|30|2.18|17.48|
|65535|60|1,09|8.74|
|65535|90|.73|5.83|
|65535|120|.55|4.37|

Есть ли потеря пакетов, то это снизит максимальная пропускная способность TCP-подключения хотя отправитель повторно передает данные, которые уже отправлены.

#### <a name="explanation-of-tcp-window-scaling"></a>Объяснение масштабирование окна TCP

Масштабирование окна TCP — это понятие, которое динамически увеличивается размер окна TCP позволяя больше данных для отправки по истечении которого запрашивается подтверждение. В нашем предыдущем примере прежде чем она необходима, подтверждение отправится 45 пакетов. Если число пакетов, отправленных до увеличения подтверждение, затем максимальная пропускная способность TCP также увеличивается за счет сокращения числа раз, отправитель ожидает подтверждения.

Пропускная способность TCP демонстрируется в простую таблицу ниже:

| | | | |
|-|-|-|-|
|Размер окна TCP<br/>в байтах|Задержка приема-Передачи в миллисекундах|Максимальная<br/>МБ / пропускную способность|Максимальная<br/> Мегабит в пропускную способность|
|65535|30|2.18|17.48|
|131,070|30|4.37|34.95|
|262,140|30|8.74|69.91|
|524,280|30|17.48|139.81|

Тем не менее значение заголовка TCP для размера окна TCP является только 2 байта, это означает, что окно приема максимальное значение равно 65 535. Чтобы увеличить максимальный размер окна, был введен коэффициент масштабирования окна TCP.

Коэффициент масштабирования также является параметром, который можно настроить в операционной системе. Формула для расчета размера окна TCP, с помощью коэффициентов масштабирования выглядит следующим образом: Размер окна TCP = размер окна TCP в байтах \* (2 ^ коэффициента масштабирования). Если коэффициент масштабирования окна 3 и размер окна 65535, расчета выглядит следующим образом: 65535 \* (2 ^ 3) = 262,140 байт. Коэффициент масштабирования из 14 приводит размер окна TCP из 14 (максимально разрешенное смещение), то размер окна TCP будет 1,073,725,440 байт (8,5 гигабит).

#### <a name="support-for-tcp-window-scaling"></a>Поддержка масштабирование окна TCP

Windows имеет возможность задать разные коэффициенты масштабирования для каждого типа подключения - имеется несколько классов подключений (центра обработки данных, Интернет и т. д.). Вы увидите окно масштабирования классификации подключения с помощью команды powershell Get-NetTCPConnection.

```powershell
Get-NetTCPConnection
```

Вы увидите значения каждого класса с помощью команды powershell Get-NetTCPSetting.

```powershell
Get-NetTCPSetting
```

Начальный размер окна TCP и TCP коэффициента масштабирования можно задать в Windows с помощью команды powershell Set-NetTCPSetting. Дополнительные сведения можно найти на [NetTCPSetting набор страниц](https://docs.microsoft.com/powershell/module/nettcpip/set-nettcpsetting?view=win10-ps)

```powershell
Set-NetTCPSetting
```

Действующие параметры TCP/scannow являются следующим образом.

| | | | |
|-|-|-|-|
|/ Scannow|Коэффициент масштабирования|Коэффициент масштабирования|Формула для<br/>вычислить максимальный размер окна|
|Отключено|Нет|Нет|Размер окна|
|С ограниченным доступом|4.|2^4|Размер окна * (2 ^ 4)|
|Ограничен|2|2^2|Размер окна * (2 ^ 2)|
|В обычном режиме|8|2^8|Размер окна * (2 ^ 8)|
|Экспериментальная возможность|14|2^14|Размер окна * (2 ^ 14)|

Хотя эти параметры являются скорее негативно влияет производительность TCP, следует отметить, что множество других факторов, в Интернете, за пределами элемента управления Azure, также могут повлиять на производительность TCP.

#### <a name="increase-mtu-size"></a>Увеличьте размер MTU

Логические вопрос: «можно увеличить размер MTU increase производительности TCP как больших MTU означает больше MSS»? Простой ответ состоит в — скорее всего, не. Как уже говорилось, существуют преимущества и недостатки размер пакета, которые можно использовать за пределами только TCP-трафик. Как уже говорилось ранее, наиболее важные факторы, влияющие на производительность пропускной способности TCP является размер окна TCP, потери пакетов и составляет время кругового пути.

> [!IMPORTANT]
> Не рекомендуется, чтобы клиенты Azure изменить значение MTU по умолчанию на виртуальных машинах.
>
>

### <a name="accelerated-networking-and-receive-side-scaling"></a>Ускорение сети и масштабирование на стороне приема

#### <a name="accelerated-networking"></a>Ускорение работы в сети

Функции сети виртуальных машин традиционно были на гостевой виртуальной Машины и узле низкоуровневой оболочки/интенсивное использование ресурсов ЦП. Каждый пакет, который изменится через узел обрабатывается в программном обеспечении ЦП — в том числе все виртуальные сети инкапсуляция/de-capsulation узлом. Таким образом больше трафика, проходит через узел, то чем выше нагрузку на ЦП. И, если узел ЦП занят выполнением других операций, затем, также влияет на пропускную способность сети и задержки. Эта проблема была устранена через повышение производительности сети.

Повышение производительности сети предоставляет согласованный сверхнизкой задержи через собственные программируемых оборудования Azure и технологий, таких как SR-IOV. Путем перемещения большую часть Azure программно определяемого сетевого стека off процессоров и в основе FPGA SmartNICs, вычислений циклов были удалены сборщиком приложения для конечных пользователей, поместив меньшей нагрузки на виртуальной Машине, уменьшение дрожания и несогласованности задержки. Другими словами производительность может быть более детерминированным.

Повышение производительности сети обеспечивает повышение производительности, позволяя гостевой виртуальной Машины для обхода узла и установить datapath непосредственно с SmartNIC узла. Приведены преимущества повышения производительности сети.

- **Уменьшить задержку в секунду (pps) выше пакетов в**: Благодаря обходу виртуального коммутатора на пути к данным на узле не выполняется обработка политики пакетов. Таким образом увеличивается число пакетов, которые могут быть обработаны на виртуальной машине.

- **Уменьшение дрожания**: Обработка с помощью виртуального коммутатора зависит от числа политик, которые необходимо применить, и рабочей нагрузки ЦП, выполняющего обработку. Так как принудительное применение политик осуществляется на аппаратном уровне, эта зависимость устраняется за счет доставки пакетов непосредственно на виртуальную машину. Это позволяет избежать обмена данными между узлом и виртуальной машиной, прерываний работы программного обеспечения и переключений контекста.

- **Уменьшение нагрузки ЦП**: Обход виртуального коммутатора на узле приводит к меньшему использованию ЦП для обработки сетевого трафика.

Ускорение работы в сети должно быть явно включено на основе на виртуальной Машине. Инструкции по включению ускоренной сети на виртуальной Машине можно найти по адресу [Создание виртуальной машины Linux с ускоренной сетью страницей](https://docs.microsoft.com/azure/virtual-network/create-vm-accelerated-networking-cli).

#### <a name="receive-side-scaling-rss"></a>(RSS) масштабирования на стороне приема

Масштабирование на стороне приема — это технология драйвера сети, которая распределяет получения сетевого трафика, более эффективно распределяя получения обработки между несколькими ЦПУ в многопроцессорной системе. Проще говоря RSS позволяет обрабатывать больший объем полученных трафика, так как она использует все доступные процессоры вместо одного в системе. Дополнительные технические обсуждение RSS можно найти в [введение в масштабирование на стороне приема страницы](https://docs.microsoft.com/windows-hardware/drivers/network/introduction-to-receive-side-scaling).

Для достижения максимальной производительности при включенной ускоренной сети на виртуальной Машине требуется RSS. Может также существовать преимущества в с помощью RSS на виртуальных машинах, которые не имеют включенной функцией ускорения сети. Общие сведения определить, если включена функция RSS и конфигурацию для включения его можно найти в [оптимизировать пропускную способность сети для виртуальных машин Azure страницы](http://aka.ms/FastVM).

### <a name="tcp-time-wait-and-time-wait-assassination"></a>Время ожидания TCP и время ожидания Assassination

Другая типичная проблема, которая влияет на производительность сети и приложений является параметром TCP времени ожидания. На загруженные виртуальные машины, которые являются открывающей и закрывающей много сокетов, как клиент или сервер (исходный порт IP:Source + IP:Destination порт назначения), во время обычной работы протокола TCP данного сокета могут быть сохранены в состоянии времени ожидания для значительного количества времени. Это состояние «время ожидания» предназначен для разрешить дополнительные данные, которые доставляются на сокете перед его закрытием. Таким образом стеков TCP/IP обычно предотвратить повторное использование сокета, автоматическое удаление пакетов TCP SYN клиентов.

Это время сокета, вовремя, состояние ожидания, можно настроить, но может варьироваться от 30 секунд до 240 секунд. Сокеты представляют собой ограниченный ресурс, и количество сокетов, которые могут использоваться в любой момент времени можно настроить (номер обычно находится около 30 000 потенциальных сокеты). Если это число будет исчерпан, или клиенты и серверы имеют параметры несоответствующие времени ожидания и производится попытка повторного использования сокет в состояние ожидания время виртуальной Машины, новые соединения завершится ошибкой, как пакетов TCP SYN автоматически отбрасываются.

Обычно значение для диапазона портов для исходящие сокеты, а также параметры TCP времени ожидания и повторное использование сокета настраиваются в стеке TCP/IP операционной системы. Изменение этих номеров потенциально может улучшить масштабируемость, но в зависимости от сценария, может привести к проблемам взаимодействия и должно быть изменено с осторожностью.

Возможность времени ожидания Assassination появилась Чтобы решить эту проблему, масштабирование ограничение. Время ожидания Assassination позволяет сокета позволяет повторно использовать в определенных сценариях, например, если порядковый номер в пакете IP-адрес нового подключения превышает порядковый номер последнего пакета из предыдущее подключение. В этом случае операционная система позволит установить новое соединение (принятия новых SYN ACK) и принудительно закройте предыдущее подключение было времени ожидания состояния. Эта возможность поддерживается на виртуальных машинах Windows в Azure сегодня и поддержки в других виртуальных машин следует изучить Azure клиентов с соответствующими поставщиками операционной системы.

Документация по настройке параметров TCP времени ожидания и диапазон портов источника доступна в [параметры, которые можно изменить, чтобы повысить производительность сети страницы](https://docs.microsoft.com/biztalk/technical-guides/settings-that-can-be-modified-to-improve-network-performance).

## <a name="virtual-network-factors-that-can-affect-performance"></a>Виртуальные сети факторы, которые могут повлиять на производительность

### <a name="vm-maximum-outbound-throughput"></a>Пропускная способность максимальное исходящего трафика виртуальной Машины

Azure предоставляет несколько разных типов и размеров виртуальных машин, каждый из которых имеет определенное сочетание характеристик производительности. Один такой производительности возможности сетевой пропускной способности (или пропускной способности), измеряется в мегабитах в секунду (Мбит/с). Поскольку виртуальные машины размещены на общем оборудовании, пропускная способность сети должна справедливо распределяться между виртуальными машинами на одном элементе оборудования. Крупным виртуальным машинам предоставляется больше пропускной способности, чем более мелким.

Пропускная способность сети, выделяемая каждой виртуальной машине, определяет скорость передачи данных от виртуальной машины (исходящий трафик). Ограничение распространяется на весь сетевой трафик, покидающий виртуальную машину, независимо от его назначения. Например если виртуальная машина имеет ограничение в 1000 Мбит/с, этот предел применяет как исходящий трафик, предназначенный для другой виртуальной машине в той же виртуальной сети или за пределами Azure.
Входящий трафик не измеряется и не ограничивается напрямую. Однако способность виртуальной машины обрабатывать входящие данные может быть ограничена другими факторами, такими как ограничения на использование ЦП и (или) хранилища.

Повышение производительности сети — это компонент, предназначенный для повышения производительности сети, включая задержку, пропускную способность и использование ЦП. Повышение производительности сети повысить пропускную способность виртуальной машины, это можно сделать только для доступа к виртуальной машине выделенной пропускной способности.

К виртуальной машине Azure можно присоединить несколько сетевых интерфейсов, и по меньшей мере один должен присутствовать обязательно. Пропускная способность, выделенная для виртуальной машины, оценивается по сумме исходящего трафика на всех присоединенных к ней сетевых интерфейсах. Другими словами, пропускная способность выделяется на виртуальную машину в целом, независимо от количества присоединенных к ней сетевых интерфейсов.
 
Ожидаемая пропускная способность и число сетевых интерфейсов, поддерживаемых каждой виртуальной Машиной размера подробно описана здесь. См. в разделе максимальная пропускная способность, выберите тип, например общего назначения, а затем выберите серию размеров на соответствующей странице, такие как серия Dv2. Каждый ряд содержит таблицу с сетью спецификации в последнем столбце под названием, максимальное число сетевых адаптеров и ожидаемая производительность сети (Мбит/с).

Ограничение пропускной способности применяется ко всей виртуальной машине. Пропускная способность не зависит от следующих факторов.

- **Количество сетевых интерфейсов**: Ограничение пропускной способности является совокупным весь исходящий трафик из виртуальной машины.

- **Повышение производительности сети**: На то, что функция может быть максимально эффективно использовать заявленный предел, ограничение не затрагивает.

- **Назначение трафика**: Ограничения на исходящий учитываются все назначения.

- **Протокол**: Весь исходящий трафик по всем протоколам учитывается при подсчете ограничение.

Объект [таблицы максимальная пропускная способность каждого типа виртуальной Машины можно найти, посетив эту страницу](https://docs.microsoft.com/azure/virtual-machines/windows/sizes) и щелкнув и соответствующие типы виртуальных Машин. На каждой странице Тип таблицы отобразится максимальное сетевых адаптеров и максимальной ожидаемой пропускной способности сети.

Дополнительные сведения о пропускной способности сети виртуальной Машины можно найти в [пропускной способности сети виртуальной машины](http://aka.ms/AzureBandwidth).

### <a name="internet-performance-considerations"></a>Рекомендации по безопасности Интернета

Как описано в этой статье, факторов, в Интернете и за пределами элемента управления Azure может повлиять на производительность сети. Эти факторы являются:

- **Задержка**: Время кругового пути между двумя конечными точками может зависеть от проблем на промежуточных сетей трафика избегания «» кратчайшего пути путь невозможно и не самые оптимальные пути пиринга

- **Потеря пакетов**: Потеря пакетов может быть вызвана перегрузка сети, физический путь проблем и в выполнении сетевых устройств

- **Размер MTU/фрагментации**: Фрагментация вдоль пути может привести к задержкам в поступления данных или пакеты, поступающие в неправильном порядке, что может повлиять на доставку пакетов

Трассировка маршрута — это хороший инструмент для измерения характеристик производительности сети (например, потери пакетов и задержки) каждого сетевого пути между исходного и целевого устройства.

### <a name="network-design-considerations"></a>Рекомендации по проектированию сети

А также указанные выше требования топологии виртуальной сети может повлиять на производительность виртуальной сети. Например звездообразной узор что трафик backhauls глобально в одном концентраторе виртуальной сети будет приводить к задержкам в сети и таким образом влияет на производительность сети. Аналогичным образом число сетевых устройств, сетевой трафик проходит через могут также влиять на общую задержку. Например в звездообразной архитектуре, если трафик передается через периферийной зоны виртуальное сетевое устройство и виртуальное устройство центра перед транзитом к Интернету, затем задержки могут быть вызваны виртуальные сетевые устройства.

### <a name="azure-regions-virtual-networks-and-latency"></a>Регионы Azure, виртуальные сети и задержки

Регионы Azure состоят из нескольких центрах обработки данных, которые существуют в общий географический регион. Эти центры обработки данных может не находиться рядом друг с другом и в некоторых случаях могут быть разделены по 10 километров. Виртуальная сеть располагается там логических перекрыл сети center физических данных Azure и виртуальной сети не подразумевает, что любой топологии конкретной сети в центре обработки данных. Например виртуальной Машины A и B виртуальной Машины находятся в одной и той же виртуальной сети и подсети, но могут находиться в разных стойках, строк или даже центров обработки данных. Они могут быть разделены метров оптический кабель или километров от оптический кабель. Это реальность может стать переменная задержка (несколько разницу в миллисекундах) между разными виртуальными машинами.

Это географическое расположение и, таким образом задержку между двумя виртуальными машинами, могут зависеть через конфигурацию группы доступности и зон доступности, тем не менее, расстояние между центрами обработки данных в регионе конкретного региона и преимущественно соответствовавшего этой структуре Топология центра обработки данных в регионе.

### <a name="source-nat-port-exhaustion"></a>Нехватка портов NAT источника

Развертывание в Azure могут взаимодействовать с конечными точками за пределами Azure в общедоступный Интернет и в пространстве общедоступных IP-адрес. Когда экземпляр инициирует это исходящее подключение, Azure динамически сопоставляет частный IP-адрес общедоступного IP-адреса. После создания этого сопоставления обратный трафик исходящего потока можно также направлять по частному IP-адресу, с которого изначально отправлен поток.

Для каждого исходящего подключения балансировщик нагрузки Azure необходимо поддерживать это сопоставление для некоторого периода времени. С несколькими клиентами природой Azure обслуживание это сопоставление для каждого исходящего потока для каждой виртуальной Машины может быть много ресурсов. Таким образом существуют ограничения, которые задаются и на основе конфигурации виртуальной сети Azure. Или указано более точно - виртуальной Машины Azure можно сделать только определенное количество исходящих подключений в определенный момент времени. Если эти ограничения исчерпан, виртуальной Машине Azure сможет вносить любые дополнительные исходящие подключения.

Это поведение, тем не менее, можно настроить. Дополнительные сведения о [SNAT и SNAT порта нехватки], см. в разделе [в этой статье](https://docs.microsoft.com/azure/load-balancer/load-balancer-outbound-connections).

## <a name="measure-network-performance-on-azure"></a>Измерение производительности сети в Azure

Ряд максимальные ограничения производительности в этой статье относятся к задержкам в сети / приема-передачи времени (RTT) между двумя виртуальными машинами. Этот раздел содержит советы по тестированию задержки или времени приема-Передачи, а также производительность TCP и производительность сети виртуальной Машины. Значения TCP/IP & сети, описанных выше, можно оптимизировать и тестирование производительности с помощью методики, описанные ниже. Можно использовать в вычислениях, перечисленных выше значения задержки, MTU, MSS и размер окна и теоретического максимума можно сравнивать с фактическими значениями, во время тестирования.

### <a name="measure-round-trip-time-and-packet-loss"></a>Измерения времени кругового пути и потери пакетов

Производительность TCP основывается на время приема-Передачи и потери пакетов. Самый простой способ измерения времени приема-Передачи и потерю пакетов использует служебную программу ping доступны в Windows и Linux. Минимальное/максимальное/среднее задержки между исходной и целевой как и потери пакетов будут показаны результаты из проверки связи. Проверка связи по протоколу ICMP по умолчанию. Чтобы протестировать TCP времени приема-Передачи, затем PsPing может использоваться. Дополнительные сведения о PsPing доступен по [эту ссылку](https://docs.microsoft.com/sysinternals/downloads/psping).

### <a name="measure-actual-throughput-of-a-tcp-connection"></a>Мера фактическая пропускная способность TCP-подключения

NTttcp — это средство, которое используется для проверки производительности TCP из виртуальной Машины Windows или Linux. Различные параметры TCP может быть оптимизировано и преимущества протестирован с использованием NTttcp. Дополнительные сведения о NTttcp можно найти по приведенным ниже ссылкам.

- [Проверка (NTttcp) пропускной способности](https://aka.ms/TestNetworkThroughput)

- [NTttcp Utility](https://gallery.technet.microsoft.com/NTttcp-Version-528-Now-f8b12769)

### <a name="measure-actual-bandwidth-of-a-virtual-machine"></a>Мера фактическую пропускную способность виртуальной машины

Тестирование производительности разных типов виртуальных Машин, повышения производительности сети и т. д., можно проверить при помощи средство Iperf, также доступны на Linux и Windows. Iperf можно использовать TCP или UDP для тестирования общую пропускную способность сети. Тестов пропускной способности TCP, с помощью Iperf зависят от факторов, описанных в этой статье (задержки, время приема-Передачи и т. д.). Таким образом UDP может дает лучшие результаты для простой проверки максимальной пропускной способности.

Дополнительные сведения можно найти ниже:

- [Устранение проблем с производительностью сети Expressroute](https://docs.microsoft.com/azure/expressroute/expressroute-troubleshooting-network-performance)

- [Порядок проверки пропускной способности VPN для виртуальной сети](https://docs.microsoft.com/azure/vpn-gateway/vpn-gateway-validate-throughput-to-vnet)

### <a name="detect-inefficient-tcp-behaviors"></a>Обнаружить неэффективным поведения TCP

Клиенты Azure могут см. в разделе пакеты TCP с флагами TCP (SACK, DUP ACK, повторно ПЕРЕДАВАЕМЫХ и БЫСТРО ПОВТОРЯТЬ) в записи пакетов, которые могут указывать на проблемы с производительностью сети. Эти пакеты отдельно указали неэффективное использование сети в результате потери пакетов. Тем не менее потери пакетов не обязательно из-за проблем с производительностью в Azure. Проблемы с производительностью может быть результатом приложения, операционной системы или других проблем, не связанных напрямую к платформе Azure. Это также важно отметить, что некоторые повторной передаче или повторяющиеся ACK в сети находится в обычном состоянии – протоколы TCP были созданы надежность. И свидетельство пакетов TCP в записи пакета не обязательно проблемы с сетью системные пока не будут чрезмерное.

Тем не менее он должен определить четко, чтобы узнать, что пропускная способность TCP не достигает его максимальной производительности — по причинам, описанным в других разделах эти типы пакетов.
