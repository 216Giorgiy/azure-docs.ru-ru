<properties 
	pageTitle="Заметки о выпуске HDInsight для платформы Azure" 
	description="Заметки о выпуске HDInsight." 
	services="hdinsight" 
	documentationCenter="" 
	editor="cgronlun" 
	manager="paulettm" 
	authors="bradsev"/>

<tags 
	ms.service="hdinsight" 
	ms.workload="big-data" 
	ms.tgt_pltfrm="na" 
	ms.devlang="na" 
	ms.topic="article" 
	ms.date="01/30/2015" 
	ms.author="bradsev"/>


#Заметки о выпуске Microsoft HDInsight

## Заметки о выпуске HDinsight от 29.01.2015 ##

Полный номер версии кластеров HDInsight, развернутых в данном выпуске:

* HDInsight 	2.1.10.455.1309616 (HDP 1.3.9.0-01351 - без изменений)
* HDInsight 	3.0.6.455.1309616	(HDP 2.0.9.0-2097 -  без изменений)
* HDInsight 	3.1.2.455.1309616	(HDP 2.1.9.0-2196 -  без изменений)
* Пакет SDK недоступен

Этот выпуск содержит следующее обновление.

<table border="1">
<tr>
<th>Заголовок</th>
<th>Описание</th>
<th>Затронутые области 
(например службы компонентов ОС, пакет SDK, PS, AUX)</p></th>
<th>Кластер влияет на тип (например, Hadoop, HBase, Storm, все)</th>
<th>JIRA (если применимо)</th>
</tr>


<tr>

<td> Исправления ошибок</td>
<td>Мы внесли ряд важных исправлений для повышения надежности кластеров HDInsight во время обновления Azure.</td>
<td>Службы</td>
<td></td>
<td>Недоступно</td>
</tr>



</table>
<br>

## Заметки о выпуске HDinsight от 05.01.2015 ##

Полный номер версии кластеров HDInsight для данного выпуска:

* HDInsight 	2.1.10.420.1246118(HDP 1.3.9.0-01351 - без изменений)
* HDInsight 	3.0.6.420.1246118(HDP 2.0.9.0-2097 - без изменений)
* HDInsight 	3.1.2.420.1246118(HDP 2.1.9.0-2196 - без изменений)


Этот выпуск содержит следующее обновление.

<table border="1">
<tr>
<th>Заголовок</th>
<th>Описание</th>
<th>Компонент</th>
<th>Тип кластера</th>
<th>JIRA (если применимо)</th>
</tr>


<tr>
<td>Примеры для анализа тенденций Twitter и рекомендаций по фильмам с использованием Mahout</td>
<td><p>В этом выпуске консоль запросов HDInsight имеет два дополнительных примера:</p>

<p><b>Анализ тенденций Twitter</b><br>
Общедоступные API, предоставляемые сайтами, такими как Twitter, - полезный источник данных для анализа и понимания популярных тенденций. В этом учебнике рассматривается использование Hive для получения списка пользователей Twitter, отправивших наибольшее количество твитов, содержащих определенное слово. </p>

<p><b>Рекомендации по фильмам с использованием Mahout</b><br>
Apache Mahout - это библиотека машинного обучения Apache Hadoop. Mahout содержит алгоритмы для обработки данных, такие как фильтрация, классификация и кластеризация. В этом учебнике будет использована подсистему рекомендаций для создания списка рекомендуемых к просмотру фильмов, основанного на фильмах, которые просмотрели друзья.</p></td>
<td>Консоль запросов</td>
<td>Hadoop</td>
<td>Недоступно</td>
</tr>

<tr>
<td>Изменить значение по умолчанию для параметра hive.auto.convert.join.noconditionaltask.size</td>
<td><p>Этот параметр размера относится к автоматически преобразованным соединениям сопоставлений. Значение представляет сумму размеров таблиц, которые могут быть преобразованы в хэш-карты, помещающиеся в памяти. В предыдущем выпуске это значение было увеличено со значения по умолчанию 10 МБ до 128 МБ. Тем не менее, новое значение 128 МБ вызывало сбои выполнения заданий из-за нехватки памяти. В этом выпуске возвращается значение по умолчанию 10 МБ. Пользователи по-прежнему могут переопределить это значение во время создания кластера, учитывая их размеры таблиц и запросов. Дополнительные сведения о параметре и его переопределении см. раздел  <a href="http://docs.hortonworks.com/HDPDocuments/HDP2/HDP-2.0.0.2/ds_Hive/optimize-joins.html#JoinOptimization-OptimizeAutoJoinConversion" target="_blank">Оптимизация автоматического преобразования соединения</a> в документации по Hortonworks. </p></td>
<td>Hive</td>
<td>Hadoop, Hbase</td>
<td>Недоступно</td>
</tr>

</table>
<br>

## Заметки о выпуске HDinsight от 23.12.2014 ##

Полный номер версии кластеров HDInsight для данного выпуска:

* HDInsight 	2.1.10.420.1246783 (версия HDP без изменений)
* HDInsight 	3.0.6.420.1246783 (версия HDP без изменений)
* HDInsight 	3.1.1.420.1246783 (версия HDP без изменений)

Этот выпуск содержит следующее обновление.

<table border="1">
<tr>
<th>Заголовок</th>
<th>Описание</th>
<th>Компонент</th>
<th>Тип кластера</th>
<th>JIRA (если применимо)</th>
</tr>


<tr>
<td>Intermittent Cluster Creation Failures due to excessive load</td>
<td><p>Улучшенный алгоритм для загрузки пакетов HDP во время создания кластера позволяет осуществлять более надежную обработку сбоев, возникающих из-за избыточной нагрузки. Ожидается внедрение нескольких дополнительных улучшений в этой области, которые предоставят более широкие возможности масштабирования при увеличении нагрузки, связанных с созданием кластеров.</p></td>
<td>Control</td>
<td>Hadoop, Hbase, Storm</td>
<td>Недоступно</td>
</tr>



</table>
<br>

## Заметки о выпуске HDinsight от 18.12.2014 ##

Данный выпуск содержит следующие обновления для компонентов.

<table border="1">
<tr>
<th>Заголовок</th>
<th>Описание</th>
<th>Компонент</th>
<th>Тип кластера</th>
<th>JIRA (если применимо)</th>
</tr>

<tr>
<td><a href = "http://azure.microsoft.com/ru-ru/documentation/articles/hdinsight-hadoop-customize-cluster/" target="_blank">Общедоступность настройки кластеров</a></td>
<td><p>Настройки предоставляет возможности для настройки кластеров Azure HDInsight с проектами, доступными из экосистемы Apache Hadoop. С помощью этой новой функции можно поэкспериментировать с и развертывать проекты Hadoop в Azure HDInsight. Это обеспечивается с помощью компонента <b>Действие сценария</b>, который позволяет вносить изменения в кластеры Hadoop кластеров произвольными способами с помощью пользовательских сценариев. Эта настройка доступна для всех типов кластеров HDInsight, включая Hadoop, HBase и Storm. Чтобы продемонстрировать возможности эту возможность, в документацию был включен процесс установки популярных модулей  <a href = "http://azure.microsoft.com/ru-ru/documentation/articles/hdinsight-hadoop-spark-install/" target="_blank">Spark</a>, <a href = "http://azure.microsoft.com/ru-ru/documentation/articles/hdinsight-hadoop-r-scripts/" target="_blank">R</a>, <a href = "http://azure.microsoft.com/ru-ru/documentation/articles/hdinsight-hadoop-solr-install/" target="_blank">Solr</a>и <a href = "http://azure.microsoft.com/ru-ru/documentation/articles/hdinsight-hadoop-giraph-install/" target="_blank">Giraph</a> . В этот выпуск также добавлена возможность пользователям указывать свои действия пользовательского сценария на портале управления Azure, предоставлены руководства и рекомендации по созданию действий пользовательского сценария, используя вспомогательные методы, а также рекомендации по тестированию действия сценария. </p></td>
<td>Общедоступный компонент</td>
<td>Все</td>
<td>Недоступно</td>
</tr>


</table>
<br>

## Заметки о выпуске HDinsight от 5.12.2014 ##

Полный номер версии кластеров HDInsight для данного выпуска:

* HDInsight 	2.1.9.406.1221105	(HDP 1.3.9.0-01351)
* HDInsight 	3.0.5.406.1221105	(HDP 2.0.9.0-2097)
* HDInsight 	3.1.1.406.1221105	(HDP 2.1.9.0-2196)
* Пакет SDK для HDInsight недоступен

Данный выпуск содержит следующие обновления для компонентов.

<table border="1">
<tr>
<th>Заголовок</th>
<th>Описание</th>
<th>Компонент</th>
<th>Тип кластера</th>
<th>JIRA (если применимо)</th>
</tr>

<tr>
<td>Исправление ошибки: промежуточная ошибка при добавлении большого числа разделов в таблицу в Hive DDL. </td>
<td><p>Если при добавлении разделов в таблицу Hive произойдет промежуточная ошибка подключения к базе метаданных Hive, создание библиотеки DDL Hive может завершиться сбоем. Если такой сбой произойдет, в журнале ошибок Hive отобразится следующая инструкция: </p><p>"ERROR [main]: ql.Driver (SessionState.java:printError(547)) - FAILED: Execution Error, return code 1 from org.apache.hadoop.hive.ql.exec.DDLTask. MetaException(message:java.lang.RuntimeException: commitTransaction was called but openTransactionCalls = 0. Это, вероятно, указывает на то, что существуют несбалансированные вызовы openTransaction/commitTransaction)"</p></td>
<td>Hive</td>
<td>Hadoop, Hbase</td>
<td>HIVE-482 (внутренняя запись JIRA, внешняя ссылка не предоставляется; здесь приводится для справки)</td>
</tr>

<tr>
<td>Исправление ошибки: Случайные зависания в запросе HDInsight  Консоль запросов</td>
<td>В этом случае в журнале WebHCat для задания запуска WebHCat отобразится следующая инструкция: <p>"org.apache.hive.hcatalog.templeton.CatchallExceptionMapper | org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.yarn.exceptions.YarnRuntimeException): Could not load history file {wasb url to the history file}"</p></td>
<td>WebHCat</td>
<td>Hadoop</td>
<td>HIVE-482 (внутренняя запись JIRA, внешняя ссылка не предоставляется; здесь приводится для справки)</td>
</tr>

<tr>
<td>Исправление ошибки: случайный всплеск задержек запросов Hbase</td>
<td>В этом случае пользователи заметят случайный всплеск задержек запросов Hbase продолжительностью 3 секунды. </td>
<td>Шлюз кластера HDInsigh</td>
<td>HBase</td>
<td>Недоступно</td>
</tr>

<tr>
<td>Изменения имен JAR-файлов HDP</td>
<td>В кластеры HDI версии 3.0 внесен ряд изменений, касающийся внутренних JAR-файлов, установленных HDP. Файл jetty-6.1.26.jar
 был заменен файлом jetty-6.1.26.hwx.jar. Файл jetty-util-6.1.26.jar был заменен файлом jetty-util-6.1.26.hwx.jar. Эти изменения касаются проектов Hadoop, Mahout, WebHCat и Oozie.**</td>
<td>Hadoop, Mahout, WebHCat, Oozie</td>
<td>Hadoop, HBase</td>
<td>Недоступно</td>
</tr>

</table>
<br>


## Заметки о выпуске HDinsight от 21.11.2014 ##

Полный номер версии кластеров HDInsight для данного выпуска:

* HDInsight 2.1.9.382.1169709 (с 14.11.2014 изменения отсутствуют)
* HDInsight 3.0.5.382.1169709 (с 14.11.2014 изменения отсутствуют)
* HDInsight 3.1.1.382.1169709 (с 14.11.2014 изменения отсутствуют)
* HDINsight SDK 1.4.0

Данный выпуск содержит следующие обновления для компонентов.

<table border="1">
<tr>
<th>Заголовок</th>
<th>Описание</th>
<th>Компонент</th>
<th>Тип кластера</th>
<th>JIRA (если применимо)</th>
</tr>

<tr>
<td>Доступ к журналам приложений</td>
<td>Возможность программно пронумеровать приложения, которые были запущены в ваших кластерах, и скачать журналы для конкретных приложений или контейнеров, чтобы упростить отладку проблемных приложений.</td>
<td>SDK</td>
<td>Hadoop</td>
<td>Недоступно</td>
</tr>

<tr>
<td>Возможность указать название региона в IHdInsightClient.DeleteCluster </td>
<td>Пакет SDK для Azure HDInsight теперь предоставляет возможность указывать название региона при использовании **DeleteCluster**. Это позволяет разблокировать клиентов, которые имели 2 ресурса с одинаковыми именами в разных регионах и не могли удалить ни один из них.</td>
<td>SDK</td>
<td>Все</td>
<td>Недоступно</td>
</tr>

<tr>
<td>ClusterDetails.DeploymentId</td>
<td>Объект **ClusterDetails** теперь возвращает поле **DeploymentID**, которое представляет собой уникальный идентификатор кластера. Он является гарантированно уникальным среди попыток создания кластера с одинаковыми именами.</td>
<td>SDK</td>
<td>Все</td>
<td>Недоступно</td>
</tr>
</table>
<br>

## Заметки о выпуске HDinsight от 14.11.2014 ##

Полный номер версии кластеров HDInsight для данного выпуска:

* HDInsight 2.1.9.382.1169709
* HDInsight 3.0.5.382.1169709
* HDInsight 3.1.1.382.1169709

Данный выпуск содержит следующие новые функции, обновления для компонентов и исправления ошибок.

<table border="1">
<tr>
<th>Заголовок</th>
<th>Описание</th>
<th>Компонент</th>
<th>Тип кластера</th>
<th>JIRA (если применимо)</th>
</tr>

<tr>
<td>Действие сценария (предварительная версия)</td>
<td>Предварительная версия функции настройки кластеров, которая позволяет изменять кластеры Hadoop произвольным способом с помощью пользовательских сценариев. С помощью этой новой функции пользователи могут экспериментировать с проектами, доступными в экосистеме Apache Hadoop, а также выполнять их развертывание на кластерах Azure HDInsight. Эта функция настройки доступна в кластерах HDInsight всех типов, в том числе Hadoop, HBase и Storm.</td>
<td>Новая функция</td>
<td>Все</td>
<td>Недоступно</td>
</tr>

<tr>
<td>Предварительно созданные задания для анализа журналов веб-сайтов и службы хранилища Azure</td>
<td>Консоль запросов HDInsight содержит коллекцию для начала работы, которая поддерживает решения, работающие как с вашими данными, так и с примерами данных.
<p>Решения, работающие на ваших данных:<br>
Мы разработали задания для наиболее распространенных сценариев анализа данных, которые послужат вам отправной точкой для создания ваших собственных решений. Вы можете использовать с заданием свои собственные данные, чтобы увидеть, как это работает. Затем, когда будете готовы, используйте приобретенные знания для создания собственного решения, смоделированного по предварительно созданному заданию.</p>
<p>Решения, работающие на примерах данных:<br>
Узнайте, как работать с HDInsight, пошагово пройдя некоторые базовые сценарии, такие как анализ веб-журналов и данных датчиков. Вы научитесь не только использовать HDInsight для анализа этих данных, но и подключать к этим данным другие приложения и службы. Визуализация данных с помощью подключения к Microsoft Excel наглядно демонстрирует преимущества такого подхода.</p></td>
<td>Консоль запросов</td>
<td>Hadoop</td>
<td>Недоступно</td>
</tr>

<tr>
<td>Устранение проблемы доступа к памяти в Templeton</td>
<td>С проблемой доступа к памяти в Templeton столкнулись клиенты, у которых был долго работающий кластер или которые отправляли сотни запросов на выполнение заданий в секунду. Проблема выражалась в отображении ошибок Templeton с кодом "5xx", а для избавления от проблемы требовалась перезагрузка службы. Это действие больше не требуется.</td>
<td>Templeton</td>
<td>Все</td>
<td>https://issues.apache.org/jira/browse/HADOOP-11248</td>
</tr>
</table>
<br>


Примечание. Чтобы продемонстрировать новые возможности, ставшие доступными благодаря настройке кластера, были написаны разделы, в которых описываются процедуры использования действий сценария для установки на кластере модулей Spark и R. Дополнительную информацию см. в разделах:

* [Установка и использование Spark 1.0 на кластерах HDInsight][hdinsight-install-spark]
* [Установка и использование R на кластерах HDInsight Hadoop][hdinsight-r-scripts]




## Заметки о выпуске HDinsight от 07.11.2014 ##

Полный номер версии кластеров HDInsight для данного выпуска:

* HDInsight 2.1	2.1.9.374.1153876
* HDInsight 3.0	3.0.5.374.1153876
* HDInsight 3.1	3.1.1.374.1153876

Данный выпуск содержит следующие обновления для компонентов.

<table border="1">
<tr>
<th>Заголовок</th>
<th>Описание</th>
<th>Компонент</th>
<th>Тип кластера</th>
<th>JIRA (если применимо)</th>
</tr>

<tr>
<td>HDP 2.1.7</td>
<td>Этот выпуск основывается на платформе данных Hortonworks (HDP) версии 2.1.7. Заметки о выпуске HDP 2.1.7 доступны на сайте Hortonworks по адресу http://docs.hortonworks.com/HDPDocuments/HDP2/HDP-2.1.7-Win/bk_releasenotes_HDP-Win/content/ch_relnotes-HDP-2.1.7.html.</td>
<td>HDP</td>
<td>Все</td>
<td>Недоступно</td>
</tr>

<tr>
<td>YARN Timeline Server</td>
<td>YARN Timeline Server (также называемый сервером истории универсальных приложений) включен по умолчанию. Timeline Server предоставляет общую информацию о завершенных приложениях, такую как код приложения, имя приложения, состояние приложения, время отправки приложения и время завершения приложения. <p>Эту информацию о приложении можно получить от головного узла, обратившись по универсальному коду ресурса (URI) http://headnodehost:8188 или выполнив команду YARN: yarn application -list -appStates ALL.</p> 
<p>Также эту информацию можно получить удаленно, используя REST API по адресу https://{ClusterDnsName}. azurehdinsight.net/ws/v1/applicationhistory/.</p> 
<p>Дополнительная информация о Timeline Server доступна по адресу http://hadoop.apache.org/docs/r2.4.0/hadoop-yarn/hadoop-yarn-site/TimelineServer.html.</p></td>
<td>Служба, YARN</td>
<td>Hadoop, HBase</td>
<td>Недоступно</td>
</tr>

<tr>
<td>Идентификатор развертывания кластера</td>
<td>Начиная с последней версии пакета SDK, 1.3.3.1.5426.29232, пользователи могут получать доступ к HDInsight, используя уникальный идентификатор для каждого кластера. Это позволит клиентам получать уникальные экземпляры кластеров, когда DNS-имя повторно используется в различных сценариях создания или удаления.</td>
<td>SDK</td>
<td>Все</td>
<td>Недоступно</td>
</tr>
</table>
<br>

* Обратите внимание, что в данном выпуске была исправлена ошибка, которая не позволяла полной версии отображаться на портале и возвращаться пакетом SDK или PowerShell. 

## Заметки о выпуске от 15/10/2014 ##

Данный выпуск содержит исправление, которое устраняет проблему доступа к памяти в Templeton, возникающую у активных пользователей Templeton. В некоторых случаях активные пользователи Templeton сталкивались с ошибками "Код ошибки: 500", потому что для выполнения запроса не хватало памяти. Для избавления от проблемы требовалась перезагрузка службы Templeton. Теперь эта проблема исправлена.


## Заметки о выпуске от 7.10.2014 ##

* При использовании конечной точки Ambari  "https://{clusterDns}.azurehdinsight.net/ambari/api/v1/clusters/{clusterDns}.azurehdinsight.net/services/{servicename}/components/{componentname}", поле *host_name* теперь возвращает полностью определенное доменное имя (FQDN) узла вместо только одного имени узла. Например, вместо возвращаемого значения "**headnode0**" вы получите полное доменное имя "**headnode0.{ClusterDNS}.azurehdinsight.net**". Это изменение было продиктовано необходимостью использовать сценарии, в которых кластеры различного типа, например кластеры HBase и Hadoop, можно было бы размещать в одной виртуальной сети (VNET). Такая необходимость может возникнуть, например, при использовании HBase в качестве вспомогательной платформы для Hadoop.

* Мы позаботились о новых настройках памяти для стандартного размещения кластера HDInsight. Прошлые стандартные настройки памяти в недостаточной мере предусматривали ориентацию на количество установленных основных процессоров. Новые настройки памяти должны обеспечить лучшие значения по умолчанию, в соответствии с рекомендациями Hortonworks. Чтобы изменить эти настройки, см. справочную документацию по пакету SDK (об изменении конфигурации кластера). Новые настройки памяти предусматривают использование 4 ядер CPU (8 контейнеров). Кластеры HDInsight перечисляются в таблице ниже: (Значения предыдущих версий также указаны в скобках) 
 
<table border="1">
<tr><th>Компонент</th><th>Выделение памяти</th></tr>
<tr><td> yarn.scheduler.minimum-allocation</td><td>768 MБ (раньше 512 MБ)</td></tr>
<tr><td> yarn.scheduler.maximum-allocation</td><td>6144 MБ (не изменялось)</td></tr>
<tr><td>yarn.nodemanager.resource.memory</td><td>6144 MБ (не изменялось)</td></tr>
<tr><td>mapreduce.map.memory</td><td>768 MБ (раньше 512 MБ)</td></tr>
<tr><td>mapreduce.map.java.opts</td><td>opts=-Xmx512m (раньше -Xmx410m)</td></tr>
<tr><td>mapreduce.reduce.memory</td><td>1536 МБ (раньше 1024 MБ)</td></tr>
<tr><td>mapreduce.reduce.java.opts</td><td>opts=-Xmx1024m (раньше -Xmx819m)</td></tr>
<tr><td>yarn.app.mapreduce.am.resource</td><td>768 MБ (раньше 1024 MБ)</td></tr>
<tr><td>yarn.app.mapreduce.am.command</td><td>opts=-Xmx512m (раньше -Xmx819m)</td></tr>
<tr><td>mapreduce.task.io.sort</td><td>256 MБ (раньше 200 MБ)</td></tr>
<tr><td>tez.am.resource.memory</td><td>1536 MБ (не изменялось)</td></tr>

</table><br>

Для получения более подробной информации о настройках памяти YARN и MapReduce на платформе данных Hortonworks, используемой HDInsight, см. раздел [Определение настроек памяти для платформы Hortonworks](http://docs.hortonworks.com/HDPDocuments/HDP2/HDP-2.1-latest/bk_installing_manually_book/content/rpm-chap1-11.html) Платформы Hortonworks также оснащены устройством подсчета необходимого количества памяти.

Ошибка HDInsight PowerShell/SDK: "*Кластер не настроен для доступа служб HTTP*":

* Эта ошибка известна как [ошибка совместимости](https://social.msdn.microsoft.com/Forums/azure/en-US/a7de016d-8de1-4385-b89e-d2e7a1a9d927/hdinsight-powershellsdk-error-cluster-is-not-configured-for-http-services-access?forum=hdinsight), которая может появляться в случае различия версии SDK/PowerShell и версии кластера. Кластеры, созданные на основе версии 8/15 и более поздней версии, поддерживают новые возможности распределения в виртуальных сетях. Но эти же возможности неправильно интерпретируются более старыми версиями SDK и PowerShell. В результате мы имеем ошибку при отправке задания. При использовании интерфейсов API пакета SDK или командлетов PowerShell для отправки заданий (**Use-AzureHDInsightCluster**, **Invoke-Hive**), эти операции могут завершиться ошибкой с сообщением об ошибке "*Кластер <имя_кластера> не настроен для доступа служб HTTP*" или в зависимости от операции, другими сообщениями об ошибках, таких как "*Не удается подключиться к кластеру*".

* Эти проблемы с совместимостью решены в последней версии HDInsight SDK и Azure PowerShell. Мы советуем обновить HDInsight SDK до версии 1.3.1.6 или до более поздней версии, а набор инструментов Azure PowerShell до версии 0.8.8 или до более поздней версии. Доступ к последней версии HDInsight SDK можно получить в разделе [NuGet](http://nuget.codeplex.com/wikipage?title=Getting%20Started), а к последней версии PowerShell Tools в разделе [Установка и настройка Azure PowerShell](http://azure.microsoft.com/ru-ru/documentation/articles/install-configure-powershell/).

* Можете быть уверены в том, что SDK и PowerShell будут бесперебойно работать после обновления кластеров, до тех пор пока версия кластеров не изменится. Например, версия кластеров 3.1 совместима с текущими версиями SDK и PowerShell 1.3.1.6 и 0.8.8. соответственно.


## Заметки о выпуске HDinsight версии 3.1 от 12.09.2014##

* Этот выпуск основывается на платформе данных Hortonworks (HDP) версии 2.1.5. С перечнем ошибок, исправленных в этом выпуске, можно ознакомиться на странице [Исправления этого выпуска](http://docs.hortonworks.com/HDPDocuments/HDP2/HDP-2.1.5/bk_releasenotes_hdp_2.1/content/ch_relnotes-hdp-2.1.5-fixed.html) веб-сайта Hortonworks.
* В папке библиотек Pig файл "avro-mapred-1.7.4.jar" был заменен на "avro-mapred-1.7.4-hadoop2.jar". В содержании этого файла была исправлена незначительная ошибка, связанная с требованием неразрывности. Мы советуем пользователям не изменять имя JAR-файла самостоятельно, чтобы избежать проблем с появлением разрывов после переименования файла.


## Заметки о выпуске от 21.08.2014 ##

* Мы добавляем следующую новую конфигурацию WebHCat (HIVE-7155), которая определяет предельный объем памяти по умолчанию для задания контроллера Templeton на уровне 1 ГБ (предыдущее значение по умолчанию было 512 МБ):
	
	* templeton.mapper.memory.mb (=1024)
	* Это изменение позволяет устранить следующие ошибки, которые возникали при выполнении определенных запросов Hive вследствие более низких предельных объемов памяти: "Контейнер выходит за предельные объемы физической памяти".
	* Чтобы вернуться к старым значениям по умолчанию, можно задать значение этой конфигурации на 512 с помощью PowerShell SDK во время создания кластера, используя следующую команду:
	
		Add-AzureHDInsightConfigValues -Core @{"templeton.mapper.memory.mb"="512";}


* Имя узла роли zookeeper было изменено на zookeeper. Это оказывает влияние на разрешение имени в кластере, но не влияет на внешние REST API. При наличии компонентов с именем узла zookeepernode необходимо будет обновить их, чтобы они вместо этого использовали новые имена. Для трех узлов zookeeper используются следующие новые имена: 
	* zookeeper0 
	* zookeeper1 
	* zookeeper2 
* Обновлена матрица поддержки версии HBase. Для производственных нагрузок HBase поддерживается только версия HDInsight 3.1 (HBase версии 0.98). Версия 3.0, которая была доступна для предварительной версии, в дальнейшем поддерживаться не будет. Во время переходного периода клиенты по-прежнему могут создавать кластеры версии 3.0. 

## Заметки о кластерах, созданных до 15.08.2014 ##

Ошибка в HDInsight PowerShell и SDK с текстом "Кластер <clustername> не настроен для доступа служб HTTP" (или, в зависимости от отправленной задачи, с текстом другого типа, например: "Невозможно соединиться с кластером") чаще всего встречается при различии версии SDK или PowerShell и версии кластера. Кластеры, созданные на основе версии 8/15 и более поздней версии, поддерживают новые возможности распределения в виртуальных сетях. Данная возможность неправильно интерпретируется на SDK и PowerShell старых версий, что приводит к ошибкам при отправке задания. Если для отправки задания вы используете командлеты SDK API или PowerShell (такие как Use-AzureHDInsightCluster, Invoke-AzureHDInsightHiveJob), то задания могут возвратиться с ошибками, описанными выше.

Эти проблемы с совместимостью решены в последней версии SDK и Azure PowerShell. Мы советуем обновить HDInsight SDK до версии 1.3.1.6 или до более поздней версии, а набор инструментов Azure PowerShell до версии 0.8.8 или более поздней версии. Доступ к последней версии HDInsight SDK можно получить в разделе [nuget](https://www.nuget.org/packages/Microsoft.WindowsAzure.Management.HDInsight/), а к последней версии PowerShell Tools в разделе [Microsoft Web PI](http://go.microsoft.com/?linkid=9811175&clcid=0x409).

Можете быть уверены в том, что SDK и PowerShell будут бесперебойно работать после обновления кластеров, до тех пор пока версия кластеров не изменится. Например, версия кластеров 3.1 совместима с текущими версиями SDK и PowerShell 1.3.1.6 и 0.8.8. соответственно.


## Заметки о выпуске от 28.07.2014 ##

* **Служба HDInsight доступна в новых регионах**: В этом выпуске присутствие службы HDInsight расширено на три новых географических региона. Клиенты HDInsight могут теперь создавать кластеры в этих регионах. 
	* Восточная Азия, 
	* Северо-центральный регион США и 
	* Южно-центральный регион США. 
* С выходом этого выпуска HDInsight v1.6 (HDP1.1, Hadoop 1.0.3) и HDInsight v2.1 (HDP1.3, Hadoop 1.2) удаляются с портала управления Azure. Можно продолжить создавать кластеры Hadoop для этих версий с помощью командлетов([New-AzureHDInsightCluster](http://msdn.microsoft.com/ru-ru/library/dn593744.aspx)) или с помощью [пакета HDInsight SDK](http://msdn.microsoft.com/ru-ru/library/azure/dn469975.aspx). Для получения дополнительной информации см. раздел [Версии компонентов HDInsight ](http://azure.microsoft.com/ru-ru/documentation/articles/hdinsight-component-versioning/).
* Изменения платформы данных Hortonworks Data Platform (HDP) в этом выпуске: 

<table border="1">
<tr><th>HDP</th><th>изменения</th></tr>
<tr><td>HDP 1.3 / HDI 2.1</td><td>Без изменений</td></tr>
<tr><td>HDP 2.0 / HDI 3.0</td><td>Без изменений</td></tr>
<tr><td>HDP 2.1 / HDI 3.1</td><td>zookeeper: ['3.4.5.2.1.3.0-1948'] -> ['3.4.5.2.1.3.2-0002']</td></tr>


</table><br>

## Заметки о выпуске 24/06/2014 ##

В этом выпуске содержится несколько новых улучшений службы HDInsight: 

* **Доступность HDP 2.1**: Служба HDInsight 3.1, содержащая HDP 2.1, теперь общедоступна и представляет собой версию по умолчанию для новых кластеров.
* **HBase - улучшения портала управления Azure**: Кластеры HBase становятся доступны в предварительной версии. Теперь можно создавать кластеры HBase из портала с помощью всего 3 щелчков.

![](http://i.imgur.com/cmOl5fM.png)

Благодаря кластерам HBase можно создавать различные рабочие нагрузки на HDInsight в реальном времени, начиная от интерактивных веб-сайтов с большими наборами данных до служб, сохраняющих данные датчиков и телеметрии от миллионов конечных точек. На следующем шаге было бы необходимо проанализировать данные в этих рабочих нагрузках с помощью заданий Hadoop. Это можно сделать прямо в службе HDInsight через такие представленные интерфейсы, как PowerShell и панель мониторинга кластеров Hive.

### Библиотеке Apache Mahout теперь предустановлена в службе HDInsight 3.1 ###

 Библиотека [Mahout](http://hortonworks.com/hadoop/mahout/) предустановлена в кластерах HDInsight 3.1 Hadoop. Благодаря этому можно выполнять задания Mahout без необходимости дополнительно настраивать кластер. Например, можно выйти на удаленный кластер Hadoop с использованием протокола удаленного рабочего стола (RDP) и без дополнительных шагов выполнить команду Mahout "Привет всем!":

		mahout org.apache.mahout.classifier.df.tools.Describe -p /user/hdp/glass.data -f /user/hdp/glass.info -d I 9 N L  

		mahout org.apache.mahout.classifier.df.BreimanExample -d /user/hdp/glass.data -ds /user/hdp/glass.info -i 10 -t 100

Более подробную информацию об этой процедуре см. в документации [Пример Breiman](https://mahout.apache.org/users/classification/breiman-example.html) на веб-сайте Apache Mahout. 


### Запросы Hive можно использовать в Tez 3.1 на HDInsight ###

Hive 0.13 теперь доступен в HDInsight 3.1 и может выполнять запросы с использованием Tez, что даст возможность значительно улучшить производительность. 
Среда Tez по умолчанию недоступна для запросов Hive. Чтобы ее использовать, необходимо ее выбрать. Можно включить Tez, выполнив следующий фрагмент кода:

		set hive.execution.engine=tez;
		select sc_status, count(*), histogram_numeric(sc_bytes,5) from website_logs_orc_local group by sc_status;

На платформе Hortonworks опубликована подробная разбивка улучшений производительности запросов Hive с использованием Tez по данным стандартных тестов производительности. Подробную информацию см. в разделе [Тест производительности Apache Hive 13 для Enterprise Hadoop](http://hortonworks.com/blog/benchmarking-apache-hive-13-enterprise-hadoop/) 

Более подробную информацию об использовании Hive с Tez см. в разделе [Hive на вики-странице Tez](https://cwiki.apache.org/confluence/display/Hive/Hive+on+Tez)

###Глобальная доступность
С выходом Azure HDInsight на Hadoop 2.2 корпорация Microsoft сделала службу HDInsight доступной во все основных регионах расположения Azure. В частности, подключены центры обработки данных в Западной Европе и Юго-Восточной Азии. Благодаря этому клиенты могут подобрать кластеры в центре обработки данных, который расположен неподалеку и, возможно, находится в зоне со схожими требованиями по соблюдению законодательства. 


###Полезные советы по работе с кластерами разных версий

**Хранилище метаданных Oozie, используемое с кластером HDInsight 3.1, обратно не совместимо с кластерами HDInsight 2.1, и его использование с кластерами предыдущих версий невозможно.**

Стандартную базу метаданных Oozie, развернутую в кластере HDInsight 3.1, невозможно повторно использовать с кластерами HDInsight 2.1. В данном случае это невозможно, даже если хранилище метаданных было развернуто с кластером версии 2.1. Такой сценарий не поддерживается, поскольку при использовании с кластером версии 3.1 схема хранилища метаданных обновляется и становится несовместимой для работы с кластерами версии 2.1. Все попытки повторного использования хранилища метаданных Oozie с версией кластера 2.1, если до этого оно использовалось с версией кластера 3.1, бесполезны. 

**Хранилища метаданных Oozie не могут принадлежать разным кластерам**
В более общем и в некотором ином смысле, хранилища метаданных Oozie прикреплены к конкретным кластерам, и к ним невозможно предоставить общий доступ.

###Критические изменения

**Синтаксис префикса**:
В кластерах HDInsight 3.0  и 3.1 поддерживается только синтаксис "wasb://". Прежний синтаксис "asv: / /" поддерживается в кластерах HDInsight 2.1 и 1.6, однако не поддерживается в кластерах HDInsight 3.0 или в последующих версиях. Это означает, что все задания, отправляемые в кластер HDInsight версий 3.0   или 3.1, которые явно используют синтаксис "asv://", завершатся ошибкой. Вместо этого следует использовать синтаксис "wasb://". Кроме того, сбоем будут завершатся задания, отправляемые в кластеры HDInsight 3.0 или 3.1, которые созданы с существующим метахранилищем, содержащим явные ссылки на ресурсы с использованием синтаксиса "asv://". Эти метахранилища потребуется создать повторно с использованием синтаксиса wasb://, чтобы адресовать ресурсы. 


**Порты**: Изменены порты, используемые службой HDInsight. Номера ранее используемых портов находились во временном диапазоне портов ОС Windows. Порты распределяются автоматически из предопределенного временного диапазона для краткосрочных обменов данными на базе протокола IP. Новый набор допустимых номеров портов службы платформы данных Hortonworks (HDP) теперь находится вне этого диапазона, что позволяет избежать конфликтов, которые могли бы возникать с портами, уже используемыми службами, выполняемыми на головном узле. Новые номера портов не должны вызывать никаких критических изменений. В настоящее время используются следующие номера:

 **HDInsight 1.6 (HDP 1.1)**
<table border="1">
<tr><th>Имя</th><th>Значение</th></tr>
<tr><td>dfs.http.address</td><td>namenodehost:30070</td></tr>
<tr><td>dfs.datanode.address</td><td>0.0.0.0:30010</td></tr>
<tr><td>dfs.datanode.http.address</td><td>0.0.0.0:30075</td></tr>
<tr><td>dfs.datanode.ipc.address</td><td>0.0.0.0:30020</td></tr>
<tr><td>dfs.secondary.http.address</td><td>0.0.0.0:30090</td></tr>
<tr><td>mapred.job.tracker.http.address</td><td>jobtrackerhost:30030</td></tr>
<tr><td>mapred.task.tracker.http.address</td><td>0.0.0.0:30060</td></tr>
<tr><td>mapreduce.history.server.http.address</td><td>0.0.0.0:31111</td></tr>
<tr><td>templeton.port</td><td>30111</td></tr>
</table><br>

 **HDInsight 3.0 и 3.1 (HDP 2.0 и 2.1)**
<table border="1">
<tr><th>Имя</th><th>Значение</th></tr>
<tr><td>dfs.namenode.http-address</td><td>namenodehost:30070</td></tr>
<tr><td>dfs.namenode.https-address</td><td>headnodehost:30470</td></tr>
<tr><td>dfs.datanode.address</td><td>0.0.0.0:30010</td></tr>
<tr><td>dfs.datanode.http.address</td><td>0.0.0.0:30075</td></tr>
<tr><td>dfs.datanode.ipc.address</td><td>0.0.0.0:30020</td></tr>
<tr><td>dfs.namenode.secondary.http-address</td><td>0.0.0.0:30090</td></tr>
<tr><td>yarn.nodemanager.webapp.address</td><td>0.0.0.0:30060</td></tr>
<tr><td>templeton.port</td><td>30111</td></tr>
</table><br>

###Зависимости 

В HDInsight 3.x (HDP2.x) добавлены следующие зависимости:

* guice-servlet
* optiq-core
* javax.inject
* activation
* jsr305
* geronimo-jaspic_1.0_spec
* jul-to-slf4j
* java-xmlbuilder
* ant
* commons-compiler
* jdo-api
* commons-math3
* paranamer
* jaxb-impl
* stringtemplate
* eigenbase-xom
* jersey-servlet
* commons-exec
* jaxb-api
* jetty-all-server
* janino
* xercesImpl
* optiq-avatica
* jta
* eigenbase-properties
* groovy-all
* hamcrest-core
* mail
* linq4j
* jpam
* jersey-client
* aopalliance
* geronimo-annotation_1.0_spec
* ant-launcher
* jersey-guice
* xml-apis
* stax-api
* asm-commons
* asm-tree
* wadl
* geronimo-jta_1.1_spec
* guice
* leveldbjni-all
* velocity
* jettison
* snappy-java
* jetty-all
* commons-dbcp

В HDInsight 3.x (HDP2.x) больше не существуют следующие зависимости:

* jdeb
* kfs
* sqlline
* ivy
* aspectjrt
* json
* core
* jdo2-api
* avro-mapred
* datanucleus-enhancer
* jsp
* commons-logging-api
* commons-math
* JavaEWAH
* aspectjtools
* javolution
* hdfsproxy
* hbase
* snappy

###Изменения версий 

Между HDInsight 2.x (HDP1.x) и HDInsight 3.x (HDP2.x) были сделаны следующие изменения версий:

* metrics-core: ['2.1.2'] -> ['3.0.0']
* derbynet: ['10.4.2.0'] -> ['10.10.1.1']
* datanucleus: ['rdbms-3.0.8'] -> ['rdbms-3.2.9']
* jasper-compiler: ['5.5.12'] -> ['5.5.23']
* log4j: ['1.2.15', '1.2.16'] -> ['1.2.16', '1.2.17']
* derbyclient: ['10.4.2.0'] -> ['10.10.1.1']
* httpcore: ['4.2.4'] -> ['4.2.5']
* hsqldb: ['1.8.0.10'] -> ['2.0.0']
* jets3t: ['0.6.1'] -> ['0.9.0']
* protobuf-java: ['2.4.1'] -> ['2.5.0']
* derby: ['10.4.2.0'] -> ['10.10.1.1']
* jasper: ['runtime-5.5.12'] -> ['runtime-5.5.23']
* commons-daemon: ['1.0.1'] -> ['1.0.13']
* datanucleus-core: ['3.0.9'] -> ['3.2.10']
* datanucleus-api-jdo: ['3.0.7'] -> ['3.2.6']
* zookeeper: ['3.4.5.1.3.9.0-01320'] -> ['3.4.5.2.1.3.0-1948']
* bonecp: ['0.7.1.RELEASE'] -> ['0.8.0.RELEASE']


###Драйверы
Драйвер JDBC для SQL Server используется в HDInsight и не используется для внешних операций. Если нужно подключиться к HDInsight с использованием ODBC, следует использовать драйвер ODBC для Microsoft Hive. Дополнительную информацию об использовании Hive ODBC см. в разделе [Подключение Excel к HDInsight с помощью драйвера Microsoft Hive ODBC][connect-excel-with-hive-ODBC].


### Исправления ошибок ###

В этом выпуске были обновлены следующие HDInsight  (Платформы данных Hortonworks - HDP) версии с несколькими исправлениями ошибок:

* HDInsight 2.1 (HDP 1.3)
* HDInsight 3.0 (HDP 2.0)
* HDInsight 3.1 (HDP 2.1)


## Заметки о выпуске Hortonworks ##

Заметки о выпуске HDP, используемые версиями кластерами HDInsight, доступны в следующих местоположениях.

* Кластер HDInsight версии 3.1 использует пакет Hadoop, основанный на платформе данных [Нortonworks Data Platform 2.1.7][hdp-2-1-7]. С 7.11.2014 г. этот кластер Hadoop создается по умолчанию при использовании портала Azure HDInsight. Кластеры HDInsight 3.1, созданные до 7.11.2014 г., работают на платформе данных [Hortonworks Data Platform 2.1.1][hdp-2-1-1] 

* Кластер HDInsight версии 3.0 использует пакет Hadoop, основанный на платформе данных [Hortonworks Data Platform 2.0][hdp-2-0-8].

* Кластер HDInsight версии 2.1 использует пакет Hadoop, основанный на платформе данных [Hortonworks Data Platform 1.3][hdp-1-3-0]. 

* Кластер HDInsight версии 1.6 использует пакет Hadoop, основанный на платформе данных [Hortonworks Data Platform 1.1][hdp-1-1-0]. 

[hdp-2-1-7]: http://docs.hortonworks.com/HDPDocuments/HDP2/HDP-2.1.7-Win/bk_releasenotes_HDP-Win/content/ch_relnotes-HDP-2.1.7.html

[hdp-2-1-1]: http://docs.hortonworks.com/HDPDocuments/HDP2/HDP-2.1.1/bk_releasenotes_hdp_2.1/content/ch_relnotes-hdp-2.1.1.html

[hdp-2-0-8]: http://docs.hortonworks.com/HDPDocuments/HDP2/HDP-2.0.8.0/bk_releasenotes_hdp_2.0/content/ch_relnotes-hdp2.0.8.0.html

[hdp-1-3-0]: http://docs.hortonworks.com/HDPDocuments/HDP1/HDP-1.3.0/bk_releasenotes_hdp_1.x/content/ch_relnotes-hdp1.3.0_1.html

[hdp-1-1-0]: http://docs.hortonworks.com/HDPDocuments/HDP1/HDP-Win-1.1/bk_releasenotes_HDP-Win/content/ch_relnotes-hdp-win-1.1.0_1.html


[hdinsight-install-spark]: ../hdinsight-hadoop-spark-install/
[hdinsight-r-scripts]: ../hdinsight-hadoop-r-scripts/



<!--HONumber=42-->
