---
title: "Управление нагрузкой микрослужбы Azure с помощью метрик | Документация Майкрософт"
description: "Узнайте, как настраивать и использовать метрики в Service Fabric, чтобы управлять потреблением ресурсов службы."
services: service-fabric
documentationcenter: .net
author: masnider
manager: timlt
editor: 
ms.assetid: 0d622ea6-a7c7-4bef-886b-06e6b85a97fb
ms.service: Service-Fabric
ms.devlang: dotnet
ms.topic: article
ms.tgt_pltfrm: NA
ms.workload: NA
ms.date: 01/05/2017
ms.author: masnider
translationtype: Human Translation
ms.sourcegitcommit: bb27d279396aa7b670187560cebe2ed074576bad
ms.openlocfilehash: c0e5418574920495bf277f4127b97ff5b07b56ef


---
# <a name="managing-resource-consumption-and-load-in-service-fabric-with-metrics"></a>Управление потреблением ресурсов и нагрузкой в Service Fabric с помощью метрик
Метрики — общий термин в Service Fabric, относящийся к ресурсам, которые нужны вашим службам и которые предоставляются узлами в кластере. Вообще метрика — это все, чем требуется управлять, чтобы контролировать производительность своих служб.

Примерами метрик может служить использование памяти, дисков и ЦП. Это физические метрики, т. е. ресурсы, соответствующие физическим ресурсам на узле, которыми нужно управлять. Метрики также могут быть (и зачастую являются) логическими. Примерами логических метрик могут служить MyWorkQueueDepth, MessagesToProcess и TotalRecords. Логические метрики определяются в приложении и соответствуют определенному потреблению физических ресурсов (само приложение не знает, как его измерить). Это типичная ситуация. Большинство встречающихся пользователям метрик являются логическими. Это преимущественно вызвано тем, что на сегодняшний день для создания многих служб используется управляемый код. Из-за этого в хост-процессе сложно измерить потребление физических ресурсов одним объектом службы, равно как и предоставить соответствующие отчеты. Именно из-за сложности измерения и создания отчетов о собственных метриках мы предоставляем метрики по умолчанию.

## <a name="default-metrics"></a>Метрики по умолчанию
Предположим, вы хотите приступить к работе и не знаете, какие ресурсы вы будете использовать, или даже не знаете, какие из них для вас важны. Поэтому вы переходите к реализации и создаете службы без указания метрик. Все в порядке. Cluster Resource Manager в Service Fabric собирает значения нескольких простых метрик автоматически. Если вы не указали собственные метрики, мы по умолчанию используем для вас сегодня следующие метрики: PrimaryCount (первичное количество), ReplicaCount (количество реплик) и Count (количество). В следующей таблице показана связь нагрузки для каждой метрики с каждым из объектов службы.

| Метрика | Нагрузка экземпляра без отслеживания состояния | Вторичная нагрузка с отслеживанием состояния | Первичная нагрузка с отслеживанием состояния |
| --- | --- | --- | --- |
| PrimaryCount |0 |0 |1 |
| ReplicaCount |0 |1 |1 |
| Count |1 |1 |1 |

Итак, что же вы получаете с помощью этих используемых по умолчанию метрик? Оказывается, что работа правильно распределяется между основными рабочими нагрузками. В следующем примере показано, что происходит при создании двух служб. Первая из них — служба с отслеживанием состояния, тремя разделами и размером целевого набора реплик равным трем. Вторая — служба без отслеживания состояния с одним разделом и числом экземпляров равным трем.

<center>
![Макет кластера с метриками по умолчанию][Image1]
</center>

Вот что получается в итоге.

* Первичные реплики для службы с отслеживанием состояния не расположены на одном узле.
* Реплики одного раздела не находятся на одном и том же узле.
* Общее число первичных и вторичных реплик распределено в кластере.
* Общее количество объектов службы равномерно выделено на каждом узле.

Хорошо!

Все будет работать отлично, пока вы не начнете запускать большое количество фактических рабочих нагрузок. Какова вероятность того, что выбранная схема секционирования приведет к идеально равномерному использованию ресурсов всеми разделами? Какова вероятность того, что данная служба испытывает одинаковую нагрузку все время или даже прямо сейчас?

В действительности можно обойтись метриками по умолчанию, но обычно в таком случае кластер используется меньше, чем хотелось бы. Это связано с тем, что отчеты по стандартным метрикам не адаптивны и подразумевают эквивалентность всех служб. В худшем случае это может привести к неправильному планированию использования узлов, что, в свою очередь, может вызвать проблемы с производительностью. Лучше использовать пользовательские метрики с отчетами о динамической нагрузке. Их мы и рассмотрим ниже. Для любой серьезной рабочей нагрузки вероятность того, что все службы будут всегда эквивалентны, незначительна. Поэтому если вы стремитесь максимально эффективно использовать кластер и избежать проблем с производительностью, возможно, стоит создать пользовательскую метрику.

## <a name="custom-metrics"></a>Настраиваемые метрики
Метрики настраиваются отдельно для каждого экземпляра именованной службы во время ее создания.

У любой метрики есть описывающие ее свойства: имя, нагрузка по умолчанию и вес.

* Metric Name: имя метрики, которое представляет собой уникальный идентификатор метрики в кластере с точки зрения Resource Manager.
* Загрузка по умолчанию представляется по-разному в зависимости от того, какой является служба: с отслеживанием или без отслеживания состояния.
  * Для служб без отслеживания состояния у каждой метрики есть одно свойство — DefaultLoad.
  * Для служб с отслеживанием состояния можно определить следующие свойства:
    * PrimaryDefaultLoad — величина метрики по умолчанию, которая соответствует потреблению службы в качестве первичной реплики.
    * SecondaryDefaultLoad — величина метрики по умолчанию, которая соответствует потреблению службы в качестве вторичной реплики.
* Weight — это вес метрики, который определяет ее важность по сравнению с другими метриками для этой службы.

Если определены пользовательские метрики и необходимо также использовать метрики по умолчанию, следует явно добавить их снова. Это требуется для того, чтобы у вас было четкое представление о связи между стандартными и пользовательскими метриками. Например, вас может больше интересовать потребление памяти или глубина рабочей очереди, чем распространение нагрузки в первичной реплике.

### <a name="defining-metrics-for-your-service---an-example"></a>Определение метрик для службы (пример)
Предположим, вы хотите настроить службу, которая предоставляет значение метрики с именем MemoryInMb (память в мегабайтах), и при этом использовать метрики по умолчанию. Предположим, вы провели основные измерения и выяснили, что обычно первичная реплика этой службы может занимать 20 единиц MemoryInMb, а вторичные реплики — 5. Вы знаете, что MemoryInMb является наиболее важной метрикой с точки зрения управления производительностью данной службы, но вы все равно хотите, чтобы нагрузка между первичными репликами была сбалансирована. Это отличная идея, поскольку в результате потери узла или домена сбоя не будет пропадать слишком много первичных реплик. Кроме этих настроек вы хотите использовать метрики по умолчанию.

Ниже приведен код, написанный для создания службы с этой конфигурацией метрики.

Код:

```csharp
StatefulServiceDescription serviceDescription = new StatefulServiceDescription();
StatefulServiceLoadMetricDescription memoryMetric = new StatefulServiceLoadMetricDescription();
memoryMetric.Name = "MemoryInMb";
memoryMetric.PrimaryDefaultLoad = 20;
memoryMetric.SecondaryDefaultLoad = 5;
memoryMetric.Weight = ServiceLoadMetricWeight.High;

StatefulServiceLoadMetricDescription primaryCountMetric = new StatefulServiceLoadMetricDescription();
primaryCountMetric.Name = "PrimaryCount";
primaryCountMetric.PrimaryDefaultLoad = 1;
primaryCountMetric.SecondaryDefaultLoad = 0;
primaryCountMetric.Weight = ServiceLoadMetricWeight.Medium;

StatefulServiceLoadMetricDescription replicaCountMetric = new StatefulServiceLoadMetricDescription();
replicaCountMetric.Name = "ReplicaCount";
replicaCountMetric.PrimaryDefaultLoad = 1;
replicaCountMetric.SecondaryDefaultLoad = 1;
replicaCountMetric.Weight = ServiceLoadMetricWeight.Low;

StatefulServiceLoadMetricDescription totalCountMetric = new StatefulServiceLoadMetricDescription();
totalCountMetric.Name = "Count";
totalCountMetric.PrimaryDefaultLoad = 1;
totalCountMetric.SecondaryDefaultLoad = 1;
totalCountMetric.Weight = ServiceLoadMetricWeight.Low;

serviceDescription.Metrics.Add(memoryMetric);
serviceDescription.Metrics.Add(primaryCountMetric);
serviceDescription.Metrics.Add(replicaCountMetric);
serviceDescription.Metrics.Add(totalCountMetric);

await fabricClient.ServiceManager.CreateServiceAsync(serviceDescription);
```

PowerShell:

```posh
New-ServiceFabricService -ApplicationName $applicationName -ServiceName $serviceName -ServiceTypeName $serviceTypeName –Stateful -MinReplicaSetSize 2 -TargetReplicaSetSize 3 -PartitionSchemeSingleton –Metric @("MemoryInMb,High,20,5”,"PrimaryCount,Medium,1,0”,"ReplicaCount,Low,1,1”,"Count,Low,1,1”)
```

(Напоминаем, что если вы хотите использовать метрики по умолчанию, то вам вообще не нужно ничего менять в коллекции метрик или делать что-то специальное при создании службы.)

Теперь, изучив основы и проанализировав пример, давайте подробнее разберем каждый из этих параметров и поговорим о поведении, которое получится в результате.

## <a name="load"></a>загрузить
Весь смысл определения метрики заключается в том, чтобы представить определенную нагрузку. Нагрузка — это количество единиц определенной метрики, используемое экземпляром или репликой службы на заданном узле. Предполагаемую нагрузку можно настроить при создании службы, обновить после ее создания, добавить в отчеты для каждого отдельного объекта службы или сделать все вышеперечисленное.

## <a name="default-load"></a>Нагрузка по умолчанию
Нагрузка по умолчанию — это нагрузка, потребляемая каждым объектом этой службы (экземпляром или репликой) по умолчанию. Для простых служб нагрузка по умолчанию — это статическое определение, которое никогда не обновляется и используется в течение всего времени существования службы. Нагрузки по умолчанию прекрасно подходят для простых сценариев планирования ресурсов, в которых различным рабочим нагрузкам выделяются определенные объемы ресурсов.

Cluster Resource Manager позволяет службам с отслеживанием состояния задать различные нагрузки по умолчанию для первичных и вторичных реплик, в то время как для служб без отслеживания состояния можно указать только одно значение. Для служб с отслеживанием состояния нагрузки по умолчанию для первичных и вторичных реплик обычно отличаются, поскольку в каждой из этих ролей реплики выполняют различные виды работы. Например, в отличие от вторичных реплик, первичные обычно используются для обработки операций чтения и записи (и берут на себя большую часть вычислительной нагрузки). Предполагается, что нагрузка по умолчанию для первичной реплики больше, чем для вторичной, но фактические показатели будут зависеть от ваших собственных измерений.

## <a name="dynamic-load"></a>Динамическая нагрузка
Предположим, что ваша служба работает уже некоторое время. С помощью средств мониторинга вы определили, что:

1. некоторые разделы или экземпляры данной службы потребляют больше ресурсов, чем другие;
2. нагрузки некоторых служб меняются с течением времени.

Такого рода колебания нагрузки могут возникать по различным причинам. Возможно, служба или раздел связаны с определенным клиентом или соответствуют рабочим нагрузкам, которые изменяются в течение дня. Так или иначе, вы не можете использовать для нагрузки по умолчанию какое-либо строго определенное значение. Какую бы величину вы ни выбрали, какое-то время она будет неправильной. Это проблематично, поскольку при неверно заданных нагрузках по умолчанию Cluster Resource Manager будет выделять для службы избыточное или недостаточное количество ресурсов. В результате у вас появятся недостаточно и избыточно используемые узлы, даже если с точки зрения Cluster Resource Manager кластер будет казаться сбалансированным. Тем не менее даже в этом случае использовать нагрузки по умолчанию весьма удобно, поскольку они предоставляют определенные сведения, хотя и не отражают реальное состояние рабочих нагрузок большую часть времени. Именно поэтому Cluster Resource Manager позволяет каждому объекту службы обновлять данные о своих нагрузках во время выполнения. Это называется передачей данных о динамической нагрузке.

Отчеты о динамической нагрузке позволяют репликам или экземплярам во время своего существования регулировать заявленную или реальную нагрузку для метрик. Реплики или экземпляры службы, которые простаивали и не выполняли никакой работы, обычно сообщают, что они использовали меньшее количество заданной метрики. В то же время загруженные реплики или экземпляры сообщают, что они используют больше ресурсов.

Отчеты для каждой реплики или экземпляра позволяют Cluster Resource Manager реорганизовать отдельные объекты служб в кластере, чтобы эти службы получали необходимые им ресурсы. По сути, загруженные службы "высвобождают" неиспользуемые или мало используемые ресурсы других реплик или экземпляров.

В надежной службе код, используемый для динамического создания отчетов о нагрузке, будет выглядеть следующим образом:

Код:

```csharp
this.ServicePartition.ReportLoad(new List<LoadMetric> { new LoadMetric("MemoryInMb", 1234), new LoadMetric("metric1", 42) });
```

Реплики или экземпляры службы могут сообщать о нагрузке только для тех метрик, которые настроены для использования при создании. Список метрик, о которых может сообщать служба, состоит из тех же элементов, которые были заданы при создании службы. Список метрик, связанных со службой, также может обновляться динамически. Если реплика или экземпляр службы пытается сообщить о нагрузке для метрики, которая не настроена для использования, Service Fabric заносит отчет в журнал, но игнорирует его. Если в рамках одного допустимого вызова API сообщаются и другие метрики, соответствующие отчеты принимаются и используются. Это чудесно, так как такое поведение позволяет больше экспериментировать. Код может измерять значения всех известных метрик и сообщать о них. При этом оператору не придется вносить изменения в код, чтобы задать или обновить конфигурацию метрик для данной службы. Например, администратор или члены эксплуатационной группы могут отключить метрики с отчетом с ошибками для определенной службы, перенастроив веса метрик на основе поведения или включение новой метрики только после развертывания кода и его проверки с помощью других механизмов.

## <a name="mixing-default-load-values-and-dynamic-load-reports"></a>Совместное использование значений нагрузки по умолчанию и отчетов о динамической загрузке
Если нагрузки по умолчанию недостаточно и рекомендуется динамическое создание отчетов о нагрузке, можно ли использовать одновременно и то, и другое? Да! По сути, это рекомендуемая конфигурация. Если задана нагрузка по умолчанию и используются отчеты о динамической нагрузке, значение по умолчанию применяется в качестве оценочного, пока не появятся динамические отчеты. Это удобно, поскольку у службы Cluster Resource Manager сразу есть с чем работать. Используя нагрузку по умолчанию, она может оптимально разместить объекты службы при их создании. Если сведения по умолчанию не предоставляются, службы размещаются произвольным образом. Получив отчеты о нагрузке в дальнейшем, Cluster Resource Manager почти всегда вынужден перемещать службы.

Возьмем наш предыдущий пример и посмотрим, что произойдет, если мы добавим пользовательские метрики и будем динамически создавать отчеты о нагрузке. В этом примере мы используем в качестве образца метрику "Память". Предположим, мы создали службу с отслеживанием состояния с помощью следующей команды:

PowerShell:

```posh
New-ServiceFabricService -ApplicationName $applicationName -ServiceName $serviceName -ServiceTypeName $serviceTypeName –Stateful -MinReplicaSetSize 2 -TargetReplicaSetSize 3 -PartitionSchemeSingleton –Metric @("MemoryInMb,High,21,11”,"PrimaryCount,Medium,1,0”,"ReplicaCount,Low,1,1”,"Count,Low,1,1”)
```

Напомним, что синтаксис выглядит следующим образом: ("MetricName, MetricWeight, PrimaryDefaultLoad, SecondaryDefaultLoad").

Один из возможных макетов кластера может выглядеть как:

<center>
![Сбалансированный кластер с метриками по умолчанию и пользовательскими метриками][Image2]
</center>

Обратите внимание на следующие факторы.

* Так как реплики и экземпляры используют нагрузку службы по умолчанию, пока они не сообщат о своей собственной нагрузке, мы знаем, что реплики внутри раздела 1 службы с отслеживанием состояния не сообщали о нагрузках динамически.
* Вторичные реплики в разделе могут иметь собственную нагрузку.
* В целом метрики выглядят сбалансированными. В случае памяти отношение между минимальной и максимальной нагрузкой составляет 1,75 (узел с наибольшей нагрузкой — N3, с наименьшей — N2, следовательно 28/16 = 1,75).

Но некоторые факторы все же необходимо объяснить.

* Как определить, является ли соотношение 1,75 разумным? Как Cluster Resource Manager узнает, достаточно ли этого соотношения или нужно еще что-то делать?
* Когда происходит балансировка нагрузки?
* Что означает, если вес метрики "Память" определен как высокий?

## <a name="metric-weights"></a>Вес метрик
Важно иметь возможность отслеживать одни и те же показатели для разных служб. Это позволяет Cluster Resource Manager отслеживать потребление ресурсов в кластере, обеспечивать его балансировку межу узлами и следить за тем, чтобы узлы не использовали больше ресурсов, чем запланировано. Тем не менее важность одной и той же метрики для разных служб может отличаться. Кроме того, в кластере с множеством метрик и большим количеством служб для некоторых метрик полностью сбалансированные решения могут и не существовать. Как в таких ситуациях должен поступать Cluster Resource Manager?

Веса метрик позволяют Cluster Resource Manager принимать решение о способе балансировки кластера, когда нет идеального решения. Веса метрик также позволяют Cluster Resource Manager по-разному выполнять балансировку для определенных служб. Метрики могут иметь четыре разных уровня веса: нулевой, низкий, средний и высокий. Метрики с нулевым весом не играют роли для балансировки нагрузки, но их нагрузка имеет значение для таких характеристик, как количество используемых ресурсов.

Фактическое влияние разных весов метрик в кластере проявляется в том, что Cluster Resource Manager создает различные решения. По ним он определяет, какие из метрик важнее других. При отсутствии идеального решения служба Cluster Resource Manager может выбрать решения, которые лучше балансируют метрики с большими весами. Если метрика неважна для одной службы, с точки зрения Cluster Resource Manager ее использование может казаться несбалансированным. Это позволит другой службе получить необходимое ей равномерное распределение.

Рассмотрим пример нескольких отчетов о нагрузке и влияния разных весов метрик на выделение ресурсов в кластере. В этом примере мы видим, что переключение относительного веса метрики влияет на то, как Cluster Resource Manager выбирает разные решения путем различного размещения служб.

<center>
![Пример веса метрики и его влияния на решения балансировки нагрузки][Image3]
</center>

В этом примере есть четыре разные службы. Все они сообщают разные значения для двух разных метрик, А и Б. В первом случае все службы считают метрику А важной (вес = высокий), а метрику Б — незначительной (вес = низкий). В этом случае мы видим, что Cluster Resource Manager размещает службы таким образом, чтобы нагрузка по метрике А была лучше сбалансирована (имела меньшее стандартное отклонение), чем нагрузка по метрике Б. Во втором случае мы поменяли веса метрик местами. В результате Cluster Resource Manager, вероятно, поменяет местами службы А и Б, чтобы предложить выделение, при котором нагрузка для метрики Б сбалансирована лучше, чем для метрики А.

### <a name="global-metric-weights"></a>Глобальный вес метрик
Итак, если служба А считает метрику А более важной, а для службы Б эта метрика вообще не имеет значения, то какой вес будет использоваться в конечном итоге?

В действительности для каждой метрики отслеживаются несколько весов. Первый набор состоит из весов, которые определены для метрики в каждой службе. Еще один вес — это глобальное значение, которое вычисляется как среднее по всем службам, сообщающим значения данной метрики. Cluster Resource Manager использует оба эти веса для вычисления оценки решений. Это связано с тем, что при балансировке нагрузки в службе важно не только учитывать ее собственные приоритеты, но и обеспечить правильное выделение ресурсов в кластере в целом.

Что произойдет, если Cluster Resource Manager не будет учитывать и глобальный, и локальный баланс? Конечно, очень просто создать решения с глобальной балансировкой нагрузки, но это приводит к неправильному выделению ресурсов для отдельных служб. В следующем примере рассмотрим метрики по умолчанию, которые настроены для службы с отслеживанием состояния, и увидим, что происходит, если учитывается только глобальная балансировка нагрузки.

<center>
![Результаты решения только глобальной балансировки][Image4]
</center>

В примере выше, где нас интересовала только глобальная балансировка нагрузки, кластер в целом действительно сбалансирован. Все узлы имеют одинаковое количество первичных реплик и реплик вообще. Однако, если взглянуть на результаты такого выделения ресурсов, окажется, что оно не совсем правильное. Потеря одного узла непропорционально влияет на конкретную рабочую нагрузку, так как вместе с ним теряются все его первичные реплики. Например, в случае сбоя первого узла будут потеряны три первичные реплики для трех разных разделов службы "Круг". И, наоборот, другие две службы ("Треугольник" и "Шестиугольник") теряют реплики своих разделов и это не нарушает работу (если не учитывать, что нужно восстановить потерянную реплику).

В примере ниже служба Cluster Resource Manager распределил реплики с учетом глобального баланса и баланса каждой службы. При вычислении оценки решения она присваивает наибольший вес глобальному решению и (настраиваемой) части для отдельных служб. Глобальный баланс вычисляется на основе среднего веса метрик, настроенных для каждой службы. Каждая служба балансируется с учетом определенных для нее весов метрик. Это гарантирует, что внутренняя балансировка служб выполняется в максимальном соответствии с их потребностями. В результате, если сбой произойдет на том же первом узле, потеря первичных (и вторичных) реплик распределяется на все разделы всех служб. При этом она влияет одинаково на каждую из них.

## <a name="next-steps"></a>Дальнейшие действия
* Дополнительные сведения о других вариантах настройки служб см. в статье [Настройка параметров диспетчера кластерных ресурсов для служб Service Fabric](service-fabric-cluster-resource-manager-configure-services.md).
* Определение метрик дефрагментации — один из способов объединения нагрузки на узлах вместо ее рассредоточения. Сведения о настройке дефрагментации см. в [этой статье](service-fabric-cluster-resource-manager-defragmentation-metrics.md).
* Чтобы узнать, как диспетчер кластерных ресурсов управляет нагрузкой кластера и балансирует ее, ознакомьтесь со статьей о [балансировке нагрузки](service-fabric-cluster-resource-manager-balancing.md)
* Начните с самого начала, [изучив общие сведения о диспетчере кластерных ресурсов Service Fabric](service-fabric-cluster-resource-manager-introduction.md)
* Стоимость перемещения — один из способов сообщить диспетчеру кластерных ресурсов, что некоторые службы перемещать затратнее, чем остальные. Сведения о стоимости перемещения см. в [этой статье](service-fabric-cluster-resource-manager-movement-cost.md).

[Image1]:./media/service-fabric-cluster-resource-manager-metrics/cluster-resource-manager-cluster-layout-with-default-metrics.png
[Image2]:./media/service-fabric-cluster-resource-manager-metrics/Service-Fabric-Resource-Manager-Dynamic-Load-Reports.png
[Image3]:./media/service-fabric-cluster-resource-manager-metrics/cluster-resource-manager-metric-weights-impact.png
[Image4]:./media/service-fabric-cluster-resource-manager-metrics/cluster-resource-manager-global-vs-local-balancing.png



<!--HONumber=Jan17_HO4-->


