<properties
   pageTitle="Планирование емкости для приложений Service Fabric | Microsoft Azure"
   description="Описание процедуры определения количество вычислительных узлов, необходимых для приложения Service Fabric."
   services="service-fabric"
   documentationCenter=".net"
   authors="mani-ramaswamy"
   manager="coreysa"
   editor=""/>

<tags
   ms.service="service-fabric"
   ms.devlang="dotnet"
   ms.topic="article"
   ms.tgt_pltfrm="NA"
   ms.workload="NA"
   ms.date="11/12/2015"
   ms.author="subramar"/>


# Планирование емкости для приложений Service Fabric


В этом документе содержатся сведения об определении объема ресурсов (ЦП, ОЗУ, дискового хранилища), необходимых для выполнения приложений Service Fabric. Чаще всего требования к ресурсам со временем меняются. Как правило, при разработке или тестировании службы требуется незначительное количество ресурсов, но по мере перехода в производственный режим и расширения распространения приложения объем необходимых ресурсов растет. При проектировании приложения следует подумать о требованиях в долгосрочной перспективе и сразу принять решения, которые обеспечат беспроблемное масштабирование службы в соответствии с высокими запросами клиентов. Создавая кластер Service Fabric, вы решаете, какие виртуальные машины (ВМ) будут входить в его состав. Каждая виртуальная машина имеет ограниченный объем ресурсов в виде ЦП (ядра и быстродействие), пропускной способности сети, ОЗУ и дискового пространства. По мере расширения вашей службы можно выполнить обновление до виртуальных машин с более высоким объемом и (или) добавить в кластер дополнительные виртуальные машины. Разумеется, чтобы решить последнюю задачу, необходимо первоначально так разработать службу, чтобы она смогла поддерживать преимущества новых виртуальных машин, динамически добавляемых в кластер.

Некоторые службы не управляют данными на самих виртуальных машинах или управляют лишь незначительными объемами, поэтому планирование емкости должно касаться главным образом повышения производительности. Это означает, что необходимо уделить особое внимание производительности алгоритмов кода и ЦП виртуальных машин (ядра и быстродействие), необходимых для выполнения алгоритмов. Кроме того, также следует учесть пропускную способность сети и, в частности, частоту передачи данных и объем передаваемых данных. Если по мере увеличения степени использования функционирование службы должно оставаться на высоком уровне, в кластер можно добавить дополнительные виртуальные машины и обеспечить балансировку сетевых запросов на всех виртуальных машинах.

Главным аспектом планирования емкости для служб, управляющих большим объемом данных на виртуальных машинах, должен быть размер. Это означает, что необходимо тщательно продумать вопрос выделения объема ОЗУ и дискового пространства для виртуальной машины. В системе управления виртуальной памяти Windows дисковое пространство выглядит как ОЗУ в коде приложения. Это позволяет приложениям использовать больше памяти, чем доступно физически на виртуальной машине. Увеличение объема памяти просто приводит к увеличению производительности, так как виртуальная машина может содержать больше дискового пространства в ОЗУ. При выборе виртуальной машины выберите ту, дисковое пространство которой может содержать все данные виртуальной машины, и выберите размер ОЗУ, позволяющий обращаться к данным с нужной скоростью. По мере увеличения объема данных службы в кластер можно добавить дополнительные виртуальные машины и секционировать данные на всех виртуальных машинах.

## Сколько узлов необходимо?

Секционирование службы позволяет масштабировать данные службы (дополнительные сведения о секционировании см. в статье [Секционирование Service Fabric](service-fabric-concepts-partitioning.md)). Каждая секция должна умещаться в одной виртуальной машине. Однако в одной машине также можно разместить несколько небольших секций. Таким образом, наличие большего количества небольших секций обеспечивает большую гибкость в отличие от небольшого количества секций большего размера. Компромисс заключается в том, что значительное количество секций увеличивает нагрузку на Service Fabric и вы не можете выполнять транзакционные операции между секциями. Если коду службы часто требуется доступ к фрагментам данных, расположенным в разных секциях, увеличивается объем потенциального сетевого трафика. При разработке службы следует внимательно рассмотреть эти преимущества и недостатки, чтобы в результате прийти к эффективной стратегии секционирования.

Предположим, в вашем приложении имеется одна служба с отслеживанием состояния, размер хранилища которой в течение года увеличится до DB\_Size ГБ, и в связи с расширением вы хотите добавить несколько приложений (и секций). Чтобы узнать общий размер базы данных во всех репликах, нужно также принять во внимание коэффициент репликации (RF), который определяет количество реплик для службы (общий размер базы данных во всех репликах — это коэффициент репликации, умноженный на значение DB\_size). Node\_Size представляет дисковое пространство/ОЗУ для каждого узла, используемого для службы. Для достижения максимальных результатов потребуется, чтобы база данных помещалась в памяти в кластере и поместить в Node\_Size, объем которого приблизительно соответствует емкости ОЗУ выбранной виртуальной машины. Выделяя Node\_Size, который больше емкости ОЗУ, вы полагаетесь на подкачку ОС, и поэтому производительность может не быть оптимальной, но будет достаточной для службы.

Таким образом, количество узлов, необходимое для достижения максимальной производительности, можно вычислить следующим образом.

```
Number of Nodes = (DB_Size * RF)/Node_Size

```


## Действия с учетом расширения службы

Наряду с вычислением исходного размера базы данных можно вычислить количество узлов на основании размера базы данных, до которого будет расширена служба, и увеличить количество узлов по мере расширения службы, чтобы не выделить слишком большое количество узлов. Количество секций должно быть основано на количестве узлов, необходимых при работе службы на максимально эффективном уровне. Рекомендуется иметь несколько доступных в любое время запасных машин (избыточных ресурсов), чтобы обрабатывать непредвиденные пиковые нагрузки или сбои инфраструктуры (например, выход из строя нескольких виртуальных машин). Несмотря на то, что этот момент должен быть определен с учетом ожидаемых скачков, хорошей отправной точкой может стать резервирование нескольких дополнительных виртуальных машин (дополнительно 5–10 %).

Вышеприведенные условия предполагают, что имеется одна служба с отслеживанием состояния. Если существует несколько служб с отслеживанием состояния, в уравнение также потребуется добавить объем БД, связанный с другими службами, или вычислить количество узлов отдельно для каждой службы с отслеживанием состояния. У службы могут быть реплики или секции, которые не сбалансированы (например, некоторые секции могут содержать больше данных, чем другие. Соответствующие рекомендации см. в статье о секционировании). Однако приведенное выше уравнение зависит от количества секций или реплик, так как Service Fabric обеспечивает оптимальное распределение реплик между узлами.


## Таблица для расчета стоимости

Теперь давайте введем несколько реальных цифр в приведенную выше формулу. В [представленном здесь](https://servicefabricsdkstorage.blob.core.windows.net/publicrelease/SF%20VM%20Cost%20calculator-NEW.xlsx) примере таблицы показано планирование емкости для приложения, содержащего три типа объектов данных. Для каждого объекта мы приблизительно определяем его размер и планируемое количество объектов. Мы также выбрали, сколько требуется реплик каждого типа объекта. Таблица вычисляет общий объем памяти для хранения в кластере. Затем вводим размер виртуальной машины и ежемесячные расходы. В зависимости от размера виртуальной машины в таблице выводится минимальное количество секций, на которые необходимо разбить данные для физического размещения на узлах. В соответствии с конкретными вычислениями вашего приложения и потребностями сетевого трафика может потребоваться дополнительное количество секций. В таблице показано увеличение количества секций, управляющих объектами профиля пользователя, от 1 до 6.

Теперь на основе этой информации понятно, что вы можете физически получить все данные с нужными разделами и репликами на 26-узловом кластере. Однако поскольку этот кластер плотно упакован, могут потребоваться дополнительные узлы для сбоев и обновлений. В таблице также показано, что наличие более 57 узлов не дает дополнительных преимуществ — у вас просто будут пустые узлы. Опять же, может потребоваться более 57 узлов для обслуживания сбоев и обновлений узлов. Таблицу можно настроить в соответствии с конкретными потребностями.

![][Image1]



## Дальнейшие действия

См. статью [Секционирование служб Service Fabric][10] для получения дополнительных сведений о секционировании службы.



<!--Image references-->
[Image1]: ./media/SF-Cost.png

<!--Link references--In actual articles, you only need a single period before the slash-->
[10]: service-fabric-concepts-partitioning.md

<!---HONumber=AcomDC_1125_2015-->