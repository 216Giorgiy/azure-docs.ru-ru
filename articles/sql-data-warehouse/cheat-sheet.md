---
title: "Памятка для хранилища данных SQL Azure | Документация Майкрософт"
description: "Найдите ссылки, рекомендации по быстрому созданию решений хранилища данных SQL Azure."
services: sql-data-warehouse
documentationcenter: NA
author: acomet
manager: jhubbard
editor: 
ms.assetid: 51f1e444-9ef7-4e30-9a88-598946c45196
ms.service: sql-data-warehouse
ms.devlang: NA
ms.topic: article
ms.tgt_pltfrm: NA
ms.workload: data-services
ms.custom: manage
ms.date: 12/14/2017
ms.author: acomet
ms.openlocfilehash: 2d17385ff255ddf7b85baa81600a2af60d015540
ms.sourcegitcommit: 48fce90a4ec357d2fb89183141610789003993d2
ms.translationtype: HT
ms.contentlocale: ru-RU
ms.lasthandoff: 01/12/2018
---
# <a name="cheat-sheet-for-azure-sql-data-warehouse"></a>Памятка для хранилища данных SQL Azure
Эта страница поможет при разработке решения хранилища данных для основных вариантов использования. Эта памятка станет отличной поддержкой во время создания хранилища данных мирового уровня. Тем не менее, мы настоятельно рекомендуем подробно узнать о каждом шаге. Во-первых, рекомендуем прочесть эту замечательную статью о том, **[что такое]** хранилище данных SQL.

Ниже приведен эскиз процесса, который необходимо выполнить в начале разработки хранилища данных SQL.

![Эскиз]

## <a name="queries-and-operations-across-tables"></a>Запросы и операции для нескольких таблиц

Важно заранее изучить наиболее важные операции и запросы, которые выполняются в хранилище данных. Чтобы эти операции выполнялись, необходимо назначить приоритет для архитектуры хранилища данных. Типичными примерами операций могут быть:
* Соединение одной или двух таблиц фактов и таблиц измерений, фильтрация этой таблицы в течение заданного времени и добавление результатов в киоск данных.
* Создание больших или маленьких обновлений с учетом продажи.
* Добавление только данных в таблицы.

Зная тип операций, вы сможете оптимизировать структуру таблицы.

## <a name="data-migration"></a>Перенос данных

Сначала мы рекомендуем загрузить данные **[в ADLS]** или хранилище BLOB-объектов Azure. Затем с помощью Polybase загрузить данные в хранилище данных SQL в промежуточной таблице. Используйте следующие конфигурации:

| Проектирование | Рекомендации |
|:--- |:--- |
| Дистрибутив | Циклический перебор, |
| Индексация | Куча |
| Секционирование | Нет |
| Класс ресурсов | largerc или xlargerc |

Подробнее о **[миграции данных], [загрузке данных]**, а также **[подробное руководство] по загрузке**. 

## <a name="distributed-or-replicated-tables"></a>Распределенные или реплицируемые таблицы

Мы рекомендуем следующие стратегии в зависимости от свойств таблицы:

| type | Подходит | Не подходит|
|:--- |:--- |:--- |
| Реплицированный | • Малые таблицы измерения в схеме типа "звезда" с хранилищем размером менее 2 ГБ после сжатия (приблизительно в 5 раз) |•  Выполняется большое количество транзакций записей для таблицы (например вставка, Upsert, удаление, обновление)<br></br>•   Часто меняется подготовка единиц использования хранилища данных (DWU)<br></br>• Используются только 2–3 столбца, в то время как таблица содержит много столбцов<br></br>•  Индексируется реплицированная таблица |
| Циклический перебор (по умолчанию) | • Временная или промежуточная таблица<br></br> • Нет очевидного ключа соединения или потенциальной колонки |•   Производительность снижается из-за перемещения данных |
| Хэш | • Таблицы фактов<br></br>•    Большие таблицы измерений |• Нельзя обновить ключ распределения |

**Советы**
* Начните с циклического перебора, но стремитесь к реализации стратегии распределения хэша, чтобы воспользоваться архитектурой массового параллелизма.
* Убедитесь, что общие ключи хэша имеют одинаковый формат данных.
* Не распределяйте в формате varchar.
* Таблицы измерений с общим ключом хэша к таблице фактов с частыми операциями объединения можно распределить по хэшу.
* С помощью *[sys.dm_pdw_nodes_db_partition_stats]* анализируйте любую асимметрию в данных.
* С помощью *[sys.dm_pdw_request_steps]* анализируйте перемещения данных по запросам, контролируйте время трансляции и операций смешения. Кроме того, с его помощью можно рассмотреть вашу стратегию распределения.

Подробнее о **[реплицированных таблицах] и [распределенных таблицах]**.

## <a name="indexing-your-table"></a>Индексирование таблицы

Индексирование **отлично** подходит для быстрого чтения таблиц. Существует уникальный набор технологий, которые можно использовать в зависимости от ваших потребностей:

| type | Подходит | Не подходит|
|:--- |:--- |:--- |
| Куча | • Промежуточная или временная таблица<br></br>• Маленькие таблицы с небольшой областью поиска |• Любой поиск сканирует всю таблицу |
| Кластеризованный индекс | • Не более 100 млн строк таблицы<br></br>• Большие таблицы (более 100 млн строк) с 1–2 используемыми столбцами |•    Используется реплицированная таблица<br></br>•    Выполняются сложные запросы, включающие несколько операций присоединения, группирования<br></br>•  Создаются обновления в индексированных столбцах; это занимает память |
| Кластеризованный индекс columnstore (CCI) (по умолчанию) | •   Большие таблицы (более 100 млн строк) | • Используется реплицированная таблица<br></br>•    Выполняются массовые операции обновления в таблице<br></br>•   Допущено избыточное секционирование таблицы: группы строк не охватывают разные узлы и секции распределения |

**Советы**
* Возможно, в дополнение к кластеризованному индексу в активно используемый для фильтра столбец вы захотите добавить некластеризованный индекс. 
* Следите за управлением памятью для таблицы с CCI. Нужно, чтобы при загрузке пользователь (или запрос) использовал большой класс ресурсов. Убедитесь, что избежали обрезки и создания множества маленьких групп сжатых строк.
* Оптимизация для уровня вычислений отлично подходит для CCI.
* Недостаточно эффективное сжатие групп может снизить производительность. Необходимо перестроить или реорганизовать CCI. На сжатую группу строк потребуется, по крайней мере, 100 тыс. строк. Идеальный вариант — 1 млн строк в каждой группе.
* С учетом того, как часто добавляется поэтапная нагрузка, а также ее размера при реорганизации и перестройке индексов можно автоматизировать процессы. Всегда можно использовать очистку Spring.
* Если необходимо обрезать группу строк, учитывайте различные факторы. Каков размер открытых групп строк? Какой объем данных необходимо загрузить в течение нескольких дней?

Подробнее об **[индексах]**.

## <a name="partitioning"></a>Секционирование
Большие таблицы фактов (более 1 млрд строк) можно разделить на секции. В 99 % случаев ключ секции должен быть основан на дате. Старайтесь не допустить избыточного секционирования, особенно если у вас кластеризованный индекс columnstore.
Использовать разделение можно для промежуточных таблиц, которым необходимо извлечение, преобразование и загрузка. Это упрощает управление жизненным циклом данных.
Старайтесь не допустить избыточного секционирования данных, особенно в кластеризованном индексе columnstore.

Подробнее о **[секциях]**.

## <a name="incremental-load"></a>Поэтапная загрузка

Сначала вы должны убедиться, что назначили большие классы ресурсов для загрузки данных. Для автоматизации конвейеров извлечения, преобразования и загрузки в хранилище данных SQL рекомендуем использовать Polybase и ADF V2.

Для большого пакета обновлений исторических данных рекомендуем сначала удалить соответствующие данные. Затем можно выполнить массовую вставку новых данных. Такой двухэтапный подход более эффективен.

## <a name="maintain-statistics"></a>Обеспечение статистики
Общедоступная версия авто-статистики появится в ближайшее время. А пока для хранилища данных SQL необходимо вести статистику вручную. Важно также обновлять статистику, так как данные могут быть **существенно** изменены. Это поможет оптимизировать ваши планы запросов. Если ведение статистики занимает слишком много времени, нужно выбирать отдельные столбцы, для которых необходимо создавать статистику. Кроме того, вы можете определить частоту обновлений. Например, можно ежедневно обновлять столбцы дат, в которые добавляются новые значения. Статистику рекомендуется вести в столбцах, которые являются частью объединения, используются в предложении WHERE или GROUP BY.

Подробнее о **[статистике]**.

## <a name="resource-class"></a>Класс ресурсов
Чтобы выделить память для выполнения запросов, в хранилище данных SQL используются группы ресурсов. Если для повышения скорости запроса или загрузки вам требуется больше памяти, необходимо выделить более высокие классы ресурсов. С другой стороны, использование больших классов ресурсов влияет на параллелизм. Обратите на это внимание, прежде чем перемещать всех своих пользователей в большой класс ресурсов.

Если вы заметили, что запросы занимают слишком много времени, убедитесь, что пользователи не работают в больших классах ресурсов. Большие классы потребляют значительно количество слотов выдачи. Они могут создать дополнительные запросы в очереди.

Наконец, если вы используете уровень, оптимизированный для вычислений, каждый класс ресурсов получает в 2,5 раза больше памяти, чем на уровне, оптимизированном для эластичности.

Подробнее о работе с **[классами ресурсов и параллелизмом]**.

## <a name="lower-your-cost"></a>Сокращение расходов
В хранилище данных SQL предоставляется возможность приостановить ресурсы, если вы их не используете. Счет выставляется только за используемые вычислительные ресурсы. Еще одной ключевой возможностью выступает масштабирование ресурсов. Приостановить работу и выполнить масштабирование ресурсов можно с помощью портала Azure или команд PowerShell.

Выполняйте автоматическое масштабирование с помощью службы "Функции Azure" в любое время:

<a href="https://ms.portal.azure.com/#create/Microsoft.Template/uri/https%3A%2F%2Fraw.githubusercontent.com%2FMicrosoft%2Fsql-data-warehouse-samples%2Fmaster%2Farm-templates%2FsqlDwTimerScaler%2Fazuredeploy.json" target="_blank">
<img src="https://raw.githubusercontent.com/Azure/azure-quickstart-templates/master/1-CONTRIBUTION-GUIDE/images/deploytoazure.png"/>
</a>

## <a name="optimize-you-architecture-for-performance"></a>Оптимизация архитектуры для производительности

Рекомендуем рассматривать базу данных SQL и Azure Analysis Services в архитектуре центра и Spokes. Это решение может обеспечить изоляцию рабочей нагрузки между различными группами пользователей, а также использование некоторых расширенных функций безопасности базы данных SLQ и Azure Analysis Services. Это также поможет обеспечить неограниченный параллелизм для ваших пользователей.

Подробнее о **[стандартных архитектурах, использующих хранилище данных SQL]**.

Одним щелчком разверните периферийные зоны в базах данных SQL из хранилища данных SQL:

<a href="https://ms.portal.azure.com/#create/Microsoft.Template/uri/https%3A%2F%2Fraw.githubusercontent.com%2FMicrosoft%2Fsql-data-warehouse-samples%2Fmaster%2Farm-templates%2FsqlDwSpokeDbTemplate%2Fazuredeploy.json" target="_blank">
<img src="https://raw.githubusercontent.com/Azure/azure-quickstart-templates/master/1-CONTRIBUTION-GUIDE/images/deploytoazure.png"/>
</a>


<!--Image references-->
[Эскиз]:media/sql-data-warehouse-cheat-sheet/picture-flow.png

<!--Article references-->
[загрузке данных]:./design-elt-data-loading.md
[подробное руководство]: ./guidance-for-loading-data.md
[индексах]:./sql-data-warehouse-tables-index.md
[секциях]:./sql-data-warehouse-tables-partition.md
[статистике]:./sql-data-warehouse-tables-statistics.md
[классами ресурсов и параллелизмом]:./sql-data-warehouse-develop-concurrency.md

<!--MSDN references-->


<!--Other Web references-->
[стандартных архитектурах, использующих хранилище данных SQL]: https://blogs.msdn.microsoft.com/sqlcat/2017/09/05/common-isv-application-patterns-using-azure-sql-data-warehouse/
[что такое]:https://blogs.msdn.microsoft.com/sqlcat/2017/09/05/azure-sql-data-warehouse-workload-patterns-and-anti-patterns/
[миграции данных]:https://blogs.msdn.microsoft.com/sqlcat/2016/08/18/migrating-data-to-azure-sql-data-warehouse-in-practice/
[реплицированных таблицах]:https://docs.microsoft.com/azure/sql-data-warehouse/design-guidance-for-replicated-tables
[распределенных таблицах]:https://docs.microsoft.com/azure/sql-data-warehouse/sql-data-warehouse-tables-distribute
[в ADLS]: https://docs.microsoft.com/azure/data-factory/connector-azure-data-lake-store
[sys.dm_pdw_nodes_db_partition_stats]: https://docs.microsoft.com/sql/relational-databases/system-dynamic-management-views/sys-dm-db-partition-stats-transact-sql
[sys.dm_pdw_request_steps]:https://docs.microsoft.com/sql/relational-databases/system-dynamic-management-views/sys-dm-pdw-request-steps-transact-sql
