<properties
   pageTitle="Рекомендации по использованию хранилища данных SQL Azure | Microsoft Azure"
   description="Рекомендации, которые следует учитывать при разработке решений для хранилища данных SQL Azure. Они помогут вам обеспечить эффективную работу."
   services="sql-data-warehouse"
   documentationCenter="NA"
   authors="sonyam"
   manager="barbkess"
   editor=""/>

<tags
   ms.service="sql-data-warehouse"
   ms.devlang="NA"
   ms.topic="article"
   ms.tgt_pltfrm="NA"
   ms.workload="data-services"
   ms.date="07/29/2016"
   ms.author="sonyama;barbkess"/>

# Рекомендации по использованию хранилища данных SQL Azure

В этой статье содержатся рекомендации, которые позволяют достичь оптимального соотношения цены и производительности в хранилище данных SQL Azure. Некоторые вопросы, рассмотренные в этой статье, достаточно простые и понятные, но есть и вопросы, предназначенные для более опытных пользователей, поэтому они рассмотрены лишь поверхностно. Здесь представлены основные рекомендации и сведения относительно важных моментов, которые следует учитывать при создании хранилища данных. В каждом разделе содержится краткое описание определенных вопросов и ссылки на статьи с более детальными сведениями.

Если вы еще мало знакомы с хранилищем данных SQL Azure, некоторые разделы могут показаться вам очень сложными. Разделы здесь в основном расположены в порядке важности. Поэтому для начала вам будет достаточно рассмотреть первых три раздела статьи. Набравшись опыта работы с хранилищем данных SQL, вы можете приступить к изучению следующих разделов. Вам не понадобится много времени, чтобы разобраться с этими вопросами. Для начинающих пользователей содержащаяся здесь информация может показаться очень сложной, но, некоторое время поработав с хранилищем данных SQL, вы быстро все поймете.

## Снижение расходов за счет приостановки и масштабирования ресурсов
В хранилище данных SQL предоставляется возможность приостановить ресурсы, если вы их не используете. Счет выставляется только за используемые вычислительные ресурсы. Еще одной ключевой возможностью выступает масштабирование ресурсов. Приостановить работу и выполнить масштабирование ресурсов можно с помощью портала Azure или команд PowerShell. Эти возможности позволяют существенно снизить расходы на хранилище данных, когда оно не используется. Чтобы сохранять постоянную доступность хранилища данных, вместо приостановки работы можно уменьшить его размер (до размера DW100).

Дополнительные сведения см. в разделах о [приостановке][] и [возобновлении][] использования вычислительных ресурсов, а также об их [масштабировании][].


## Очистка транзакций перед приостановкой использования и масштабированием вычислительных ресурсов 
Когда вы приостанавливаете работу хранилища данных SQL или масштабируете его, экземпляр базы данных останавливает работу. Это означает, что все активные запросы будут отменены. Отмена типичного запроса SELECT выполняется очень быстро и почти не влияет на время, необходимое для приостановки работы или масштабирования экземпляра. Однако остановка транзакционных запросов, с помощью которых изменяются данные или их структура, занимает длительное время. **Транзакционные запросы должны полностью завершиться или выполнить откат изменений.** На откат изменений, выполненных с помощью транзакционных запросов, требуется столько же времени (или даже больше), как и на выполнение самих изменений. Например, если отменить запрос на удаление строк, который уже выполняется в течение часа, системе понадобится столько же времени, чтобы вставить удаленные строки обратно. Процесс приостановки работы и масштабирования ресурсов во время выполнения транзакционных запросов займет более длительное время, так как он не начнется, пока не будет выполнен откат изменений.

Дополнительные сведения см. в статьях [Транзакции в хранилище данных SQL][] и [Оптимизация транзакций для хранилища данных SQL][].

## Обеспечение статистики
В отличие от SQL Server, который автоматически обнаруживает и создает или обновляет статистику в столбцах, в хранилище данных SQL этот процесс необходимо выполнять самостоятельно. В будущем мы планируем решить эту проблему. Однако пока вам понадобится вести статистику, чтобы обеспечивать оптимизацию планов хранилища данных SQL. Планы, созданные с помощью оптимизатора, зависят от доступной статистики. **Проще всего приступить к работе со статистикой, создав статистику для каждого столбца.** Не менее важно также обновлять статистику, так как данные могут быть существенно изменены. Рекомендуется выполнять обновление статистики ежедневно или после каждой загрузки. Однако всегда есть компромиссы между производительностью и затратами на создание и обновление статистики. Если ведение статистики занимает слишком много времени, нужно выбирать отдельные столбцы, для которых необходимо создавать статистику, или столбцы, требующие частого обновления статистики. Например, можно ежедневно обновлять столбцы дат, в которые добавляются новые значения. **Статистику рекомендуется вести в столбцах, которые являются частью объединения, используются в предложении WHERE или GROUP BY**.

Дополнительные сведения см. в статьях [Manage table statistics][] \(Управление статистикой таблиц), [CREATE STATISTICS (Transact-SQL)][] и [UPDATE STATISTICS (Transact-SQL)][].

## Объединение инструкций INSERT в группы
Одноразовую загрузку в небольшую таблицу или даже периодическую перезагрузку результатов поиска рекомендуется выполнять, используя такой синтаксис инструкции INSERT: `INSERT INTO MyLookup VALUES (1, 'Type 1')`. Однако для загрузки тысяч или миллионов строк на протяжении дня одноэлементных инструкций INSERT может быть недостаточно. Вместо них можно создать процессы, которые будут записывать инструкции INSERT в файл и периодически загружать его.

Дополнительные сведения см. в статье [Инструкция INSERT (Transact-SQL)][].
 
## Быстрая загрузка и экспорт данных с помощью PolyBase
Хранилище данных SQL поддерживает загрузку и экспорт данных при помощи нескольких инструментов, включая фабрику данных Azure, PolyBase и BCP. При работе с данными небольшого объема, что не требует высокой производительности, можно использовать любой инструмент. Однако для загрузки или экспорта данных большого объема, что требует высокой производительности, лучше всего использовать PolyBase. Этот инструмент использует архитектуру вычислений с массовым параллелизмом (MPP) хранилища данных SQL. Поэтому загрузка и экспорт данных с его помощью выполняется быстрее. Загрузку данных с помощью PolyBase можно выполнить, используя команды CTAS или INSERT INTO. **Команда CTAS позволяет свести к минимуму нагрузку ведения журнала транзакций и быстрее всего выполнить загрузку данных.** Фабрика данных Azure также поддерживает загрузку данных с помощью PolyBase. PolyBase поддерживает различные форматы файлов, включая формат GZIP. **Чтобы максимально повысить пропускную способность при использовании текстовых файлов в формате GZIP, необходимо разбить файлы на 60 или больше частей. Это позволит достичь максимальной степени параллелизма загрузки.** Кроме того, для повышения общей пропускной способности можно загружать данные одновременно.

Дополнительные сведения см. в статьях [Загрузка данных в хранилище данных SQL][], [Руководство по использованию PolyBase в хранилище данных SQL][], [Azure SQL Data Warehouse loading patterns and strategies][] \(Стратегии и шаблоны загрузки данных в хранилище данных SQL Azure), [Загрузка данных с помощью фабрики данных Azure][], [Перемещение данных в хранилище данных SQL Azure и из него с помощью фабрики данных Azure][], [CREATE EXTERNAL FILE FORMAT (Transact-SQL)][], [Функция Create Table As Select (CTAS) в хранилище данных SQL][].

## Хэш-распределение больших таблиц
По умолчанию таблицы распределяются по методу циклического перебора. Это позволяет упростить процесс создания таблиц, так как пользователям не нужно принимать решение о типе распределения. Таблицы, распределяемые по методу циклического перебора, подходят для некоторых рабочих нагрузок, но зачастую намного эффективнее использовать столбец распределения. Наглядно это превосходство можно увидеть при объединении больших таблиц фактов. Например, во время выполнения запроса на объединение таблицы Orders, распределенной по идентификатору order\_id, с таблицей Transactions, распределенной по тому же идентификатору, этот запрос превращается в запрос к серверу, что исключает выполнение операций перемещения данных. Чем меньше применяемых действий, тем быстрее выполняется запрос. Скорость выполнения запроса также зависит от объема перемещаемых данных. В этом разделе представлены только общие сведения. При загрузке распределенной таблицы входящие данные не должны быть отсортированы по ключу распределения, так как это замедлит процесс загрузки. Ниже приведены ссылки на статьи, содержащие сведения о том, как с помощью столбца распределения можно улучшить производительность и как определить распределенную таблицу в предложение WITH инструкции CREATE TABLES.

Дополнительные сведения см. в статье [Overview of tables in SQL Data Warehouse][] \(Общие сведения о таблицах в хранилище данных SQL), а также в статьях о [распределении таблиц][], [выборе распределения таблиц][], [инструкции CREATE TABLE][] и [CREATE TABLE AS SELECT][].

## Недопущение избыточного секционирования
Не смотря на то, что секционирование данных — это эффективный способ управления данными, который реализуется благодаря переключению секций или оптимизации сканирования путем исключения секций, наличие большого количества секций может повлиять на производительность запросов. Стратегия разделения данных на большое количество секций, как правило, эффективна в SQL Server, но она не всегда работает в хранилище данных SQL. Слишком большое количество секций снижает эффективность кластеризованных индексов Columnstore, если в секции содержится менее миллиона строк. Помните, что в хранилище данных SQL данные секционируются на 60 баз данных, поэтому при создании таблицы с 100 секциями фактически будет создана таблица с 6000 секций. Все рабочие нагрузки отличаются, поэтому рекомендуется поэкспериментировать с секционированием, чтобы выбрать наиболее подходящее количество секций для вашей рабочей нагрузки. В хранилище данных SQL можно использовать меньшее количество секций, чем в SQL Server. Например, попробуйте использовать еженедельные или ежемесячные секции вместо ежедневных.

Дополнительные сведения см. в статье о [секционировании таблиц][].

## Уменьшение размера транзакций
Инструкции INSERT, UPDATE и DELETE выполняются в транзакциях. В случае сбоя их необходимо откатить. Чтобы сократить время выполнения отката, необходимо по возможности уменьшить размеры транзакций. Это можно сделать, разделив инструкции INSERT, UPDATE и DELETE на части. Например, если на выполнение инструкции INSERT требуется 1 час, рекомендуется разделить ее на 4 части. Таким образом, каждая часть будет выполняться 15 минут. К пустым таблицам можно применять специальные операции, которые сопровождаются записью в журнал минимальных сведений, (такие как CTAS, TRUNCATE, DROP TABLE или INSERT), чтобы снизить риск отката. Устранить откаты также можно, используя для управления данными только операции с метаданными (например, переключение секций). Например, вместо выполнения инструкции DELETE для удаления всех строк в таблице, упорядоченной по идентификатору order\_date (октябрь 2001 г.), данные можно секционировать ежемесячно, а потом переключить секцию с данными на пустую секцию из другой таблицы (см. примеры использования инструкции ALTER TABLE). Используя инструкцию CTAS вместо DELETE, можно записать данные, которые необходимо сохранить в несекционированной таблице. Если на выполнение этих двух инструкций требуется одинаковое количество времени, целесообразно использовать инструкцию CTAS, так как для ее выполнения необходима минимальная нагрузка ведения журнала транзакций, и ее можно быстро отменить.

Дополнительные сведения см. в статьях [Транзакции в хранилище данных SQL][] и [Оптимизация транзакций для хранилища данных SQL][], а также в статьях о [секционировании таблиц][], [инструкции TRUNCATE TABLE][], [ALTER TABLE][] и [функции Create Table As Select (CTAS)][].

## Использование минимального размера столбца
При определении DDL рекомендуется использовать поддерживаемый тип данных с наименьшим размером. Это позволит повысить производительность запросов. Это особенно важно для столбцов CHAR и VARCHAR. Если самое длинное значение в столбце состоит из 25 знаков, столбец необходимо определить как VARCHAR(25). Не рекомендуется использовать по умолчанию длинные значения столбцов. Кроме того, по возможности определяйте столбцы как VARCHAR, а не NVARCHAR.

Дополнительные сведения см. в статьях, посвященных [общим сведениям о таблицах][], [типам данных таблиц][] и [инструкции CREATE TABLE][].

## Использование временных таблиц без кластеризованных индексов для хранения временных данных
Если вам необходимо временно разместить данные в хранилище данных SQL, использование таблицы без кластеризованных индексов может существенно сократить время загрузки данных. Загрузка таблицы в таблицу без кластеризованных индексов перед выполнением преобразования данных выполняется намного быстрее, чем загрузка данных в таблицу с кластеризованными индексами Columnstore. Кроме того, загрузка данных во временную таблицу выполняется гораздо быстрее, чем загрузка таблицы в постоянное хранилище. Временные таблицы начинаются с # и доступны только в сеансах, в которых они были созданы, поэтому они могут не работать в некоторых сценариях. Таблицы без кластеризованных индексов определены в предложении WITH инструкции CREATE TABLE. При использовании временной таблицы рекомендуется создавать в ней статистику.

Дополнительные сведения см. в статьях о [временных таблицах][], инструкциях [CREATE TABLE][] и [CREATE TABLE AS SELECT][].

## Оптимизация таблиц с кластеризованными индексами columnstore
Использование кластеризованных индексов Columnstore — это один из наиболее эффективных способов для хранения данных в хранилище данных SQL Azure. По умолчанию в хранилище данных SQL используются таблицы с кластеризованными индексами Columnstore. Качество кластеризованного сегмента Columnstore существенно влияет на эффективность выполнения запросов в таблицах с кластеризованными индексами Columnstore. Если во время записи строк в таблицы Columnstore возникает нехватка памяти, качество сегмента Columnstore может ухудшиться. Качество сегмента можно изменить по числу строк в сжатой группе строк. Дополнительные сведения об определении и улучшении качества сегмента для таблиц с кластеризованными индексами Columnstore см. в разделе [Причины низкого качества индекса Columnstore][] статьи об [индексировании таблиц][]. Чтобы обеспечить высокое качество сегментов Columnstore, для загрузки данных рекомендуется создать специальные идентификаторы пользователей, которые используют классы ресурсов среднего и большого размеров. Чем меньше DWU используется, тем больший размер ресурсов может понадобиться для пользователя, выполняющего загрузку.

В основном таблицы Columnstore не передают данные в сжатый сегмент Columnstore, пока количество строк в каждой таблице не превысит миллион, а каждая таблица хранилища данных SQL не будет секционирована на 60 таблиц. Поэтому нецелесообразно применять к таблицам Columnstore запросы до тех пор, пока количество строк в таблице не превысит 60 миллионов. Для таблицы с количеством строк менее 60 миллионов бессмысленно использовать индекс Columnstore, хотя он и не повлияет на производительность. Более того, чтобы воспользоваться преимуществами кластеризованного индекса Columnstore при секционировании данных, каждая секция должна состоять из миллиона строк. Если таблица состоит из 100 секций, чтобы использовать кластеризованный индекс Columnstore, она должна состоять из как минимум 6 миллиардов строк (60 распределений *100 секций* 1 миллион строк). Если таблица не содержит такого количества строк, рекомендуется уменьшить количество секций или использовать таблицу без кластеризованных индексов. Чтобы получить более высокую производительность, возможно, вместо кластеризованной таблицы стоит использовать таблицу без кластеризованных индексов, содержащую вторичные индексы. Таблицы ColumnStore еще не поддерживают вторичные индексы.

Если выбрать только необходимые столбцы, запросы к таблице ColumnStore будут выполняться быстрее.

Ознакомьтесь также с [индексированием таблиц][], [руководством по индексам Columnstore][] и [перестроением индексов columnstore][].

## Использование класса ресурсов большого размера для повышения производительности запросов
Чтобы выделить память для выполнения запросов, в хранилище данных SQL используются группы ресурсов. По умолчанию для всех пользователей настроен класс ресурсов небольшого размера, предусматривающий 100 МБ памяти для каждого распределения. В хранилище данных SQL содержится 60 распределений, на каждое из которых выделяется как минимум 100 МБ памяти. Поэтому в целом для системы выделяется 6000 МБ памяти (около 6 ГБ). На выполнение некоторых запросов (например, на объединение таблиц с кластеризованными индексами Columnstore или добавления в них данных) требуется больше памяти. На выполнение некоторых запросов, таких как запросы на обычное сканирование, память не требуется. В тоже время перед перемещением всех пользователей в класс ресурсов большего размера следует учитывать, что использование такого класса влияет на параллелизм.
 
Дополнительные сведения см. в статье [Управление параллелизмом и рабочей нагрузкой в хранилище данных SQL][].

## Использование класса ресурсов небольшого размера для увеличения параллелизма
Если во время выполнения пользовательских запросов возникают длительные задержки, возможно, используются классы ресурсов большого размера или превышено количество одновременно используемых слотов выдачи. В таком случае запросы помещаются в очередь. Чтобы посмотреть очередь выполнения пользовательских запросов, выполните команду `SELECT * FROM sys.dm_pdw_waits`, которая позволяет просмотреть возвращенные строки.

Дополнительные сведения см. в статьях [Управление параллелизмом и рабочей нагрузкой в хранилище данных SQL][] и [sys.dm\_pdw\_waits (Transact-SQL)][].

## Использование динамических административных представлений для отслеживания и оптимизации запросов
В хранилище данных SQL содержится несколько динамических административных представлений, которые можно использовать для отслеживания выполнения запроса. В первой статье в списке ниже предоставлены пошаговые инструкции по отслеживанию выполнения запроса. Чтобы быстро определить запросы в динамических административных представлениях, используйте в запросах параметр LABEL.

Дополнительные сведения см. в статьях [Мониторинг рабочей нагрузки с помощью динамических административных представлений][], [Использование меток для инструментирования запросов в хранилище данных SQL][], [Предложение OPTION (Transact-SQL)][], [sys.dm\_exec\_sessions (Transact-SQL)][], [sys.dm\_pdw\_exec\_requests (Transact-SQL)][], [sys.dm\_pdw\_request\_steps (Transact-SQL)][], [sys.dm\_pdw\_sql\_requests (Transact-SQL)][], [sys.dm\_pdw\_dms\_workers (Transact-SQL)], [DBCC PDW\_SHOWEXECUTIONPLAN (Transact-SQL)][] и [sys.dm\_pdw\_waits (Transact-SQL)][].

## Другие ресурсы:
Дополнительные сведения о распространенных проблемах и решениях см. в статье [Устранение неполадок хранилища данных SQL Azure][].

Если вы не нашли нужных сведений в этой статье, попробуйте использовать поиск по документации в левой части страницы, чтобы найти все документы, связанные с хранилищем данных SQL Azure. На [форуме по хранилищу данных SQL Azure на портале MSDN][] можно задать вопросы другим пользователям и разработчикам хранилища данных SQL. Мы регулярно просматриваем этот форум и следим за тем, чтобы другие пользователи или наши специалисты ответили на интересующий вас вопрос. Вопросы также можно задавать на [форуме по хранилищу данных SQL Azure на сайте Stack Overflow][].

Наконец, используйте страницу [отзывов о хранилище данных SQL Azure][], чтобы оставить запросы на функции. Ваши отзывы и голоса за отзывы, оставленные другими пользователями, помогут нам определить, какие улучшения функций наиболее приоритетные.

<!--Image references-->

<!--Article references-->
[Create a support ticket]: ./sql-data-warehouse-get-started-create-support-ticket.md
[Управление параллелизмом и рабочей нагрузкой в хранилище данных SQL]: ./sql-data-warehouse-develop-concurrency.md
[Функция Create Table As Select (CTAS) в хранилище данных SQL]: ./sql-data-warehouse-develop-ctas.md
[функции Create Table As Select (CTAS)]: ./sql-data-warehouse-develop-ctas.md
[Overview of tables in SQL Data Warehouse]: ./sql-data-warehouse-tables-overview.md
[общим сведениям о таблицах]: ./sql-data-warehouse-tables-overview.md
[типам данных таблиц]: ./sql-data-warehouse-tables-data-types.md
[распределении таблиц]: ./sql-data-warehouse-tables-distribute.md
[индексированием таблиц]: ./sql-data-warehouse-tables-index.md
[индексировании таблиц]: ./sql-data-warehouse-tables-index.md
[Причины низкого качества индекса Columnstore]: ./sql-data-warehouse-tables-index.md#causes-of-poor-columnstore-index-quality
[перестроением индексов columnstore]: ./sql-data-warehouse-tables-index.md#rebuilding-indexes-to-improve-segment-quality
[секционировании таблиц]: ./sql-data-warehouse-tables-partition.md
[Manage table statistics]: ./sql-data-warehouse-tables-statistics.md
[временных таблицах]: ./sql-data-warehouse-tables-temporary.md
[Руководство по использованию PolyBase в хранилище данных SQL]: ./sql-data-warehouse-load-polybase-guide.md
[Загрузка данных в хранилище данных SQL]: ./sql-data-warehouse-overview-load.md
[Перемещение данных в хранилище данных SQL Azure и из него с помощью фабрики данных Azure]: ../data-factory/data-factory-azure-sql-data-warehouse-connector.md
[Загрузка данных с помощью фабрики данных Azure]: ./sql-data-warehouse-get-started-load-with-azure-data-factory.md
[Load data with bcp]: ./sql-data-warehouse-load-with-bcp.md
[Load data with PolyBase]: ./sql-data-warehouse-get-started-load-with-polybase.md
[Мониторинг рабочей нагрузки с помощью динамических административных представлений]: ./sql-data-warehouse-manage-monitor.md
[приостановке]: ./sql-data-warehouse-manage-compute-overview.md#pause-compute-bk
[возобновлении]: ./sql-data-warehouse-manage-compute-overview.md#resume-compute-bk
[масштабировании]: ./sql-data-warehouse-manage-compute-overview.md#scale-performance-bk
[Транзакции в хранилище данных SQL]: ./sql-data-warehouse-develop-transactions.md
[Оптимизация транзакций для хранилища данных SQL]: ./sql-data-warehouse-develop-best-practices-transactions.md
[Устранение неполадок хранилища данных SQL Azure]: ./sql-data-warehouse-troubleshoot.md
[Использование меток для инструментирования запросов в хранилище данных SQL]: ./sql-data-warehouse-develop-label.md

<!--MSDN references-->
[ALTER TABLE]: https://msdn.microsoft.com/library/ms190273.aspx
[CREATE EXTERNAL FILE FORMAT (Transact-SQL)]: https://msdn.microsoft.com/library/dn935026.aspx
[CREATE STATISTICS (Transact-SQL)]: https://msdn.microsoft.com/library/ms188038.aspx
[CREATE TABLE]: https://msdn.microsoft.com/library/mt203953.aspx
[инструкции CREATE TABLE]: https://msdn.microsoft.com/library/mt203953.aspx
[CREATE TABLE AS SELECT]: https://msdn.microsoft.com/library/mt204041.aspx
[DBCC PDW\_SHOWEXECUTIONPLAN (Transact-SQL)]: https://msdn.microsoft.com/library/mt204017.aspx
[Инструкция INSERT (Transact-SQL)]: https://msdn.microsoft.com/library/ms174335.aspx
[Предложение OPTION (Transact-SQL)]: https://msdn.microsoft.com/library/ms190322.aspx
[инструкции TRUNCATE TABLE]: https://msdn.microsoft.com/library/ms177570.aspx
[UPDATE STATISTICS (Transact-SQL)]: https://msdn.microsoft.com/library/ms187348.aspx
[sys.dm\_exec\_sessions (Transact-SQL)]: https://msdn.microsoft.com/library/ms176013.aspx
[sys.dm\_pdw\_exec\_requests (Transact-SQL)]: https://msdn.microsoft.com/library/mt203887.aspx
[sys.dm\_pdw\_request\_steps (Transact-SQL)]: https://msdn.microsoft.com/library/mt203913.aspx
[sys.dm\_pdw\_sql\_requests (Transact-SQL)]: https://msdn.microsoft.com/library/mt203889.aspx
[sys.dm\_pdw\_dms\_workers (Transact-SQL)]: https://msdn.microsoft.com/library/mt203878.aspx
[sys.dm\_pdw\_waits (Transact-SQL)]: https://msdn.microsoft.com/library/mt203893.aspx
[руководством по индексам Columnstore]: https://msdn.microsoft.com/library/gg492088.aspx

<!--Other Web references-->
[выборе распределения таблиц]: https://blogs.msdn.microsoft.com/sqlcat/2015/08/11/choosing-hash-distributed-table-vs-round-robin-distributed-table-in-azure-sql-dw-service/
[отзывов о хранилище данных SQL Azure]: https://feedback.azure.com/forums/307516-sql-data-warehouse
[форуме по хранилищу данных SQL Azure на портале MSDN]: https://social.msdn.microsoft.com/Forums/sqlserver/home?forum=AzureSQLDataWarehouse
[форуме по хранилищу данных SQL Azure на сайте Stack Overflow]: http://stackoverflow.com/questions/tagged/azure-sqldw
[Azure SQL Data Warehouse loading patterns and strategies]: https://blogs.msdn.microsoft.com/sqlcat/2016/02/06/azure-sql-data-warehouse-loading-patterns-and-strategies

<!---HONumber=AcomDC_0803_2016-->