   <properties
   pageTitle="Загрузка данных в хранилище данных SQL | Microsoft Azure"
   description="Распространенные сценарии загрузки данных в хранилище данных SQL."
   services="sql-data-warehouse"
   documentationCenter="NA"
   authors="lodipalm"
   manager="barbkess"
   editor=""/>

<tags
   ms.service="sql-data-warehouse"
   ms.devlang="NA"
   ms.topic="article"
   ms.tgt_pltfrm="NA"
   ms.workload="data-services"
   ms.date="01/07/2016"
   ms.author="lodipalm;barbkess;sonyama"/>

# Загрузка данных в хранилище данных SQL
Хранилище данных SQL предоставляет множество возможностей для загрузки данных, включая следующие.

- PolyBase;
- Фабрика данных Azure
- служебная программа командной строки BCP;
- SQL Server Integration Services (SSIS);
- средства загрузки данных сторонних производителей.

Хотя все перечисленные выше методы можно использовать с хранилищем данных SQL, способность PolyBase прозрачно параллелизовать нагрузки из хранилища BLOB-объектов делает его самым быстрым средством для загрузки данных. Ознакомьтесь с дополнительными сведениями о [загрузке данных с помощью PolyBase][]. Кроме того, так как у многих пользователей начальная нагрузка от локальных источников составляет от сотен гигабайт до десятков терабайт, в разделе ниже мы поместили руководство по загрузке начальных данных.

## Начальная загрузка в хранилище данных SQL из SQL Server 
При загрузке в хранилище данных SQL из локального экземпляра SQL Server рекомендуется следующее:

1. Экспортируйте данные SQL Server в неструктурированные файлы с помощью **BCP**. 
2. Используйте **AzCopy** или **Импорт и экспорт** (для более крупных наборов данных) для перемещения файлов в Azure.
3. Настройте PolyBase для чтения файлов из вашей учетной записи хранения
4. Создайте новые таблицы и загрузите данные с помощью **PolyBase**.

В следующих разделах мы рассмотрим каждый шаг очень подробно и приведем примеры процесса.

> [AZURE.NOTE] Прежде чем переносить данные из системы, например из SQL Server, мы рекомендуем просмотреть статьи документации о [схеме миграции][] и [переносе кода][].

## Экспорт файлов с помощью BCP

Чтобы подготовить файлы для перемещения в Azure, необходимо экспортировать их в неструктурированные файлы. Это лучше всего сделать с помощью служебной программы командной строки BCP. Если служебная программа отсутствует, ее можно загрузить вместе с [Microsoft Command Line Utilities для SQL Server][]. Пример команды BCP может выглядеть следующим образом:

```
bcp "select top 10 * from <table>" queryout "<Directory><File>" -c -T -S <Server Name> -d <Database Name> -- Export Query
or
bcp <table> out "<Directory><File>" -c -T -S <Server Name> -d <Database Name> -- Export Table
```

Чтобы повысить пропускную способность, попробуйте распараллелить процесс. Для этого запустите несколько параллельных команд BCP для отдельных таблиц или отдельных разделов в одной таблице. Это позволит распределить ресурсы ЦП, используемые BCP, по нескольким ядрам на сервере, на котором работает BCP. При извлечении данных из системы SQL DW или SQL PDW добавьте идентификатор -q в кавычках — это аргумент для команды BCP. Также может понадобиться добавить -U и -P, чтобы указать имя пользователя и пароль, если в вашей среде не используется Active Directory.

Кроме того, так как мы будем загружать данные с помощью PolyBase, обратите внимание, что PolyBase еще не поддерживает UTF-16, так что все файлы должны быть в кодировке UTF-8. Это легко можно сделать, включив флаг "-c" в вашу команду BCP. Вы также можете преобразовать неструктурированные файлы из UTF-16 в UTF-8 с помощью приведенного ниже кода:

```
Get-Content <input_file_name> -Encoding Unicode | Set-Content <output_file_name> -Encoding utf8
```
 
После успешного экспорта данных в файлы самое время переместить их в Azure. Это можно сделать с помощью AZCopy или с помощью службы импорта и экспорта, как описано в следующем разделе.

## Загрузка в Azure с помощью AZCopy или службы импорта и экспорта
При перемещении данных размером 5–10 терабайт или более мы рекомендуем использовать для переноса нашу службу доставки диска [Импорт и экспорт][]. Однако в наших примерах мы смогли без проблем переместить данные объемом менее 10 ТБ с помощью Интернета и AZCopy. Этот процесс можно ускорить или расширить с помощью ExpressRoute.

Ниже подробно рассказано о том, как переместить данные из локальной в учетную запись хранения Azure с помощью AZCopy. При отсутствии учетной записи хранения Azure в том же регионе можно создать ее, следуя [документации хранилища Azure][]. Можно также загрузить данные из учетной записи хранения в другом регионе, но производительность в этом случае не будет оптимальной.

> [AZURE.NOTE] В этой документации предполагается, что вы установили программу командной строки AZCopy и можете запустить ее с помощью Powershell. Если это не так, следуйте [инструкциям по установке AZCopy][].

Теперь, имея набор файлов, созданный с помощью программы BCP, AzCopy можно просто запустить из Azure Powershell или путем запуска сценария Powershell. На высоком уровне строки, необходимые для запуска AZCopy, будут иметь вид:

```
AZCopy /Source:<File Location> /Dest:<Storage Container Location> /destkey:<Storage Key> /Pattern:<File Name> /NC:256
```

Помимо основных советов рекомендуется использовать следующие соображения для загрузки с помощью AZCopy.


+ **Одновременные подключения**: помимо увеличения числа операций AzCopy, выполняемых одновременно, саму операцию AzCopy можно дополнительно параллелизовать, задав параметр /NC, который открывает несколько одновременных подключений к точке назначения. Хотя максимальное значение параметра — 512, мы выяснили, что оптимальная передача данных осуществляется при значении 256, и рекомендуем проверить несколько значений для получения оптимальной конфигурации.

+ **ExpressRoute**: как уже говорилось выше, этот процесс можно ускорить, если включен ExpressRoute. Обзор Express Route и шаги для настройки можно найти в [документации по ExpressRoute][].

+ **Структура папок**: для упрощения переноса с помощью PolyBase убедитесь, что каждая таблица сопоставлена собственной папке. Позже это сведет к минимуму и упростит шаги при загрузке с помощью PolyBase. Учитывая это, нет разницы, разбивается ли таблица на несколько файлов или даже каталогов в папке.
	 

## Настройка PolyBase 

Теперь, когда данные хранятся в хранилище BLOB-объектов Azure, мы будем импортировать их в экземпляр хранилища данных SQL с помощью PolyBase. Следующие действия предназначены только для настройки, и многие из них необходимо выполнить один раз для каждого экземпляра хранилища данных SQL, пользователя или учетной записи хранения. Более подробно эти действия описаны в нашей документации по [загрузке с помощью PolyBase][].

1. **Создайте главный ключ базы данных.** Эту операцию достаточно выполнить один раз для каждой базы данных. 

2. **Создайте учетные данные уровня базы данных.** Данная операция потребуется только в том случае, если вы хотите создать новые учетные данные или пользователя, в противном случае можно воспользоваться ранее созданными учетными данными.

3. **Создайте формат внешнего файла.** Форматы внешних файлов также используются многократно, их потребуется создать только при загрузке нового типа файлов.

4. **Создайте внешний источник данных.** Если навести указатель мыши на учетную запись хранения, можно использовать внешний источник данных при загрузке из того же контейнера. Для параметра LOCATION используйте расположение в формате wasbs://mycontainer@ test.blob.core.windows.net/path.

```
-- Creating master key
CREATE MASTER KEY;

-- Creating a database scoped credential
CREATE DATABASE SCOPED CREDENTIAL <Credential Name> 
WITH 
    IDENTITY = '<User Name>'
,   Secret = '<Azure Storage Key>'
;

-- Creating external file format (delimited text file)
CREATE EXTERNAL FILE FORMAT text_file_format 
WITH 
(
    FORMAT_TYPE = DELIMITEDTEXT 
,   FORMAT_OPTIONS  (
                        FIELD_TERMINATOR ='|' 
                    ,   USE_TYPE_DEFAULT = TRUE
                    )
);

--Creating an external data source
CREATE EXTERNAL DATA SOURCE azure_storage 
WITH 
(
    TYPE = HADOOP 
,   LOCATION ='wasbs://<Container>@<Blob Path>'
,   CREDENTIAL = <Credential Name>
)
;
```

Теперь, когда учетная запись хранения настроена правильно, можно продолжить загрузку данных в хранилище данных SQL.

## Загрузка данных с помощью PolyBase 
После настройки PolyBase можно загрузить данные непосредственно в хранилище данных SQL, просто создав внешнюю таблицу, указывающую на данные в хранилище и сопоставив эти данные с новой таблицей в хранилище данных SQL. Это можно сделать с помощью двух простых команд, указанных ниже.

1. Используйте команду 'CREATE EXTERNAL TABLE' для определения структуры данных. Чтобы убедиться, что записи состояния данных осуществляются быстро и эффективно, рекомендуется создать сценарий для таблицы SQL Server в среде SSMS и затем настроить вручную с учетом отличий внешней таблицы. После создания внешней таблицы в Azure она будет по-прежнему указывать на то же расположение, даже если данные обновлены или добавлены дополнительные данные.  

```
-- Creating external table pointing to file stored in Azure Storage
CREATE EXTERNAL TABLE <External Table Name> 
(
    <Column name>, <Column type>, <NULL/NOT NULL>
)
WITH 
(   LOCATION='<Folder Path>'
,   DATA_SOURCE = <Data Source>
,   FILE_FORMAT = <File Format>      
);
```

2. Загрузите данные с помощью инструкции 'CREATE TABLE...AS SELECT'. 

```
CREATE TABLE <Table Name> 
WITH 
(
	CLUSTERED COLUMNSTORE INDEX,
	DISTRIBUTION = <HASH(<Column Name>)>/<ROUND_ROBIN>
)
AS 
SELECT  * 
FROM    <External Table Name>
;
```

Обратите внимание, что можно также загрузить подраздел строк из таблицы с помощью более подробной инструкции SELECT. Тем не менее, поскольку в настоящее время PolyBase не обеспечивает дополнительные вычисления для учетных записей хранения, загрузка подраздела с помощью инструкции SELECT не будет быстрее, чем загрузка всего набора данных.

В дополнение к инструкции `CREATE TABLE...AS SELECT` можно также загрузить данные из внешних таблиц в существующие таблицы с помощью инструкции INSERT...INTO.

##  Создание статистики для вновь загруженных данных 

Хранилище данных SQL Azure пока не поддерживает автоматическое создание или автоматическое обновление статистики. Чтобы добиться максимально высокой производительности запросов, крайне важно сформировать статистические данные для всех столбцов всех таблиц после первой загрузки или после любых значительных изменений в данных. Подробные сведения о работе со статистикой см. в разделе [Статистика][] из группы разделов по разработке. Ниже приведен краткий пример создания статистики по табличным данным, загруженным в этом примере.


```
create statistics [<name>] on [<Table Name>] ([<Column Name>]);
create statistics [<another name>] on [<Table Name>] ([<Another Column Name>]);
```

## Дальнейшие действия
Дополнительные советы по разработке см. в статье [Общие сведения о разработке][].

<!--Image references-->

<!--Article references-->
[Load data with bcp]: sql-data-warehouse-load-with-bcp.md
[загрузке данных с помощью PolyBase]: sql-data-warehouse-get-started-load-with-polybase.md
[загрузке с помощью PolyBase]: sql-data-warehouse-get-started-load-with-polybase.md
[solution partners]: sql-data-warehouse-solution-partners.md
[Общие сведения о разработке]: sql-data-warehouse-overview-develop.md
[схеме миграции]: sql-data-warehouse-migrate-schema.md
[переносе кода]: sql-data-warehouse-migrate-code.md
[Статистика]: sql-data-warehouse-develop-statistics.md

<!--MSDN references-->
[supported source/sink]: https://msdn.microsoft.com/library/dn894007.aspx
[copy activity]: https://msdn.microsoft.com/library/dn835035.aspx
[SQL Server destination adapter]: https://msdn.microsoft.com/library/ms141237.aspx
[SSIS]: https://msdn.microsoft.com/library/ms141026.aspx

<!--Other Web references-->
[инструкциям по установке AZCopy]: https://azure.microsoft.com/ru-RU/documentation/articles/storage-use-azcopy/
[Microsoft Command Line Utilities для SQL Server]: http://www.microsoft.com/ru-RU/download/details.aspx?id=36433
[Импорт и экспорт]: https://azure.microsoft.com/ru-RU/documentation/articles/storage-import-export-service/
[документации хранилища Azure]: https://azure.microsoft.com/ru-RU/documentation/articles/storage-create-storage-account/
[документации по ExpressRoute]: http://azure.microsoft.com/documentation/services/expressroute/

<!---HONumber=AcomDC_0218_2016-->