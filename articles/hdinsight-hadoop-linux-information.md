<properties
   pageTitle="Что нужно знать о Hadoop в HDInsight на платформе Linux | Azure"
   description="Кластеры HDInsight на основе Linux предоставляют Hadoop в привычной среде Linux, выполняемой в облаке Azure."
   services="hdinsight"
   documentationCenter=""
   authors="Blackmist"
   manager="paulettm"
   editor="cgronlun"/>

<tags
   ms.service="hdinsight"
   ms.devlang=""
   ms.topic="article"
   ms.tgt_pltfrm="na"
   ms.workload="big-data"
   ms.date="02/18/2015"
   ms.author="larryfr"/>

#Работа с HDInsight в Linux (предварительная версия)

Кластеры HDInsight на основе Linux предоставляют Hadoop в привычной среде Linux, выполняемой в облаке Azure. Для большинства задач они должны работать так же, как и любые другие установки Hadoop в Linux. В этом документе рассматриваются определенные отличия, которые при этом следует учитывать.

##Имена доменов

Полное доменное имя (FQDN), используемое при подключении к кластеру, - **&lt;имя_кластера>.azurehdinsight.net** или (только для SSH) **&lt;имя_кластера>.aurehdinsight.net**.

##Службы доступны удаленно

* **Ambari (Интернет)** - https://&lt;имя_кластера>.azurehdinsight.net

	> [AZURE.NOTE] Выполните аутентификацию, используя имя пользователя и пароль администратора кластеров, а затем войдите в Ambari. При этом также используется имя пользователя и пароль администратора кластера.
	> 
	> В аутентификации используется открытый текст - всегда используйте протокол HTTPS, чтобы обеспечить безопасное соединение.

	Хотя Ambari для кластера доступен напрямую через Интернет, некоторые функциональные возможности зависят от доступа к узлам по внутреннему доменному имени, используемому в кластере. Так как это внутреннее доменное имя, а не общедоступное, вы получите ошибки "сервер не найден", если попытаетесь получить доступ к некоторым функциям сервера через Интернет.

	Чтобы обойти эту проблему, используйте туннель SSH для проксирования веб-трафика на головном узле кластера. Используйте следующие статьи, чтобы создать туннель SSH от порта на локальном компьютере до кластера.

	* <a href="../hdinsight-hadoop-linux-use-ssh-unix/#tunnel" target="_blank">Использование SSH с Hadoop на основе Linux в HDInsight из Linux, Unix или OS X</a> - шаги по созданию туннеля SSH с помощью команды `ssh`

	* <a href="../hdinsight-hadoop-linux-use-ssh-windows/#tunnel" target="_blank">Использование SSH с Hadoop на основе Linux в HDInsight из Windows</a> - шаги по созданию туннеля SSH с помощью PuTTY

* **Ambari (REST)** -https://&lt;имя_кластера>.azurehdinsight.net/ambari

	> [AZURE.NOTE] Выполняйте аутентификацию с помощью имени пользователя и пароля администратора кластера.
	> 
	> В аутентификации используется открытый текст - всегда используйте протокол HTTPS, чтобы обеспечить безопасное соединение.

* **WebHCat (Templeton)** -https://&lt;имя_кластера>.azurehdinsight.net/templeton

	> [AZURE.NOTE] Выполняйте аутентификацию с помощью имени пользователя и пароля администратора кластера.
	> 
	> В аутентификации используется открытый текст - всегда используйте протокол HTTPS, чтобы обеспечить безопасное соединение.

* **SSH** - &lt;имя_кластера>-ssh.azurehdinsight.net через порт 22

	> [AZURE.NOTE] Доступ к головному узлу кластера можно получить только по протоколу SSH с клиентского компьютера. После подключения с головного узла можно получить доступ к рабочим узлам по протоколу SSH.

##Местоположения файлов

Связанные с Hadoop файлы можно найти на узлах кластера в папке `/usr/hdp/current`.

Пример данных и JAR-файлы можно найти в HDFS (WASB) в папке /example или 'wasb:///example'.

##Рекомендации по HDFS, WASB и хранению

В большинстве дистрибутивов Hadoop распределенная файловая система Hadoop (Hadoop Distributed File System - HDFS) реализуется на базе локального хранилища на компьютерах в кластере. Несмотря на эффективность, в случае облачного решения с почасовой платой за вычислительные ресурсы такой подход может оказаться весьма затратным.

HDInsight использует хранилище больших двоичных объектов Azure в качестве хранилища по умолчанию, что дает следующие преимущества:

* недорогое долговременное хранение;

* доступность из внешних служб, например веб-сайтов, служебных программ для отправки или скачивания файлов, пакетов SDK для различных языков и веб-браузеров.

Поскольку это хранилище по умолчанию для HDInsight, в большинстве случаев его можно использовать без какой-либо специальной подготовки. Например, следующая команда отображает список файлов в папке **/example/data**, которая хранится в хранилище больших двоичных объектов Azure.

	hadoop fs -ls /example/data

Для некоторых команд, возможно, нужно будет указать, что вы используете хранилище больших двоичных объектов. Для этого можно добавить к команде префикс **WASB://**.

HDInsight также позволяет связать несколько учетных записей хранилища больших двоичных объектов с кластером. Для доступа к данным из-под учетной записи хранилища больших двоичных объектов, отличной от заданной по умолчанию, можно использовать формат **WASB://&lt;имя_контейнера>@&lt;имя_учетной_записи>.blob.core.windows.net/**. Например, ниже будет перечислено содержимое каталога **/example/data** для указанного контейнера и учетной записи хранения.

	hadoop fs -ls wasb://mycontainer@mystorage.blob.core.windows.net/example/data

###Какие хранилища больших двоичных объектов используются в кластере?

При создании кластера можно на выбор использовать имеющиеся учетную запись хранения и контейнер или создать новые. Если вы забудете, что именно выбрали, учетную запись хранения и контейнер можно найти следующими способами.

**Портал Azure**

1. На <a href="https://manage.windowsazure.com/" target="_blank">портале управления Azure</a>выберите кластер HDInsight.

2. Выберите **панель мониторинга** в верхней части страницы.

3. Учетные записи хранения и контейнеры перечислены на странице в разделе **связанные ресурсы**.

	![linked resources](./media/hdinsight-hadoop-linux-information/storageportal.png)

**Кроссплатформенный интерфейс командной строки Azure**

*Скоро!*

###Как получить доступ к хранилищу больших двоичных объектов?

Получить доступ к большим двоичным объектам можно не только с помощью команды Hadoop из кластера, но и множеством других способов:

* <a href="http://azure.microsoft.com/ documentation/articles/xplat-cli/" target="_blank">Кроссплатформенный интерфейс командной строки Azure</a> - информацию об использовании хранилища после установки см. в описании `azure storage`, а информацию об определенных командах для больших двоичных объектов - в описании `azure blob`.

* Различные пакеты SDK:

	* <a href="https://github.com/Azure/azure-sdk-for-java" target="_blank">Java</a>

	* <a href="https://github.com/Azure/azure-sdk-for-node" target="_blank">Node.js</a>

	* <a href="https://github.com/Azure/azure-sdk-for-php" target="_blank">PHP</a>

	* <a href="https://github.com/Azure/azure-sdk-for-python" target="_blank">Python</a>

	* <a href="https://github.com/Azure/azure-sdk-for-ruby" target="_blank">Ruby</a>

	* <a href="https://github.com/Azure/azure-sdk-for-net" target="_blank">.NET</a>

* <a href="https://msdn.microsoft.com/ru-ru/library/azure/dd135733.aspx" target="_blank">API REST хранилища.</a>


##Дальнейшие действия

* [Использование Hive с HDInsight](../hdinsight-use-hive/)
* [Использование Pig с HDInsight](../hdinsight-use-pig/)
* [Использование заданий MapReduce с HDInsight](../hdinsight-use-mapreduce)


<!--HONumber=45--> 
