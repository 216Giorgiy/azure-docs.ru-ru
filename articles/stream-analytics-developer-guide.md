<properties 
	pageTitle="Руководство разработчика по Stream Analytics | Azure" 
	description="Узнайте, как разрабатывать приложения анализа потоков Azure" 
	services="stream-analytics" 
	documentationCenter="" 
	authors="mumian" 
	manager="paulettm" 
	editor="cgronlun"/>

<tags 
	ms.service="stream-analytics" 
	ms.devlang="na" 
	ms.topic="article" 
	ms.tgt_pltfrm="na" 
	ms.workload="data-services" 
	ms.date="2/17/2015" 
	ms.author="jgao"/>


# Руководство разработчика по Stream Analytics 

[Этот раздел из предварительной документации может быть изменен в будущих выпусках.] 

Azure Stream Analytics является полностью управляемой службой, обеспечивающей низкую задержку и высокий уровень доступности, масштабируемую обработку сложных событий посредством потоковой передачи данных в облако. В предварительном выпуске Stream Analytics позволяет клиентам настраивать задания потоковой передачи данных для анализа потоков данных осуществлять аналитику в квазиреальном времени.  

Области применения Stream Analytics:

- Выполнение сложной обработки событий с данными большого объема при высокой скорости передачи   
- Сбор данных о событиях из глобально распределенных ресурсов или оборудования, такого как подключенные автомобили или распределительные электросети 
- Обработка данных телеметрии для мониторинга и диагностики в квазиреальном времени 
- Захват и архивирование событий в реальном времени для последующей обработки

Дополнительную информацию см. в разделе [Введение в Azure Stream Analytics][stream.analytics.introduction]. 

Задания Stream Analytics состоят из одного или нескольких входных источников, запроса, передаваемого через входящие потоковые данные, и выходной цели.  


##Содержание

+ [Входные данные](#inputs) 
+ [Query](#query)
+ [Выходные данные](#output)
+ [Задания масштабирования](#scale)
+ [Мониторинг заданий и устранение неполадок в них](#monitor)
+ [Управление заданиями](#manage)
+ [Дальнейшие действия](#nextsteps)



##<a name="inputs"></a>Входные данные

### Поток данных

В каждом определении задания Stream Analytics должен содержаться как минимум один входной источник потока данных, потребляемый и изменяемый заданием.  [Хранилище больших двоичных объектов Azure][azure.blob.storage] и [концентраторы событий Azure Service Bus][azure.event.hubs] поддерживаются как входные источники потоков данных.  Входные источники концентратора событий используются для сбора потоков событий из нескольких различных устройств и служб, в то время как хранилище больших двоичных объектов может быть входным источником для приема больших объемов данных.  Поскольку большие двоичные объекты не осуществляют потоковую передачу данных, задания Stream Analytics, работающие с такими объектами, не будут по своей природе временными, если только в большом двоичном объекте не содержатся метки времени.

### Ссылочные данные

Stream Analytics также поддерживает второй тип входных источников: ссылочные данные.  Это вспомогательные данные, используемые для проверки взаимосвязи и подстановки; данные здесь, как правило, не меняются или меняются редко.  В предварительной версии хранилище больших двоичных объектов - единственный поддерживаемый входной источник для ссылочных данных.

### Сериализация
Чтобы обеспечить правильное поведение запросов, Stream Analytics должен учитывать формат сериализации, применяемый к входящим потокам данных. В настоящее время поддерживаются форматы JSON, CSV и Avro для потоковой передачи данных и CSV для ссылочных данных.

### Созданные свойства
В зависимости от используемого в задании входного типа будет создано несколько дополнительных полей с метаданными событий.  Эти поля можно использовать в запросах так же, как и другие входные столбцы.  Если в существующем событии есть поле с таким же именем, как одно из указанных ниже свойств, оно будет перезаписано входными метаданными.

<table border="1">
	<tr>
		<th></th>
		<th>Свойство</th>
		<th>Описание</th>
	</tr>
	<tr>
		<td rowspan="4" valign="top"><strong>BLOB-объект</strong></td>
		<td>BlobName</td>
		<td>Имя входного большого двоичного объекта, от которого возникло событие</td>
	</tr>
	<tr>
		<td>EventProcessedUtcTime</td>
		<td>Дата и время обработки записи большого двоичного объекта</td>
	</tr>
	<tr>
		<td>BlobLastModifiedUtcTime</td>
		<td>Дата и время последнего изменения большого двоичного объекта</td>
	</tr>
	<tr>
		<td>PartitionId</td>
		<td>Идентификатор раздела для входного адаптера (нумерация идет от нуля)</td>
	</tr>
	<tr>
		<td rowspan="3" valign="top"><b>Концентратор событий</b></td>
		<td>EventProcessedUtcTime</td>
		<td>Дата и время обработки события</td>
	</tr>
	<tr>
		<td>EventEnqueuedUtcTime</td>
		<td>Дата и время получения события концентратором событий</td>
	</tr>
	<tr>
		<td>PartitionId</td>
		<td>Идентификатор раздела для входного адаптера (нумерация идет от нуля)</td>
	</tr>
</table>



###Дополнительные ресурсы
Дополнительные сведения о создании входных источников см. в разделах [Руководство разработчика концентраторов событий Azure][azure.event.hubs.developer.guide] и [Использование хранилища больших двоичных объектов Azure][azure.blob.storage.use].  



##<a name="query"></a>Query
Логика фильтрации входящих данных, их обработки и управления ими определяется в запросе заданий Stream Analytics.  Запросы пишутся на языке запросов Stream Analytics, SQL-подобном языке, во многом представляющем собой подмножество стандартного синтаксиса T-SQL с некоторыми специфическими расширениями для временных запросов.

###Оконное расширение
Оконные расширения позволяют выполнять агрегирование и вычисление над подмножествами событий, попадающими в определенный период времени. Функции оконного расширения вызываются с помощью оператора GROUP BY. Например, следующий запрос подсчитывает количество событий, полученное в секунду: 

	SELECT Count(*) 
	FROM Input1 
	GROUP BY TumblingWindow(second, 1) 

###Шаги выполнения
При составлении более сложных запросов можно использовать стандартное SQL-условие WITH, чтобы определить временное именованное результирующее множество.  Например, этот запрос использует WITH, чтобы выполнить преобразование за два этапа.
 
	WITH step1 AS ( 
		SELECT Avg(Reading) as avr 
		FROM temperatureInput1 
		GROUP BY Building, TumblingWindow(hour, 1) 
	) 

	SELECT Avg(avr) AS campus_Avg 
	FROM step1 
	GROUP BY TumblingWindow (day, 1) 

Дополнительные сведения о языке запросов см. в разделе [Справочник по языку запросов Azure Stream Analytics][stream.analytics.query.language.reference]. 

##<a name="output"></a>Выходные данные
В выходной источник будут записаны результаты выполнения задания Stream Analytics. Результаты постоянно записываются в выходной источник по мере обработки заданием входных событий.  Поддерживаются следующие выходные источники:

- Концентраторы событий Service Bus в системе Azure. Если нужно объединить несколько потоковых конвейеров - например, для ответной выдачи команд устройствам, - выберите в качестве выходного источника концентратор событий.
- Большие двоичные объекты хранилища Azure. Используйте хранилище больших двоичных объектов для долгосрочного архивирования выходных данных или хранения данных для последующей обработки.
- База данных SQL Azure. Этот выходной источник подходит для реляционных данных или для приложений, зависящих от содержимого, размещенного в базе данных.


##<a name="scale"></a>Задания масштабирования

Задание Stream Analytics можно масштабировать с помощью настроек единиц потоковой передачи, определяющих объем вычислительной мощности, получаемый заданием. Каждая единица потоковой передачи соответствует примерно 1 МБ в секунду пропускной способности. Каждая подписка предоставляет квоту в 12 единиц потоковой передачи на регион, распределяемую между заданиями в этом регионе.

Дополнительные сведения см. в разделе [Задания по масштабированию в Azure Stream Analytics][stream.analytics.scale.jobs].


##<a name="monitor"></a>Мониторинг заданий и устранение неполадок в них

###Учетная запись хранилища регионального мониторинга

Для мониторинга заданий в Stream Analytics вам необходимо назначить учетную запись Azure Storage для мониторинга данных в каждом регионе, содержащем задания Stream Analytics.  Этот процесс производится при создании задания.  

###Метрики
Для мониторинга использования и производительности заданий Stream Analytics доступны следующие метрики.

- Входящая пропускная способность: объем данных, полученных заданием Stream Analytics, измеренный счетчиком событий
- Исходящая пропускная способность: объем данных, отправляемых заданием Stream Analytics в выходной источник, измеренный счетчиком событий
- Число ошибок: количество сообщений об ошибках, вызванных заданием Stream Analytics

###Журналы операций
Отладку и диагностику заданий Stream Analytics лучше всего осуществлять с помощью журналов операций Azure.  Журналы операций можно открыть в разделе "Службы управления" портала.  Чтобы просмотреть журналы своего задания, задайте значение параметра "Тип службы" равным "Stream Analytics", а значение параметра "Имя службы" - равным имени задания.


##<a name="manage"></a>Управление заданиями 

###Запуск и остановка заданий
В предварительной версии Stream Analytics при остановке задания не сохраняется состояние последних событий, использованных в задании.  Из-за этого перезапуск остановленного задания может привести к удалению событий или дублированию данных.  Если необходимо временно остановить задание, рекомендуется изучить выходные данные и примерно оценить время остановки задания по времени вставки последней записи.  Затем нужно указать это время в параметре "Начало вывода" на вкладке "Настройка" после перезапуска задания.
Это ограничение временно, и возможность запуска и остановки задания без потери данных подлежит скорейшей реализации в будущих версиях продукта.  

###Настройка заданий
Вы сможете настроить следующие параметры верхнего уровня для задания Stream Analytics.

- Начало вывода: задает время начала выдачи заданием результирующих выходных данных. Если связанный запрос включает в себя окно, задание начнет получать входные данные из входных источников ввода в начале требуемого периода окна, чтобы подготовить первое выходное событие к указанному времени. Доступны два значения параметра: "Время запуска задания" и "Пользовательский". По умолчанию выставляется параметр "Время запуска задания". При выборе параметра "Пользовательский" вам необходимо указать дату и время. Этот параметр полезен для указания объема используемых данных из входных источников и для приема данных из конкретного времени: например, с момента последней остановки задания. 
- Неупорядоченная политика: параметры для обработки событий, которые не поступают в задание Stream Analytics последовательно. Вы можете указать временной порог, в пределах которого события будут переупорядочены, задав диапазон отклонений, и также указать действие, применяемое к событиям за пределами этого диапазона: "Удалить" или "Изменить".  Вариант "Удалить" приведет к удалению всех событий, полученных в неактуальное время, а вариант "Изменить" изменит значение System.Timestamp для таких событий на метку времени подходящего события, полученного в последнюю очередь.  
- Локаль: этот параметр используется для указания приоритета интернационализации для задания Stream Analytics. Хотя метки времени данных не зависят от локали, данные параметры влияют на анализ, сравнение и сортировку данных заданием. В предварительной версии поддерживается только локаль en-US.


##<a name="support"></a>Получение поддержки
За дополнительной поддержкой обращайтесь на [Форум Azure Stream Analytics][stream.analytics.forum]. 


##<a name="nextsteps"></a>Дальнейшие действия

- [Введение в Azure Stream Analytics][stream.analytics.introduction]
- [Приступая к работе с Azure Stream Analytics][stream.analytics.get.started]
- [Задания по масштабированию в Azure Stream Analytics][stream.analytics.scale.jobs]
- [Ограничения и известные проблемы Azure Stream Analytics][stream.analytics.limitations]
- [Справочник по языку запросов Azure Stream Analytics][stream.analytics.query.language.reference]
- [Справочник по REST API для управления Azure Stream Analytics][stream.analytics.rest.api.reference] 



<!--Image references-->
[5]: ./media/markdown-template-for-new-articles/octocats.png
[6]: ./media/markdown-template-for-new-articles/pretty49.png
[7]: ./media/markdown-template-for-new-articles/channel-9.png


<!--Link references-->
[azure.blob.storage]: http://azure.microsoft.com/documentation/services/storage/
[azure.blob.storage.use]: http://azure.microsoft.com/documentation/articles/storage-dotnet-how-to-use-blobs/

[azure.event.hubs]: http://azure.microsoft.com/services/event-hubs/
[azure.event.hubs.developer.guide]: http://msdn.microsoft.com/library/azure/dn789972.aspx

[stream.analytics.query.language.reference]: http://go.microsoft.com/fwlink/?LinkID=513299
[stream.analytics.forum]: http://go.microsoft.com/fwlink/?LinkId=512151

[stream.analytics.introduction]: ../stream-analytics-introduction/
[stream.analytics.get.started]: ../stream-analytics-get-started/
[stream.analytics.developer.guide]: ../stream-analytics-developer-guide/
[stream.analytics.scale.jobs]: ../stream-analytics-scale-jobs/
[stream.analytics.limitations]: ../stream-analytics-limitations/
[stream.analytics.query.language.reference]: http://go.microsoft.com/fwlink/?LinkID=513299
[stream.analytics.rest.api.reference]: http://go.microsoft.com/fwlink/?LinkId=517301

<!--HONumber=46--> 
