---
title: Конфигурации рабочих нагрузок SAP с использованием Зон доступности Azure | Документация Майкрософт
description: Архитектура с высоким уровнем доступности и сценарии для SAP NetWeaver с использованием Зон доступности Azure
services: virtual-machines-windows,virtual-network,storage
documentationcenter: saponazure
author: msjuergent
manager: patfilot
editor: ''
tags: azure-resource-manager
keywords: ''
ms.assetid: 887caaec-02ba-4711-bd4d-204a7d16b32b
ms.service: virtual-machines-windows
ms.devlang: NA
ms.topic: article
ms.tgt_pltfrm: vm-windows
ms.workload: infrastructure-services
ms.date: 02/03/2019
ms.author: juergent
ms.custom: H1Hack27Feb2017
ms.openlocfilehash: 409a304296d3fdff897a203177e2c150162755c6
ms.sourcegitcommit: 947b331c4d03f79adcb45f74d275ac160c4a2e83
ms.translationtype: HT
ms.contentlocale: ru-RU
ms.lasthandoff: 02/05/2019
ms.locfileid: "55746223"
---
# <a name="sap-workload-configurations-with-azure-availability-zones"></a>Конфигурации рабочих нагрузок SAP с использованием Зон доступности Azure

Одной из функций Azure для поддержания высокого уровня доступности рабочих нагрузок SAP в Azure являются [Зоны доступности Azure](https://docs.microsoft.com/azure/availability-zones/az-overview). Зоны доступности уже предоставляются в нескольких [регионах Azure](https://azure.microsoft.com/global-infrastructure/regions/). Количество таких регионов будет увеличиваться. 

Базовая архитектура SAP с высоким уровнем доступности выглядит примерно так, как на этом изображении.

![Стандартная конфигурация с высоким уровнем доступности](./media/sap-ha-availability-zones/standard-ha-config.png)

Прикладной уровень SAP развертывается в пределах одной [группы доступности](https://docs.microsoft.com/azure/virtual-machines/windows/manage-availability) Azure. Чтобы обеспечить высокий уровень доступности Центральных служб SAP, разверните две виртуальные машины в отдельную группу доступности и с помощью служб отказоустойчивого кластера Windows или Linux Pacemaker разверните платформу высокого уровня доступности, чтобы выполнять автоматический переход на другой ресурс в случае аппаратных или программных проблем. Следующие документы содержат подробное описание таких развертываний.

- [Кластеризация экземпляра SAP ASCS/SCS в отказоустойчивом кластере Windows с помощью общего диска кластера в Azure](https://docs.microsoft.com/azure/virtual-machines/workloads/sap/sap-high-availability-guide-wsfc-shared-disk)
- [Кластеризация экземпляра SAP ASCS/SCS в отказоустойчивом кластере Windows с помощью файлового ресурса в Azure](https://docs.microsoft.com/azure/virtual-machines/workloads/sap/sap-high-availability-guide-wsfc-file-share)
- [Руководство по обеспечению высокого уровня доступности виртуальных машин Azure для SAP NetWeaver на SUSE Linux Enterprise Server для приложений SAP](https://docs.microsoft.com/azure/virtual-machines/workloads/sap/high-availability-guide-suse)
- [Обеспечение высокого уровня доступности SAP NetWeaver в виртуальных машинах Azure с Red Hat Enterprise Linux](https://docs.microsoft.com/azure/virtual-machines/workloads/sap/high-availability-guide-rhel)

Аналогичная архитектура применяется и для уровня СУБД SAP NetWeaver, S/4HANA или систем Hybris. Уровень СУБД развертывается в режиме "активный — пассивный" с решением отказоустойчивого кластера, в котором используются специальные платформы для отработки отказа СУБД, службы отказоустойчивого кластера Windows или Pacemaker для запуска отработки отказа в случае аппаратных или программных проблем. 

Чтобы развернуть аналогичную архитектуру на основе Зон доступности Azure, потребуется внести ряд изменений. Эти изменения описаны в нескольких частях этого документа.

## <a name="considerations-deploying-across-availability-zones"></a>Рекомендации по развертыванию в Зонах доступности

При использовании Зон доступности есть несколько моментов, которые следует учесть. Ниже приведен список рекомендаций.

- Зоны доступности Azure не дают никаких гарантий определенного расстояния между зонами в пределах региона Azure.
- Зоны доступности Azure не следует считать идеальным решением для аварийного восстановления. Если грандиозное стихийное бедствие причинит существенный ущерб нескольким регионам мира, в том числе инфраструктуре электропитания, расстояние между зонами доступности может оказаться недостаточным для хорошего решения аварийного восстановления.
- Задержка сети между Зонами доступности Azure в разных регионах Azure может отличаться. В некоторых случаях вы можете выполнить прикладной уровень SAP, развернутый в разных зонах, так как задержка сети при обращении из разных зон к активной виртуальной машине СУБД остается в допустимых пределах и не затрудняет бизнес-процессы. Но в некоторых регионах Azure будет складываться такая ситуация, в которой задержка между активной виртуальной машиной СУБД в одной зоне и экземпляром приложения SAP на виртуальной машине в другой зоне будет слишком значительной и неприемлемой для бизнес-процессов SAP. Это означает, что архитектуры развертывания для приложений в таких системах должны различаться: "активный — активный" или "активный — пассивный", если задержка сети между зонами слишком высока.
- Выберите конфигурацию, для которой можно применить Зоны доступности Azure. Учитывайте сетевые задержки, которые вы наблюдаете между разными зонами. Сетевая задержка играет важную роль в двух аспектах.
    - Задержка между двумя экземплярами СУБД, между которыми нужно настроить синхронную репликацию. Чем выше сетевая задержка, тем выше вероятность ухудшения масштабируемости такой рабочей нагрузки.
    - Разница сетевой задержки между виртуальной машиной, которая выполняет экземпляр диалога SAP в той же зоне, где расположен активный экземпляр СУБД, и аналогичной виртуальной машиной в другой зоне. Чем больше разница между ними, тем большее влияние они будут оказывать на время выполнения бизнес-процессов и пакетных заданий, в зависимости от того, находятся ли они в одной с СУБД зоне или в разных зонах.


Что касается использования функций Azure, существуют некоторые ограничения на их применение при развертывании виртуальных машин Azure между зонами и настройке решений для отработки отказа в разных зонах доступности в том же регионе Azure. Вот список этих ограничений:

- Использование [управляемых дисков Azure](https://azure.microsoft.com/services/managed-disks/) является обязательным для развертывания в Зонах доступности Azure. 
- Сопоставление перечислений зон с физическими зонами фиксируется на уровне подписки Azure. Если вы используете разные подписки для развертывания систем SAP, для каждой подписки следует отдельно определить оптимальные зоны.
- Вы не можете развертывать группы доступности Azure в Зоне доступности Azure. В качестве платформы развертывания для виртуальных машин нужно выбрать Зону доступности или группу доступности Azure.
- Вы не можете использовать [Azure Load Balancer (цен. категория "Базовый")](https://docs.microsoft.com/azure/load-balancer/load-balancer-overview#skus) для создания отказоустойчивых кластерных решений, основанных на службах отказоустойчивого кластера Windows или Linux Pacemaker. Вместо этого необходимо использовать [номер SKU Load Balancer (цен. категория "Стандартный") Azure](https://docs.microsoft.com/azure/load-balancer/load-balancer-standard-availability-zones).



## <a name="ideal-zone-combination"></a>Идеальная комбинация зон
Чтобы решить, как лучше всего использовать зоны доступности, выполните исследование и соберите следующие данные.

- Сетевая задержка между тремя разными зонами в регионе Azure. Это позволит выбрать зоны с наименьшей сетевой задержкой для трафика между зонами.
- Разница задержек между виртуальными машинами в пределах выбранной зоны и сетевой задержки между двумя выбранными зонами.
- Доступность типов виртуальных машин, которые вы намерены развернуть в выбранных зонах доступности, в соответствующих зонах. Это особенно важно при использовании виртуальных машин серии M. Некоторые номера SKU виртуальных машин серии M доступны лишь в двух из трех зон.

### <a name="network-latency-between-zones-and-within-zone"></a>Сетевая задержка между зонами и в пределах зоны.
Чтобы узнать задержку между несколькими зонами, сделайте следующее:

- Разверните в каждой из трех зон виртуальную машину с тем номером SKU, который вы намерены использовать для экземпляра СУБД. Перед выполнением измерений убедитесь, что включено [ускорение работы в сети Azure](https://azure.microsoft.com/blog/maximize-your-vm-s-performance-with-accelerated-networking-now-generally-available-for-both-windows-and-linux/).
- Когда вы найдете две зоны с наименьшей сетевой задержкой, разверните во всех трех зонах доступности еще три виртуальные машины с тем номером SKU, который вы планируете использовать для прикладного уровня. Измерьте сетевую задержку для двух виртуальных машин СУБД в двух выбранных зонах для СУБД. 
- Для измерения задержки используйте **niping**. Это разработанное SAP средство, принципы работы которого описаны в примечаниях по поддержке SAP [#500235](https://launchpad.support.sap.com/#/notes/500235) и [#1100926](https://launchpad.support.sap.com/#/notes/1100926/E). Сосредоточьтесь на документированных командах SAP для измерений задержки. Мы не рекомендуем использовать **ping**, так как средство **ping** не работает с сетевыми путями, к которым применено ускорение работы в сети Azure.

По результатам этих измерений и с учетом доступности нужных номеров SKU виртуальных машин в разных зонах вам следует принять следующие решения:

- Определите оптимальные зоны для уровня СУБД.
- Исходя из различий сетевой задержки в пределах зоны и между зонами, нужно ли распределить активный прикладной уровень SAP на одну, две или все три зоны.
- Определите, нужно ли развертывать конфигурацию "активный — пассивный" или "активный — активный" с точки зрения приложения (см. ниже).

При принятии этих решений учитывайте также рекомендации компании SAP по сетевым задержкам, которые описаны в примечании SAP [#1100926](https://launchpad.support.sap.com/#/notes/1100926/E).

### <a name="be-aware-of"></a>Обратите внимание на следующее.

> [!IMPORTANT]
> Все измерения и принятые решения применимы только для той подписки Azure, которую вы использовали для этих измерений. Если вы будете использовать другую подписку Azure, повторите все измерения, так как сопоставление зон в зависимых от подписки перечислениях может существенно отличаться.


> [!IMPORTANT]
> Считается нормальным, что описанные выше измерения дадут разные результаты в каждом из регионов Azure, который поддерживает [зоны доступности](https://docs.microsoft.com/azure/availability-zones/az-overview). Даже если требования к сетевой задержке будут одинаковыми, для разных регионов Azure могут подходить разные стратегии развертывания из-за различий в сетевых задержках между зонами. Считается нормальным, что в некоторых регионах Azure сетевая задержка между тремя разными зонами будет очень разной. В то же время в других регионах сетевая задержка между тремя разными зонами будет относительно стабильной. Утверждение о том, что сетевая задержки между зонами **всегда** составляет от 1 до 2 мс, **неверно**. Не существует общих правил, характеризующих сетевую задержку между зонами доступности в регионах Azure.


## <a name="activeactive-deployment"></a>Развертывание архитектуры "активный — активный"
Такая архитектура развертывания называется "активный — активный", так как подразумевает развертывание активных экземпляров диалогов SAP в двух или трех зонах. Центральные службы SAP, использующие службу постановки в очередь для репликации, будут развертываться между двумя зонами. Это же справедливо и для уровня СУБД, который будет развертываться в тех же зонах, что и центральная служба SAP.

Эту конфигурацию есть смысл рассматривать, если вам удастся найти в нужном регионе две зоны доступности, сетевая задержка между которыми приемлема для используемой рабочей нагрузки и для синхронной репликации СУБД. Кроме того, разница между сетевыми задержками в пределах выбранной зоны и между разными зонами не должна быть слишком большой. Это второе требование связано с тем, что вам не нужны слишком большие различия во времени выполнения бизнес-процессов или пакетной обработки, которые запущены в одной зоне с сервером СУБД или в разных зонах. Небольшие колебания допустимы, но не системные различия.

Упрощенная схема развертывания "активный — активный" между двумя зонами может выглядеть примерно так:

![active_active_zone_deployment](./media/sap-ha-availability-zones/active_active_zones_deployment.png)

Для этой конфигурации следует принимать во внимание следующие соображения.

- Зоны доступности Azure следует воспринимать как домены сбоя и обновления для всех виртуальных машин, так как в зонах доступности Azure нельзя развернуть группы доступности.
- Подсистемы балансировки нагрузки Azure, которые вы используете для отказоустойчивых кластеров центральных служб SAP и для уровня СУБД, должны иметь [номер SKU уровня "Стандартный"](https://docs.microsoft.com/azure/load-balancer/load-balancer-standard-availability-zones). Подсистема балансировки нагрузки уровня "Базовый" не будет работать между зонами.
- Виртуальная сеть Azure и все подсети, развернутые для размещения системы SAP, распределяются по нескольким зонам. **Нет необходимости** выделять виртуальные сети для каждой зоны.
- Для всех развернутых виртуальных машин используйте [управляемые диски Azure](https://azure.microsoft.com/services/managed-disks/). Неуправляемые диски не поддерживаются для зональных развертываний.
- Хранилище Azure класса Premium или [хранилище SSD (ценовой категории "Ультра")](https://docs.microsoft.com/azure/virtual-machines/windows/disks-ultra-ssd) не поддерживают репликацию хранилища между зонами. Это означает, что приложение (СУБД или Центральные службы SAP) должно самостоятельно реплицировать важные данные.
- Это относится и к общей папке sapmnt, которая содержит общий диск (для Windows), общую папку CIFS (для Windows) или общую папку NFS (Linux). Вам нужна технология, которая позволяет реплицировать такой общий диск или общую папку в нескольких зонах. Сейчас поддерживаются следующие технологии:
    - Для Windows между зонами можно применить кластерное решение на основе SIOS Datakeeper, которое описано в статье [Кластеризация экземпляра SAP ASCS/SCS в отказоустойчивом кластере Windows с помощью общего диска кластера в Azure](https://docs.microsoft.com/azure/virtual-machines/workloads/sap/sap-high-availability-guide-wsfc-shared-disk).
    - Для SUSE Linux поддерживается общая папка NFS, созданная по инструкциям из статьи [Обеспечение высокого уровня доступности NFS на виртуальных машинах Azure в SUSE Linux Enterprise Server](https://docs.microsoft.com/azure/virtual-machines/workloads/sap/high-availability-guide-suse-nfs).
    - Сейчас решение на основе масштабируемых файловых служб (SOFS) Windows, которое описано в статье [Подготовка высокодоступной инфраструктуры Azure для SAP с помощью отказоустойчивого кластера Windows и файлового ресурса для экземпляров SAP ASCS/SCS](https://docs.microsoft.com/azure/virtual-machines/workloads/sap/sap-high-availability-infrastructure-wsfc-file-share), **не поддерживается для работы между зонами**.
- Третья зона используется для размещения устройства SBD, если вы создаете [кластер Pacemaker в SUSE Linux](https://docs.microsoft.com/azure/virtual-machines/workloads/sap/high-availability-guide-suse-pacemaker#create-azure-fence-agent-stonith-device) или дополнительные экземпляры приложения.
- Чтобы добиться стабильного времени выполнения для важных бизнес-транзакций и (или) заданий, вы можете направить конкретные пакетные задания или определенных пользователей к конкретным экземплярам приложений, которые находятся в одной зоне с активным экземпляром СУБД, используя группы серверов пакетной службы SAP, группы входа или группы RFC. Но в случае зональной отработки отказа вам придется вручную перемещать эти группы в экземпляры диалогов, размещенные в сохранивших работоспособность зонах. 
- Решите, нужно ли развертывать неактивные экземпляры диалога во всех зонах, чтобы немедленно получить прежние объемы ресурсов в случае выхода из строя той зоны, в которой вы развернули часть экземпляров приложения.


## <a name="activepassive-deployment"></a>Развертывание архитектуры "активный — пассивный"
Если вы не сможете найти сочетание зон с приемлемой разницей сетевых задержек внутри одной зоны и между зонами, попробуйте развернуть архитектуру "активный — пассивный" с точки зрения прикладного уровня SAP. Здесь вы определяете "активную" зону, в которой будет развернут весь прикладной уровень и будут выполняться активный экземпляр СУБД и активный экземпляр Центральных служб SAP. Такая конфигурация позволяет гарантировать, что различия во времени выполнения бизнес-транзакций и пакетных заданий не будут критически большими в зависимости от того, выполняется ли задание в одной зоне с активным экземпляром СУБД или в другой зоне.

Базовая схема такой архитектуры выглядит следующим образом.

![active_active_zone_deployment](./media/sap-ha-availability-zones/active_active_zones_deployment.png)

Для этой конфигурации следует принимать во внимание следующие соображения.

- Группы доступности невозможно развернуть в Зонах доступности Azure. В нашем примере это означает, что для прикладного уровня существует только один домен обновления и домен сбоя. Это связано с тем, что развертывание выполняется в одной зоне. Такая конфигурация незначительно хуже, чем эталонная архитектура с развертыванием прикладного уровня в группе доступности Azure.
- Применяя такую архитектуру, вам придется внимательно отслеживать состояние и стараться удерживать активные экземпляры службы СУБД и центральных служб SAP в той же зоне, где развернут прикладной уровень. При отработке отказа экземпляра центральной службы SAP или СУБД вам важно как можно раньше вручную выполнить восстановление размещения в ту зону, где развернут прикладной уровень SAP.
- Подсистемы балансировки нагрузки Azure, которые вы используете для отказоустойчивых кластеров центральных служб SAP и для уровня СУБД, должны иметь [номер SKU уровня "Стандартный"](https://docs.microsoft.com/azure/load-balancer/load-balancer-standard-availability-zones). Подсистема балансировки нагрузки уровня "Базовый" не будет работать между зонами.
- Виртуальная сеть Azure и все подсети, развернутые для размещения системы SAP, распределяются по нескольким зонам. **Нет необходимости** выделять виртуальные сети для каждой зоны.
- Для всех развернутых виртуальных машин необходимо использовать [управляемые диски Azure](https://azure.microsoft.com/services/managed-disks/). Неуправляемые диски не поддерживаются для зональных развертываний.
- Хранилище Azure класса Premium или [хранилище SSD (ценовой категории "Ультра")](https://docs.microsoft.com/azure/virtual-machines/windows/disks-ultra-ssd) не поддерживают репликацию хранилища между зонами. Это означает, что приложение (СУБД или Центральные службы SAP) должно самостоятельно реплицировать важные данные.
- Это относится и к общей папке sapmnt, которая содержит общий диск (для Windows), общую папку CIFS (для Windows) или общую папку NFS (Linux). Вам нужна технология, которая позволяет реплицировать такой общий диск или общую папку в нескольких зонах. Сейчас поддерживаются следующие технологии:
    - Для Windows между зонами можно применить кластерное решение на основе SIOS Datakeeper, которое описано в статье [Кластеризация экземпляра SAP ASCS/SCS в отказоустойчивом кластере Windows с помощью общего диска кластера в Azure](https://docs.microsoft.com/azure/virtual-machines/workloads/sap/sap-high-availability-guide-wsfc-shared-disk).
    - Для SUSE Linux поддерживается общая папка NFS, созданная по инструкциям из статьи [Обеспечение высокого уровня доступности NFS на виртуальных машинах Azure в SUSE Linux Enterprise Server](https://docs.microsoft.com/azure/virtual-machines/workloads/sap/high-availability-guide-suse-nfs).
    - Сейчас решение на основе масштабируемых файловых служб (SOFS) Windows, которое описано в статье [Подготовка высокодоступной инфраструктуры Azure для SAP с помощью отказоустойчивого кластера Windows и файлового ресурса для экземпляров SAP ASCS/SCS](https://docs.microsoft.com/azure/virtual-machines/workloads/sap/sap-high-availability-infrastructure-wsfc-file-share), **не поддерживается для работы между зонами**.
- Третья зона используется для размещения устройства SBD, если вы создаете [кластер Pacemaker в SUSE Linux](https://docs.microsoft.com/azure/virtual-machines/workloads/sap/high-availability-guide-suse-pacemaker#create-azure-fence-agent-stonith-device) или дополнительные экземпляры приложения.
- Разверните неактивные виртуальные машины в пассивной зоне (с точки зрения СУБД), чтобы иметь возможность запустить ресурсы приложения в случае сбоя зоны.
    - Вы не можете использовать [Azure Site Recovery](https://azure.microsoft.com/services/site-recovery/) для репликации активных виртуальных машин на неактивные виртуальные машины в другой зоне. Сейчас Azure Site Recovery не работает в такой конфигурации.
- Создайте средства автоматизации, которые позволят автоматически запускать прикладной уровень SAP во второй зоне в случае сбоя зоны.

## <a name="combined-high-availability-and-disaster-recovery-configuration"></a>Сочетание конфигураций высокого уровня доступности и аварийного восстановления
Несмотря на то, что корпорация Майкрософт не предоставляет сведений о географическом расстоянии между элементами инфраструктуры, на которых размещаются разные зоны доступности Azure в определенном регионе Azure, некоторые клиенты успешно применяют зоны для создания конфигураций, поддерживающих одновременно высокий уровень доступности и аварийное восстановление с теоретически нулевым значением RPO (**R**ecovery **P**oint **O**bjective — целевая точка восстановления). Это означает, что вы не потеряете зафиксированные в базе данных транзакции даже при необходимости аварийного восстановления. 

> [!NOTE]
> Мы рекомендуем применять такие конфигурации только в особых обстоятельствах. Например, если недопустимо перемещение данных за пределы региона Azure из-за требований безопасности и соответствия. 

На следующем изображении представлен пример такой конфигурации.

![combined_ha_dr_in_zones](./media/sap-ha-availability-zones/combined_ha_dr_in_zones.png)

Для этой конфигурации следует принимать во внимание следующие соображения.

- Вы вынуждены предполагать, что элементы инфраструктуры, на которых размещается зона доступности, далеко расположены друг от друга, или не имеете возможности выйти за пределы определенного региона Azure. Группы доступности невозможно развернуть в Зонах доступности Azure. В нашем примере это означает, что для прикладного уровня существует только один домен обновления и домен сбоя. Это связано с тем, что развертывание выполняется в одной зоне. Этот вариант незначительно хуже, чем эталонная архитектура с развертыванием прикладного уровня в группе доступности Azure.
- Применяя такую архитектуру, вам придется внимательно отслеживать состояние и стараться удерживать активные экземпляры службы СУБД и центральных служб SAP в той же зоне, где развернут прикладной уровень. При отработке отказа экземпляра центральной службы SAP или СУБД вам важно как можно раньше вручную выполнить восстановление размещения в ту зону, где развернут прикладной уровень SAP.
- У вас есть рабочие экземпляры приложения, предварительно установленные на виртуальных машинах, на которых выполняются активные экземпляры приложения для контроля качества.
- В случае зонального сбоя вам нужно завершить работу экземпляров приложения для контроля качества и вместо них запустить рабочие экземпляры. Имейте в виду, что в этом варианте нужно использовать для экземпляров приложения виртуальные имена.
- Подсистемы балансировки нагрузки Azure, которые вы используете для отказоустойчивых кластеров центральных служб SAP и для уровня СУБД, должны иметь [номер SKU уровня "Стандартный"](https://docs.microsoft.com/azure/load-balancer/load-balancer-standard-availability-zones). Подсистема балансировки нагрузки уровня "Базовый" не будет работать между зонами.
- Виртуальная сеть Azure и все подсети, развернутые для размещения системы SAP, распределяются по нескольким зонам. **Нет необходимости** выделять виртуальные сети для каждой зоны.
- Для всех развернутых виртуальных машин необходимо использовать [управляемые диски Azure](https://azure.microsoft.com/services/managed-disks/). Неуправляемые диски не поддерживаются для зональных развертываний.
- Хранилище Azure класса Premium или [хранилище SSD (ценовой категории "Ультра")](https://docs.microsoft.com/azure/virtual-machines/windows/disks-ultra-ssd) не поддерживают репликацию хранилища между зонами. Это означает, что приложение (СУБД или Центральные службы SAP) должно самостоятельно реплицировать важные данные.
- Это относится и к общей папке sapmnt, которая содержит общий диск (для Windows), общую папку CIFS (для Windows) или общую папку NFS (Linux). Вам нужна технология, которая позволяет реплицировать такой общий диск или общую папку в нескольких зонах. Сейчас поддерживаются следующие технологии:
    - Для Windows между зонами можно применить кластерное решение на основе SIOS Datakeeper, которое описано в статье [Кластеризация экземпляра SAP ASCS/SCS в отказоустойчивом кластере Windows с помощью общего диска кластера в Azure](https://docs.microsoft.com/azure/virtual-machines/workloads/sap/sap-high-availability-guide-wsfc-shared-disk).
    - Для SUSE Linux поддерживается общая папка NFS, созданная по инструкциям из статьи [Обеспечение высокого уровня доступности NFS на виртуальных машинах Azure в SUSE Linux Enterprise Server](https://docs.microsoft.com/azure/virtual-machines/workloads/sap/high-availability-guide-suse-nfs).
    - Сейчас решение на основе масштабируемых файловых служб (SOFS) Windows, которое описано в статье [Подготовка высокодоступной инфраструктуры Azure для SAP с помощью отказоустойчивого кластера Windows и файлового ресурса для экземпляров SAP ASCS/SCS](https://docs.microsoft.com/azure/virtual-machines/workloads/sap/sap-high-availability-infrastructure-wsfc-file-share), **не поддерживается для работы между зонами**.
- Третья зона используется для размещения устройства SBD, если вы создаете [кластер Pacemaker в SUSE Linux](https://docs.microsoft.com/azure/virtual-machines/workloads/sap/high-availability-guide-suse-pacemaker#create-azure-fence-agent-stonith-device) или дополнительные экземпляры приложения.





## <a name="next-steps"></a>Дальнейшие действия
Изучите дальнейшие действия по развертыванию в нескольких зонах доступности Azure.

- [Кластеризация экземпляра SAP ASCS/SCS в отказоустойчивом кластере Windows с помощью общего диска кластера в Azure](https://docs.microsoft.com/azure/virtual-machines/workloads/sap/sap-high-availability-guide-wsfc-shared-disk).
- [Подготовка высокодоступной инфраструктуры Azure для SAP с помощью отказоустойчивого кластера Windows и файлового ресурса для экземпляров SAP ASCS/SCS](https://docs.microsoft.com/azure/virtual-machines/workloads/sap/sap-high-availability-infrastructure-wsfc-file-share).






