---
title: Использование хранилища Azure Data Lake Storage Gen2 (предварительная версия) с кластерами Azure HDInsight
description: Узнайте, как запрашивать данные из хранилища Azure Data Lake Storage Gen2 (предварительная версия) и сохранять результаты анализа.
author: jamesbak
ms.component: data-lake-storage-gen2
ms.service: storage
ms.topic: article
ms.date: 06/27/2018
ms.author: jamesbak
ms.openlocfilehash: 3869d83ada1cbe0b234694b6acae88b6f68fc2dd
ms.sourcegitcommit: e2348a7a40dc352677ae0d7e4096540b47704374
ms.translationtype: HT
ms.contentlocale: ru-RU
ms.lasthandoff: 09/05/2018
ms.locfileid: "43782283"
---
# <a name="use-azure-data-lake-storage-gen2-preview-with-azure-hdinsight-clusters"></a>Использование хранилища Azure Data Lake Storage Gen2 (предварительная версия) с кластерами Azure HDInsight

Для анализа данных в кластере HDInsight вы можете хранить данные либо в службе хранилища Azure, либо в Azure Data Lake Storage Gen1, либо в Azure Data Lake Storage Gen2 (предварительная версия). Все варианты хранилищ позволяют безопасно и без потери пользовательских данных удалять используемые для расчетов кластеры HDInsight.

В Hadoop поддерживается концепция файловой системы по умолчанию. Файловая система по умолчанию подразумевает использование центра сертификации и схемы по умолчанию. Она также может использоваться для разрешения относительных путей. При создании кластера HDInsight в качестве файловой системы по умолчанию можно указать контейнер больших двоичных объектов в службе хранилища Azure или в Azure Data Lake Storage. При использовании HDInsight 3.5 в качестве файловой системы по умолчанию можно выбрать либо службу хранилища Azure, либо Azure Data Lake Storage за несколькими исключениями.

Из этой статьи вы узнаете, как хранилище Azure Data Lake Storage Gen2 работает с кластерами HDInsight. Дополнительные сведения о создании кластера HDInsight см. в [кратком руководстве по настройке кластеров в HDInsight](quickstart-create-connect-hdi-cluster.md).

Служба хранилища Azure — это надежное, универсальное решение, которое полностью интегрируется с HDInsight. HDInsight может использовать хранилище Azure Data Lake Storage в качестве файловой системы по умолчанию для кластера. С помощью интерфейса распределенной файловой системы Hadoop (HDFS) все компоненты HDInsight могут напрямую взаимодействовать с файлами в хранилище Azure Data Lake Storage.

Применяемую по умолчанию файловую систему не рекомендуется использовать для хранения бизнес-данных. Чтобы сократить затраты на хранение, файловую систему по умолчанию рекомендуется удалять после каждого использования. Обратите внимание, что контейнер по умолчанию содержит журнал приложения и системный журнал. Обязательно извлеките эти журналы перед удалением контейнера.

Совместное использование одной файловой системы для нескольких кластеров не поддерживается.

## <a name="hdinsight-storage-architecture"></a>Архитектура хранилища HDInsight

Следующая схема является абстрактным представлением архитектуры хранилища HDInsight с использованием службы хранилища Azure.

![Кластеры Hadoop используют API HDFS для доступа к структурированным и неструктурированным данным и их хранения в хранилище BLOB-объектов.](./media/use-hdi-cluster/HDI.ABFS.Arch.png "Архитектура хранилища HDInsight")

HDInsight предоставляет доступ к распределенной файловой системе, которая локально присоединена к вычислительным узлам. Доступ к этой файловой системе может осуществляться с использованием полного универсального кода ресурса (URI), например:

    hdfs://<NAME_NODE_HOST>/<PATH>

Кроме того, HDInsight позволяет получить доступ к данным, содержащимся в хранилище Azure Data Lake Storage. Синтаксис:

    abfs[s]://<FILE_SYSTEM_NAME>@<ACCOUNT_NAME>.dfs.core.windows.net/<path>

Ниже приведены некоторые рекомендации для использования учетной записи хранения Azure с кластерами HDInsight.

* **Файлы в учетных записях хранения, которые подключены к кластеру**, в ходе создания имеют имя учетной записи и ключ, связанные с кластером. Эта конфигурация дает вам полный доступ к файлам в файловой системе.

* **Общедоступные файлы в учетных записях хранения, которые НЕ подключены к кластеру**. Вам предоставлен доступ только для чтения к файлам в файловой системе.
  
  > [!NOTE]
  > Общедоступные файловые системы позволяют получить список всех доступных в них файлов и доступ к метаданным. Общедоступные файловые системы позволяют получить доступ к файлам только при условии, что вам известен точный URL-адрес. Дополнительные сведения см. в разделе об [ограничении доступа к контейнерам и большим двоичным объектам](http://msdn.microsoft.com/library/windowsazure/dd179354.aspx) (правила для контейнеров и больших двоичных объектов работают одинаково для файлов и файловой системы).
 
* **Частные файловые системы в учетных записях хранения, НЕ подключенные к кластеру**. Вы не можете получить доступ к файлам в файловой системе, пока не определите учетную запись хранения при отправке заданий WebHCat. Причины этого ограничения описаны ниже в этой статье.

Определенные на этапе создания учетные записи хранения и их ключи хранятся в файле *%HADOOP_HOME%/conf/core-site.xml* на узлах кластера. По умолчанию HDInsight будет использовать учетные записи хранения, определенные в файле *core-site.xml*. Этот параметр можно изменить с помощью [Ambari](../../hdinsight/hdinsight-hadoop-manage-ambari.md).

Несколько заданий WebHCat, включая Hive, MapReduce, потоковую передачу Hadoop и Pig, могут переносить описание учетных записей хранения и метаданные вместе с ними. (В настоящее время этот подход работает для Pig с учетными записями хранения, но не с метаданными.) Дополнительные сведения см. в разделе [Использование кластера HDInsight с дополнительными учетными записями хранения и метахранилищами](http://social.technet.microsoft.com/wiki/contents/articles/23256.using-an-hdinsight-cluster-with-alternate-storage-accounts-and-metastores.aspx).

## <a id="benefits"></a>Преимущества службы хранилища Azure

Предполагаемые рабочие затраты из-за отсутствия совмещенных вычислительных ресурсов и ресурсов хранения снижаются за счет того, что создание вычислительных кластеров происходит в непосредственной близости от ресурсов учетных записей хранения в регионе Azure, в котором высокоскоростная сеть обеспечивает вычислительным узлам эффективный доступ к данным в службе хранилища Azure.

Ниже перечислены некоторые преимущества, связанные с хранением данных в службе хранилища Azure (вместо HDFS).

* **Повторное использование данных и общий доступ к данным.** Данные в файловой системе HDFS расположены внутри вычислительного кластера. Только приложения, имеющие доступ к вычислительному кластеру, могут использовать данные через API HDFS. Доступ к данным в службе хранилища Azure может осуществляться через интерфейсы API HDFS или через [интерфейсы REST API хранилища BLOB-объектов][blob-storage-restAPI]. Таким образом, для создания и использования данных можно применять больший набор приложений (включая другие кластеры HDInsight) и средств.

* **Архивация данных.** Хранение данных в службе хранилища Azure позволяет безопасно (без потери пользовательских данных) удалять используемые для расчетов кластеры HDInsight.

* **Затраты на хранение данных.** Хранение данных в собственной файловой системе DFS в долгосрочной перспективе является более затратным, чем хранение данных в службе хранилища Azure, так как стоимость вычислительного кластера превышает стоимость службы хранилища Azure. Кроме того, поскольку данные не требуется повторно загружать при создании каждого вычислительного кластера, вы экономите также на загрузке данных.

* **Гибкое масштабирование.** Хотя HDFS и представляет собой масштабируемую файловую систему, масштаб определяется количеством узлов, создаваемых для кластера. Изменение масштаба может оказаться более сложным процессом, чем использование гибких возможностей масштабирования службы хранилища Azure, которые вы получаете автоматически.

* **Репликация.** Доступна функция георепликации данных службы хранилища Azure. Хотя эта функция обеспечивает возможность географического восстановления и избыточность данных, поддержка отработки отказа в расположение для георепликации заметно сказывается на производительности, что может привести к дополнительным затратам. Поэтому мы рекомендуем взвешенно подходить к использованию георепликации, применяя ее, только когда стоимость данных окупает дополнительные затраты.

* **Управление жизненным циклом данных.** Все данные в файловой системе имеют свой жизненный цикл. Сначала данные являются очень ценными и часто используемыми. Затем их ценность падает, а вслед за этим — и необходимость в частом доступе. В конечном итоге такие данные требуют архивации или удаления. Служба хранилища Azure обеспечивает политики многоуровневого хранения данных и управления жизненным циклом, которые распределяют данные по уровням в соответствии с этапом их жизненного цикла.

Определенные задания и пакеты MapReduce могут создавать промежуточные результаты, которые нет нужды хранить в службе хранилища Azure. В таком случае можно выбрать хранение данных в локальной системе HDFS. Фактически, HDInsight использует собственную реализацию HDFS (или DFS) для некоторых таких промежуточных результатов в заданиях Hive и других процессах.

> [!NOTE]
> Большинство команд HDFS (например, `ls`, `copyFromLocal` и `mkdir`) по-прежнему работают правильно. В службе хранилища Azure будет отличаться поведение только тех команд, которые относятся к DFS, например `fschk` и `dfsadmin`.

## <a name="create-an-data-lake-storage-file-system"></a>Создание файловой системы хранилища Data Lake

Чтобы использовать файловую систему, сначала создайте [учетную запись службы хранилища Azure][azure-storage-create]. В рамках этого процесса укажите регион Azure, в котором создается учетная запись хранения. Кластер и учетная запись хранения должны размещаться в одном регионе. База данных SQL Server метахранилища Hive и база данных SQL Server метахранилища Oozie также должны располагаться в одном регионе.

Где бы ни находился созданный большой двоичный объект, он принадлежит файловой системе в вашей учетной записи хранения Azure Data Lake Storage. 

Стандартная файловая система Data Lake Storage хранит сведения о кластере, включая журналы и историю заданий. Не используйте стандартную файловую систему хранения хранилища Data Lake с несколькими кластерами HDInsight. Это может привести к искажению истории заданий. С разными кластерами рекомендуется использовать разные файловые системы, размещая общие данные в связанной учетной записи хранения, которая указывается при развертывании всех соответствующих кластеров. Использовать учетную запись хранения по умолчанию не рекомендуется. Дополнительные сведения о настройке связанных учетных записей хранения см. в статье [Создание кластеров HDInsight][hdinsight-creation]. Тем не менее вы можете повторно использовать файловую систему хранилища по умолчанию после удаления исходного кластера HDInsight. Для кластеров HBase можно сохранить все данные и схемы таблицы HBase, создав кластер HBase с помощью контейнера больших двоичных объектов по умолчанию, который используется удаленным кластером HBase.

[!INCLUDE [secure-transfer-enabled-storage-account](../../../includes/hdinsight-secure-transfer.md)]

### <a name="use-the-azure-portal"></a>Использование портала Azure

При создании кластера HDInsight с помощью портала можно указать (как показано на снимке экрана ниже) сведения об учетной записи хранения. Вы также можете указать, требуется ли дополнительная учетная запись хранения, связанная с кластером, и если требуется, то выберите один из доступных вариантов хранения для дополнительного хранилища.

![источник данных для создания hadoop в HDInsight](./media/use-hdi-cluster/create-storage-account.png)

> [!WARNING]
> Использование дополнительной учетной записи хранения, расположение которой отличается от расположения кластера HDInsight, не поддерживается.

### <a name="use-azure-powershell"></a>Использование Azure PowerShell

Если у вас [установлен и настроен модуль Azure PowerShell][powershell-install], вы можете создать учетную запись хранения и контейнер, выполнив следующий код в командной строке Azure PowerShell:

[!INCLUDE [upgrade-powershell](../../../includes/hdinsight-use-latest-powershell.md)]

    $SubscriptionID = "<Your Azure Subscription ID>"
    $ResourceGroupName = "<New Azure Resource Group Name>"
    $Location = "WEST US 2"

    $StorageAccountName = "<New Azure Storage Account Name>"
    $containerName = "<New Azure Blob Container Name>"

    Connect-AzureRmAccount
    Select-AzureRmSubscription -SubscriptionId $SubscriptionID

    # Create resource group
    New-AzureRmResourceGroup -name $ResourceGroupName -Location $Location

    # Create default storage account
    New-AzureRmStorageAccount -ResourceGroupName $ResourceGroupName `
      -Name StorageAccountName `
      -Location $Location `
      -SkuName Standard_LRS `
      -Kind StorageV2 
      -HierarchialNamespace $True

    # Create default blob containers
    $storageAccountKey = (Get-AzureRmStorageAccountKey -ResourceGroupName $resourceGroupName -StorageAccountName $StorageAccountName)[0].Value
    $destContext = New-AzureStorageContext -StorageAccountName $storageAccountName -StorageAccountKey $storageAccountKey  
    New-AzureStorageContainer -Name $containerName -Context $destContext

> [!NOTE]
> Создание контейнера является синонимом создания файловой системы в Azure Data Lake Storage.

### <a name="use-azure-cli"></a>Использование интерфейса командной строки Azure

[!INCLUDE [use-latest-version](../../../includes/hdinsight-use-latest-cli.md)]

Если у вас уже [установлен и настроен интерфейс командной строки Azure CLI](../../cli-install-nodejs.md), можно использовать следующую команду для учетной записи хранения и контейнера.

```bash
az storage account create \
    --name <STORAGE_ACCOUNT_NAME> \
    --resource-group <RESOURCE_GROUP_NAME> \
    --location westus2 \
    --sku Standard_LRS \
    --kind StorageV2 \
    --Enable-hierarchical-namespace true
```

> [!NOTE]
> На этапе общедоступной предварительной версии Data Lake Storage Gen2 поддерживается только `--sku Standard_LRS`.

Вам будет предложено указать географический регион, в котором будет создана учетная запись хранения. Создайте учетную запись хранения в том же регионе, в котором планируется создание кластера HDInsight.

После создания учетной записи хранения используйте следующую команду, чтобы получить ключи учетной записи хранения:

    azure storage account keys list <STORAGE_ACCOUNT_NAME>

Чтобы создать контейнер, используйте следующую команду:

    azure storage container create <CONTAINER_NAME> --account-name <STORAGE_ACCOUNT_NAME> --account-key <STORAGE_ACCOUNT_KEY>

> [!NOTE]
> Создание контейнера является синонимом создания файловой системы в Azure Data Lake Storage.

## <a name="address-files-in-azure-storage"></a>Обращение к файлам в службе хранилища Azure

Схема URI для доступа к файлам в службе хранилища Azure из HDInsight:

    abfs[s]://<FILE_SYSTEM_NAME>@<ACCOUNT_NAME>.dfs.core.windows.net/<PATH>

Эта схема URI предоставляет как незашифрованный доступ с префиксом *abfs:*, так и доступ с использованием SSL-шифрования с *abfss*. Мы рекомендуем использовать *abfss* всегда, когда это возможно, даже при обращении к данным, которые хранятся в том же регионе Azure.

* &lt;FILE_SYSTEM_NAME&gt; идентифицирует путь к файловой системе Azure Data Lake Storage.
* &lt;ACCOUNT_NAME&gt; определяет имя учетной записи службы хранилища Azure. Обязательно использовать полное доменное имя (FQDN).

    Если значения для &lt;FILE_SYSTEM_NAME&gt; или &lt;ACCOUNT_NAME&gt; не указаны, используется файловая система по умолчанию. Для файлов в файловой системе по умолчанию можно использовать относительный или абсолютный путь. Например, для ссылки на файл *hadoop-mapreduce-examples.jar*, который поставляется с кластерами HDInsight, можно использовать один из следующих вариантов:
    
        abfs://myfilesystempath@myaccount.dfs.core.windows.net/example/jars/hadoop-mapreduce-examples.jar
        abfs:///example/jars/hadoop-mapreduce-examples.jar
        /example/jars/hadoop-mapreduce-examples.jar

> [!NOTE]
> В кластерах HDInsight версий 2.1 и 1.6 файл называется *hadoop-examples.jar*.

* &lt;PATH&gt; — это имя пути к файлу или каталогу HDFS.

> [!NOTE]
> При работе с файлами вне HDInsight большинство программ не распознают формат ABFS и вместо этого ожидают формат базового пути, например `example/jars/hadoop-mapreduce-examples.jar`.
 
## <a name="use-additional-storage-accounts"></a>Использование дополнительных учетных записей хранения

При создании кластера HDInsight укажите учетную запись хранения Azure, которую необходимо с ним связать. Помимо этой учетной записи хранения в процессе создания или после создания кластера можно добавить дополнительные учетные записи хранения из той же или других подписок Azure. Инструкции по добавлению дополнительных учетных записей хранения см. в статье [Создание кластеров Hadoop в HDInsight](../../hdinsight/hdinsight-hadoop-provision-linux-clusters.md).

> [!WARNING]
> Использование дополнительной учетной записи хранения, расположение которой отличается от расположения кластера HDInsight, не поддерживается.

## <a name="next-steps"></a>Дополнительная информация

Из этой статьи вы узнали, как использовать HDFS-совместимую службу хранилища Azure с HDInsight. Это позволяет создавать масштабируемые, долгосрочные решения для получения данных архивирования, а также использовать HDInsight для разблокирования информации внутри хранимых структурированных и неструктурированных данных.

Дополнительные сведения можно найти в разделе 

* [Сведения о драйвере файловой системы ABFS Hadoop для Azure Data Lake Storage Gen2](abfs-driver.md)
* [Общие сведения о хранилище Azure Data Lake Storage Gen2 (предварительная версия)](introduction.md)
* [Краткое руководство по настройке кластеров в HDInsight](quickstart-create-connect-hdi-cluster.md)
* [Сведения о приеме данных в Azure Data Lake Storage с использованием Distcp](use-distcp.md)

[powershell-install]: /powershell/azureps-cmdlets-docs
[hdinsight-creation]: ../../hdinsight/hdinsight-hadoop-provision-linux-clusters.md

[blob-storage-restAPI]: http://msdn.microsoft.com/library/windowsazure/dd135733.aspx
[azure-storage-create]: ../common/storage-create-storage-account.md

[img-hdi-powershell-blobcommands]: ./media/use-hdi-cluster/HDI.PowerShell.BlobCommands.png
