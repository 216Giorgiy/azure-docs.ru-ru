<properties 
	pageTitle="Введение в Stream Analytics | Azure" 
	description="Понимание анализа потоков Azure" 
	services="stream-analytics" 
	documentationCenter="" 
	authors="mumian" 
	manager="paulettm" 
	editor="cgronlun"/>

<tags 
	ms.service="stream-analytics" 
	ms.devlang="na" 
	ms.topic="article" 
	ms.tgt_pltfrm="na" 
	ms.workload="data-services" 
	ms.date="2/10/2015" 
	ms.author="jgao"/>


# Введение в Azure Stream Analytics

Azure Stream Analytics является полностью управляемой службой, обеспечивающей низкую задержку и высокий уровень доступности, масштабируемую обработку сложных событий посредством потоковой передачи данных в облако.

# Содержание

+ [Обзор и причины создания](#motivation) 
+ [Ключевые возможности](#capabilities)
+ [Коммерческие предпосылки выбора Azure Stream Analytics](#decision)
+ [Сценарии и варианты использования](#scenarios)
+ [Дальнейшие действия](#neststeps)


##<a name="motivation"></a>Обзор и причины создания

Сегодня по сети передается огромное количество данных на высоких скоростях.  Организации, которые могут обрабатывать и реагировать на эти данные в режиме реального времени, могут существенно повысить свою эффективность и дифференцировать себя на рынке.  Сценарии анализа потока в режиме реального времени можно найти во всех отраслях: персонализированный торговый анализ в режиме реального времени и сигналы, предлагаемые компаниями, предоставляющими финансовые услуги, выявление мошенничества в режиме реального времени, службы защиты данных и личной информации, надежный сбор и анализ данных, поступающих от датчиков и приводов, вмонтированных в физические объекты (IoT), потоковая аналитика переходов на сайтах и CRM-приложения, отправляющие сигналы при падении уровня обслуживания клиента в течение определенного промежутка времени.  Фирмы ищут наиболее гибкий, надежный и экономичный способ осуществления такого потокового анализа данных для событий в режиме реального времени для успешной деятельности в современном высококонкурентном мире.  

Создание систем потоковой обработки является сложной задачей.  Такие потоковые операции, как корреляция и группировка, должны не только эффективно внедряться, но также должны быть масштабируемыми и отказоустойчивыми.  Для этого требуется выполнить дополнительные задачи оперативного характера, включая развертывание, отладку и наблюдение.  Затраты, связанные с построением и обслуживанием такого решения быстро растут.  Более крупные предприятия отказались платить такую большую цену, создавая решения под заказ, в то время как небольшие компании часто не могут воспользоваться такой возможностью из-за высокого барьера доступа и чрезмерно высоких затрат, связанных с этим.  Azure Stream Analytic позволяет преодолеть эти трудности.

Azure Stream Analytics - это услуга потоковой обработки в режиме реального времени под полным управлением, которая размещена на Microsoft Azure и обеспечивает высокую надежность, малую задержку и масштабируемую обработку сложных событий потоковых данных.  Azure Stream Analytics позволяет разработчикам легко объединять потоки данных с историческими записями или ссылочными данными для легкого и быстрого получения бизнес-информации.  

При помощи нескольких щелчков мышью в Azure Portal клиенты могут создавать потоковые задания с использованием языка похожего на SQL для того, чтобы задавать преобразования и вести мониторинг масштаба/скорости их общего потокового конвейера. Службу можно легко масштабировать, начиная от нескольких килобайт и заканчивая гигабайтом или несколькими событиями, обрабатываемых в секунду.  Большинство других потоковых решений, которые доступны сегодня, требуют от клиентов написания сложного пользовательского кода, в то время как, используя Azure Stream Analytics, клиенту достаточно написать простой, декларативный, знакомый SQL-код.

Azure Stream Analytics предлагает целый ряд операторов от простых фильтров до сложных корреляций.  Определение таких операций, обрабатываемых методом окна, на основе времени, как агрегаты данных, реализуемые посредством окна, или коррелирующие множественные потоки для выявления таких закономерностей, как последовательности, или даже для сравнения текущих условий с историческими значениями и моделями, можно выполнить в считанные минуты при помощи простых операторов языка запроса потоковой аналитики, похожих на SQL.  Указание конвейера потоковой передачи сводится к настройке его входящих и исходящих данных, а также предоставлении SQL-подобного запроса, описывающего необходимые преобразования.  Хотя этого достаточно для большинства простых случаев, более масштабные и более сложные сценарии можно задать при помощи настройки потоковой аналитики.  Пользователи могут определять, какой объем вычислительной мощности необходимо выделить для каждого этапа конвейера для достижения нужной пиковой пропускной способности.

В настоящее время Azure Stream Analytics подключается непосредственно к Azure Event Hub для получения потока и к большим двоичным объектам Azure - для исторических данных.  Используя целый ряд входных и выходных интерфейсов Azure Event Hub, легко интегрировать Azure Stream Analytics с другими источниками данных и обработчиками без потери потоковых вычислений.  Данные могут записываться из Stream Analytics в Azure Storage, где их позже можно снова обработать как последовательность событий или использовать в других формах пакетной аналитики с помощью HDInsight.  Azure Stream Analytics основана на многолетнем опыте исследовательской работы Microsoft по разработке высокоточных потоковых обработчиков данных, критичных ко времени их обработки, а также интеграции языков для их интуитивного определения.  Azure Stream Analytics создана с использованием опыта сообщества открытого исходного кода Hadoop, YARN и REEF в области масштабируемой обработки.


##<a name="capabilities"></a>Ключевые возможности

###Простота использования
Stream Analytics поддерживает простую декларативную модель запроса для описания преобразований.  Для оптимизации работы мы в качестве DSL-языка выбрали SQL. Таким образом мы оградили клиентов от чрезмерных технических сложностей, лежащих в основе нашей системы потоковой передачи.  С помощью языка запросов Stream Analytics вы можете быстро и легко реализовать временные функции, включая соединения с привязкой ко времени, агрегаты данных на основе окон, временные фильтры, а также другие операции общего характера, например соединения, агрегаты данных, прогнозирования, фильтры и т. д.

Хотя мы и расширили семантику SQL несколькими способами, знакомыми пользователям SQL, мы остаемся в синтаксических границах стандарта SQL, чтобы облегчить реализацию и использование инструментов. Дополнительные сведения о нашем языке запросов см. в разделе "Ресурсы Azure Stream Analytics".

###Масштабируемость
Stream Analytics способна обрабатывать события при высокой пропускной способности, до 1 Гб/с. Интеграция с Azure Event Hubs позволяет решению принимать миллионы событий в секунду, которые поступают из подключенных устройств, потоков с переходами, файлов журналов. И это только незначительная часть большого количества возможностей. Для достижения этого мы задействовали возможности секционирования Event Hubs, которые могут дать 1 МБ/с на одну секцию. Stream Analytics предоставляет поддержку секционирования при обработке этих принятых событий по горизонтальной и вертикальной оси.  Пользователь может разбить вычислительную обработку на целый ряд логических шагов при определении запроса, каждый из которых может дополнительно быть разделен на элементы выполнения с параллельными данными.  Со временем Stream Analytics будет автоматически масштабироваться в зависимости от скорости получения событий, сложности обработки и ожидаемых задержек для того, чтобы дать возможность пользователям настраивать свою рабочую нагрузку соответствующим образом.  Для получения дополнительной информации по реализации масштабируемости см. ссылки в разделе "Ресурсы".  

###Надежное, воспроизводимое и быстрое восстановление
Stream Analytics не гарантирует отсутствия потерь данных, но обеспечивает непрерывность бизнес-процессов при наличии сбоев узлов благодаря встроенным функциям восстановления и профилактического копирования памяти в контрольных точках.  Это реализовано с помощью такой архитектуры модели Stream Analytics, у которой есть точка привязки к клиенту.  Служба спроектирована таким образом, чтобы сохранять состояние оптимизации возобновления после сбоя узла, повторных вычислений, а также для кэширования исходящих данных с целью эффективного учета сбоев на последующих участках.  

Благодаря функции внутренней поддержки состояния служба может обеспечивать воспроизводимость результатов, если предусмотрена возможность архивирования событий и многократного применения обработки в будущем с получением одинаковых результатов.  Эта функция позволяет клиентам вернуться назад во времени и исследовать вычисления по сценариям наподобие анализа основных причин и анализа гипотетических вариантов.  В сочетании эти функции обеспечивают быстрое восстановление после сбоев узлов обработки, проводя быструю повторную обработку потерянного состояния при помощи возврата во времени. 

###Малые задержки
В настоящее время Stream Analytics оптимизирована под сквозные наблюдаемые задержки порядка менее секунды.  Это позволяет системе осуществлять непрерывную обработку при высокой пропускной способности. Модель взаимодействия - адаптивная модель с пакетной обработкой данных, основанная на запросах, которая работает на основе настроенного времени ожидания и предельных размеров.  Таким образом, события и другие записи разделяются на пакеты до достижении пределов.  Поэтому даже при высокой пропускной способности система может обеспечить малую задержку.

###Ссылочные данные
Stream Analytics предоставляет пользователям возможность указывать и использовать ссылочные данные.  Это могут быть архивные данные или с меньшей вариативностью по времени.  Система упрощает использование ссылочных данных, которые рассматриваются как любой другой входящий поток событий для объединения с другими потоками событий, принимаемыми в режиме реального времени для выполнения преобразований.  Дополнительные сведения по построению и использованию ссылочных данных см. в разделе "Ресурсы".



##<a name="decision"></a> Коммерческие предпосылки выбора Azure Stream Analytics

###Стоимость
Служба Stream Analytics оптимизирована таким образом, чтобы предоставить пользователям очень низкую стоимость пуска в эксплуатацию и поддержки работоспособности аналитических решений в режиме реального времени.  Служба построена таким образом, чтобы вы могли оплачивать ее исходя из интенсивности ее использования вами.  Интенсивность использования определяется на основе объема обработанных событий и объема вычислительной мощности, провизионированной в кластере для обработки соответствующих потоковых задач.  

###Настройка и пуск за считанные минуты
Благодаря Stream Analytics вы получаете решение для обработки событий с высокой масштабируемостью в режиме реального времени без необходимости какого-либо оборудования или других первоначальных расходов, а также без затрат времени на установку или настройку.  Обо всем этом для вас позаботился Azure.  Вы можете настроить и запустить решение в считанные минуты, просто подписавшись на службу, воспользовавшись порталом Azure.  Понятный пользовательский интерфейс на портале при помощи краткого пошагового руководства позволит вам настроить и протестировать ваш источник ввода данных, хранилище для выводимых данных, а также редактор простых запросов благодаря функциям автозаполнения и рекомендациям.  

###Обеспечивает возможность быстрой разработки
Stream Analytics позволяет уменьшить нестыковки и понизить сложность разработки аналитических функций для масштабирования распределенных систем.  Разработчики просто описывают нужное преобразование на языке запросов на основе SQL, а система автоматически распределяет рабочую нагрузку с учетом масштабирования, производительности и надежности, исключая необходимость процедурного программирования, которое необходимо в большинстве решений потоковой обработки.  Благодаря своим встроенным возможностям, доступным сразу же после приобретения, и дружественному порталу Stream Analytics предоставляет разработчикам на языках высокого уровня возможность легкой обработки в режиме реального времени, при которой можно не беспокоиться о таких аспектах, как обслуживание инфраструктуры, текущее обслуживание и масштабирование. 

##<a name="scenarios"></a>Сценарии и варианты использования

###Анализ в режиме реального времени Интернета вещей (IoT)
По мере того как устройства становятся все более интеллектуальными и все большее количество устройств поддерживает коммуникационные возможности, перспективы возможностей обработки данных, формируемых и собираемых с этих устройств, расширяются как в области коммерции, так и в области потребительского рынка. Ожидается, что при таком большом количестве данных можно быстро объединять и обрабатывать данные, получая более подробные сведения об окружающей нас среде и об устройствах, которыми мы постоянно пользуемся. Традиционный сценарий IoT можно описать на примере торгового автомата. Торговые автоматы регулярно отправляют такие данные, как наличие продукта, состояние, температура и т. д., на полевой шлюз (если торговый автомат не поддерживает IP-протокол) или на облачный шлюз (при поддержке IP-протокола) для передачи данных в систему. Входной поток данных обрабатывается и преобразуется, чтобы полученные в результате вычислений выходные данные могли сразу передаваться через шлюзы на устройство для выполнения соответствующих действий.  Например, при перегреве машины устройству может потребоваться перезагрузка или автоматическое выполнение обновления встроенного ПО без вмешательства человека.  Обработанные выходные данные могут также активировать и выдачу других оповещений и уведомлений техническому специалисту, причем можно реализовать автоматическое планирование на основе событий. 

По мере того, как все большее количество данных собирается и обрабатывается, для разработки и обучения на основе шаблонов, встречающихся в системе, может использоваться и машинное обучение. Например, возможность спрогнозировать тот момент, когда может понадобиться обслуживание машин на основе потоков событий в режиме реального времени, поступающих в систему или запланировать профилактическое обслуживание в графике технического специалиста, когда что-то может пойти не так.

Такую схему отправки информации устройством в систему обработки и потенциальное принятие мер на основе результатов, обработанных в режиме реального времени, можно часто наблюдать в случаях использования IoT.  Другие подобные сценарии включают подключение автомобилей, аналитику потоков и переходов, техническое управление и т. д. Чтобы оптимизировать эту цепь обратной связи с целью получения малых задержек и высокой пропускной способности, Stream Analytics может использоваться для приема данных из концентратора событий Azure с целью обработки данных и их передачи обратно на концентратор событий для соответствующего подключенного устройства с целью выполнения соответствующего действия.  


![Azure Stream Analytics real time analysis for the Internet of Things (IoT)][img.stream.analytics.scenario1]


###Анализ телеметрии и журнала с помощью панели мониторинга
По мере того как количество устройств, машин и приложений растет, распространенным вариантом корпоративного использования в деловой сфере является необходимость мониторинга и реагирования на изменяющиеся потребности бизнеса за счет формирования развитой аналитики в квазиреальном режиме времени. Канонический сценарий анализа телеметрии и архивных данных можно описать на примере онлайн-службы или приложения. В то же время, такая модель поведения, как правило, характерна для тех компаний, которые собирают и отчитываются в отношении телеметрии приложения или устройства. Приложение или служба регулярно собирают данные об исправности.  Собираются данные, представляющие текущее состояние приложения или инфраструктуры на момент времени, журналы запросов пользователей и другие данные, представляющие собой действия или манипуляции, осуществляемые в приложении. Архивные данные сохраняются в большом двоичном объекте или других типах хранилищ данных для дальнейшей обработки. По последней тенденции, направленной на отображение данных в режиме реального времени, помимо сохранения данных в большом двоичном объекте или другом типе хранилища результатов анализа архивных данных, клиенты стремятся обработать и преобразовать поток входящих данных непосредственно таким образом, чтобы его можно было сразу же предоставить конечным пользователям в виде панелей мониторинга и/или уведомлений, если требуется выполнить какое-либо действие. Например, если обслуживающий сайт выходит из строя, обслуживающий персонал можно уведомить, чтобы начать исследовать причину сбоя и быстро ее устранить. Согласно некоторым из таких вариантов использования человек, как правило, наблюдает за панелью мониторинга в режиме реального времени на основе обновленного набора данных после обработки полученных данных при помощи Stream Analytics. 
 
![Azure Stream Analytics telemetry and log analysis via dashboards][img.stream.analytics.scenario2]

###Архивирование событий для дальнейшей обработки
Потребности компаний в отношении быстрого и гибкого выполнения продолжают расти. Теперь организации и разработчики выбирают простые в использовании облачные платформы, чтобы удовлетворить потребность в большей гибкости и подыскивают платформы, которые позволяют им принимать и обрабатывать непрерывный поток данных, создаваемый их системами в квазиреальном режиме времени.  В настоящее время эти клиенты не смогут использовать службу, оптимизированную для записи в хранилище данных с малой задержкой и, таким образом, теряют некоторые важные массивы данных, которые могут оказаться ценными с точки зрения получения информации о работе компании.  Традиционный сценарий архиватора событий можно описать следующим образом: Данные от различных устройств и платформ, географически рассредоточенных по всему миру, направляются в централизованный сборщик данных. После поступления данных в центр накопления над ними выполняются некоторые преобразующие операции без сохранения состояния: например, очистка программных сведений, добавление гео-тегов, подстановка IP-адреса и т. д. Преобразованные данные затем архивируются в хранилищах больших двоичных объектов и готовы к непосредственному использованию HDInsight и другими средствами обработки в автономном режиме.

![Azure Stream Analytics event archival for future processing][img.stream.analytics.scenario3]
 







<!--Every topic should have next steps and links to the next logical set of content to keep the customer engaged-->
##<a name="nextsteps"></a>Дальнейшие действия

- [Начало использования Azure Stream Analytics][stream.analytics.get.started]
- [Руководство по Azure Stream Analytics для разработчиков][stream.analytics.developer.guide]
- [Масштабирование заданий в Scale Azure Stream Analytics][потоковая.аналитика.масштабирование.задания]
- [Ограничения Azure Stream Analytics и известные проблемы][stream.analytics.limitations]
- [Справочник по языку запросов для Azure Stream Analytics][stream.analytics.query.language.reference]
- [Справочник по REST API для управления Azure Stream Analytics ][потоковая.аналитика.rest.api.справочник] 



<!--Image references-->
[img.stream.analytics.scenario1]: ./media/stream-analytics-introduction/Introduction-to-Azure-Stream-Analytics_01.png
[img.stream.analytics.scenario2]: ./media/stream-analytics-introduction/Introduction-to-Azure-Stream-Analytics_02.png
[img.stream.analytics.scenario3]: ./media/stream-analytics-introduction/Introduction-to-Azure-Stream-Analytics_03.png


<!--Link references-->
[stream.analytics.developer.guide]: ../stream-analytics-developer-guide/
[stream.analytics.scale.jobs]: ../stream-analytics-scale-jobs/
[stream.analytics.limitations]: ../stream-analytics-limitations/
[stream.analytics.introduction]: ../stream-analytics-introduction/
[stream.analytics.get.started]: ../stream-analytics-get-started/
[stream.analytics.query.language.reference]: http://go.microsoft.com/fwlink/?LinkID=513299
[stream.analytics.rest.api.reference]: http://go.microsoft.com/fwlink/?LinkId=517301

<!--HONumber=46--> 
