<properties
	pageTitle="Задания по масштабированию в Stream Analytics | Azure"
	description="Узнайте, как масштабировать задания анализа потоков"
	services="stream-analytics"
	documentationCenter=""
	authors="jeffstokes72"
	manager="paulettm"
	editor="cgronlun"/>

<tags
	ms.service="stream-analytics"
	ms.devlang="na"
	ms.topic="article"
	ms.tgt_pltfrm="na"
	ms.workload="data-services"
	ms.date="04/28/2015"
	ms.author="jeffstok"/>

# Задания по масштабированию в Azure Stream Analytics

Узнайте, как вычислить *единицы потоковой передачи* для задания службы Stream Analytics и масштабирования заданий Stream Analytics с помощью настройки входных разделов и определения запроса, а также определения единиц потоковой передачи.

Определение задания Azure Stream Analytics включает запрос, а также входные и выходные данные. Входные данные — это точки, откуда задания считывают данные из потока, запрос используется для преобразования входного потока, а выходные данные являются точками, куда направляются результаты задания.

Задание требует по крайней мере один источник потока входных данных. Входной источник потока данных может храниться в концентраторе событий служебной шины Azure или в хранилище больших двоичных объектов Azure. Дополнительные сведения см. во [введении в службу Azure Stream Analytics](stream-analytics-introduction.md), [статье о начале работы с Azure Stream Analytics](stream-analytics-get-started.md) и [руководстве разработчика по Azure Stream Analytics](stream-analytics-developer-guide.md).

Ресурс, доступный для обработки заданий Stream Analytics, измеряется единицей потоковой передачи. Для пропускной способности каждой единицы потоковой передачи можно указать не более 1 МБ в секунду. Каждое задание требует не менее одной единицы потоковой передачи, используемой по умолчанию для всех заданий. На портале Azure можно задать до 50 единиц потоковой передачи для задания Stream Analytics. Каждая подписка Azure может включать до 50 единиц потоковой передачи для всех заданий в определенном регионе. Чтобы увеличить единицы потоковой передачи для вашей подписки (до 100 единиц), свяжитесь со [службой технической поддержки Майкрософт](http://support.microsoft.com).

Число единиц потоковой передачи для использования в одном задании зависит от конфигурации раздела для входных данных и запроса, определенного для задания. В этой статье показано, как вычислить и настроить запрос для увеличения пропускной способности.


## Расчет максимального количества единиц потоковой передачи для задания
Общее число единиц потоковой передачи, которое можно использовать заданием Stream Analytics, зависит от числа шагов в запросе, определенных для задания, и количества разделов для каждого шага.

### Шаги в запросе
Запрос может иметь один или несколько шагов. Каждый шаг — это вложенный запрос, определенный с помощью ключевого слова WITH. Запрос, находящийся за пределами ключевого слова WITH, также учитывается в качестве шага (например, инструкция SELECT в следующем запросе).

	WITH Step1 (
		SELECT COUNT(*) AS Count, TollBoothId
		FROM Input1 Partition By PartitionId
		GROUP BY TumblingWindow(minute, 3), TollBoothId, PartitionId
	)

	SELECT SUM(Count) AS Count, TollBoothId
	FROM Step1
	GROUP BY TumblingWindow(minute,3), TollBoothId, PartitionId

Предыдущий запрос включает 2 шага.

> [AZURE.NOTE]Этот образец запроса будет описан далее в этой статье.

### Разделы шага

Разделение шага требует наличия следующих условий.

- Источник входных данных должен быть секционирован. Дополнительные сведения см. в [руководстве разработчика по Stream Analytics](stream-analytics-developer-guide.md) и [руководстве по программированию концентраторов событий](azure-event-hubs-developer-guide.md).
- Инструкция SELECT запроса должна читаться из разделенного источника входных данных.
- Запрос внутри шага должен включать ключевое слово **Partition By**.

Если запрос разделен, входные данные событий будут обработаны и объединены в отдельные группы секции, а выходные данные событий будут сгенерированы для каждой из групп. Если желательно иметь объединенный запрос, необходимо создать второй неразделенный шаг для объединения.

### Рассчитайте максимальное количество единиц потоковой передачи для задания

Все несекционированные шаги можно масштабировать до шести единиц потоковой передачи для задания Stream Analytics. Для добавления дополнительных единиц потоковой передачи данных шаг должен быть секционирован. Каждая секция может включать шесть единиц потоковой передачи.

<table border="1">
<tr><th>Запрос задания</th><th>Максимальное количество единиц потоковой передачи для задания</th></td>

<tr><td>
<ul>
<li>Запрос содержит один шаг.</li>
<li>Шаг не секционирован.</li>
</ul>
</td>
<td>6</td></tr>

<tr><td>
<ul>
<li>Поток входных данных секционирован по 3.</li>
<li>Запрос содержит один шаг.</li>
<li>Шаг является секционированным.</li>
</ul>
</td>
<td>18</td></tr>

<tr><td>
<ul>
<li>Запрос состоит из двух шагов.</li>
<li>Ни один из шагов не секционирован.</li>
</ul>
</td>
<td>6</td></tr>



<tr><td>
<ul>
<li>Поток входных данных секционирован по 3.</li>
<li>Запрос состоит из двух шагов. Входной шаг секционирован, а второй шаг — нет.</li>
<li>Инструкция SELECT считывает из секционированных входных данных.</li>
</ul>
</td>
<td>24 (18 и 6 секционированных и несекционированных шагов соответственно)</td></tr>
</table>

### Пример шкалы
Следующий запрос вычисляет количество машин, проходящих через пропускной пункт с тремя пунктами для оплаты и пропускной способности три минуты для каждого пункта. Этот запрос можно масштабировать до шести единиц потоковой передачи.

	SELECT COUNT(*) AS Count, TollBoothId
	FROM Input1
	GROUP BY TumblingWindow(minute, 3), TollBoothId, PartitionId

Чтобы использовать дополнительные единицы потоковой передачи для запроса, входной поток данных и запрос должны быть секционированы. При наличии раздела потока данных, равного 3, следующий измененный запрос можно масштабировать до 18 единиц потоковой передачи.

	SELECT COUNT(*) AS Count, TollBoothId
	FROM Input1 Partition By PartitionId
	GROUP BY TumblingWindow(minute, 3), TollBoothId, PartitionId

Если запрос секционирован, входные данные событий будут обработаны и объединены в отдельные группы секций. Кроме того, для каждой из групп будут сформированы выходные данные событий. Секционирование может вызвать некоторые непредвиденные результаты, если поле **Group-by** не является ключом секции во входном потоке данных. Например, поле TollBoothId в предыдущем примере запроса не является ключом раздела Input1. Данные из пункта 1 можно распределить между несколькими секциями.

Каждая из секций Input1 будет обрабатываться отдельно с помощью Stream Analytics, и будет создаваться несколько записей для автомобиля, проходящего через один и тот же пункт. Если нельзя изменить ключ секции ввода, эту проблему можно устранить, добавив дополнительные несекционированные действия, например:

	WITH Step1 (
		SELECT COUNT(*) AS Count, TollBoothId
		FROM Input1 Partition By PartitionId
		GROUP BY TumblingWindow(minute, 3), TollBoothId, PartitionId
	)

	SELECT SUM(Count) AS Count, TollBoothId
	FROM Step1
	GROUP BY TumblingWindow(minute, 3), TollBoothId, ParititonId

Этот запрос можно увеличить до 24 единиц потоковой передачи.

>[AZURE.NOTE]При объединении двух потоков убедитесь в том, что потоки разделены с помощью ключа раздела для объединяемого столбца и количество разделов в обоих потоках одинаковое.


## Настройка раздела задания Stream Analytics

**Настройка единицы потоковой передачи для задания**

1. Войдите на [портал управления](https://manage.windowsazure.com).
2. Щелкните **Stream Analytics** в области слева.
3. Выберите задание Stream Analytics, которое необходимо расширить.
4. В верхней части страницы щелкните **МАСШТАБ**.

![Масштабирование заданий Azure Stream Analytics][img.stream.analytics.configure.scale]


## Мониторинг производительности задания

На портале управления можно отслеживать пропускную способность задания событий в секунду:

![Отслеживание заданий Azure Stream Analytics][img.stream.analytics.monitor.job]

Рассчитайте ожидаемую пропускную способность рабочей нагрузки событий в секунду. Если пропускная способность меньше, чем ожидалось, настройте входную секцию и запрос, а также добавьте в задание дополнительные единицы потоковой передачи.

##Масштабирование пропускной способности службы ASA — сценарий для компьютера Raspberry Pi


Рассмотрите следующий эксперимент, чтобы понять, как в типичном сценарии масштабируется пропускная способность службы ASA для нескольких единиц потоковой передачи. Этот эксперимент состоит в следующем: данные датчиков (клиентов) отправляются в концентратор событий, служба ASA обрабатывает эти данные и отправляет предупреждение или статистические сведения в качестве выходных данных на другой концентратор событий.

Клиент отправляет синтезированные данные датчиков в формате JSON на концентраторы событий в службу ASA. Выходные данные также отправляются в формате JSON. Ниже приведен пример данных.

    {"devicetime":"2014-12-11T02:24:56.8850110Z","hmdt":42.7,"temp":72.6,"prss":98187.75,"lght":0.38,"dspl":"R-PI Olivier's Office"}

Запрос: "Send an alert when the light is switched off"

    SELECT AVG(lght),
	 “LightOff” as AlertText
	FROM input TIMESTAMP
	BY devicetime
	 WHERE
		lght< 0.05 GROUP BY TumblingWindow(second, 1)

Измерение пропускной способности. Пропускная способность в этом контексте — это объем входных данных, обрабатываемых службой ASA в определенный промежуток времени (10 минут). Чтобы обеспечить оптимальную пропускную способность для обработки входных данных, поток входных данных и запрос должны быть секционированы. В запрос также включается COUNT(), что позволяет подсчитать количество обработанных событий ввода. Чтобы убедиться, что служба ASA не просто ожидает поступления событий ввода, в каждую секцию концентратора событий ввода были предварительно загружены входные данные в достаточном объеме (300 МБ).

Ниже приведены результаты с увеличением количества единиц потоковой передачи и соответствующими данными о числе секций в концентраторах событий.

<table border="1">
<tr><th>Секции ввода</th><th>Секции вывода</th><th>Единицы потоковой передачи</th><th>Поддерживаемая пропускная способность
</th></td>

<tr><td>12</td>
<td>12</td>
<td>6</td>
<td>4,06&#160;МБ/с</td>
</tr>

<tr><td>12</td>
<td>12</td>
<td>12</td>
<td>8,06&#160;МБ/с</td>
</tr>

<tr><td>48</td>
<td>48</td>
<td>48</td>
<td>38,32&#160;МБ/с</td>
</tr>

<tr><td>192</td>
<td>192</td>
<td>192</td>
<td>172,67&#160;МБ/с</td>
</tr>

<tr><td>480</td>
<td>480</td>
<td>480</td>
<td>454,27&#160;МБ/с</td>
</tr>

<tr><td>720</td>
<td>720</td>
<td>720</td>
<td>609,69&#160;МБ/с</td>
</tr>
</table>

![img.stream.analytics.perfgraph][img.stream.analytics.perfgraph]

## Получение справки
За дополнительной помощью обращайтесь на наш [форум Azure Stream Analytics](https://social.msdn.microsoft.com/Forums/en-US/home?forum=AzureStreamAnalytics).


## Дальнейшие действия

- [Введение в Azure Stream Analytics](stream-analytics-introduction.md)
- [Приступая к работе с Azure Stream Analytics](stream-analytics-get-started.md)
- [Масштабирование заданий в службе Azure Stream Analytics](stream-analytics-scale-jobs.md)
- [Справочник по языку запросов Azure Stream Analytics](https://msdn.microsoft.com/library/azure/dn834998.aspx)
- [Справочник по API-интерфейсу REST управления Stream Analytics](https://msdn.microsoft.com/library/azure/dn835031.aspx)


<!--Image references-->

[img.stream.analytics.monitor.job]: ./media/stream-analytics-scale-jobs/StreamAnalytics.job.monitor.png
[img.stream.analytics.configure.scale]: ./media/stream-analytics-scale-jobs/StreamAnalytics.configure.scale.png
[img.stream.analytics.perfgraph]: ./media/stream-analytics-scale-jobs/perf.png

<!--Link references-->

[microsoft.support]: http://support.microsoft.com
[azure.management.portal]: http://manage.windowsazure.com
[azure.event.hubs.developer.guide]: http://msdn.microsoft.com/library/azure/dn789972.aspx

[stream.analytics.developer.guide]: stream-analytics-developer-guide.md
[stream.analytics.limitations]: stream-analytics-limitations.md
[stream.analytics.introduction]: stream-analytics-introduction.md
[stream.analytics.get.started]: stream-analytics-get-started.md
[stream.analytics.query.language.reference]: http://go.microsoft.com/fwlink/?LinkID=513299
[stream.analytics.rest.api.reference]: http://go.microsoft.com/fwlink/?LinkId=517301

<!--HONumber=54-->